{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CharTrajectories.run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_df(model,drop_rate,epochs,param):\n",
    "   \n",
    "    config_dir = 'CharTrajectories/configs/train_'+model+'.yaml'\n",
    "    with open(config_dir) as file:\n",
    "        config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    config.drop_out = drop_rate\n",
    "    config.param = param\n",
    "    config.epochs =epochs\n",
    "    val_loss,val_acc = main(config=config,return_loss=True)\n",
    "\n",
    "    model_list = [model+'_'+config.param]*config.epochs\n",
    "    epoch_list = range(config.epochs)\n",
    "    return pd.DataFrame({'model':model_list,'epochs':epoch_list,\n",
    "                        'val_loss':val_loss,'val_acc':val_acc})\n",
    "\n",
    "def get_all_losses(drop_rate_list,models,params,runs:int=3):\n",
    "    dfs = []\n",
    "    for i in range(runs):\n",
    "        for model in models:\n",
    "            for drop_rate in drop_rate_list:\n",
    "                for param in params:\n",
    "                    df = create_loss_df(model,drop_rate,100,param)\n",
    "                    dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2e0pvzj2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 46142... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▁▃▄▅▅▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▁▂▅▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▁▃▅▇▇▇▇▇███████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.95105</td></tr><tr><td>accuracy_train</td><td>0.9765</td></tr><tr><td>accuracy_validation</td><td>0.94406</td></tr><tr><td>best_test_accuracy</td><td>0.95105</td></tr><tr><td>best_val_accuracy</td><td>0.95105</td></tr><tr><td>best_val_loss</td><td>0.15512</td></tr><tr><td>loss_train</td><td>0.07409</td></tr><tr><td>loss_validation</td><td>0.23052</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2e0pvzj2\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2e0pvzj2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220122_230644-2e0pvzj2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2e0pvzj2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3n21qzmi\" target=\"_blank\">LSTM</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 8180\n",
      "GPU's available: 1\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_param_s_nhid1_40_nhid2_None_droprate_0.3_gamma_0.1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 00:25:35.725432\n",
      "RNN(\n",
      "  (rnn): LSTM(4, 40, batch_first=True)\n",
      "  (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 2.7258 Acc: 0.1055\n",
      "2022-01-23 00:25:37.103628\n",
      "validation Loss: 2.4888 Acc: 0.2005\n",
      "2022-01-23 00:25:37.412344\n",
      "Accuracy of the network on the 429 test samples: 20.04662004662005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.4496 Acc: 0.2165\n",
      "2022-01-23 00:25:39.069501\n",
      "validation Loss: 2.4636 Acc: 0.1981\n",
      "2022-01-23 00:25:39.374883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000002e-06\n",
      "------------------------------\n",
      "train Loss: 2.4331 Acc: 0.2155\n",
      "2022-01-23 00:25:40.733287\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:41.024470\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000004e-08\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:42.453191\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:42.759231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-10\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:44.177391\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:44.504921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-12\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:45.900897\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:46.202878\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000008e-14\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:47.563521\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:47.851358\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-16\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:49.216784\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:49.489434\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-18\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:50.858482\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:51.154166\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000011e-20\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:52.467100\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:52.769480\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000012e-22\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:54.107100\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:54.393501\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000014e-24\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:55.705426\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:56.001606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-26\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:57.312676\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:57.608426\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-28\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:25:59.059953\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:25:59.364198\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-30\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:00.788607\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:01.082218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-32\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:02.515767\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:02.811310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000019e-34\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:04.105334\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:04.418464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-36\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:05.696160\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:06.017113\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-38\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:07.323397\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:07.605192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000022e-40\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:08.900978\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:09.194463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-42\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:10.501232\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:10.778545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-44\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:12.078160\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:12.362117\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-46\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:13.675301\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:13.998977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-48\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:15.433736\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:15.752065\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000025e-50\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:17.115075\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:17.413070\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000026e-52\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:18.888537\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:19.192058\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000028e-54\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:20.680948\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:20.975695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000003e-56\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:22.272998\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:22.556049\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000032e-58\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:23.888762\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:24.170550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000034e-60\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:25.525237\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:25.810663\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000035e-62\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:27.146715\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:27.443458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000037e-64\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:28.785208\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:29.075752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000038e-66\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:30.471120\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:30.754921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000004e-68\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:32.128554\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:32.445122\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-70\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:33.840499\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:34.181617\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-72\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:35.527998\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:35.840930\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000043e-74\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:37.211952\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:37.494568\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-76\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:38.911126\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:39.229896\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-78\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:40.664205\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:40.943387\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000045e-80\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:42.320522\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:42.624837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000046e-82\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:43.982949\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:44.301711\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000048e-84\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:45.671540\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:45.961365\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000049e-86\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:47.328564\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:47.625151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000005e-88\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:49.001305\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:49.289828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000052e-90\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:50.646301\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:50.927454\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000054e-92\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:52.271668\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:52.577803\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000055e-94\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:54.115728\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:54.422672\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000057e-96\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:55.871475\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:56.187353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000058e-98\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:57.608108\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:57.916509\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-100\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:26:58.625929\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:26:58.942682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-102\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:00.507057\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:00.802937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000063e-104\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:02.197530\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:02.501320\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000064e-106\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:03.882470\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:04.173850\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000065e-108\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:05.601947\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:05.905900\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-110\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:07.277895\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:07.572781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-112\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:08.943364\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:09.219880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000069e-114\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:10.708857\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:10.993430\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-116\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:12.361754\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:12.653281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-118\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:14.016797\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:14.347464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-120\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:15.695019\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:15.993984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000072e-122\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:17.377062\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:17.714467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000073e-124\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:19.136126\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:19.422077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000075e-126\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:20.858721\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:21.151890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000076e-128\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:22.526629\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:22.821458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000077e-130\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:24.248750\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:24.551398\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000078e-132\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:25.926276\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:26.218750\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-134\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:27.627202\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:27.924512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-136\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:29.323505\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:29.635845\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000081e-138\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:31.041887\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:31.379392\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000083e-140\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:32.767645\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:33.084510\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000084e-142\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:34.441051\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:34.732037\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000085e-144\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:36.056970\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:36.361559\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000087e-146\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:37.766536\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:38.071859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000088e-148\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:39.484317\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:39.781303\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000009e-150\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:41.139937\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:41.437808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-152\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:42.172921\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:42.492206\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-154\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:43.876074\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:44.174709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000094e-156\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:45.549968\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:45.861150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-158\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:47.257352\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:47.555356\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-160\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:48.926085\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:49.233207\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000097e-162\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:50.652796\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:50.941281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000098e-164\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:52.284988\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:52.570039\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-166\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:53.970339\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:54.250270\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-168\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:55.624489\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:55.916880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000103e-170\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:57.257767\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:57.534519\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000104e-172\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:27:58.876029\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:27:59.151656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000105e-174\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:00.480215\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:00.804577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000107e-176\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:02.118298\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:02.422253\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000108e-178\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:03.760961\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:04.058016\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000011e-180\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:05.505193\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:05.788943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000111e-182\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:07.081010\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:07.366876\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000112e-184\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:08.749398\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:09.045139\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000113e-186\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:10.454964\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:10.749877\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000114e-188\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:12.084542\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:12.450079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000115e-190\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:13.883831\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:14.178219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000116e-192\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:15.583831\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:15.900282\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-194\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:17.312265\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:17.608285\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-196\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:19.002191\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:19.325937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000118e-198\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:20.699653\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:21.021520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000119e-200\n",
      "------------------------------\n",
      "train Loss: 2.4329 Acc: 0.2155\n",
      "2022-01-23 00:28:22.416655\n",
      "validation Loss: 2.4633 Acc: 0.1981\n",
      "2022-01-23 00:28:22.759465\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.2005\n",
      "Accuracy of the network on the 429 test samples: 20.04662004662005\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3n21qzmi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 83188... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁</td></tr><tr><td>accuracy_train</td><td>▁███████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.20047</td></tr><tr><td>accuracy_train</td><td>0.2155</td></tr><tr><td>accuracy_validation</td><td>0.19814</td></tr><tr><td>best_test_accuracy</td><td>0.20047</td></tr><tr><td>best_val_accuracy</td><td>0.20047</td></tr><tr><td>best_val_loss</td><td>2.48877</td></tr><tr><td>loss_train</td><td>2.43294</td></tr><tr><td>loss_validation</td><td>2.46331</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>num_para</td><td>8180</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3n21qzmi\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3n21qzmi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_002526-3n21qzmi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3n21qzmi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ykx6fms\" target=\"_blank\">LSTM</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 8180\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_param_s_nhid1_40_nhid2_None_droprate_0.3_gamma_0.1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 00:28:32.229835\n",
      "RNN(\n",
      "  (rnn): LSTM(4, 40, batch_first=True)\n",
      "  (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 2.6750 Acc: 0.1210\n",
      "2022-01-23 00:28:33.619775\n",
      "validation Loss: 2.4497 Acc: 0.1655\n",
      "2022-01-23 00:28:33.917743\n",
      "Accuracy of the network on the 429 test samples: 15.151515151515152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3733 Acc: 0.2070\n",
      "2022-01-23 00:28:35.725923\n",
      "validation Loss: 2.3200 Acc: 0.2821\n",
      "2022-01-23 00:28:36.016449\n",
      "Accuracy of the network on the 429 test samples: 26.107226107226104\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000002e-06\n",
      "------------------------------\n",
      "train Loss: 2.3141 Acc: 0.2645\n",
      "2022-01-23 00:28:37.725060\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:38.053057\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000004e-08\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:39.714674\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:40.003622\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-10\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:41.682092\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:41.959292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-12\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:43.306364\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:43.624602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000008e-14\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:45.049729\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:45.346102\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-16\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:47.041961\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:47.355627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-18\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:48.742912\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:49.029641\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000011e-20\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:50.728065\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:51.028069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000012e-22\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:52.388974\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:52.689576\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000014e-24\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:54.081118\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:54.408890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-26\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:55.747309\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:56.042644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-28\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:57.432469\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:57.749627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-30\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:28:59.183712\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:28:59.466679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-32\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:00.899004\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:01.240337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000019e-34\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:02.610317\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:02.921227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-36\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:04.284860\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:04.580141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-38\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:05.305554\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:05.616998\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000022e-40\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:06.966568\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:07.256682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-42\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:08.616221\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:08.909249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-44\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:10.335380\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:10.665657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-46\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:12.148953\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:12.469532\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-48\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:13.876263\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:14.173895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000025e-50\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:15.581760\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:15.902809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000026e-52\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:17.270474\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:17.558863\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000028e-54\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:18.270439\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:18.603643\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000003e-56\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:20.085277\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:20.413230\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000032e-58\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:21.802538\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:22.135525\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000034e-60\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:23.659019\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:23.970768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000035e-62\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:25.281374\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:25.564596\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000037e-64\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:26.957826\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:27.250258\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000038e-66\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:28.649408\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:28.949672\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000004e-68\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:30.359271\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:30.713684\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-70\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:32.462458\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:32.760190\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-72\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:34.132704\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:34.447018\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000043e-74\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:35.870761\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:36.181504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-76\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:37.692617\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:38.004989\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-78\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:39.397182\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:39.693448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000045e-80\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:41.209895\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:41.522212\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000046e-82\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:42.840414\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:43.136873\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000048e-84\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:44.511203\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:44.802846\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000049e-86\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:46.075931\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:46.370261\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000005e-88\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:47.708489\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:48.036189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000052e-90\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:49.383996\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:49.655314\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000054e-92\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:50.941547\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:51.241154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000055e-94\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:52.516880\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:52.806263\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000057e-96\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:54.216863\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:54.512532\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000058e-98\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:55.889893\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:56.171022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-100\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:57.546812\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:57.827033\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-102\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:29:59.202650\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:29:59.489356\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000063e-104\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:00.830047\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:01.116722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000064e-106\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:02.490505\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:02.800278\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000065e-108\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:04.237929\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:04.549815\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-110\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:05.932177\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:06.230015\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-112\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:07.666319\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:07.987928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000069e-114\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:09.379614\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:09.679019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-116\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:11.053591\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:11.365355\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-118\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:12.726908\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:13.020554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-120\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:14.441133\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:14.730598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000072e-122\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:15.619194\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:15.926550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000073e-124\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:17.334974\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:17.641136\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000075e-126\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:18.994325\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:19.300838\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000076e-128\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:20.676646\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:20.990338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000077e-130\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:22.379878\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:22.669327\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000078e-132\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:24.025562\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:24.320392\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-134\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:25.683567\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:25.973799\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-136\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:27.343550\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:27.658240\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000081e-138\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:29.040537\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:29.354019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000083e-140\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:30.742654\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:31.076219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000084e-142\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:32.442328\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:32.762942\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000085e-144\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:34.171769\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:34.460244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000087e-146\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:35.839883\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:36.146558\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000088e-148\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:37.508283\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:37.796853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000009e-150\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:39.183957\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:39.489451\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-152\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:40.892463\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:41.192366\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-154\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:42.552923\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:42.893594\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000094e-156\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:44.299273\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:44.589454\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-158\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:45.946375\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:46.237538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-160\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:47.645801\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:47.963102\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000097e-162\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:49.337413\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:49.614668\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000098e-164\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:50.971761\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:51.272353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-166\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:52.657885\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:52.946143\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-168\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:54.386939\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:54.687852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000103e-170\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:56.045323\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:56.358807\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000104e-172\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:57.788807\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:58.113138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000105e-174\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:30:59.562178\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:30:59.869595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000107e-176\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:00.689032\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:00.971203\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000108e-178\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:02.343120\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:02.639200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000011e-180\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:04.012399\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:04.311515\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000111e-182\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:05.698799\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:05.995771\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000112e-184\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:07.373760\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:07.655397\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000113e-186\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:08.983494\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:09.286129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000114e-188\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:10.713186\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:11.018067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000115e-190\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:12.375708\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:12.687170\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000116e-192\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:14.125901\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:14.403316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-194\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:15.791693\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:16.103776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-196\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:17.466788\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:17.766961\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000118e-198\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:19.150492\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:19.439505\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000119e-200\n",
      "------------------------------\n",
      "train Loss: 2.3129 Acc: 0.2645\n",
      "2022-01-23 00:31:21.118623\n",
      "validation Loss: 2.3197 Acc: 0.2821\n",
      "2022-01-23 00:31:21.449530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.2821\n",
      "Accuracy of the network on the 429 test samples: 26.340326340326342\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1ykx6fms) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 69750... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁███████</td></tr><tr><td>accuracy_train</td><td>▁███████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.2634</td></tr><tr><td>accuracy_train</td><td>0.2645</td></tr><tr><td>accuracy_validation</td><td>0.28205</td></tr><tr><td>best_test_accuracy</td><td>0.2634</td></tr><tr><td>best_val_accuracy</td><td>0.28205</td></tr><tr><td>best_val_loss</td><td>2.31968</td></tr><tr><td>loss_train</td><td>2.31293</td></tr><tr><td>loss_validation</td><td>2.31968</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>num_para</td><td>8180</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ykx6fms\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1ykx6fms</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_002823-1ykx6fms/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1ykx6fms). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/lnzfp5ga\" target=\"_blank\">LSTM</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 8180\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_param_s_nhid1_40_nhid2_None_droprate_0.3_gamma_0.1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 00:31:30.767340\n",
      "RNN(\n",
      "  (rnn): LSTM(4, 40, batch_first=True)\n",
      "  (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 2.6825 Acc: 0.1180\n",
      "2022-01-23 00:31:32.068530\n",
      "validation Loss: 2.5759 Acc: 0.1911\n",
      "2022-01-23 00:31:32.383380\n",
      "Accuracy of the network on the 429 test samples: 18.181818181818183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5348 Acc: 0.1800\n",
      "2022-01-23 00:31:33.964290\n",
      "validation Loss: 2.5552 Acc: 0.1795\n",
      "2022-01-23 00:31:34.254114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000002e-06\n",
      "------------------------------\n",
      "train Loss: 2.5226 Acc: 0.1785\n",
      "2022-01-23 00:31:35.552951\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:35.845271\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000004e-08\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:37.228770\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:37.533328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-10\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:38.926236\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:39.208641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-12\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:40.588972\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:40.908981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000008e-14\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:42.255880\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:42.550003\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-16\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:43.959300\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:44.273808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-18\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:44.981896\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:45.281448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000011e-20\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:46.691686\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:47.039017\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000012e-22\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:48.412544\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:48.712326\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000014e-24\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:50.060424\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:50.359570\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-26\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:51.241810\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:51.567335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-28\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:52.908003\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:53.208914\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-30\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:54.556362\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:54.856862\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-32\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:56.312428\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:56.651749\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000019e-34\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:58.024405\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:31:58.300758\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-36\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:31:59.752055\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:00.076469\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-38\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:01.459082\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:01.735880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000022e-40\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:03.275654\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:03.595098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-42\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:04.962025\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:05.268394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-44\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:06.656764\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:06.967976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-46\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:08.353207\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:08.674929\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-48\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:10.166263\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:10.483895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000025e-50\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:11.998726\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:12.314902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000026e-52\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:13.671480\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:13.969456\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000028e-54\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:15.376602\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:15.681751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000003e-56\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:17.088216\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:17.379826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000032e-58\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:18.755034\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:19.061626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000034e-60\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:20.386348\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:20.675580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000035e-62\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:22.062654\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:22.362244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000037e-64\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:23.752815\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:24.046305\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000038e-66\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:25.435632\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:25.763577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000004e-68\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:27.131988\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:27.432541\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-70\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:28.830388\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:29.137022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-72\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:30.513500\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:30.803262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000043e-74\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:32.171166\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:32.482685\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-76\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:33.903416\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:34.214430\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-78\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:35.637639\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:35.922587\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000045e-80\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:37.364905\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:37.672962\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000046e-82\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:39.073209\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:39.357874\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000048e-84\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:40.809413\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:41.113190\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000049e-86\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:42.511393\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:42.795378\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000005e-88\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:44.285711\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:44.620398\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000052e-90\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:46.073435\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:46.371572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000054e-92\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:47.755437\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:48.034699\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000055e-94\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:49.380613\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:49.664857\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000057e-96\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:51.048166\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:51.338783\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000058e-98\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:52.735948\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:53.067553\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-100\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:54.455991\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:54.763645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-102\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:56.142456\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:56.450971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000063e-104\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:57.838967\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:58.169844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000064e-106\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:32:59.509342\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:32:59.787257\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000065e-108\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:01.164819\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:01.465238\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-110\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:02.938190\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:03.246340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-112\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:04.583006\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:04.896776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000069e-114\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:06.235478\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:06.515492\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-116\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:07.843137\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:08.132407\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-118\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:09.451537\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:09.748041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-120\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:11.007808\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:11.302851\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000072e-122\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:12.534952\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:12.826439\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000073e-124\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:14.121849\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:14.420802\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000075e-126\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:15.748206\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:16.052451\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000076e-128\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:17.454377\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:17.777409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000077e-130\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:19.126760\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:19.427792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000078e-132\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:20.769133\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:21.061010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-134\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:22.422130\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:22.736010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-136\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:24.188244\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:24.548151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000081e-138\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:25.947385\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:26.256986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000083e-140\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:27.756934\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:28.060494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000084e-142\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:29.474712\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:29.770874\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000085e-144\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:31.273781\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:31.553409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000087e-146\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:32.903486\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:33.185960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000088e-148\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:34.569119\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:34.873796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000009e-150\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:36.303547\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:36.638620\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-152\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:38.048107\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:38.367332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-154\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:39.747627\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:40.070371\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000094e-156\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:41.456014\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:41.750576\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-158\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:43.142107\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:43.459551\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-160\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:44.829743\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:45.151371\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000097e-162\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:46.500687\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:46.793824\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000098e-164\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:48.189107\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:48.500247\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-166\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:49.870858\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:50.157867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-168\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:51.546271\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:51.839183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000103e-170\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:53.176178\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:53.456467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000104e-172\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:54.836718\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:55.115034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000105e-174\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:56.453072\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:56.751857\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000107e-176\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:58.105104\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:33:58.415305\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000108e-178\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:33:59.798842\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:00.111767\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000011e-180\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:01.495351\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:01.803157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000111e-182\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:03.248480\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:03.555547\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000112e-184\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:05.006950\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:05.293739\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000113e-186\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:06.651227\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:06.926808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000114e-188\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:08.342490\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:08.645731\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000115e-190\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:10.028671\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:10.321786\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000116e-192\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:11.667261\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:11.976220\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-194\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:13.432772\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:13.762430\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-196\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:15.135810\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:15.464645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000118e-198\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:16.908294\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:17.217581\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000119e-200\n",
      "------------------------------\n",
      "train Loss: 2.5224 Acc: 0.1785\n",
      "2022-01-23 00:34:18.577546\n",
      "validation Loss: 2.5550 Acc: 0.1795\n",
      "2022-01-23 00:34:18.865251\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.1911\n",
      "Accuracy of the network on the 429 test samples: 18.181818181818183\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lnzfp5ga) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 58195... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁</td></tr><tr><td>accuracy_train</td><td>▁███████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.18182</td></tr><tr><td>accuracy_train</td><td>0.1785</td></tr><tr><td>accuracy_validation</td><td>0.17949</td></tr><tr><td>best_test_accuracy</td><td>0.18182</td></tr><tr><td>best_val_accuracy</td><td>0.19114</td></tr><tr><td>best_val_loss</td><td>2.5759</td></tr><tr><td>loss_train</td><td>2.52244</td></tr><tr><td>loss_validation</td><td>2.55498</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>num_para</td><td>8180</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/lnzfp5ga\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/lnzfp5ga</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_003121-lnzfp5ga/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lnzfp5ga). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1720hewj\" target=\"_blank\">LSTM</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 8180\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_param_s_nhid1_40_nhid2_None_droprate_0.3_gamma_0.1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 00:34:28.320879\n",
      "RNN(\n",
      "  (rnn): LSTM(4, 40, batch_first=True)\n",
      "  (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 2.6150 Acc: 0.1455\n",
      "2022-01-23 00:34:29.705520\n",
      "validation Loss: 2.4803 Acc: 0.1818\n",
      "2022-01-23 00:34:30.004852\n",
      "Accuracy of the network on the 429 test samples: 20.51282051282051\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.4249 Acc: 0.2150\n",
      "2022-01-23 00:34:31.718513\n",
      "validation Loss: 2.4099 Acc: 0.2168\n",
      "2022-01-23 00:34:32.009591\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000002e-06\n",
      "------------------------------\n",
      "train Loss: 2.3854 Acc: 0.2240\n",
      "2022-01-23 00:34:33.728542\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:34.039994\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000004e-08\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:35.716895\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:36.004373\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-10\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:37.694456\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:38.017777\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-12\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:39.638112\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:39.922890\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000008e-14\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:41.586537\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:41.862443\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-16\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:43.555655\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:43.846969\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-18\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:45.327772\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:45.635523\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000011e-20\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:47.137992\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:47.432507\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000012e-22\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:48.935971\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:49.240711\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000014e-24\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:50.706956\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:51.013273\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-26\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:52.346282\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:52.638848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-28\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:53.920307\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:54.222399\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-30\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:55.637623\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:55.914610\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-32\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:57.253562\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:57.551059\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000019e-34\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:34:58.845940\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:34:59.130508\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-36\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:00.406309\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:00.706559\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-38\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:01.984255\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:02.296655\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000022e-40\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:03.705941\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:04.021721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-42\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:05.391064\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:05.702938\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-44\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:07.085614\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:07.381943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-46\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:08.734222\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:09.016995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-48\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:10.381939\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:10.692825\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000025e-50\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:12.062780\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:12.349993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000026e-52\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:13.730107\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:14.028349\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000028e-54\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:15.430227\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:15.729918\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000003e-56\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:17.107466\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:17.418791\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000032e-58\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:18.765494\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:19.072640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000034e-60\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:20.428047\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:20.749721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000035e-62\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:22.151830\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:22.435321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000037e-64\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:23.791357\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:24.092214\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000038e-66\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:25.446265\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:25.745585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000004e-68\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:27.103750\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:27.386216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-70\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:28.723068\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:29.017367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-72\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:30.447052\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:30.766315\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000043e-74\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:32.170563\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:32.479198\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-76\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:33.907847\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:34.216957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-78\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:35.613390\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:35.940949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000045e-80\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:37.305437\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:37.632105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000046e-82\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:38.999814\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:39.317441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000048e-84\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:40.697628\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:41.002449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000049e-86\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:42.352861\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:42.651692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000005e-88\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:44.027707\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:44.328367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000052e-90\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:45.671769\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:45.971183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000054e-92\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:47.341561\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:47.635227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000055e-94\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:49.041061\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:49.347779\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000057e-96\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:50.680396\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:50.981736\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000058e-98\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:52.361604\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:52.644291\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-100\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:54.007889\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:54.306737\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-102\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:55.746714\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:56.039427\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000063e-104\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:57.414013\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:57.745152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000064e-106\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:35:59.124627\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:35:59.416805\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000065e-108\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:00.795473\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:01.083118\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-110\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:02.318070\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:02.637300\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-112\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:03.352558\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:03.646983\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000069e-114\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:05.011147\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:05.316855\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-116\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:06.715925\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:07.023573\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-118\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:08.406562\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:08.708275\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-120\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:10.094177\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:10.363473\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000072e-122\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:11.705062\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:12.011105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000073e-124\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:13.364667\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:13.664518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000075e-126\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:15.057273\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:15.344019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000076e-128\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:16.573611\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:16.861838\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000077e-130\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:18.251948\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:18.567241\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000078e-132\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:19.940579\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:20.253542\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-134\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:21.682101\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:21.984416\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-136\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:23.354800\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:23.636581\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000081e-138\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:24.995256\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:25.280539\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000083e-140\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:26.624936\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:26.929443\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000084e-142\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:28.275945\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:28.557173\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000085e-144\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:29.958911\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:30.298853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000087e-146\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:31.767648\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:32.048547\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000088e-148\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:33.591633\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:33.912139\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000009e-150\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:35.305446\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:35.569174\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-152\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:36.851394\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:37.144460\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-154\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:38.428318\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:38.741692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000094e-156\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:40.147051\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:40.463337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-158\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:41.757907\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:42.085395\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-160\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:43.396358\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:43.719467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000097e-162\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:45.044798\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:45.350965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000098e-164\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:46.721515\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:47.052850\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-166\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:48.479788\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:48.808827\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-168\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:50.204985\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:50.524226\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000103e-170\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:51.986644\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:52.268282\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000104e-172\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:53.491920\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:53.828014\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000105e-174\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:55.222786\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:55.511710\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000107e-176\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:56.862182\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:57.147579\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000108e-178\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:36:58.504985\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:36:58.786853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000011e-180\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:00.157868\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:00.458897\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000111e-182\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:01.821302\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:02.125703\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000112e-184\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:03.547147\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:03.847283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000113e-186\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:05.290485\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:05.599131\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000114e-188\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:07.037642\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:07.360928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000115e-190\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:08.078065\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:08.397099\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000116e-192\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:10.052637\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:10.389974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-194\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:11.795711\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:12.100932\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-196\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:13.454019\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:13.745192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000118e-198\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:15.164391\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:15.473656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000119e-200\n",
      "------------------------------\n",
      "train Loss: 2.3851 Acc: 0.2240\n",
      "2022-01-23 00:37:16.908909\n",
      "validation Loss: 2.4093 Acc: 0.2168\n",
      "2022-01-23 00:37:17.194005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.2168\n",
      "Accuracy of the network on the 429 test samples: 23.076923076923077\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1720hewj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 43930... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁███████</td></tr><tr><td>accuracy_train</td><td>▁███████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.23077</td></tr><tr><td>accuracy_train</td><td>0.224</td></tr><tr><td>accuracy_validation</td><td>0.21678</td></tr><tr><td>best_test_accuracy</td><td>0.23077</td></tr><tr><td>best_val_accuracy</td><td>0.21678</td></tr><tr><td>best_val_loss</td><td>2.40928</td></tr><tr><td>loss_train</td><td>2.38511</td></tr><tr><td>loss_validation</td><td>2.40928</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>num_para</td><td>8180</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1720hewj\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1720hewj</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_003419-1720hewj/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1720hewj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3jjayyvc\" target=\"_blank\">LSTM</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 8180\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_out': 0.7, 'drop_rate': 0.3, 'epochs': 100, 'gamma': 0.1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM', 'n_hidden1': 40, 'n_hidden2': None, 'optimizer': 'Adam', 'param': 's', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_param_s_nhid1_40_nhid2_None_droprate_0.3_gamma_0.1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 00:37:26.867175\n",
      "RNN(\n",
      "  (rnn): LSTM(4, 40, batch_first=True)\n",
      "  (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 2.7743 Acc: 0.1005\n",
      "2022-01-23 00:37:28.283201\n",
      "validation Loss: 2.6456 Acc: 0.1096\n",
      "2022-01-23 00:37:28.549499\n",
      "Accuracy of the network on the 429 test samples: 10.955710955710956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6438 Acc: 0.1105\n",
      "2022-01-23 00:37:30.225717\n",
      "validation Loss: 2.6508 Acc: 0.1119\n",
      "2022-01-23 00:37:30.516453\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000002e-06\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:32.163920\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:32.448021\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000004e-08\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:34.090039\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:34.407978\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-10\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:36.122459\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:36.407995\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000006e-12\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:38.044594\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:38.370845\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000008e-14\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:39.797572\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:40.120401\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-16\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:41.513370\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:41.822194\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000001e-18\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:43.175078\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:43.475802\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000011e-20\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:44.829170\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:45.133801\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000012e-22\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:46.832481\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:47.140196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000014e-24\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:48.534145\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:48.862429\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-26\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:50.234687\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:50.569057\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000015e-28\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:52.080939\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:52.393872\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-30\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:53.927775\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:54.269852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000017e-32\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:55.833857\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:56.123671\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000019e-34\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:57.605728\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:57.901963\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-36\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:37:59.203175\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:37:59.504149\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000002e-38\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:01.185826\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:01.489144\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000022e-40\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:02.885922\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:03.160540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-42\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:04.568324\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:04.888222\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000023e-44\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:06.579785\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:06.865846\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-46\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:08.252375\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:08.562116\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000024e-48\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:09.964493\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:10.261960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000025e-50\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:11.634185\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:11.943176\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000026e-52\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:13.398816\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:13.713097\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000028e-54\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:15.119374\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:15.414905\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000003e-56\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:16.887409\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:17.196198\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000032e-58\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:18.438161\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:18.748227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000034e-60\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:19.480403\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:19.772669\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000035e-62\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:21.131641\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:21.418866\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000037e-64\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:22.723567\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:23.025413\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000038e-66\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:24.332931\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:24.649578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000004e-68\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:25.944476\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:26.235124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-70\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:27.536901\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:27.821833\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000042e-72\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:29.124772\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:29.421213\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000043e-74\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:30.790725\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:31.067916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-76\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:32.462566\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:32.773256\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000044e-78\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:34.137214\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:34.457059\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000045e-80\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:35.791875\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:36.082470\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000046e-82\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:37.452853\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:37.732106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000048e-84\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:39.084857\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:39.368821\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000049e-86\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:40.777906\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:41.078904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000005e-88\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:42.502417\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:42.823085\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000052e-90\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:44.267119\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:44.603861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000054e-92\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:46.092623\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:46.420465\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000055e-94\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:47.787418\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:48.073317\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000057e-96\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:49.428918\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:49.739861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000058e-98\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:51.197747\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:51.497232\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-100\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:52.882216\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:53.185913\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000006e-102\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:54.530971\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:54.856228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000063e-104\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:56.222747\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:56.512617\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000064e-106\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:57.865137\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:58.170353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000065e-108\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:38:59.530162\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:38:59.828464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-110\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:01.186111\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:01.499033\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000066e-112\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:02.849889\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:03.145196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000069e-114\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:04.512483\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:04.803296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-116\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:06.168278\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:06.450394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-118\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:07.789495\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:08.087665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000007e-120\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:09.457627\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:09.739387\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000072e-122\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:11.132083\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:11.430989\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000073e-124\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:12.956126\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:13.286165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000075e-126\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:14.817778\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:15.103138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000076e-128\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:16.536493\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:16.810664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000077e-130\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:18.280423\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:18.562268\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000078e-132\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:19.931189\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:20.224125\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-134\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:21.591342\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:21.864094\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000008e-136\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:23.326266\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:23.617250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000081e-138\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:24.986239\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:25.306133\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000083e-140\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:26.707286\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:27.057355\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000084e-142\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:28.591027\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:28.871655\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000085e-144\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:30.294957\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:30.602997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000087e-146\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:31.979756\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:32.313074\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000088e-148\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:33.680437\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:33.986657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000009e-150\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:35.341834\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:35.659803\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-152\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:37.057842\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:37.367834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000092e-154\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:38.733808\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:39.058070\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000094e-156\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:40.436544\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:40.754615\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-158\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:42.136179\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:42.417219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000096e-160\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:43.770389\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:44.065975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000097e-162\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:45.446976\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:45.789370\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000098e-164\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:47.150088\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:47.475508\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-166\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:48.846142\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:49.188778\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 1.00000000000001e-168\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:50.741093\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:51.090885\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000103e-170\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:52.449263\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:52.757892\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000104e-172\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:54.096094\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:54.437151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000105e-174\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:55.861053\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:56.141624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000107e-176\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:57.551808\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:57.832871\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000108e-178\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:39:59.177561\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:39:59.464156\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 1.000000000000011e-180\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:00.720432\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:01.020798\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000111e-182\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:02.349698\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:02.625078\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000112e-184\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:03.974312\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:04.280624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000113e-186\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:05.587646\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:05.874929\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000114e-188\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:07.161826\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:07.456670\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000115e-190\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:08.730991\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:09.023340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000116e-192\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:10.289894\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:10.573520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-194\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:11.881449\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:12.174452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000117e-196\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:13.597662\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:13.885580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000118e-198\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:15.285003\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:15.582093\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 1.0000000000000119e-200\n",
      "------------------------------\n",
      "train Loss: 2.6379 Acc: 0.1130\n",
      "2022-01-23 00:40:16.967829\n",
      "validation Loss: 2.6507 Acc: 0.1119\n",
      "2022-01-23 00:40:17.280643\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.1119\n",
      "Accuracy of the network on the 429 test samples: 11.188811188811188\n"
     ]
    }
   ],
   "source": [
    "df_lstm_dev = get_all_losses(drop_rate_list=[0.7],models=['lstm_dev'],params = ['SO','Sp'],runs = 5)\n",
    "df_lstm = get_all_losses(drop_rate_list=[0.7],models=['lstm'],params = ['s'],runs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = pd.concat([df_lstm_dev,df_lstm])\n",
    "# rename model name in df\n",
    "dfs1.loc[(dfs1.model == 'lstm_dev_SO'),'model']='LSTM+DEV(SO)'\n",
    "dfs1.loc[(dfs1.model == 'lstm_dev_Sp'),'model']='LSTM+DEV(Sp)'\n",
    "dfs1.loc[(dfs1.model == 'lstm_s'),'model']='LSTM'\n",
    "dfs1['time_rescale'] = np.where(dfs1['model']=='LSTM',5,5) \n",
    "dfs1['training time / seconds'] = dfs1.epochs*dfs1.time_rescale\n",
    "dfs1 = dfs1.rename(columns={'val_loss':'validation loss','val_acc':'validation accuracy'})\n",
    "dfs1.to_csv('CharTrajectories/notebooks/training_process.csv')#save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEUCAYAAABkhkJAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACiy0lEQVR4nOydd3gdV52w3zP19qteLfcel8TpPQTSe0hCgFDCBljCLtvosBtgaYEQOgRCyH4Lm9BbGiHNJE6P092rrN6l2+/U74+Rri1LsiVZzfa8z+PH0twpZ47uzO/8unBd18XHx8fHx2eakaZ7AD4+Pj4+PuALJB8fHx+fGYIvkHx8fHx8ZgS+QPLx8fHxmRH4AsnHx8fHZ0bgCyQfHx8fnxmBL5B8fHx8fGYEynQPYKLp6UnjOONPrSotjdDVlZrAER2e+POwF38uPPx52Is/Fx5jnQdJEhQXh0f8/IgTSI7jHpJAGjiHjz8P++LPhYc/D3vx58JjIufBN9n5+Pj4+MwIfIHk4+Pj4zMjOOJMdj4+Rzqu65JK9ZHNpnAce8qu294u4TjOlF1vJuPPhceB5kFRNIqLy5Hl0YsZXyD5+Bxm9PR0IISgpKQSWVYQQkzJdRVFwrL8lzD4czHASPPgui7pdIKeng7KyqpHfT7fZOfjc5hhGDmKikpRFHXKhJGPz1gQQhAOx7AsY0zH+QLJx+eww0UI/9H1mdmMZ7Hkf6t9fHx8fGYEvkDah5SRZndPA5ZjTfdQfHx8ppmvfOUL/PSnPxrVvtdccxkvvvj8JI/oyMcXSPtguw6tyXZ29e0ha+Wmezg+Pj4+RxW+QNoPXQ0AsLN3N735vmkejY+Pj8/Rgx/2PQy6rKEImZZUG3Et5kcy+fjMYK655jKuvvpaHn74QZqaGnnrW8/nwx/+KF/5yhd5/fVXWb58Bf/9318nFouxbt3fueOOH9LZ2c7ChYv5+Mc/w9y58wDYunUzX//6f9PQ0MCpp57O/o/9008/xZ13/pjW1mbmzZvPf/zHZ1i4cNE03PGRi68hjYAsyTg45O2xhS36+PhMPWvXPs63v/1D7r33Dzz99FN8/OMf48Mfvpn7738E13X43e9+xZ499XzhC5/jX/7l37n//kc59dTT+dSn/g3TNDFNk8985uNccMHFPPTQ47zlLW9l7drHC+ffunUzX/val/jEJz7LAw88xpVXvp1Pf/rfMQz//TCR+ALpIOR8X5KPz4znmmveQUlJKeXlFaxefSzLl69g8eKl6LrOWWedw7ZtW3j88Uc49dQzOPHEU1AUhXe+8z3k83neeOM1Nmx4A8uyuO66d6EoCm95y9tYtuyYwvn/8pc/csUVV3PMMSuQZZlLLrkMVVXZsOGNabzrIw/fZHcAVKGSMtMUBeLTPRQfH58DUFxcUvhZ1wNDfs9ksnR2dlBVtbdqgCRJVFRU0tnZgSRJlJdXDDLPV1ZWFX5ubW3hoYfu5/e//3Vhm2madHZ2TNYtHZX4AukAaLJKykzhuq7vR/LxOcwpKytnx47thd9d16W9vY2ysnKEEHR0tA961tvbW6mtnQVARUUl733vB3jf+/4B8EsHTRa+ya6flJHmmy99n5Zke2GbJCRsx8FwzGkcmY+Pz0Rw7rlv49ln1/HSSy9gWRb33vtLVFVj5crVrFixClmW+e1vf4VlWfz974+zceOGwrGXX34Vf/7zH9iw4U1c1yWbzfLMM+vIZNLTeEdHHr6G1I8mq6TNDK+0vMmFs6r2+USQs/LosjZtY/Px8Tl0Zs+ey3/+53/zne98k46OdhYtWsKtt96OqqoAfPWr3+TWW7/MnXf+mFNPPZ2zzz63cOzSpcv55Cc/x7e//Q0aG/eg6wFWrlzNscceN123c0QiXNc9otoednWlxt3B8Gdv/JKN3Zv5p9U3oUierM5ZecJqkNpozUQOc8ZTXh6loyM53cOYEcy0uWhtraeqas6UX9c3U+3FnwuPg83D/t9VSRKUlkZG3N832e3DcRUrydsG23t3FbZpskrSTHOEyW0fHx+fGYcvkPZhfnwuES3Mhu7NhW2+H8nHx8dnavAF0j5IQuKYisXs7KsnY2b3+cQlb+enbVw+Pj4+RwO+QNqPYyqW4LgOm3u2FbapkkLS8KNpfHx8fCaTKYmy6+np4ZOf/CR79uxB0zTmzJnDl770JUpKSgbt9+lPf5pnnnmG4uJiAC688EI+8pGPTMUQC1RGyigPlrKhazNrKlYBoEoqKcPPR/Lx8fGZTKZEIAkhuOmmmzj55JMBuPXWW7ntttv46le/OmTfD33oQ9xwww1TMawROaZkKWubnqYn10txoAhZkrHtLKZjovnh3z4+Pj6TwpSY7IqKigrCCODYY4+lubl5Ki49JoQAASwrXQzAG12bCp85LmQt34/k4+PjM1lMuQ/JcRzuvfdezj333GE/v/vuu7nsssu4+eab2bFjx5SOTZW8BLmYFmVR0XzWt71KxswAoEkqCWPm5KL4+Pj4HGlMeWLsF7/4Rdra2vjBD36AJA2Wh21tbZSXlyNJEn/605/47ne/y6OPPoosy1MyNsdxeL1tE1EtTEe6i+88dxcnzzqOK5aej+M6pM0sKyuXIgk/FsRn+tiwYSM1NVOfGHsgrrzyEr71re+yYMHCwrb161/khz/8PqZpYBgGZWVlfP/7d/CZz3yC5uYmALZt28qCBQuRJImSkhK++90fccopa1i2bDl33/3LwrnuvPMO7rrrp9x223c444yzRjWm++//C9/5zm3U1NSSz+dRVZVzzjmXG254H4FAoDBuXdfRtL2m+FtvvZ1vfOOrnHXWOVx99TWF7a7r8va3X87nP/8F1qw5nq1bt3DnnXfwzW9+G4BEIsH3v/9t1q9/CVmWKSoq5qMf/WeOPXYNAL///W9JJhO8//3/MM5ZPvxobq7nmGOWj3r/KS0ddOutt1JfX88dd9wxRBgBVFZWFn6+8sor+drXvkZrayu1tbWjvsahVGoACKoBOrqTqFKI1WUreL7xVY6JH0NpoJikkabR7SKoBMZ9/sOFmVadYDqZaXPhOM60VAk4WFa+be8dl2VZfPrTn+D73/9JoYnd1q2bsW2Xr3zlm4VjzjjjBH78458TCoX6j/OOdxyXbdu2M2/efFzX5W9/+yvz5y/Att0hY7jrrp9QXV3DxRdfNmi747iccMJJfPnL3wCgp6ebr3/9v/nc5z7Frbd+u7Dff//315k/f+GgYy+++HJ+9atfcvnlVxe2vfzySwghWLnyWAB++MPvc+ONNxXG85nPfJIFCxZw771/QJZlXnllPZ/+9Me54467mTWrjksuuYJ3vevtXHXVtYTDI1crOJw42HfCcZxBz87BKjVMmUC6/fbbefPNN/npT386aDWyL21tbQWh9NRTTyFJ0iAhNRXEtAjtdi+qpHB6zcls6NrM3xuf5uqFlyKEIGNmjwqB5HP48PQbLax7vWVSzn3GqmpOX1l98B33I5PJkM1mBkXSLl68dNTHX3TRJTz00H3cfPO/8Mor65k/fwF9fX1jHse+FBeX8LnPfZGrrrqInTt3MH/+ghH3PfPMs/nWt77G7t27Ch1lH3jgL1x88WUIIWhtbWHPnnpWrPAicV999WUaGur51re+V7DoHHfc8Vx88eX84hd385nP/BeKonDSSafw2GOPcPnlVx3SvRypTIntadu2bfzkJz+hvb2d66+/niuuuIKPfvSjAFxxxRW0tbUB8KlPfYrLLruMyy+/nB//+Mf8+Mc/RlGmtv5rWAth40n8sBrilOoT2Na7k4ZkE5qkkTASUzoeH5/DkVgsxuWXX8X111/NJz/5b/ziF/9DW1vrqI9/y1vexpNP/h3btnnwwfu46KLLDn7QKMc1a9Zsdu3aWdj2+c9/ive//128//3v4h/+4T0AqKrKeeddxIMP/gWATCbNU0/9nYsuuhSAV15Zz/Lle01RO3ZsY8mSpUPeV8ccs5Lt27cN+n39+hcm5F6ORKbkbb9o0SK2bNky7Gd//vOfCz//z//8z1QM54AEFJ19M41OqDiWl9tf54nGdbxn6XWkrQy2YyNLU+PX8vE5GKevHJ8WM9n8+79/ine84928/PJLPPfc0/zyl3fzs5/9grq62Qc9NhgMsWLFSp588glef/1VPv3p/+RXv9rrU7rvvj/x+9//BoDu7i4UReE3v7kXgA9/+GZOPfWMA5x9sEn/y1++dYjJDuCSSy7n4x//Zz784X/iscceYeXK1VRUeBab9vZ2iotL955xlK740tIy2tvbD77jUYrffmI/VFlFEhKO6yAJCVVWObnqeB5reJLuXA+arJG1c0Sk8HQP1cdnxlNbO4va2llcdtmV/Md/fIynn36S668fXZ7hxRdfxn/+56e48MJLh2gel112JZdddiUwsg9pOBKJBI2NDQc01w2waNFiSkvLee65Z3jwwb9w7bXvKnym6zqGsTcNZOHCxdxzzy+wLGvQWDdseGNQoIdh5NF1/aDXPlrxw8X2QwhBWAlj7lNMdUmx94Xa0rMDWcik/TJCPj4HJJPJ8MILzxU0h2QySUtLE9XVow9QOu6447nhhht5+9uvm5Ax9fT08LWvfYkTTjiJefPmj+qYSy65nJ///Kc0NOzhzDPPLmxfsGAhe/bUF34/9tg1zJpVx49+9F1s2wY8v9IDD/yZ97znxsJ+u3fvYuHCxRNyP0civoY0DGEtRDKdQpe9lUxUi1AbqWZLzzZOqjqOhJGiMlxR2H9Am/LxOZr513/9aMGhn8/nWbVqNd/+9jfQNB3btjn//Is4++y3jPp8Qgje+c5Dq9ry0ksvcOON7+oP+9Y466xzuOGG9w3a5/Of/xSatldr+fSnP8/SpZ5/6LzzLuSHP/wul19+VaGRH8Dq1cfR0tJMKpUiEvGixr785Vv5wQ++w/XXX4UsK8Tjcf77v28dZKJ84YXn+NCHbj6kezqS8Rv07Ud5eZT65nZ2JeqJqnvDE19se4XHG57iQyveiyIrLCyaj2EbdGa7yNsGc2OzCShHjio+00Kdp5OZNhd+g77pR1Ek7r77LjRN4x3vePeojqmv3803v/lVfvCDn07y6KYOv0HfFDBcu/IlRQNmu+3gwq6+evYkGrEcG1lI1Cf2kLeNqR6qj4/PNPGOd7x7TP6g9vZW/uM/Pj2JIzr88QXSMMiSjC7rWI5V2BbTo1SHK9nSs52wGkKTVKJaBF3W0GUdCYn6RAOG7Tfy8/E5GtA0jSuvvObgO/Zz4omnjNp3dbTiC6QRiKiDAxsAlhQvojXTTtJIoUiD3W+6ooPrUp9swHbsqRyqj4+PzxGBL5BGIKyGsBwb27FJWxn68kkWxucC/Wa7YQgoAQzbIG1lpnCkPj4+PkcGvkAaAU3WQIDhmJQFSqgMl6PJGlWhihEFEoAmaXTneqduoD4+Pj5HCL5AGgFd1lhYNJ/FxQsoD5VRGihGCMHi4gU0p1tpSg1fO0yTVNJGGtP3Jfn4+PiMCV8gHQBd1goty2VJpjhQzPzYXMJqiF9u/i1/q3+CrJUbdIwQAoQgZfrJsz4+Pj5jwU+MHQPFepwutZsPHvMenmp+npfbX2NzzzYun38hc2N7k98CkkZProfiQNH0DdbHZwq55prL+MY3vj2oJtzLL7/Ej3/8fUzTxDQNSkvL+M53fsTnPvdJWlq8jtHbt3v9kITw+iHdfvsPOOOME1i6dDk/+9n/Fs51110/4e677+TWW7/N6aefOaoxPfjgfXzve9+iuroGwzBQFJWzz34L7373e9H1QGHcmqYNSoz92tdu47bbvs6ZZ541KIrOdV2uu+5KPvvZ/+LEE09k27Yt3HXXT/j6128HvFYaXpkgAbh88IMf4Ywzzma8PPjgfTzzzFOF9hnDsW3bVr773dtIpVJYlkkkEuWrX/0mJSWlIx4zUfzxj78jnU5yww03HnznUeILpDEQUPT+YAeTt80+i1Vly/njjgd4omEd71/+zoI2pcoqSSNFzsofUcmyPj6jxbIsPve5Tw7phySE4Gtfu62w3/79kAZwXZddu3YW+iE9+ujDI9afO1Atu+H6If3Xf31mUD+k4YqrXnKJ1w9pX4H0yivrkSRRaLh3xx0/5MYbbxp03MC9PPvs0/zXf32Ghx56fFI7Fnzxi5/nIx/554KQbmjYQyAQnLTr7ctll13Ju999zYT2d/IF0hgpD5ZSn2hAl3UqQmWcWHkcj+xZS1umg6p9ygkJIUgaKV8g+Uw65tanMbc8OSnnVpechbr49DEfd7T1Q9qfNWuOJ5vNkEwmKS4uZsOGN7njju+TTnum/Jtu+kdOO+0MLMvik5/8V/r6+sjn8yxffgyf+MRnB5UpOhAdHV6X7QEGyhRt2rSBr371i/ziF78pfPa+972Tj3/805imyXe/+y2WLz+GDRveQFEUPv/5L3H33Xeya9cOKioq+cpXvkkwGOSuu37C7t276OvrpbOzg3nz5vOZz9xCJBKZlP5Ovg9pjITUIIqkFHKNlpcsQZEUXut8c9B+AVmnO9cz6rL0Pj5HEkdbP6T9+fvf13L88SdSXFxMMpnkttu+yi23fIWf//yXfOMb3+Gb3/wqyWQSWZa55ZYvc9ddv+AXv/g1tm3zwAN/HvG8+/Pe936Aj370g/zbv32Uu+76CfX1uwFYtuwYgsEQr7yyHoDXXnsFSRKsXLkagN27d3L11dfyv//7a445ZhX/8R//zD//87/xy1/+FkmSePTRhwvXeP31V/jCF77CPff8nnA4wv/8z88Kn61cuWpC+zv5GtIYkYREWbCU1nQ7US1MQNFZWryQjV1beMusM9Fkb2WjSApZK0fOzhFUpkaF9jk6URefPi4tZrI5mvohDfCRj3yATCZDV1cX3/vejwF4883XaGlp5uMf/1hhPyEETU0NLFq0hHvv/SXPPfcMjmOTTCYJBEbfkfrd734fF1xwMevXv8hLL73AP/zDDdx22/c49tg1XHPN9fzxj7/juOOO5w9/+A1XX723avrs2XNYtGgJAEuWLKGtraVwb0uWLKOxsaGw72mnnVnwSV166RV85zt7W9CXlpZOaH8nXyCNgyI9Rme2C9M2UWWV1WUreLNrM5t7trGqbO+qSRISKSPtCySfo5ajpR/SAAM+pHvu+QW33PJZ7rnn97guLFiwiB/+8M4h+//1rw/w+uuv8qMf3UkoFOZ///fnNDTsOejY9qWsrJwLLriYCy64GF3XWbv2MY49dg3nnvs2fvKTH7B162Zefnk9n/nMLYVj9g3ikCQZTdP2+V0qtNA4GPm8MaH9nXyT3TiQJZnaaDVZO4frutRGqikJFPN6x4ZB++myRq/f8tznKORo64e0P+985w2UlJTw5z//nhUrVtHYuIeXX36p8PmmTRtwXZdUKkk8XkQoFCaVSvHII38d0z099dTagvDI5/Ps3r2L6uoaABRF4ZJLLufTn/4Pzj//wjFpXvvyzDPr6OnpAbzIvzVrTix8NtH9nXwNaZxE1DBFeoyUmSakhFhddgxPNK6jM9tFWdBTbxVJIWukCpqUj8+RzNHeD2n/sX/0o//KLbd8liuuuJqvf/12fvjD7/Ld734LyzKpqanl1lu/zYUXXspTTz3Ju971doqLS1i9+jjy+aGa10g88cRj/OhH3+ufY4sTTjiZt7/9HYXPL7vsSu6++84xFYHdn9Wrj+MLX/gsHR3tzJ07n3/6p38rfPb888/wwQ9OXH8nvx/Sfoyl941hm2zv3UlQDpC38/zw9Z+zpmIVb607q7BPykxTF60lqg0fFmk7NikjjSorhNTQsPtMBzOtB9B0MtPmwu+HNP2Mpx/SdPDwww/y6KMP881vfndcx99110/IZrP80z/965DP6ut3c9ttX+X73x+5v5PfD2kK0WSVqnAFGTtLSA2xqGg+b3ZuImftXeEoQiZhpIYcazoWHZkutvbsoDHdzM6+erqy3X5Uno/PYcJY+yFNNf/+7//Ez3/+U26++V8m5fzt7a188pOfndBz+hrSfox1Ney4Dlu6txNUAnRku/ifjfdyUuUa3lJ3RuHzrJVnacnCQuKs4zps792F5VgE5QCyJOO4DmkzQ0yPUhOuQpbkcd/DRDDTtILpZKbNha8hTT9TORfPPruOn/zkR0O2HzyacPKZ6I6xvg9pH7J5i1RmbF1fJSER0yKkzQyVoXJWlC5jffurrKlYRVyPIQkJB5u8nSegeE7FZD6F6ZiDWqRLQiKqRUgZaRrdZubE6ib03nx8fA5PTj31jGkXPFOFb7Lrx3Yc/vjUTupbxx4VF9NjmK7XXfbM2lMQQuLvTc8M2idjZQFPO2rPdhKQh494CSlBUkYax/VXoj4+PkcXvkDqp6kjzaMvNbKlvmfMxwb7NR/XdYlpUU6sPI5N3VtpTnmZ6bqkFfxIKSONYRuo0vDK6YBZL28PjbQxbJO8PTYNzsfHx+dwwRdI/eiq57PJ5q0xH6tICuF9Wp6fXHU8ISXIE43rcF0XVVLJmBksx6I924kuH8QRKhjS1gKgI9vF1p7ttKbbsZyxj9PHx8dnJuMLpH4CmieQcsboMpT3J67FyDue9qLLGmfUnExjqpn6ZANCCFzXpTvXQ97OF8oLZa0cz7es59db/0Ryn0g8TdJIGYP7KTmuQyKfJKKE6cn1sq13J735Qys26ePj4zOT8IMa+gno3lSMVyCF1eCgElkry5bzZNOzvN65kbmx2chCoivXgyZpJI0Uz7S8yIauTZj9ms6zLS9y/hwvaVCTVNJmBsd1kIS3ZsjbeRzXRpZkwlII27FpTrUSVSPTHpHn4zMT+yH5HH74AqkfTZEQAvLG+ExhmqyhKRqWY6FICoqksLxkCa91biBn5dBlnbSdIayE+OP2+2lMtbC8dAknVBzLy+2v8XrnRk6tPpGoFvE0KhwM2yy0r8iYWYQkCteTJRlszycVD8QmZA58fCaKqeyH5HPkMCUCqaenh09+8pPs2bMHTdOYM2cOX/rSlwb1SgHIZrN85jOfYcOGDciyzKc+9Sne8pbRlxo5FIQQ6KpM3hyfhgRQpMXpzHah9AcsrCxbzssdr7OpeyvHVawiJkVpSrVQn2zkLbPO4KQqr9HXKdUn8HrnRl5oe7lQ5cFFkLNyBYHUm+9Dlwb7nnRJoyPXRUyPFoIhfI4+nm9Zz7MtL07KuU+tPpGTq48f83EzsR+Sz8xnSnxIQghuuukmHn74Ye677z7q6uq47bbbhux31113EYlEeOSRR7jjjjv4/Oc/X2hoNRUEdYX8OE12ABEtNChcuzJUTnmwjDc6NxW2PdvyIkElwLHlKwvbivQ4x5Qu4dWON8mYGQBUoZA2vXs3bZO8lR8SmafKKnkrN2wAhI/PdDJT+yH5zGymREMqKiri5JNPLvx+7LHHcu+99w7Z76GHHuLrX/86AHPnzmXFihU8+eSTXHTRRVMxTAKaPG4fEoAu60hCLvh+hBCsLFvG4w1P0ZHtwnUddvTt5syaUwqBDQOcUnUCb3Zt5sW2Vzh71uloskrKzOC6rldVfIRrKpJCT66XkLq3xYXt2AghCv6nownHdXBdd8x+NU8bHV815Onm5Orjx6XFTDaT2Q/J58hkyn1IjuNw7733cu655w75rLm5mdraveXpq6uraW0d/aoKOGBZioMRDWsYpk1paQRJGqcJLFRHS7KdmO7ZxE8LH8ffG59ma3IriXwSXdE5d/EpBNXBL7/i4hCrOpfycscbnL/0DEJqhEQ+RbwkQDrZR7kSG3IMQNz1EmnjJQE0WSVjZtnV00JZqJjySPmQ/cdCeXn0kI6fDhK5JIl8iqp49aiPMWyTzq5WqkvmocjDPxIzaS7a2yUUZXoWGwe6riwPHdecObOZM2c2V111Nf/6r//Es8+uY968wRW8FWXocYoicdlll/PZz36Kiy++lEBAQwiBLItpu/f9mSnjmG4ONA+SJI3p2ZlygfTf//3fhEIhbrjh0MrKj8Sh1LKThSCVt2hrT6DI4/uyuY5KMpEnLzkFX9KC+DxebHqNvG1wStUJ5FIOOTJDjj2+dA2vt23moU1Pcm7dmaTMLA12J02pNmQk1na+gEAQUHSCSpD58TkokkLKzLLTbEaRFBqTLaiSTFd3ErdYHXcE3kyr3zZaurLddGa70fLhUfvV0maGhp521Hxo2ACRmTYXjuNMS025g9Uts+2948pkMrz55uuceOLJCCFIJpM0NzdRWVk95ByWNfR+LMth1ao13HDD+zn77LdgWZ7ma9vujKin59f18zjYPDiOM+jZmVG17G699Vbq6+u54447kKShL/yamhqampoKjtCWlpZBpr7JJqgrdCXzh1RxW5ZkKkPlNKdbiUrexK8sW87W3h0oksIJlccW9nVdF8MxMBwTTdKoCJWxumwFL7a9wrzYbKrCFfTke7Fcm/t3PUx9snHQtY4pXcql884nKAdozbTjuC4RJYQsySSNFAkjSXGgaNz3cjiSs/PkrDymY6LJ2sEPAHJWHgkvLN+PWBw/M7Efks/hxZQJpNtvv50333yTn/70p4Pa5e7LhRdeyK9//WtWrlzJ7t27eeONN/jWt741VUMkqMvkDRvnEBc+cT1GZ6670JhvfnwOxXoRS4oXEO7veZQ0UwgEETVMsV5EW6YdXdZ4a92ZNKWauX/X33jvsndguy7PNr9AfbKRi+e+jSXFC8lZeZ5vXc8rHW9wStUJlAVL0FwVTdIKWkFQCdCR6SoUeD0UUkYaRVIKEX8zmbyVB1xydn6IQEoaKYJKoKC5DpCxsoSUIFk7i2EboxZkPnv53e/uG9dx69a9NKptAD/4wch9d3yODMb1psrlchjG6Guqbdu2jZ/85Ce0t7dz/fXXc8UVV/DRj34UgCuuuIK2tjYA/uEf/oFEIsF5553Hhz/8Yb70pS8N241xsghoCnnDwj5EiSQJiepQJVk7V/j9gyvew1m1pwFekmtICbG0ZBGzY7MoDZYQUAIY/QLsigUXYTgmD+1+jNc63uD1zo2cWHkcK8uWo8kaMT3K6TUnoUgKz7S8AHgBFfuaqBRJwXAMMmb2kO7FdV1a0m00p1pmfMFX1/UEUUDRh6100ZJuKxS53ZeMmSkIqeQwvat8fHymhlFpSLfeeisXXXQRq1atYu3atXzsYx9DCMG3v/3tYYMT9mfRokVs2bJl2M/+/Oc/F34OhUJ873vfG+XQJ56g7uUhmRNgGw6rIcJqmLyVR1cGC4u8bVATqS5oLkIIygKlNKab0WSVsmAp580+m4d2P0Z9soG5sdmcM+v0QecPqSGOr1jNc60vcWr1iZT3t00Hz0mvySq6rNOR7SSihcd9H1krR942EMLLhSoJFI/7XJON5drgumiyNkSw5Kw8aTND0kgT0/Y6WS3HwnJsgkqAIAE6s92UBIr9vC4fn2lgVBrSfffdx6JFXrb1D3/4Q775zW/y4x//mG9/+9uTOripRhcWrgvZQwj9HkAIQXW4AsMxB2kWedsgrIYIKcFB+0e0MAJR2Hdl6XJWl62gIljGFfMvHNbsdlLVcWiSytPNz/efO899Ox/mu6/+hNa0ZwJMW1myw2gFo6Un14sqyYTkIK3pdgzbHPe5JpuBgrOyJGO71qCxJo0kmqSS2k9QGbaJEJ7PUJEULMciZ8/0vC6BO8O1VR+f8fjiRyWQstkswWCQnp4eGhoauOCCCzjttNNoamoa8wVnMjqeGTKbm5iXbkAJUB2pJGXuNR/l7TzlobIhK3BZkikLlBbMfEIILpx7Lu9f/s4R82OCSpDjK49lS892Xu/cwN0b7mVT91YkBM+3rge8BNuOUbRGd113SAVxy7HoMxIE+rvaSki0ZdrHPA9TheVY0D+vrru3hYfjOvTk+wiroSGCKm8bg3K8ZCHRm585EXXDoWkBens7sSzTb3nvMyNxXZd0OoGijM0fOyqT3dy5c/nLX/7Cnj17OP10z3TU3d1NIHB4JhKORLC/4nd6HC0oRqJYLyJjZkiaaRShEFKChJXQsPvGAzE6cp2F3ws+kf38Q/tyUuVxrG9/jYd2P0ZMi/KupdewrWcHL7a9Ql8+QVyPkcgnSGoxYvrw+QCO69CSaiNtZZgXm43an7SbNFK47t4eTSE16J3zAOcaK67r4rjOhBSINWwTgTdWRVJIGSmiWoSclcN2LCQlCIhBFdczVhZV7H0MAkqA3lwvlaGyGZtYXFxcTirVR3d3G45z6Nr8aJEkCedQI36OEPy58DjQPCiKRnHx2HIhRyWQbrnlFr761a+iqipf+cpXAFi3bl1BOB0pDLSgyGQnTiAJIagKV5Lu3U3WyjG/aM6IwkWXNSL9fifbdbBdm5AaImWmiajD59UElADn1Z1Nc7qVs2pPI6DoxLQIL7W/yottr/C22WcTUoI0p1sJqsEh5Ydsx6Yh2UzKTKNIMg2pZuZEZ+G6Lp257iGRdQE5QEe2c8IEUiKfJGmmmBWtOeRz5ewcsvD+hpqkkjBSVAN9Rgq5X+jIQiZlpIlqXrBMxsoMirqThITt2qSM9ITd40QjhCAaLSIaLZrS6860fKzpxJ8Lj4meh1EJpFWrVvGrX/1q0LbLL7+cyy+/fMIGMhMY0JAy+Yn1kyiSQl20lq5s94ja0QClgRJ2J/ZQpMcpD5WhSSotqVZ68n2FlyiA6VjYjkVACbCibBkrypYVPotpUZaXLOb1zo2cXnMyQSVA3jFoS3cwK7q3goFhGzQkmzEcg1j/uZNmmtZ0O1FTw7DyRLXBL2VN9l70OSs/IWHgXbkusnaeGrfqkDWSvJUvaFqyJGPZXkBGb66PYP9YNUklaaSophLbsTFtE10dHPQxIHQHKq/7+PhMDaN6Azz33HM0NDQA0N7ezqc+9Sk+85nP0NHRMamDm2oCmiefs/mJN4OE1CB1sdqDvuDCaohFxQuYFa1Bl728oqpIJVEtQspMYzkWSTOF4zo4DPX7DHBi5RpMx+TVjje868tBevM9JPJJslaWpmQL23p2YTnWICEZUUL05Htp6GsuaBX7IwkxIeHRuX0Kw+YOsUCs67rkbQNF7DX9CaA314uDXRB2siRjOiambWI4w/tgNFkla+UOKRjEx8dn7IxKIH3xi18sZGDfeuutWJaFEIL//M//nNTBTTWFrrGH0ILiUBFCoO+XmCkJidpINQElgOmY1ISrWFA0l8pQeSEIYn8qQmXMi81mfftrWI739wopIeoTDezoqydlpoioIYL7BUwI4SXrZszckM8GCMg63bmeQ3ao9+UTSEJGRiJlDC2lNBZs18Zx3UECXxYSCSOJzH7+KeFVdPCCG4ZfIGiSSleu55DG5OPjMzZGZbJra2ujpqYGy7JYt24djz/+OKqqcuaZR1bnxoDuvbiMaRRIIyFLMnOiswZV8Y7rMTqzeytCDJC380hC5qSqNfx6659Y2/gM58w6DUVSiGqRg5rGJCFRFAjRk/WExL6da8EzQWatLDk7R3C/8PXRYjs2XbkeQkoQx3XoMxJUhMvGdS7wIuzEfjXRNUmjJ99HyX7lk2Rk0v1tPpRhSliBl2icyCfJh0afAD5VtKTbKAuUDPqb+/gcCYxKQ4pEInR2dvLiiy+yYMECwmHP5m5ZE+f8nwkMmOwOpUnfZCJL8iDBIAlpiJaUtXI4rkvOzjEnWsfK0uWsb3+Vuzfey55E45j8NK7rsq7pOb7/6p20ZzoHfSYJmcQBwqPTZoaO/Y7Zl4yVxcVFEpJXVcI2MOzxv/zNfUK+B5AlmZJA0ZB71mSVpJnqr9Aw/EtdCIEkSfTmesc9psnAdV0SRpL8IcyVj89MZVQa0g033MA111yDaZp89rOfBeDll19m/vz5kzq4qUbXFARgmIdPOGdUixBUAhi2ge06SJLEnOgs9iSbsByLi+e9jaUli/hb/RPcu/UP1ISr0GUNWZKRhfdPEhKykFhYNJ8F8bleC3XXZW3j07zQ9jICwUO7H+U9y64rvNyDSoDuXB/lw4RH56w89YkGbNchooWH1aI6s91o0r6mSUHGzI67jtxICbvDCWBFUsgaKRAQUUauYhGUA3TlerDsmbPwshyLvGWQtbKHVIHDx2cmMiqB9KEPfYjzzjsPWZaZPdtrrlVZWcmXv/zlSR3cVCMkiYAqZqyGNBxCCCrDFezo3U1IDTInWocmq5QHS2lINhWKu/7DMe/mudb17Ek2krPyWK7d73dxcFwHwzZ4rXMDteFqzqo9lafa6nmh7WXWlK9iVrSGv+z8Ky+2vcrJ/W3XJSHhYJO1coWCseBpKg3JJlRJQXWhNd3O3NjsQb4dwzbIWBmi6t6oQU1WSBhJigLxcc1D3s4PCmgYzby5uAcMMpGEhAt0Z3sRzIzCspZr4bgOKTNNOeM3cfr4zERGXe27rq6OV155hddff53KykqOO+44FGXK2ylNOkFNzEgf0oEIKyFqI1XEtVjBrxDVIqiSiuVYKJKCKqucWXvKiOewHZs3ujbxdPPz3Lv1DwCcWHkcb5l1BgCbirayrulZFhfNL7S0UIRMbz5REEiO69CUbMZ2LUL9kXsJI0nCSBLXY4V9urM9hQTWATRJI2WmsR17XEmyeSuHLI3++ygLGds9+N85rARpSrRSKirG7S+bSMz+v6dnmnVmbPKuj894GNUTvGPHDj7ykY+Qy+Worq6mpaUFXde54447WLBgwWSPccpw+toIqALDOrwEkhCCsn2Kq4K3ui8PldKSahuUvzQSsiRzbPkKjildyqvtbxAO6yyLLCtoEOfNPoe7NvySh3Y/xjuXXN0fDajTle0maSQAcAHHcYnuY0oKKUFa0m1E1DAOLk3JFtJWeoipbEBjydl5wtKBc7WGI2cbQ+oDHoiRIgj3RxISAUWmsbeF+fE5E1JR4lDIW3kUIeHgYNjmYdESxMdntIw67Pu6667j73//O7/+9a958sknuf766/nCF74wycObOpy+VrL3fY35SjuG4YUQH+7EtRhCiEHFXQ8Wqq1KCidWHcfps08YZM6KahHeMutMGlJNPNbwJLbj5fbEtShBOUhQDhKSg4OEEXj+Gsd1act0sLN3Fzk7S1QdPuHUC/9OD9l+MCzHGhLyPZHoio7pmLSlp7+OX7ZfE3RcMBw/sMHnyGJUAmnz5s3ceOONgx74973vfWzevHnSBjbVuLanFZXIWQzLGXcb9JmELMmUB8tIGElSZpqkmSZlpUkYyXFFtK0qW87xFatZ3/4av9j8G7qy3QghBv0bjpASoCvb3V/Lb2TtR5d1+vKJMec3eUVVx3TImAkrIbrzPfTlE5N7oYOQszxfmSrJpA+x15WPz0xjVAKpoqKCF154YdC2l156iYqKikkZ1HQgVC+6Kyhb5E2bI0BBAqA4EKc2Us3s2CwWF81nWcli5sZmIwmJpJEcUzsJIQRvm302Vy+8lISR5H82/Ypnml+k6yDVxCUhEdc9/5bt2LRl2ofdf6CKwoHCyYfDcuzJlkeFxOKGZCP1iQZSRnrKGxY6roPpmMiSjCqpZMyxa5M+PjOZUfmQ/u3f/o2bb76Zc845h5qaGpqbm1m7di3f/OY3J3t8U4fq+RRCsoVhHhkaEngms9JgyaBtES1MWA2RsbLsSTbi2g66PHpfxKKi+VQvfzcP7X6Up5qf5anmZynS4yyMz2N56RKqQhXDakuu63L/rr+xuWcb82Kzedvsc4YkrQaVAC2ZNsJaaEir8ZGYqpwcRVKIaTHythfWLksy1aFKYnp0Smre7ZtrpUjKIQWB+PjMREb1xL/1rW/lD3/4Aw899BDt7e0sWrSIj33sY8ybN2+yxzdliH7ncEBYGJbd38b8yH3QhRCE1RDzYnOoTzSQs3Ij9l0ajogW5trFV5Awkuzo3c32vl280vEGL7W/SkmgmBWlSzm2fMWgyLRnW15ic882FhcvYHeigZ9v+CUnVa5hdfkKYpr3Ulckhbxt0Jntpip8cA3cdV3SVgZlhLp7k4Eu6+iyjuVYNKSaiOQjVEcqh5R8mmhMxxykCbqui+EYBKXpj/7zGYphG5iONSgtwufAjPopnjdvHjfffPNkjmV6kVUQgoBkkTcdTPvwSY49FAKKzrz4HOqTDaSsNCE5OCiUOGvlMB0LWZKGrVQe06IcV7GS4ypWkrPybO7ZxoauzTzZ9Cwvtb3KW+vOYlnJYrb37uSp5mdZXrKES+edT9rKsLbxaZ5tfYlnW18iqkaYFa1hTfkqaiPVdGa7ieuxA0bDOa5Da7qDRD4xKKdpqvA0pihZK8f2nl1UhSsoCRRNmrZk2hbuPuWRhBDkLGNGhKP7DCVn5+nMdjE/Pne6h3LYMKJA+sQnPjGqB+sb3/jGhA5ouhBCgKKhYXrdRg0bjpJEeE1WmRubTWe2i55cLy4uuilIGEmiWoTaQDX1iQbcg0SyBRSdY8tXcGz5CtozHfx19+Pct+th3ujaSHOqlepQJRfOfWuhgOul887nlKrjqU820pRqYXdiD/WJBv5x1Y3okkprup3KUDlpM0PSSOACZYFSr927ELSm2ugx+gpReykjza+2/oG31p3FvPicKZu/oBLwmhymW0mbaaojVUP6Tk0EOSs3SBNUhELGylDM+JKJfSYX27FJ5tPkbWPStecjhRGfmjlzpu6BnikIWUfHKxOTzppQPM0DmkJUSaE6XElFsMxr1qe5hONFRPp7BRUHikjkE4RGaX6oCJVzw7JrWd/+Gk81PYsu61y18BLUft+HKqnoskZZsJSyYCnHV6ymIdnEPVt+zxudG1lTsYqkmWJXYg8SAq2/5lxjuhkpLRNUdNJWhoiyt3Hhi22v0JXr4fHGddwYq5vSpFFJSMS0KGkrw47eXdRGqlEkBUlISEIalYA6mD/IE0h7P1clZVxh8j5Tg+VYWK5J0kih7+fH9RmeEZ+Sf/qnf5rKccwMVA1FeFFnmUnoiXQ4IEsycT1GeXGUDmtvtFtpsMTTnsaQ7yMJiRMrj2NZyWIEns/KcR1cPN/H/qvGWZEaasJVvND6MseWrxjWDDcQqWfYxiBhlLNyvNrxBnEtRme2i03dWzmmdOkhzMT4CCshTMdiT6IRAbhCgOtSGiyhYoS26DkrT0++l958H3Ois0YU+jk7Pyj5V5ZkLCuL6ViTopH5HBqm41Us6c72UBoo9ps9jgK/7sg+CEVHdT0NKZOb2K6xhzu6rBHX4+RG6L90ICJquODYzVk5YloMhgliFEJwSvUJ9BkJNnVvHfF8siQTUAKDHvD17a9jOCZXLbyEimAZ65qfx3amZ1Gh9rf5iGgRomqYiBqmK9tNfaKxEGZvOzZJI0V9opHtvbvozfUhI9E2QoX0AyX/HkqVdJ/JY6Bsl+kY43pujkZ8gbQvio6M98JI52ZOheeZQlmwGNOxCzlEeStP0kiRMtNeSPIosHEoCxYTVHTMYXKg5kRmURYo4bnW9aNOkDVsk/Xtr7Ig7jUtPLP2VHrzfbzRtQnwgh+ea3mJP2y/f9hrTjZCCKJaBMPOs7NvN/WJRrb0bGdPspG8lSfaL7ADSoCMmSZjDm1WaA7T7wk8LTTtm+1mJJZj9ZtsD9yqxWcvvkDaB6FoKP0v1pzhC6T9CSgBYnqUlOlVe1BllTmxOipD5bi4JM0UeTs/4vGWY6HJGgE5QFyPk3cHr+xN2yRppTmxcg2d2S529u0e1bhe79xA1spxStUJACyIz6UmXMXTzc/Tkenk/zb/jr83PcO23p2sa35+3Pd/qASVIJqkYlh5wkqIqBohoOiDtB5N0obVkizHGk6pJKh4LTKmSxv0GRnLtZEQhVYtU51IfTjiC6R9UQNI/Sa7vOE/4MNRHiwlqkeZH5/D3PhsIlqY0mAJC4vmMT8+F9OxRnw5Zu1cwZYeUoO4+yUf5x2DIj3OvPhsYlqUZ1teOuhDbDs2L7S+zKxIDbOiNYCnkZxVeyopM83PN95DV66Hy+ZdwOqyY3ix7RVa0m2F4y3H4pE9a/n99vt4ofVlWtPtk/riUCQFfT8htC+6opMeRkvKWflh/U9Sf6HVlF+1YcaxV0Pa26plrPTkekdtfTgSGLUndN26dWzatIlMZvCD8i//8i8TPqjpQqg6ot+kkzvMWlBMFUElwOxo7Yif1YSraEw1Dymg6rouuBQCFXRZ9x7U/hYKA0KgLFjCHivDqdUn8nD949yz5fdcOu98ivShoc2d2W6ebn6epJnigrnnDvpsTqyOFaVLydsG580+h6gWYX58Ljv6dvPQ7sd437J3YLsOf9zxALsTe4hrMbb37gKgSI/z3mXvGHVF8IlGlz0taW6srjCHB+r3pEsaXdmeQosPn+nHcZ1BAUCKUOjp7z488F0PKcEDRlU6rkN7thNVVo+aoJVR3eWXvvQlHnroIU4++WSCwSM4CU/VEY4nkAzLV6/HQ1EgTsbK0ptPENknWsywDSJapNCvyQuTjpA2MwSUAFkrR0mgmJASRCBYVbocVVJ4ZM9a7t5wD2+pO5OacBU5O0fWyrGxawtbe3egSgqnVB3P/NjQNIVL5p0/6PeAonPe7HP4444HWNf8HA2pZppTrVw0922sKltO0vDCzB+uf5zHG54ccvxUoct6oY9UVIsgCYmsnRvx5aXJGgkjNeZqGz6Th+06g6pqBGSdPiNBwvB8SZZjUxYspSZSOeI58naejJkhbxmF9IsjnVEJpPvvv58///nPVFdXj/tCt956Kw8//DBNTU3cd999LF68eMg+3//+97nnnnsKRVvXrFnDLbfcMu5rjhWh6LiWJ5AOp66xM43KUDkZK0vGzKJKCkIIDMekKjD44YvpMXqNBAG8B7hIjyFLMhE1TN7Oc0zpUuoitTyw+xEern980LG6rHNa9UkcX7GakDr6RdLi4gUsKV7Ic63rkYTE5fMvZGnJIsBrsbGqbDl9+QTPtLzA0uLFLCiae6jTMS6CSpDGVDOKUCgPlWLaJtoBKqXLQqIvn/AF0gzBcR0v5L8fIcSgNAbXdenOdRFWgyNqthkzCwiyVpajJSlyVAKpuLiYaDR6SBd661vfynvf+17e/e53H3C/K6+8kk996lOHdK3xItQAOBYBxcUwfQ1pvMiSTF20lo5MJ5br+ZTCamhITa+AEgDXK44aVoOFl2lci9GYakGXdWJ6lOsXX8WOvl3YrkNA1gkoAYr1IrR+bWusvG322ViOxXEVq1gwTFmXU6tPYEvPdh6uf5x/iL4bmPpaZKqkoEoRLMeiJdWOi3PAPJaB4IayYKlfbHUGcDA/5ED1+KZUC0ElgDZMJYe+fB9hJTQu39PhyqgE0o033sjHP/5xPvzhD1NWVjbos7q6ulFd6IQTThj76Kaa/orfUdU57NqYzzR0WSsEGYyEKikEFZ2EmR4kGIJqAMTgmm0Li+ZP2NgiaphrFl0+4ueKpHDx3Lfxy82/ZW3j01xfdumEXXusKJJCVDv4YyoJCReXlJEmHvB9SaMlbWbQZG3CfTTOfia74VAkBcWxaEw1F1rCDGA6FlkrT1SLHFVV3Uf1VxjoDLt27dpB24UQbNq0aUIH9MADD7Bu3TrKy8v553/+Z4477rgJPf+BEAWBZPkCaYqI63EMxxykPWmyhiZrhcTC6aAmUsUJlcfyYtsrLGiqY2FoUeEzx3V4sulZmlItXL3wkhlT3DQg6bRk2gp5T35lgIPTneulSI+hahNbnNcLajj4fgElQNJI0ZXtpjy0d7Gfs3L7NJ10+wsc+wIJYMo6w15//fX84z/+I6qq8vTTT3PzzTfz4IMPUlw8evtpaen4v1iJkiLyQFxzSCMoLY0gSUfvQ11efmhm2tEQt3SqzGKKgoNX9Vagho50BxFt+kr3XxY7l16zh99vfIiTZ7Vy2ZK3kbPy3PvGfezorkcgeGDP3/jAcdfNmJeFaZskzG4cOU9ttIqQNrHCciq+E1NJq+MSi+iUhcd+XweaCyljUSQCxAIH//7G3QApI0O8WEdTPNNdtjdBmRIjpAaQ8w7xYp1YYGbO/UR+J8a0/GxubqatrY2qqqpDCnAYifLy8sLPp59+OtXV1Wzbto2TTjpp1Ofo6kqNu7me2W+qDUom7VmDtvYEinx0pmqVl0fp6Jiq7HJBR2rwtQzTpTuRxlSnd0Fw5bxLeSH2En/f/Rx7eppJmxnSZoaL574NEDy4+xF+//rDnDfnnGkd52BkOpJ9NLZ3ENWilAdLCCrBQ9aYpvY7MfnYjk1Hdx9uRsGNjM0febC56Mj0kcjmsbOjW6hkrBwbsruZFa3GcR12d7cRVHTyIkPazNFodFE+A9sqjfU7IUnigErDqARSe3s7//7v/86rr75KUVERvb29rF69mttvv53KypHDFsdKW1tb4XybNm2iqalpSpsACtVr0heWLYzskdPG/HAkoOgIxJiKuU4GkpC4aNE5FEnFPLj7UQKKzruXXkN12PuedmQ7ebHtFcpDpRxbvnLaxrk/uqKjuRp5K8+uvnqCSpCaSJUfhbcPpmNiuw55Z+TqIuNlICl2tATlIL35XkqDRYDAce3C8Yqk9EfaHfmM2oe0dOlSfvrTnxIKhchkMtx+++3ccsst3HHHHaO60Je//GX+9re/0dnZyY033khRUREPPPAAH/zgB/nYxz7GypUruf3229mwYQOSJKGqKt/4xjcGaU2TzUDX2LBskTdtHF8iTRuFdg5mZtoSVPdlackiZkVrUCVlULv3c2adTle2m0f2/J0SvZjZsVnTOMrBCCEIKDoBdHJWnqZUC/Pic6a0LcdMxnQsZCGTtya+OK3l2khjWEgJIdAljdZ0e6F78gCqpBw1kXbCHUUFy5NPPpl169ahqnvVWsMwOPPMM3n++emrDTYch2Kys7v2kPn9f/F85G38obWO224+nVDg6MiQ3p+ZYJ7JWXl29O4irIYGvURd1yVrZSfEDDUaiotD9PQMLXg6QN7K84vNvyVtprlh2XWUBiYvZyRr5chY2XFdI2mmqApVUDrO3jwz4TsxkXRlu2nPdOK4DstKF49JUB9sLnb17cFx7EIi+GhJGEk0SUUW8qBjk0aaJSULpi3IZyQm2mQ3qr9APB5nx44dg7bt3LmTWOzICi8d0JACkolhOVi2H2k3nQQUnapwBWlrrzBwXa+IqyKrg7ZPJ7qic82iy5CExO+2/aU/oXFyeLzhKf5306/HVbU8rIRoy3T47Sr6ydl5ZCEDAmuCi9Na7thMdgMElSBZOz9UkAnPxHikM6oZu+mmm3j/+9/Pbbfdxj333MNtt93GBz7wAW666abJHt/U0u9DCggLx3HJGX5y7HRTHCgiKAfIW56dP2VmKNKLmBurQ5PVA1YXn0qK9DhXL7yUlJHiDzvux5qEgpiu67Krrx7DNtjet2vMx0tCQhYSLem2Ubf2OJLJWTkUSUYId8L/XrZjjUt7VyWF4mHqNuKCYR/5RVZHJZCuu+46vv3tb9PT08MTTzxBT08P3/rWt3jHO94x2eObUgoakuhv0pc/8lckMx1JSNREqjAck5SZJqwGqYlUokgKsyI1GPbg6uKGbRSa4E01tZFqLpl3Pk2pFu7Z8nsakk0Tev6ObFdBKzxQA8MDEVSCJI0UPbleUobXRqQvnzhsWiNM1Dgd1yloSK4rsNyJe9k7roPdXzR4opCF5OUm7cN09PaabEZtkDz11FM59dRTJ3Ms00+/QNIG2pj7TfpmBAElQEWojD4jyaxoTeFBDygBaiNedXFJknAdl6ASxHRMcpY9LRFlS0sW4bgOTzSu454tv2d+bA5rKlYBYDgmlmPj4jLQMrdIi1MTqRqVb2BXYg8AS4oXsr13JzkrT0DRD3LUUEJK0GvB0b+AdxyX4kCMmkj1jA946Mx0E1QDRA8xkdVybAReMIEkxIS+3L3K9hPr21Qkhay91xScyCfZk2ykIlhOWahkxv/dRsuIT8GPf/xjPvKRjwDw3e9+d8QTHFHtJyQJoahoBQ3JF0gzhbJgKSWB4iEJqEWBOIZtIoRXrFWXNQzboD7RSNbKTUuE3vLSJSwqXsDL7a/xXMtL7Nxef8D9ZSFTE65ieekSji1fMeJ+uxP1lAZKOKlyDVt6trO1dwerypaPeXxKf4v1fenLJxFIVEcqZ/TLLW/nMB1jAgSSidsvkWUhk5tA0689CdqmKilkzCyu62I6Jo2pZoJKkI5sJ0kzSW2k+ogI6R9RILW2tg7785GOUHVU19eQZhpCiH4H9FAqwoPrK2qyxtxYHfXJRtJWhpA8NdF4+6JKCidXHc+xZStoy3agCKXQ10bsU+WsI9vFnmRjoe1FXIsxLz57yPlMx6Ix2cyx5SupDldSpMfZ1L1lXAJpOCJqmJ58L0JIVIcrZmzZIdOxyNo5qt2qQxKcXkt4D1mSCz7KicBx7WHbzR8KQggcPGHUlGr1ovAkBVWLkLfybO/dRUyLUhwoOmifpZnMiALpi1/8YuHnr33ta1MymJmAUHUUfIF0uDPQXr0l3UayvweNJlQ0WZvSl62u6MyOjpybFNdjLCyah+VY/HzDPfxtz+N8YPm7h0RZNSabsVybufHZCCFYVrKY51peImWmJ6RXzkB7hO5cN5ZjUhmuQB+mAvV0YzoWruuQs3KE1PGXLshZeeR+gSYLiZw9cXk++7eemEja0h1krMygVhYDSdA5K8+eZCMCQUWwjNJgyQG/65Zj4cKMav43qiXGSKV7jkSfkqQGUAbamJu+QDqcUSWF2dFalhQvZHZ0FpqikzBTM9IZrEgKF8x5C739vZj2Z3diD7KQqIt43XqXlSzGxWVL9/YJG4MQgpgWJWtl2d6zk/Z054jt6KcDx3WwXAtZKKSMQwv5z9m5gsYtCQnbdSbsXvdvzjdxuPQZCcLD9MUaSIKOqpF+H2E7bZmOEaMpXdelKdXi+RJnEKMSSKY59AE2TRPHOTwic8aCUHXkgkA68u7vaGTAZzInNot58dlYrk3STM+40Oc5sTpWli7n+daXac90DvpsV2IPsyI1hR5Q5cFSyoOlbOzeMuHjCCpBwmqIjlwXuxMNMyYCz3EdhOt1X+3J9w75+41FoOSs/KBAEoFXXWGixulOsMkOvDyysBI6qKlyoBtzZ7aL5lTrsH+/pJEiaaRIGMlJzZsbKwfU1d71rnd53T4NY0hjvdbW1iltDTFVSGoAKZMG/K6xRyIRNczConl0Zbtpy3YQU6Mzyl/ylrrT2d63k7/WP8YNS69FEhIpM01HtpOza08btO/ykiX8vekZunO9lASKJnQckpCIqmGSRpr2TCdV4YoJPf94sF0HhOfzsawsedsoRBnmrBwNySbmxGYftHGj7dhYrkVQ7A0CcF3PhDURZkrLsZFGt9YfE5KQGK3qNWCC7c33Ybs2tZHqgl/Jdmxa0q2ElCC2Y9OW6WBurG5GPAcHFEjXXnstruvyxhtvcM011xS2CyEoLS3llFNOmfQBTjVC05H6k+T8nkhHJrIkUxEuB0S/UBrcO8i0TZT+1utTTVAJ8ta6s7h/19/45ebfctHct9Ge6QBgbmxwsMMxpUt5puUFnmh8ircvvGxSxhNRQ3Rmu4hoYcqZ3vYHgzQg4TXXCyg6juvQnG4lbWXoy/cN6is0HF7Fg/3+toIJS441HWtMdewmi4G+WGkzw+5EA3XRWjRZpSvbje26BCUFRVJIGEnSVmZCfJGHygEF0lVXXQXA6tWrWbBgwZQMaLoRagBsE10RfhvzI5zyUCmmY9KT7yOmRbAdm4ydRZVUsmaSiBqZlhDoY0qXIhA82vB3/mfjvcS1KEElQGVocKHhqBbh9OqTWdv0NNt7d05oV90BhBAElSCNyWZm2aUTfv6xYLs2A4JEl3T68glKg8X05PrIWjmKtDgd2a5h0wP2Zd8IuwFk5AkrqWS71qRoSOMlrHpt0Hf17aYqXElHtmuQ8AnIOm3pdkIzoPDuqMIrFixYQGdnJ6+//jo9PT2DbLf7ak5HApKm49oWAVXyTXZHOEIIqiOVmI5Fn5FAFjJVoUqKA3F68300pVqJDONAngqWly5hbqyOxxqeYmP3FpaXLBlWYzuh8lje6NrEo3ueZE60bszFPEeDKikYjkFjXyu6E5m2qKx9fTOarJI0UqTNDG2Z9oJvxXVdEkaS4gOYMA3bGBR6DyBLErkJCv22xlk2aDIJKgHy/fl5AVkfND5N1kgYSZJGirg+vfVJR/XNevTRR/nEJz7BnDlz2L59OwsXLmTbtm2sWbPmyBNIahBsk0hAIp0zsR0HWZo5qx2fiUUSErOi1fTkgsT1eMH/UBIoRhYyjclmTHv4hMOslfMqM09SzkdIDXHZ/As4ofJY4trw5jJZkrlgzlu4Z8vvebb1Jc6qnZzI17ASoi+foLe3lZAapEiPE9OiU5rvYtgm8n6aR0t/Ts7Ayj6oBOjMdhPXYyOu9nN2HmW/nDZZyOSdidGQxtoLaarQZQ1NUocVlp4W3ETKSFMUiBNUAtNyD6O64ne+8x2++tWv8qc//YlgMMif/vQnvvSlL7FixchZ5YcrQtPBNokHJNJZa9ytLHwOHxRJoTxUNsQZHtdjzI3PJmPlh/gX0lYGWZLJWNlJKaS6L9XhygPm3NRFa1lRupTnW9fTme2atHHE9AhRLYLtODSmWmjPdh78oAnEdEykfQSJLmvkbGNQNQ5FUsjb+QNGjuWs3BBBKgvPZDcRkZeWY89IgQSMqLmpkkJEjZAy0+xO7GFbz04S+eSUR6KOataam5u56KKLBm276qqr+NOf/jQZY5pWJC0IQHHQIZ0zsWxfIB3NhNUQC0vmkLFyBcGTtXKoksrcWB1z47PJ2rlpb+lwzqwz0CSVX2z6Dc80v4i5n5CcSKGpySoxNUJ3tmfCzFyjwRNIg01NsWFKCOmyRscIgjllpMlauSFVP4QQ4LqHHPrtui6Waw0xCR4OeP7CAFHVM8vuSTbSmGoelLfnuu6kpgGMymRXWlpKZ2cnZWVl1NbW8sorr1BcXHxE5iFJmrfaKtUc0jkHyz7y7tFnbET1CHOis9iTbEQWMkIIZkdnofRHKc2Pz6U+0YBr5wd1k51KwmqI9y57B2sbn+ap5md5teMNlhQvpCvnNaHL2jneveQaaiJVE3I9IQSKJNOR7aQuWjsh5zwYhmMWqiscCF3WSRhJurLdxLQoqqziuA6dGS/UP3yAxo62Yx2Sj2zgZT3TfEhjRZGU/o7Nabb37fKKFtsmhmMQ02LURWsm5bqj0pCuvfZa1q9fD8D73/9+3vve93LFFVfwzne+c1IGNZ0I3dOQYrqN47j0pWZGvx2f6SWqR6iL1iJLEnP6ezENEFQCzI3NxnSsaa1sUBwo4qqFl/CuJW8nrIZ4ueN10maGefE56LLGuubnJvR6ATlAXz4xZYmVlm2NWM9wf8JKiNZMO1t7dlCfaGRPopGOXCcxNTJiZXVXcMiN+jyBdHgLo30JKSECko5lmyhCLvw8WYxqKfChD32o8POVV17JSSedRDabPSJDwQdMdnHFADQ6EzlmVUxv/oXPzCCmR4lo4WH9AwFFpzZcTUOqieh+eU1TTV20lvctvx5nn548z7esZ23T0zSlWqiNVE/IdYQQ6JJGW6adubHZk3rPAxF2o72GLMlEpQiu62JYeVwYVP9tOIQrhpg6x4pXNujIMvPLkoyMtxCYbJ/6uDxvNTU1R6QwApD6u8ZGVe+L2dXna0g+ezmQszqmRynSi8hYM6MUy75jPa5iJUElwNPNg+vk9eR6D6mema7opM0MKTM97nOMBtuxx/WaF0KgK/qo+kYpkkJvvu+Q/G0zpczS4cqIGtLZZ589qtXI2rVrJ3I8047o9yFFFU91T6R9geQzOoQQVIcrSJtpDNs8aAmbnJXDdG2iU5Ahr8kaJ1Wu4e9Nz9CcaqUmUsWeZCO/334/ruty86oPjKvZH0BQDtCUamF+fO5B73m82BNUZ+5ABBSdtJVhV2IPs6OzxlVGyNPkfMbLiALpm9/8ZuHnN954gz/96U+85z3voaamhubmZn75y19y5ZVXTsUYpxRJ9QRSSPKiplLZmVcZ2mfmIksyddFadvbVo0jysBpV3sqTd02iahjFtclPUTDEmopVvND2Mk83P8+q8mO4b+fDhNUQCSPJG50bObFqfLUpVVnFsmwako3Mjc2elNwkx3W8gnOTTFgJkbPy7OzbzZzorDG3uHDwNaRDYUSBtG/LiS996UvcddddVFZWFradddZZ3HTTTXzgAx+Y3BFOMQMakoaFIgtSWb8Fhc/YCKlBaiNVNKWaie5TvNV1XZJmirAapjZUQ0gNkjYz7OqrnxKBtK+WtCuxh+pwJdcsuozfb7+flzte4/jK1ePOnwkqAdJWhqZUy6A28xOFPYXBAgFFx7RNdvbtoTLk9RUa7f3Yjn1YhnzPFEY1y+3t7YRCg1cKoVCItraZ1UtjIhjQkHBMYiGVdM6ccW0KfGY+xYEiyoJlpCzPt+K4DkkzRVmwlLmxOkKqFzwTUoKElCD5KcpjOq5iFTEtyoL4XK5ffBVBJcjxFavpzSfY2bf7kM4dVkIkjRSt6XZyVm5CIw69cjwTdrqDosoqETVEe6aTXX31ZK3RNfCznJlVx+5wY1RRdueeey4f+chH+MhHPkJVVRUtLS385Cc/4dxzz53s8U05AxoSpuEJpKyF7bgosr/q8RkbFaEyTMckYSRxHYeqSBWlgeJBvlkhBBXhcur79kxJh1Zd1vjQivcOMqstLlpARA3zUttrh1ygNaKG6c0n6Mn3IfBe7LXh6oIAHi+GbU75i14SElEtQt7Os7N3N/OL5hBUDnwfE1npe3eigc3d27hw7pH3nh2JUf2Fv/jFL3Lsscdyyy23cNVVV3HLLbewevXqQW3OjxQGouywTeJhtb+ena8h+YwdSUjUhKsIKSFqozWUjdBSOqyECCqBKav2MKRsjiSzpmIV9cmGQy49JIQgooaIqmGvorTj0pZpP2QrgznKpNjJQJd1VEmhM9tzwP1c1+0vKTUxxWc3dm/htc43p7QaxnQzqpnTdZ2Pf/zjfPzjH5/s8Uw7QlZAknFtg3hIZWtTCtt2YXKCh3yOcGRJZl589gH3EUJQEaqgPtmANgVa0nCsLjuGp5tfYH3761ww5y0Tdl5d0UkYKTJWlvAYAwT2xZzmgqW6rJPIJzBCZSP+jXJ2nrxtEDtIvtNo6cn1AtCb76NKmf4GiVPBiALpxRdf5MQTTwTg2WefHfEEp546OdWFpxVFA9ukKKySzVvkDYtQYHpK7vscHYTVEAE5MGURd/sTUkMsL1nChq5NrChdOmHJswC6rNKe6TyoYD4QlmMNqdA9lQghEJKgN5egIjx8A8C+fAJlAs2KgwTSDOjYOxWM+Jb94he/yP333w/A5z73uWH3EULw2GOPTc7IphGh6GCZxELe9HQn8xTHhm9B4OMzEQghqI1UsaN3N4pQprStwwAnVx/Pzr7d/HLzb1lctICzZp1GaaD4kM+ryzpJI0nGzIw5jBo8U5jpmGjK9JopQnKQzlwXpcGhc+K4Dj253kGVxw+FvJ0nbWUATyAdLYwokAaEEcDjjz9+SBe59dZbefjhh2lqauK+++5j8eLFQ/axbZsvf/nLPPXUUwgh+NCHPsS11157SNcdN4qGa5vEQ94D0JXIsqA2Pj1j8TlqCCgBaiJVNCZbiOtTX66qNFDMh1a+lxfbXuWF1vVse3MnaypWcWbNKejjTJodQJM02jOdzB2HljTWskGTxYDJMGmkqKJo0GdpM4PtTlzbiZ7cXiHUcxQJpCkxyr71rW/l//7v/6itHbkq8H333ceePXv429/+xq9//Wu+//3v09jYOBXDG4JQvJ5IsZC3Su1KHD1ORZ/ppUiPUxyIF1bHU40ma5xecxIfWvk+ji1fwfr21/jZhl+yuXvbIQUm6IpOysqMqxCr7Tpe5dMZgC7rdOS6hsxFd65nQqMku/O9/dfT6DuKBNKUlA464YQTDrrPgw8+yLXXXoskSZSUlPC2t72Nv/71r9x0000HPXbCUXXcXJpYwJPXqYxfrcFnahBCUBWuINOXJW/lh2gmlmORtXPokjapARBhNcT5c97CyrLlPFz/OH/e+RBv9GxgTelq5sfnjktb0YVKfaKRsmAxUS1CYJTmLdu1Z0wBbVVSSBpJ0sbeBYNhm6SNNOEJLAE14D+aE62jNdM+Yeed6YyqdNBU0NLSQk3N3h4b1dXVtLa2jvk8paWHHuGih8KYuQRzqz2zieVCefnRV/H7aLznkZjquSgqCbKnr4mMkSWo6iiSSsrIoEkqCyOzaE62IgmJoDq5vs3i4nksqbmR5xpf5u+7n+N3PfdRGizm9NkncPKs45ClsRhZQliOTdbM0ummCYsQ84tno8gHDhhK5gVFBInp44/Sm0hClsz27t1URsopCxXTmzWIu2Fi+sQJpHRTknggRl1JFdt6dxKN6yjT4FfcH9M2EUKivGzv8zCRz8aoSgcdTnR1pQ6pRHp5eRTTkbFNg1QiSUCT6ezJ0NGRnMBRznzKy6NH3T2PxHTNRbFbjuqmaettJ2/lKQ2WUh4sxcnIlFBBfaKRbidFSJn8F/Xy6HJOOeM4ntv1BuvbXuUvWx7htebNXD7/wnEkvQpApjXRQzZhURM9cERfXz5JbyqDrc6cCgjxohDbmhrYyh4EAl3W6MlMnJm1NdFJkRpDd0K4uNS3tVESKJqw848X07GQEHS43vMw1mdDksQBlYZRxzJv2rSJl156iZ6enkH203/5l38Z9WAORHV1Nc3NzaxatQoYqjFNKZqOa5vgOMTDGumcheO6E5aB7eMzGoQQRLUIYdXTLPatpK3JGnNjs2lINpG2MoSnQCjJkszyksUsL1nM650b+Vv9E/y/Tb/iygUXUx2uPPgJ9iOkBOnK9xLVokT1kV9SM7EcjyQkwmoIx3UwbXPEpn/jpSfXx9KShRTrXjBVb753RgikyWZUf+Vf//rXvPOd7+S5557jzjvvZOvWrdx9993s2bNnwgZy4YUX8tvf/hbHceju7ubRRx/lggsumLDzjwUvqMECxyEW1sjkTC851sdnGpCENGxbB1VSmB2tRUJgHqSLZ942MCaw0+eqsuXcsNSLgv2/zb9jQ9fmMZ9DCEFICdKUbjlgDyLTNqY1KfZASEIaMQIxZaTHFQiStbLk7BzFehFFBYF0dAQ2jOqv/LOf/Yyf/exn/PCHPyQQCPDDH/6Q7373uyjK6FYFX/7ylznrrLNobW3lxhtv5JJLLgHggx/8IG+88QYAV1xxBbNmzeL888/nuuuu46Mf/Sh1dXXjvK1DRAmAbYJrE494GpLt+GXlfWYeiqQwK1pLxs6N+PJzXRfDNsjbExstWhWu4H3Lrqc2Us39u/7G083Pj/kFrEoKDg5t6Y4R9xlNlYYXW19hbePT09pCfl96cr386PWf80LbK2M+trs/oKEkUERYDfU3DkxM8AhnJqOSKF1dXYVIOUmScByHs88+m0984hOjusjnP/95Pv/5zw/ZfueddxZ+lmV5xtTGE6oOroNrGRSFddJZv56dz8wlrIaoCJbSme0hqg11rKetDKWBYrrzvbju0Hwe27HHnYgbUoNct+gK/lr/OOuan6c3n+DCOeeO6XxhOURPvgdd0SkJFA0RPgerY9eZ7eaJxnW4uDSlWrhywcWHVKZoItiTbMTFZV3TsywqmkfJPgnGr3VsYFvvDq5YcDHqMKa+nv6Q7+L+QrxFWszXkPalqqqqkBM0d+5cHnvsMV566SVU9Qgt8NYfueQaOeIRDcNySPqh3z4zmPJQGQFFG6IF2Y6NEIKyUClRLTqkzYXjOvQafYdkzpMlmYvnvo3Ta07mza5N3L3xXp5oWMfOvt2jKhjrFWSN0JZppz7RWDjGcR0yZhbD8Ux2GTPDC60vDzHvrW1chyqrnDf7HFrTbfzvpl/TlhlZ4xrAcizaJimkujHVgi7ryJLCQ7sfK2iOW3t28Nf6x9jRt5vnWl4a9tjuXC8CTxABFAXiR01y7KgE0k033cSOHTsAuPnmm/nEJz7B+973Pj760Y9O6uCmC1EQSBniYc8+3JMYXT8UH5/pQBIStZFqLNcmt0/vnoydpTJUjiIpFOkxTHew4MlaOWJaDMM5tErjQgjOqDnZi7pTgqxvf5XfbvsLP3jtLnaMos+SJCSiagTDNtjeu4vGZDNbunewq68eXIEkJF5se5UnGtfx4O5HCy/4+kQDO/p2c1rViaypWMW7ll6D4zr83+bfUp9oGPF6ruvy4O5H+X8bfz0p2kdTqoW6SA1vrTuTxlQzr3S8TlOqhft2/pXqcCWLixfwfOtLhXyjfenJ9RLXowUts0iP05fvOyr6so3KZHf11VcXfj777LN54YUXME2TcHji4u5nFP0tKFwrTyzsTVGnL5B8ZjgBJcD8+FyaUs0kjRSarKFJWsExPlBnbV+zne06lAaLaUq2TMgYlpUsZlnJYkzbpCndwtrGp/nj9vu5YsHFLBpFr6WgEsB2bDJmhqCiDzLf7ejbjSZrbOreSkyLcnbtaTzRuI6YFuX4ytUAVIcred+y6/n11j/yu21/4aqFlzI/PmfIdd7s2sym7q0AbOnezsnVx0/I/QNkzAw9+V5WlS1nRekyNnVvZW3jMyiSTFSLcM3Cy3Bcl919e3hkz9+5dtHlg8yoPfleivW9Jr4iPY7pWKStjNfS4whmVBrSV77yFV5//fXC75qmHbnCCJA0L69C2AbxoCeQelN++SCfmY/eHw5eHiwjb+epDlcWXuqKpBBRwxiOpyUZtkFYDRLTokhCwnEnLnBHlVXmxmZz/eKrqQiV86cdD7K5e9uojpUlmYASGCSMEkaSjmwnp1WdyHHlK3m+dT1/2H4/bZkOzq49bVDYdUQL884lV1MSKOYP2+9je++uQefvyfXyyJ611EVqqQpVsLlndOMaLU0pT7jPitQghOCCOeciAIHg2kVXEFJDRLQwZ9Sewq5EPVt7dxSOdV2XntzgEO9CpF3uyDfbjUogua7LzTffzPnnn8/3vvc9du7cOdnjml6UAQ3JJN5f8dsvH+RzuCAJiYpwGYuLFwxx7hdp8YIfKe8YlAVLkYRETItMSoPAgKLzjsVXUh2u5C87/8rD9U9Qn2gYs/AbaK8+v2gub5t9Ngvj89jet4vqUCXLSoYWaw6pIa5fcjXlwTL+uOMBHqlfS0OyCcux+MvOvyILiUvnn8/SksW0ZtqHmO2ebHqWh+sfH2T+HC2NqRYkIRVaRsT1GO9eei3vWXYdxfsImuMrVlMeLOOxhicLc5+2MhiOOWi/4qMo9HtUAunzn/88Tz75JLfccgstLS284x3v4Oqrr+buu++e7PFNCwUfkmUQ1QVCQDLrCySfwwtN1oZE1IXUIAIvYEBCItTfkjumxzAPkAt0KOiyznWLruCY0iW82bWJX239Iz987S7WNj496lD0HX27iWlRygIlSELisvkXckLFsVw0960j1tULKgGuX3wVS4sX8XrnBu7Z8nu+/+qdtGbauXDuW4lpUZYWLwQYpL21Zzp5tuVFXu14k59t+CXbenYMe/6RaEq3UBWqGKS1VYTKCprOAJKQOH/2OSSNFI/ueRLYW8OuWC8q7BfTvNI8vkDad0dJ4vTTT+drX/sa999/P0VFRXzjG9+YzLFNHwOJbpaBwCESVMlkJ+dh9fGZSlRZJagESRhJSgMlBcd5YJKbAmqyxiXzzuefV3+QK+ZfxKxoDc+3rufON3/Bhq7NB3TYW45FfaKBBfsUddVklbfOPovy0PDN8gbQFZ3L5l/APx37QS6bdwFzYnWcVn0SS/oFUVyPUR2uHGS2W9f8HLqscf3iqwgrIf6w4wEe2PW3UQUVWI5Fa7p91A0OZ0VrOLX6RN7o2sjrnRsG5SANoEgKMS3qC6R9yWQy/PnPf+ZDH/oQF1xwAbIs8/Wvf30yxzZtiIGgBtsAxyYW1kjnTD851ueIoCgQAwTxQKywTZVVNEU7YMWEiUCTVZaWLOKqBZfw3mXvIKZFuX/X37h3yx9G1Jb2JJswHYsF8Xnjvq4uaywvXcLVCy/lzNpTBn22tHgRbZkOenK9NKda2da7k5Mq1zAnVsd7l72Dk6uO582uzaOqRtGa6cB2bWZFRl/27Iyak5kTncUj9WvZ1ruj34Q6uGBpkT6xod8dmU6+9+pPC/6umcKoBNLHPvYxTj/9dH7zm99wzjnn8Pjjj3PnnXdyxRVXTPb4pod+gYRt4dpGoZ6d5ZcP8jkCiKgRKsPlQ/r3FGmxIXlKk0l1uJL3LL2OC+acS2OquWC22p+dfbtRJIXZsVmTMo6lxYsA2NKznaeanyOoBDi+8ljAC7A4u/Y0qkOV/L3pmYPmaw284MfSAn7ABBlQAuzo202RHh+SHFykT2xy7GudG8laOZ5senbCzjkRjEogrVy5kgceeID/+7//413vehclJSWTPa5pRQyY7GwTLLO/fJCJafkaks/hjyarVIbKh2wPqyFcpvY7LoTg2PIVnFp9Im92bRoSiee6Ljv6djEnOmvYqgYTQUyPUhOu4sW2V9id2MMpVScMEtZCCM6tO5OUmebFtpcPeK6mVDPFenzMlSLCaojL51+IQAxbRLVIj5OxshMSeOK4Dpu7t6LJGnuSjQfM15pqRiWQPvjBD05f5e3pQFYBgWtbYJmUx4OksiapjB/67XPk4jXME9OSgHla9YlUhyt5uP5xkkaqsL0710NvPsGC+NxJvf7S4kVkrCwRNcxx5SuHfD4rWsOS4oU837p+0Pj2xXW90kVj0Y72pS5ay3WLr+Cs2tOGfDYQEDERZrv6RANpK8P5s88hooZZN44ahJPFzCyhO80IIUDVCia72vIIrgu7W/3+QD5HLpKQvDylKTTbDSBLMpfOuwDbtXlg1yPk7TyJfJIN3VsAmD/JAmlJyUIUSeH0mpNRh6msDnB27WnYrsNTzc8N+3lvvo+MlaV2DP6j/fFyyEqHbC/r33bPlt/z0O5HaUg20ZXtZlvPDp5reYknG5/h1Y432Z3YQ8I48HtqY/cWdFljSfFCTq0+gcZUM/XJmaElTY4OfATgtaAwcG2LWeVeEvCe9jSnHDPNA/PxmURKAsU0JJswzDRhJTilbR9KAkWcW3cWD9c/znde+Ulhe3mwjLgeO8CRh05Mi/LPq286YFv44kARx1es5sW2V3iuoY75oQUFM2LezrO+3SseMF4N6UCUB0t515K383rnRjZ1b+P1zo2DPhcIXPZqORfPPY+VZcuGnMd0LLb27GBJySIUSWFV2TE817Kep5qeY060blyt6ScSXyCNgAjGcbNJcGzK4zqKLGjvyfqN+nyOaCJamMXFC+jJ9dKR68JxHQQCcJFyDpbjTHgzun1ZXXYMipBJWxl0WScg69SEqybtevtyIGE0wGnVJ9GYbOZPmx8mqAQ4tmwFhmPxRucGDMdkQXwuZYHJ8bHXRWupi9Zy3uxz2N63C8e1KdGLKQ0Uo8oqKSNNb76Pp1ue5297nqAqVD4kLH57704Mx+SYkiWAF1J+Ws2JPFz/BDv7drOgaPyRjBOBL5BGQERKcTp3IxDIOFSVhOjszWJaDro6/b3tfXwmC1mSKQuVUhSIk7VySEJCEoJYcYBX+rYQUgKTJpSEEKwYZmU/UwgoOu9Zdh29dPHEjud4tvUlJCGxtHgRJ1QeO67OuWNFk1WWD1OdIqZHielRSoMl/M/Ge/nTjgd57/J3oO+TY7axewsRNUxdtLawbWXpcl5ofYX7d/2Ndy7xSj1NF74PaQSkaBluNoHrOuA61JaF6Urk/Eg7n6MGRVIKLdSDSpCiQIw5sVlkrdyk5yvNZIQQzC+ZzdULL+XmVR/g5lUf4LL5F0yJMBoNAxF7Pfk+/rr78ULAQtbKsbOvnmUliweZYmVJ5rrFV6DKKr/a+kc6Mp3TNXRfII2EiJZ5TfryKXBs6ioipHMW3YnsdA/Nx2faiGoRZkc9oTSRLdEPVwYE9kyjLlrLWbWnsrlnG/+3+Xf8bttf+P22+3Bch+X95rp9KdLjvHPx1chC5ldb/0hntmsaRu0LpBGRop7a6mR6cB2bukovc3pnkx9p53N0E9UjzInVgYCkkSRrZbEdm5yVJ2mmSJopUmYawzZnTDjx0cjJVcdzUuUaAFJmmrydZ0nxwmFz0MAL2njnkqsRQvDLzb/l+db1U64J+z6kEZCi/c7ATKI/0i4CQGPn8DkIPj5HExEtzAJ1Ljk7R3euj5SRIqKFCSshNFkjZ+foyydImWlUSenPcfKZSoQQvKXujDEdUxIo5t1LruHRhidZ2/g0r7S/wZm1p7CoaAHaCOHwE4kvkEZAREpACNxsAmyTophGUJe9SDvHRZL8SDufoxshBEElSG0kOOSzkBqkJFBM3jbY0bsL27ELhVx9ZjbFgSKuXXQ5uxN7eKJhHffv+huSkKgMlVMTruKkyuMm7dq+yW4EhKQgAjHcbB/YBkIIasrCdPXlMCx7uofn43NYoMsateFq0lZmuofiM0bmxmbzvuXXc92iKzi5cg2ykHmtYwM7+uon7Zq+hjQSkoQIxXEyfWB5meuzyiM8+2YredMmoPlT5+MzGmJ6lCIzTtJMEVZmXgCAz8hIQmJefA7z+tvAG7aJPInJ0r6GNCICEYrjZnq9mnbA7MoIhuXQ2nXoqz3XmvryLD4+04EQgspwBQJB3jb2Bj8YKZJGmpSZJmmkydp+BOtMZ7IrOfjL/JGQFEQwDkYGJ+cFMtSVe5F2O5oTLJldfEint3tbkIuqEcrBs8N9fA53VElhVrSG5mQrYTVIWC1DV3RkISOEwHZsdvTtwpGcKS1X5DOz8AXSCAhJ8nKRADfbi+vY1PbXtGvtPjQNyXVdMLLgWIAvkHyODiJqmMUlC4b9TJUUKoLltGc6iGqRKR7ZzKUn39cfuTj5EW4zAX8pcgCkeH+RxEwfODZBXaE4qtPRk8WyD6Fig2Pj2iau4wdH+PgMUBIoQpEUzEPMfXFdl5TlmQJzVh57nM/ZdOdQua6LImRM5+hJQPY1pAMgl3odKt1+gQRQUxamtSuDaTko8jjluWODZeBaR88XbapwLQNsE6GHp3soPmNElmSqw5XsSTaialFc1yVr5bCxob/AqyIUHNfBGWgk6AIIdFlDlRQytpeWURb0Co5mzSwZK0fGyCJJEkE5MCqToO3YJMwkuqwTUoaGtU8FpmOhyepRVRHDF0gHQISKQdG8SLt+gVRXEWHT7m6yeYugPs7pcyxwba8jrc+E4hpZ3HwK2RdIhyVRLUJEDZPIJxFCUKTHKQkW4bouedska2VRJYWgEkSTNQSQMjP05HpImWmK9ThlodK9lbsDnq83bxv05nrpyvXgui5hNXRAwZS1c1SHK8mYWZJGioganvLWDKZjUqTH6LZ7p/S608mUCaRdu3bx6U9/mt7eXoqKirj11luZO3fuoH2+//3vc88991BRUQHAmjVruOWWW6ZqiEMQqtbfhqIP17ERwOyKCI4LO5v7KImNL/vcM9UJMP0OtBONa5uef87nsEQIQVW4kl6ll+JA8aBW4iEViokPOaZYjlMciB8w+VaXNSrDFZQFS+nO9dCW6SCoBIdti+66Li4uxYFiyoKltGc66Mx2EVEjUxpw4eIS1aMkjBSOe3QEe0yZQLrlllt417vexRVXXMGf//xn/uu//ov//d//HbLflVdeyac+9ampGtYBEZKCCBfjJjtx++3a82u8RmEb63s5fknFuFZNrmWAJMM0dOY84rENHMvErwlw+BJQdKqUsVfOHk0lCFmSKQ+VEVSDNCSbsByL4H5ljbJWjmK9qCCsqsKVqJJGS7qVqBqZEE3JdmwkIR3wXC6gSxphNUTWzKIr+oj7HilMicjt6upi48aNXHrppQBceumlbNy4ke7u7qm4/CEhxco9Dalfm6koDlFZHGRbQy85Y5xBCbaBkDUcPxdp4rFMsE2vbYiPzwhE1DAL4vNQZWVIFQnbtSgOFA3aVhospiRQQspMD9qesbL05PtwxvB9c12XlJkiY42syTuugyJkVFklpAYx3KPDvD8lAqmlpYXKykpk2VvByLJMRUUFLS0tQ/Z94IEHuOyyy/jABz7AK6+8MhXDOyAiXuVFxaX2Cs9jF5XR3Jmmfbzh32YeZBUcy39xTjCumff8fX4Eo89B0GSVOdE6NEkrCIe8bRBSQ0O0JoCqcDlhNUTGyuK6LkkjjS7rVIbKSR9AuOxP1spRHCgGwYgRgKZtEupvaxGQAxwtlTNnVFDD9ddfzz/+4z+iqipPP/00N998Mw8++CDFxaNPQi0tPfQchvL+BFiA1Ox5tL8IYZLE+7eff+o8Hn6hgQ0NvZywqnak04xINqci0LANmVBJCKHMzByDfefhcCGTVHBDYYLFQSR94qKjDse5mAyOxHkoKQuzrWsXuC7CllhYModYYPj7LC4NsbVzB725JAtqaqiNVuHgsrHdIKDoKAcxG7quizBslpXNIW1mqe9tpCgwtJxSIudQF6+gNBzFckL0iA5i+vSXXTJtEyEkysv2zs9EfiemRCBVV1fT1taGbdvIsoxt27S3t1NdXT1ov/LyvX06Tj/9dKqrq9m2bRsnnXTSqK/V1ZXCccafP1BeHqWjY2/PI1sUAZBoacTo314UkImHNdZvauO8NbWoytg8FmZnL0ILQS5LOtCD0KYnrPRA7D8PhwOu42D1pEBAur0XEZiYXi6H41xMBkfyPMSdUnb11SMQZBWHfHLk+4w7pYSKFeyUTJfhmfB0M0xzT9tBk3pzVo6AGiTZa+K4EmYaWlM9g9qMAyTNLMWYOBlvHJmkhZFKTnvFdNOxkBB0uN64xvqdkCRxQKVhSkx2paWlLFu2jPvvvx+A+++/n2XLllFSUjJov7a2tsLPmzZtoqmpiXnz5k3FEEdEinvOVTfVXUiUE0KwemEZe9pS9KTG5gdyHRtcByEkXOH6pqWJxLEQ/cYN9yhuse0zdnRZY26sjppw1UGj2QJKgNJQ8aCAhCI9jiIpgxraua47JLnWcEzKAt57TxISVeFK8rYxZD/RP6YBwmpowhNkTcfCnGGpJ1NmsvvCF77Apz/9aX70ox8Ri8W49dZbAfjgBz/Ixz72MVauXMntt9/Ohg0bkCQJVVX5xje+MUhrmg6ErCKCcZxMr5c7JLwpO2lpBU++1sz6zW1cdMrc0Z/QsQsvTVzvxXkg+7Dd24oUK0f4vWQOTr9wF0L2i9f6jJmAEiAwzjeiJCSqQhU0pJoIKyGydg5PxrjIQiakBsnbBmE1REjdaxEJqUFK9CJ6zQQRxcudsxwLTdYGaUNhJURPvpeJbHOY6x+jOoPKEk2ZQFqwYAG//e1vh2y/8847Cz8PCKmZhoiW4mZ6sdt3IRQdFI3FNUUEdZk3d/VwwUlzRt+wz7FwcRHgaUnWyCt513FwM70QisMMNOvNOBwbV3jziuXnePlMLVE9QiCnk7MNyoNlFOkxXFxaMx0k8n24wLzInCHHVYTLSfVlyNsGuqxhOiYxfXC+laZo/VUpJgbHdZCQkCUZy7FQhsnHmg6O/EyrCUCKVuCmurE7duEaGZxEGyLVzsr5pexsTpDKjn417pns+oWXJIOVG3ln28Q1c16yp89B8ebW9ebVTzr2mWIkITEnNpslJQsoD5WiyiqarDE7Wsvc2BxKAyXD9oNSJIXZ0VoM28R2bCzHJqwOXoAOmO8mqr5e3jaI6THKQiVk7ZnzrPgCaRSoy89FKBrGs/eQf+E3uLkkTqaPExaXkTdtXtveNepzuZYJov9LJUle3sxI+9oGWDlc0zc/jQa3PwIISfZzvHymBVVShvVBRbQwNZGqERNhA0qAumgNaTMNuGjS4C4AkpAIKjqWOzE+Z8uxiOtRoloUhvF1TRe+QBoFSvVitLNvQl1xHk5vC/m1P8PpbuSYWh1Flnhhczu2M8p8IstEiH7bsCTjHmB14hp5z2c1hhyHoxrL8Dr9SrKf4+Vz2BHTo1SEKlAkddh2EyE1jDVCYINpm6MWKo7rIIQg1F86KabHyM8QLckXSKNELq5CnnUMgXNvBkXHbtqAZiQ59ZhKNu3uZmdzYnQnsvKeSQlAyLjWAb5IRhqhBnDzvkAaFVYe+oW9cAXYfqSdz+FFWaiE2bHaEbUss9+sty9ZK4fpmiTN5KgqRuRtg7geL1yjJFCE6c6MZ8UXSKNEjlUil80DSSBXL8Fu2YKd7OCyU+sQQvCXp3ePTkuyjYJAEkIgXNeL3hsG18yCGsC18jNGpZ7JuJbpmUHBM4v6IfU+hxmeaW74AKaIGqY2WkPaSheEUtbKIQmJ+fF51EZqSJnpQaHnwzFgrhsgqARQhDLuvlETiS+QxoAUiqNULUKeuwZsE7t1KyUBh9NWVLFxdzc7mvoOeg7HMnAS7VhNG7wNArCHfhFcx8a1DISseC4nP7DhoLi2WRD2LvgCyeeIozhQxOxoHRkrS9rM9AdS1KHJKsWBIuZE68jaOTJmBsM2h2hMrusihCAo7w0gl4REWbCErJ3DciwM2xw2N2oq8AXSGBGKjrrwFESoCKdpI266lyvPmIcsHVxLcl0HbAtz4+MYL/3B6xqL6G9lvh+W4ZmdoD+Bdmao1DMV13G8HK99TB1+cqzPkUhMjzI7NouAoheE0QBRPcKC+FyKA8UoskzOzpE0UqStDI7rkLfzxLXokIoPUS2KJqvYOCiyjCarJM0U+f6OBK7reO8rK+cFW00SMyP4/DBDUgMoc47D3PQEVtceihbVcMbKav7+ajPbGvpYOmeE2nu2BbaN01kPjo3TtQcRKy/0WtoX1zZxhZevhOuZo4Q2zDl9PPap0gD9ybF+6LfPEUpUi4xYpshL8N2rAe3bnNB0LGoig0u2uY6D6jgsCFYWKsm4tkXGMWhNNNNjpAlJCoqQsR0T9AiULpqU+/IF0jhRlp2NuekJnKYNuLNXcfkZ81j3Rit/fnoXi+riyNIwyqdj4/Q2FrQdu2MXaqwCdxjnu2tkwXFw8xmEJOH6iZ4HxrH3htOD32/K56jCtQwQEkIe+krXZY2KQAmlcpB0PomeTWOnesAyccwc2CZC0J+uD95PEkFJZk6gnF4tSpeZJOfYuEiEJjF61RdI40QuqUMqnYPdtBEn2Um8fB7nHFfDoy818uhLjVxw0uyhBzk2dme998WJV+K074SFpw2fHJvPYL75CE5vM/o5H0L4XVAPjGPjwl4dSUh+cqzPEY1rWzi5FG6yo79LsosryUhqwFuQObbni7YtRH8Vk5CLt8AVspcioWiF4s7DZUjJQCk6JVqMrGOQyPVNait3XyCNEyHJKAtPxnj+N9jNmxCqztvPnseGXd384cmdzK+OsaiuaNAxrmPhdNYjlc5GLpuLuXmtF7gwTHKsnenBbtnsfakyPbjDaVw+BTxTwz4bJBnHyvudY30OK1zLwMmnvcWUmS0ENqEFQQ16lUiMDG4+3V+v0UUoOiIY6z+BZ27DtkEIEDJCUxFCOqSeSkIIQrJOMFA8qQLJf8sdAuqi00HRMDc8htWwASXRykeuWI4sCe687036mnZg79PYz0l24SY7kCsWIJV7Vcyd7oYhvg7XtnAaNxSixOz2nbiW4Sd6HgDXMgcFNAhJBttPjp0O/BSF0eG6Tr8GY+LmUtidu7GbN+F0NXjdBUzDy1W0bdx0L053A05PI242CUJGCkSRAjGvvmY/QvRrParu/S8rg56Lmc7hM9IZiBSKo510La5tYjz/K4w3/kaV6OKGU2J0Jgz+3+NN2N1NhcrTdvMmAOTKBUgls0DRsLvqh9aqsw2s5o2IaDkiVoHTth2B6yd6HggrvzcHqR/B0ZUc69omdqJ9WgWC6zjYnbv9+ov74doWbj6NnerC7qzHbNyA1fAmVtNG7ObNWB07vQT4QAwpGEPoIU+oyEq/WS2EFIh5AkgLDusrOhI4Mu9qClHmnYAIxrA2rcXa+hROVz0nrrmK7UvCrN2S5p7n+3jX2S1oFXOwW7eAFkTEqxBCQiqdg9OxC5aejes4iP4Xqt3diNvbgnrMebhGBmv7sziWgWyboMzcUDvXyIIkI6ZjjLaBa+TIPX4H2nGXIVcuOuqSY510D07XHpA15HDR9Iwhm8BNduCEipDDo+/0fDjiuq73vbMMLynbyoHRb+2QpIIfx8lnELbpWZQFCFlDqIFBLWVmaoty13U8E6GZBzOPY2aRS2ZN2vV8gXSISIEobqQEZeWFSGVzMd98hPy6u7n2xOtI5oI8uSNLIrubD14Vx27fiVw+v6BCyxXzMd/YhptNeJF3/QUVzW3PAAJl9iqcZCfWtqc9Nb5y4Yz+4tpde0AI5IoFU96/ybVM7PbtuNkE5rZnkCsX4XLwflNHCq5j4yTaEYEYTk8jkh4acWHgOpbno9BCE+oPcF0XN9GG0MK4yU44QgSS61j9KRsWrmN5Cx+zDautA+G6/e1khCeAJBkQYDmev0eIQuDATPgeuq4LVt7zQeVSuEbGEzhG1tuWT+Hm+v/PpyGfYf++F+qK81Cql0zK+HyBdIgIWUGuWIicT+MEo0ihIozXHsBadzc3rrqYaKCWtVsy/L9freXdbhqpYmHhWLl8HiZ4q9q5a4D+F/vuV5DK5yECUSQtCIqG07Eb18jB0Or1MwI3l/JWUULg9DQhldRNqvNzyPVtE7ttOwBOxy6cZCeo2lGjITnZBDgOQtfANnF6mpHK5gz6G7iui5Ppw+ltBttA6BHkeBUicOC226Mmn8Y180jBGG62D9fKD/JvHC64joWTTUG6G8fIeh2ecQuvZSFkXD2G0EKHHCwwEk66B/P1v+IkWlEWnoYy73jEQXoWuY6Nm03g5pK4+X0ETbYPJ92Dm+7GzfaNbMaWVYQeRuhhpFAxoqQO+n8XagBUHSQFuXSYCOIJwhdIE4AQAgIR5EAEwsVooSjm63/DfvU+ri6bR+2y42nZtQdCsMWsYsXAcbEK0MPYXXu81gkEsZo24Wb7UI55q7ePpCCXz8fp3O2tZsaIVx3CnNQXg+u6OH1t/Y5UHSfdA4qO3N/+fdC+joWTTSDJmvdl3/eF6Tjei1IdW19M13FwrRxO+07k2uWeTX73etTFZxwVybGeZtKO09MIVgVStAwn2wfpbqRQsVd2yjZxEu042aTnn9BCuGYeq307UjCOVDILcYidQ51kR+EcrpBwsknk6MwXSJ7pzfRqRma8lzcuezWbfovGvoJHUnWEmPjFjuvYWNufxdy8FhBI8UrM1x/C2vEc6tJzvNqWuaT3L5vEzacgl8LNJXBzqeFPqmiIcAlSrAJRtRgRiCD0iPe/FvLcCNrIGvWg8dmmH/Z9OCGFiqB4FuKEq7CbNmFueZKTjN9hRzTarCK++2SW4/e08O7TyogGVeTyedgdu7Bat+JaBvaWp0DRUGqW7T1n5ULsls3Y3U0oFfPHNB4n0YbT24YULfO+kJPh3zEyuEYaKVgEgAhEcXtbsIXkaXiSDELCyfTgJDrBtXHAE2CxSiRV91buqS5wXZTqJWMbp2Phdu4Bx0KZewK4LtaeV1EWnY44RIHk5tOYSQOYub478mnsrgaM538DWojAmTciIiU4XQ043U39SY8gJBUptLcTqVB1hKrjGmnsjl3IZXPH/f1wzRxuNlkIPxZqADfVBdGyibjDCcV1bLDyOEYOcimcfAphW/3dhhVPIzhAZJrrutjpXuz2BpxkJ0JSkIprELGKIaZq17Y8bTHTWzCRDdJezKzne7U8XxRWDmwLuXop6qqLEMEYTvt2jDcfwVj/x8EDGRAqgYj3bIfiSME4oj8oAtUTNCjalForDgVfIE0wQgikohqcXApl7hqUOcdh7XgWtj1D8YIVnNwd4IXdWTY2NXLG4ggXlsxBaXyT/CM/KJxDnnPcoNWqXLnQM+21b8ddfBpCkr1Q0XzaU+NlBSRlSOSNnenD7W1DBGO4mV6sdA9SvBIpVDTkxePaJthWIUluLDiJdtx8DnPPU8h1K5FCRbiBKE5fiyd4XNFfRUF4K7GBAqi26fnGwAuGUINgZHAyvcixijEMwMZu3wGqjlQ2BwUXu3kTdts2pLqVY76fAVzXxe5pwjQV3NCccfnFvKizXQg1gBQtL8y767pgZnFM45ADEJxEO9a2Z0ANgJDIP/2/6Gd9ABGKD7u63x+hhXGNjCeUyueNSyg5qa69bVUAIaue+cjMDavxuv35NBPtxxoOd6Dzcj7taRXm3iRzIWteHo8WQuAtQJy2HTi9zTjpbm//XNKzTjgOuA44FtnhTMGSjAgXe/v1h3MznFVDCO++tSBCDSICUYSqe4JD1pAr5iNXLS7sLlcuIlCxwDPtS0q/wAlPuZ92KvAF0iQgZAWldDZ22w4IRlGWnIW86DQCCN7rSqyeneDRDSke2ZDkaSnGDVVrmF0ZoaSkCKEFkeKVnkMRvKoOwRgiWobTsdurMp5NevkIlgmOibAsXEVDLq31XnqSgmvmvKoQuZQnJINxL+Knrw23t9U7Z6TEM5Olu3FyKS+0XAshYhW4zuicVa6Rxe6s94rFZhOYm55ArluJuugMpFj5QeZJRQQHm4lcLYSTaEeKlBWiDodc03Vxc0lvdSgkz3/UvhO5chFCkj3/W7gYu/4V5KpFSLY1vjDZfBrXyOHaQZxsH3K4ZMyncFKdninFyGKlupFiFaBouIl2MHP9eVLzRiWUCkIsmyw4y3FdrKYNOB07UVech1y5kNyT/0N+3f/zhNJAwuTAeDJ92M0bkSKlSJUL9wosLdQvlPoDb8YglFzLwEl1gxrA2rQW18qjrjjP8ydmE8j7CSTXMnB6WnAz3YhImaddjPHl6g60bXEc7wU/IHJdTxjg2DhGBjfTB0a2X/uRvZe+HvUSSDO92D0tuH0tOL0tOL2tno+lHxGMeX7caJmnafRr+kgS4bJKcnIMKVrm3U9vc/899RSCG4SkIIJRRLDIWxwEogg9DGpg1ELYtS3vXEJCLps7pjk6HPEF0iQhAhFEvAIn0eF9oWTvgVOsHMfXyiwtDbO1Lc+6nTI/a1mB0wylIcEJ80Icv7SYOcVBJBcvrDTVg1w+H2vXerKP/AAn0YGb6fVybwoXFIiiWuTKBcg1y7B2r8dp3oKb8xoHilARUulspGh5/0rWc9IKWfPUez2CFIh4poPO3WSdLmwzgBSMeTbmYV4YrmNhNW0g/8JvwXXRT3s3dtt2rN3rsfe8hohVeCWWSmZ5lRN6vQffzaeRa5ejzDnO06YcC7ttB3bjG0ixCuTZq3HzqSEv0wGcTB9Ox07PDFk8C7t9JxgZ5Kol/VMhocw9AXPDI7jJTmx1t7fyH+NLz+5rRSgash7C6WrzNMsxJBm6Rha3t8V7EQkJXAcn0Y6XXR9ABOPgWDjdDUhaYGRNwszhZPtwUt0I2+rPtxI4ro3rgLn1aUQwjjL/JISsop9+A/l1/4/cYz9CKqlDLq5FBKNYTRtx2ncUzi2iZagLT0OuW+ktDrSQt8AYg1ByrTx2xy7cXBLzuV97fqz+e1dXX4Kb6vIWSULgug5OJoHT0+i9kINFnrPdyiOXzfG0KtvEyaXByvdrEDpIKtiGF2CQTeKaGS8R2rsSnrShENVW+G4jeY54LYjb04zd04jT3ehp9OkeT3gNzEWkFKm0DqnoZKTiGqR41QF9mZHiEGaPp/0IQIqUwqzxa+Mjza1r5rxnOzD8szDl2BYoh+ZrPBDCPcLSqru6UjjO+G+pvDxKR0dywsYz0H+k8Ht/yK1j5nEtg1w2S3NHkpf3mGxoMWjq8swJQU1mXk2MZXOKWTMnTEn3qxjP3uup6rFyT4PQwwU138n0YLdtx+1r9S4k5IJwcs08Tle9F5Y9oHkdCC2EGivB0YsQ4WJEvNLz6wTC3kvLBdI9WO3bMV78A8gygdPf663+8cwe1u6XsTt3ey+oAT+OJCPFq0BWcTp3e5tKZ3tC28wW8ja0U96JXLkApXLhkKG5tonZvBmhBMDMIvQw5pansLY8SfDiTxRMjm4+TfavtyNXL0VZcR5yv0AeSesacp18GnPrOow3HqH45EvIqKVIZXOQ9/HBHPB4x8Fu346T6MTpbUKKViAVVQ/7knfNHEjSoHB518zhZBM4yS6E3d94UB26MLAaXsd46Q9ox1+FMnt1Ybvd04S180Wcniav1hkggnHkOceizFqJ09uMue0Z7/uiaF45q9I5/dplCUKWhgil0mKdzu5sQSi7Zh6zdRtO82bMjY+AC9qayz0T4ua/o8w7EWXx6UiRUpxsErtjJ26izas6kOpEyCpK3WqkinmgBpFUDSebwjUznkaC1O//cnHTPViNG3B7mr3vvBb0BIas9Gst/eHWuJ5gsgzP5Jbq8rSk/hg5ES72hE2kFClS6v0frxxz0E9xcYienoyn4bruhJvPBsyMSsV87N5WsHIILXxo53T729j0a5Cua+8V5gxY1d3+IqsuwhW4A4K+H6EFEbFy5FARMPb3pSQJSktHjur0BdJ+TLRAGi2m5ZDIGOxqTrC9qe//t3fmUVYV595+9niG7uacHulmEie4RENkcggIAQcQDJClqCESb4whxOmqiTfeDCYqWQnmXoe7NMn6EnWtLLM0MXrVOF2TKJKY4BAVFaNyUSa7m6bHM5891fdH7XO6W1oGBbqBev6BPnufvWu/p3b96n3rrSq2tmXY2pYhk5cz3ptqY3y60eTo6oCxdRbVFTaEY0kaIELRE/kUIt2OVj0CPVoFZqQsiDtVSN+TcxI8OelNZu6kEPkURrEHp6u1nLmjJRqxxs9CrxmJKGTw3nsBf8vraLEqIjMukj3EARAikHNShECrqiu/uEGuG2/zq/jN/0Qf1oA5eiJ67RgKz/4/ED6Rzy7DHHXcTmNaXsu7FJ67CwIPe+JZ6MlGCmvuQYtUEJ15cb9znX8+i/f2c+i1Y7A+PQ+jdjR69cg9EiV3yzoKz/4Sihk008ae/mX0YfUYjeNkb98rEvRsByNMFLBi/ToefqoNd8Pfcdc90ceT1dCq6tCrR6LXjJKeS2I4mqYTFNIyISYSl/Zyi6BrYPaflS98T65tWMwhnBzuG/8LVoTo7K/L39TJheMLfb7jFhH5Hmn/vvtFCUGw43385rfw2zeXhUuvHYN57AyM+jEYNaPx8yn8LeuI+hnyviGf17Dw3nsJv/VdcAvo1SOxp52LXlGNEAJ3/R/xNvwNY+RxMqTVvqm8yaQWrZLbroR1FcNErxkjx3iynfI8TZe2GtYgM986twKa9LZFIMeE3EK5Lsv0fiHFCU1es6IarSQ6ySaM6lF7lOIu14JzZbJM6GtppaTvsJFOJGKkenKy8db0MOU+vk+ESQQeFLOygxKtRHgO3vYNaLq1S6+1tN8agQ/Cl+H4MKNFC4VGs6JSfMOEFjRd1gldl8/R9/+hHUTp97BjO2ViKkHaDQerIJUQQlBwfNJ5h86eIi0dGTY2p3mvuYfWzt7B2MqITmPSYkRdBaOGJxg5PMHI+gqqoqZsmNwCIt0h00FLDWXYG9LK71a44LymgRmVIRMRQBCQTETo7s4hnIIMw72zBpHvQa8ZTdDTCoGPedQ0zHEz0aP9e25y5rpshDU7ttv5E33xO7ZQXHM3xpgTiJx0Hkb1iPKxIN1B7sn/RKTaZKJGtgu94SiCtvewPj0X65hTdrqet/UNnFcfBdPG/swC9Lox6PGkbPxNu09vMZANv2EjCilyj/4Yke8hcuJ5uK8+gtAM7JMvwBz5qXDMoKW3cQ98hGGiWzFEOHPf3/QK7tur0YY1EJm8WHo73c0EXc3SawxXb9cqqrGOnY4++jNyTAkB+VTo6cqGFcNEpHZIj7Ozd/sSeQGdyGcvRK87QopnolGmX2vaXveoRTGL98F6+VsXMvKaaDvfs4RhY4wYjzHyeIzhx/RrjIUQMl35vRfRolUYjeMwmsbL9HI7Xj4n6PoAf8tr+O2bZVi5shatIokoZGRoLbUdzAjm6M9gjpkIhi1DbZpWbjz3pn6Vyxfu+0Pgh2seit5G2wzD2HZchjJ1A0r3EAEgqKuror2rID8XgiDbGdYJDcxI2LhrA4Z45eTafNnz6D1HyHIg0GqP6DeuKIpZOc8utB3heyoCF9DkBF3dQLciMrnFjKKZZq/gmDbsh3XtlCDthoNdkD5M0fHJFV1SWYe2rjw7egrs6MrT1p2nvSdPZ6qI3+d54xGT2kSU2mERqquiVFea1MZ1qisj1AyzSVZGsGwrfJlNmf5ayMhJc14R0NDMCDX1Sbq6smGkIyDIduN/8E+8TS+jJ0dgfuo0dDsiX2xNk31IEQqcHUOrlAkAQc/23uw935W9Tw052dAceNzEeeN/8f7v71gnLiHyL7NA0xCeQ/5/bydo34x94hKMxnFyvsY7a8B3iZ55JfqHkg6E78o020JGJl1kOtCHH4N55DS0ZCN6KNRBmGFYeg5n3ZMEO94n8tml6DWjiTntdP7pHvTqkVgnfF4ujZPtgnxPGDK1ELohBcUrypDU9g3ow48lMu1c2RPtWy4hEDm5zI/33osEXc0ydbf2CJmIUhx4PomWaMSoGytDf+EcEi1WBXYFoiA7C0ZlbTlpIMh3y95wHy95TxC+i/feS7gb/oZmRTCGH4PRcDSJESPp6eiSE7QDH716FJodkStKD3B9+ZzdaPGk9DbcQumA9FJ1s9xwgybFZaAGPFy+BhGgRSplg19KXPAKaJ6DQJdlMCwwrZ2uIwJfRgECDxDSszVtKXB2HM2ypfdh2HvkQQ/UTgjPIUjvkGndIoxABIHsBGpmGNEoyoVRhw1HMy1AyPMEobjqUgQjO3cm/GynTIbRjLDzZIEdlyJkRgZlfTslSLvhUBOkvgSBwPF8XC+g6PrkCx7ZgkdrZ5bOdJHutENXukBXxiGTd8nm3X5iBfLdr4haVMUtEhU2DdVxRtZXMLKugtoqk4p4jFjEoHF4op8dRDEbTuD10Awb3ALasDr0YcPlRUuhQN3sF1YQgU+Q65ZhxEiFzDayY3IcrWe7DAlqUsxKQwBoBsU1dyHcPHqiSY5b5WXYxp68CPOISb02yacQmQ6McPX08n3dIsJ3ZAp+qk2W/4P1eBtfACeHnhwhEy2yXQMKgDXxLMzRx4OmU11fzY6Xn5Xhsb6YthSyviuKmxE0O4ox8nis407bbY9Uhs3ew333rwSpHRj1Y2WopjZMMw9k2ESLJT4yJT/Ip9Cr6vp5k6VMRJHuIChmpAiU7By6ybLnHJGC6jkyRbs0Z0lQThAg7GwkqyvpyYThG92UobPAldmeIVqf6ws0eV+EzCyrqkO3ojLs6BUhFDYZXio14L5chifcKlmu/6bLrMCK6oETP3xX1icnB4UsgZNFC3rrk9DCa1RU7zJJZ2/Y03ZC+J6ca5RPy3HSilq5eOohsp2MEqTdcCgL0kcRBALXC/CDAD8QBIEg73hkcg6d6SKpnEsm55LJh/8W5P/TOZeeTJGBzBWLmFTGTKriNpUxC12XcXTdKxIzfKqSSZKJSmIRU87XCQQgiEZMKqIWMdvEtnQsU8c0dKriFlF75x6cKGYJnHw5NCJEQNDdgt+xFW/jWilYxaxMJf7UaZhHTQMnC4EII5C94QjQZKPrZBHomPVj0eyYFMV0G6Jnh1yaqeUd/C2vyca4olqG76xoOQyiVYQJEHYMo3YM9Y3VbN/wfzhv/Qk8B6N6lByLCscjymudlZ4h8HvHIMI4fn//oXdkopxKXPIUPKfsdZbO1XRLxvxLyQThygL48lw9lkCvG/OR4lfayI3Ak+Eo3ZBhpmIWketBuHnpbVXWyHFHwwzn3PgyrBSmMTc0JD7y3RCBDGXJMJQI5+LI7T803dzj+W2iFEYTQR+76Hvn4ZXsUxpTKu0LtA/nOx2M7cT+QAnSbjgcBWlXBELgeVKo/EDg+wGO51N0Axw3oOB4dPQU6EoXyBV9Co5H0fUJhEZXKk+u4FFwZXpxIASBEDiu9ND2Bk2Dmqooo+oraKyN4/kB+fB+EctgWNxmWIWNZerkCx6FXAY/nyYR1ampNKiujGBpYQMZryaWqKbShohWRC+kCTynPLAtrBgdegNb2wvohsb40Umq4jbCycsVsTOdQADoOD4UXJ+IoREpjdcKIRv52lFoulmuE362i6DrA9n7hvLqzaUMrvBJQTfRIxUQpnJrxodCU2GDGZS9BE823r4vQ3dhLx6ETF7IdsulgMKyQTg2FxsW3ueT9fhF4O/R9w+1dwNkZ07T2GuxOhRt8XHY14Kk5iEd4uiahm3tvrEJAik2INu8urpKWrenyiImBS0gCMAPpJhl8i5Fx0PTdQxdvtAFxydX9MgVXBxXil8QCFI5OQb2XkuK1zd2YJo6tqljmjquF1AoegN6ar30rfTdwPvh80E0YmIZ0hPTdehKd+D5W/t9u6E6xojaCjJ5l55skXTOoegE/aSkMmpQNyxCstJGM3oQIoVAUFURQQQBtmmQL0Jnqkh3uojjBdQnIjTVxGhIRtB1HQ8dzwfbDIhHXSpigphtYpk6tmVg6JoMtxZ98kWPqB2hLpGgNhnFDwQbtnazflMzm1pT1CdiHHdkDccfOZxEXe+ClvmiS2faoWNHns50D7aVJh6xiEfNMBQbIRbZc4+gJEa+H9CTLZLJe+QKHvmih+fL1ayFgBGNORoqbSIDeLofRoQdF8fzqYhZ5fG63ZEverR25khW2lRX7d2ahrsjk3d4d2sPLZ1ZetIOqZyD7wc01VbwqbHVHDUisUfvyp6QL7ps25HBMg1G1Fbs9XU9P+D1jR1sak3RVFvB2MYqhtfE99iO+4PSbxoIQSyyf6TjgHlI77//Ptdddx3d3d0kk0lWrVrF2LFj+53j+z4rV67kL3/5C5qmsXz5cpYsWbJX91Ee0r5hX9nB8wN8X+D6AUEg8PwAx/XRNA1D19B1mVDruj6ZvIvj+1i6jmHoBAFkCw49WZdUzsHzA4QAEcjr5YoehaJP0fXxvADXD/D8gGFxm/pklLpEDMf1ae7I8UF7lnTOIRoxidkGFVGLqG1gWwa2qVN0fbozDt2ZIrmC16/XHAhB0ZFjd5Ypw49VMRvT1MJxuyKuv+92ptV1jeqqCN3p3oSV0nDOntZs09DCcCrl90EKlk1VXLqCRdcPk2Y8MjmXXHH3mxnqusaI2jhjhlfheD7prAz9Op4vPegwfJx3/PJ9dV2jMmZRFbOwLdlxMA3ZiSnZ2PV8WjtzdGec8r2qqyIc0VhFsjJCT6ZId8ah4HgkKmzqEjFqhkXQNNkJyhe9cmNZ6lyJMILoBwEtHTnaewr9nyX8jUs2tkydRIX01KurIlTGLOywI6Frmgx5h2OzpmXgez66Lr1eLRz2cv2AHd15utJFPF8Qj5g01cX5lzHV1CdjFIoembyLG9bTZFWERIWNBjjh2PBbm7p4+Z02coX+v4dl6jQkYzTWxGmqjVMRrnJSCpm7nny3XD9A13QsU8M0dISQ5fI8WUcrYxYVMZNYxCRf9MnkHTJ5jyAQ8rcxZYjZ80V5vLorXaQzXSCX9zjzxNEsOGUscBB7SD/4wQ9YunQpixYt4pFHHuH666/n17/+db9z/vCHP7Blyxaefvppuru7Wbx4MaeccgqjRu2/DaEU+xfZ+ECEfTdxsK83JxsC2ah4oScnhOjX6PlBgOsJvCDoO8cPTZMepGwYw2GP0niY6A3LVVfHad2exgtFNRIxiNrSKwuEoFD06EgVyoJlGBq+L0jnXdJZl7zjhV6mLLtt6cQiJhHLwPV8OlNFUjmHIIAR9RWMaagkapt4fsC2HRm2bM9QcLzyTrCGrpOotElW2FTELLxA4Lg+jhuQDxu8XMGj6Pno4fiVAAqOR67g09yeDa8jG6x4xKQ+GaMyahKPmkRsWTbb0jF1XSZAoBFoGhu2dPHBjiwvv91GxDaI2SbRiEEsIhfw1HUN09CIWgYR28DUdSl4BdmQFxwfP5CNXznBAtlQ1SdjjBudpD4ZI5V1+KA9y7tbuqWXFZUeoGXq7Ogu8F5LCsft7QTIsUpNPq/WKxClH7qmKsKxoxI01sSprpIepGUaCCHoTDls787R1pUnlXXI5l12dOdx3KBcp0r3iNkGEcvAMHU8LyiLbqlaGaH4jhleSUXUoqOnwAftWR7/++Z+dVjT+s037Yeha4xtqmLCEdWMrKugO12kPVVgR1eBrkyRd7Z28493dwz4XV2T9cMPhbl8P8AwpEU8f+cbW6aOrlEegxZC/ia6Lt+PeNSUHb1EjLrEvvVc+3JABKmjo4O33nqLe+65B4Czzz6bm266ic7OTmpqelN1n3jiCZYsWYKu69TU1HD66afz1FNPcckllxyIYioOEnRd48O70Oi6hmUOPKiv6wbWJ6jpdck4YhdjZhVRi9rERw/al8WTvR+rGDc6CfT2gksNhh42/kbYCH8YIcIMNUEfb0GUBTsQ/c8pfeYHAbombWnoUlxluaGurorW7SkZYnU9hADLkN5sqYEVYUNohJ0BXZM7Cfm+zBD1/IC+KR5Gn0av1ADqZa9JCmzB9TB1nYhlYJk6fiA91lTWwRMBtqlj6Ebo1RKKcO9yQgECUw87AbaBZZSSQ0q2kc8eiJ1dUM8PyBc8ir6HqRtlEa+rraC9I1v+Tum3MA297CWWOjBoGvmCS87xpIBbBkITZHIe3Zki6ZzcTVYKKlQPizI8GSdRaROPmtKL8wM8X3a6iq5POueQzfd68pqmETF1LMsgfDw8T9ocNExTwzJ0dE2GjDMFh3zBx7YMkuF9LDOctB4KmRcE+J7AC0odISl2scj+W9T1gAhSS0sLw4cPxwjXczMMg4aGBlpaWvoJUktLCyNG9KauNjU10draulf32pU7uKfU11d94mscCig79KJsIRkzqnqwizBkaKzbRxsbEnYOQjH8OEkWg8m+fDcOuaQGNYa0b1B26EXZQqLs0IuyhWRfjyEdkNlZTU1NbN++Hd+XYQ/f92lra6OpqWmn85qbm8t/t7S00NjYeCCKqFAoFIpB5oAIUm1tLRMmTOCxxx4D4LHHHmPChAn9wnUA8+bN44EHHiAIAjo7O/nTn/7E3LlzD0QRFQqFQjHIHLD1K374wx9y7733MnfuXO69915uuOEGAL72ta/xxhtvALBo0SJGjRrFmWeeyXnnncdll13G6NGjD1QRFQqFQjGIqJUaPoSKDUuUHXpRtpAoO/SibCE5KMeQFAqFQqHYHUqQFAqFQjEkOOTSvnX9k+fv74trHAooO/SibCFRduhF2UKyN3bY3bmH3BiSQqFQKA5OVMhOoVAoFEMCJUgKhUKhGBIoQVIoFArFkEAJkkKhUCiGBEqQFAqFQjEkUIKkUCgUiiGBEiSFQqFQDAmUICkUCoViSKAESaFQKBRDAiVIIe+//z7nn38+c+fO5fzzz2fTpk2DXaT9xqpVq5gzZw7jx4/n3XffLX++Kxscivbp6uria1/7GnPnzuXzn/88l19+OZ2dnQC89tprLFy4kLlz53LxxRfT0dFR/t6ujh2sXHrppSxcuJDFixezdOlS/vnPfwKHX53oyx133NHvHTnc6gTAnDlzmDdvHosWLWLRokX85S9/AfajLYRCCCHEsmXLxMMPPyyEEOLhhx8Wy5YtG+QS7T9eeukl0dzcLGbPni3eeeed8ue7ssGhaJ+uri6xdu3a8t8/+clPxH/8x38I3/fF6aefLl566SUhhBB33nmnuO6664QQYpfHDmZSqVT5/3/84x/F4sWLhRCHX50o8eabb4qvfvWr5XfkcKwTQoid2gghdv28n9QWSpCEEO3t7WLKlCnC8zwhhBCe54kpU6aIjo6OQS7Z/qVvZduVDQ4X+zz11FPioosuEuvWrRMLFiwof97R0SFOOOEEIYTY5bFDhf/5n/8RX/jCFw7bOlEsFsV5550ntm7dWn5HDtc6MZAg7U9bHHKrfX8cWlpaGD58OIZhAGAYBg0NDbS0tOy0zfqhyq5sIIQ45O0TBAH33Xcfc+bMoaWlhREjRpSP1dTUEAQB3d3duzyWTCYHoeT7ju9+97s8//zzCCH41a9+ddjWidtvv52FCxcyatSo8meHa50A+Na3voUQgilTpnDNNdfsV1uoMSSFArjpppuIx+NceOGFg12UQeNHP/oRq1ev5uqrr+bmm28e7OIMCq+++ipvvvkmS5cuHeyiDAl+85vf8Oijj/Lggw8ihODGG2/cr/dTggQ0NTWxfft2fN8HwPd92traaGpqGuSSHTh2ZYND3T6rVq1i8+bN3Hbbbei6TlNTE83NzeXjnZ2d6LpOMpnc5bFDhcWLF/PCCy/Q2Nh42NWJl156iY0bN3LaaacxZ84cWltb+epXv8rmzZsPyzpR+j1t22bp0qW88sor+/X9UIIE1NbWMmHCBB577DEAHnvsMSZMmHDQhx72hl3Z4FC2zy233MKbb77JnXfeiW3bABx//PEUCgVefvllAO6//37mzZu322MHK9lslpaWlvLfzzzzDIlE4rCsE8uXL+evf/0rzzzzDM888wyNjY3cddddXHLJJYdVnQDI5XKk02kAhBA88cQTTJgwYb++H2qDvpCNGzdy3XXXkUqlGDZsGKtWreKoo44a7GLtF1auXMnTTz9Ne3s71dXVJJNJHn/88V3a4FC0z4YNGzj77LMZO3Ys0WgUgFGjRnHnnXfyyiuv8IMf/IBiscjIkSP56U9/Sl1dHcAujx2MtLe3c+mll5LP59F1nUQiwbe//W2OO+64w65OfJg5c+bwi1/8gnHjxh1WdQJg69atXHHFFfi+TxAEHH300Xzve9+joaFhv9lCCZJCoVAohgQqZKdQKBSKIYESJIVCoVAMCZQgKRQKhWJIoARJoVAoFEMCJUgKhUKhGBIoQVIcclx//fXceeed+/zcT8qjjz7KxRdffEDudTCzbNkyHnjggcEuhmIQUGnfiiHFnDlzWLlyJZ/97GcHuyifiG3btnHaaaexfv16THNwlox89dVXWbVqFffff/+g3P/jsmzZMhYuXMiSJUsGuyiKA4zykBQHFZ7nDXYRDhpWr17NzJkzB7sYCsUeowRJMWS49tpraW5uZsWKFUyaNIlf/vKXbNu2jfHjx/PAAw/wuc99josuugiAK6+8kunTpzNlyhS+9KUvsWHDhvJ1rrvuOm699VYAXnjhBWbOnMndd9/NKaecwowZM3jwwQc/1rldXV2sWLGCyZMnc84553DrrbfyxS9+ccBnKS3SOm3aNCZNmsSrr77KQw891O/88ePH85vf/IYzzzyTSZMmcdttt7FlyxYuuOACJk+ezL/927/hOE75/GeffZZFixYxdepULrjgAt5+++1d2nPNmjXMmjVrp8+LxSLf+ta3OOmkk5g6dSrnnHMO7e3tAKTTab7zne8wY8YMTj31VG699dbyenUAv/vd7zjrrLOYNGkS8+fPZ/369YBctWHZsmVMnTqVBQsW8Oc//7mfjW+44QaWL1/OpEmTWLJkCVu2bCkff/7555k3bx5TpkzhxhtvpG/QZvPmzVx44YVMmTKFk046iauuumqXz6w4yNn7HTIUiv3H7NmzxfPPP1/+e+vWrWLcuHHi2muvFdlsVuTzeSGEEA888IBIp9OiWCyKlStXioULF5a/8+1vf1vccsstQggh1q5dKyZMmCBuu+024TiOWL16tZg4caLo7u7e63OvuuoqcdVVV4lcLic2bNggZs6cKS644IIBn6NUbtd1y589+OCD/c4fN26cWLFihUin0+Ldd98Vxx13nPjyl78stmzZIlKplDjrrLPEQw89JIQQYv369eLkk08Wr732mvA8Tzz00ENi9uzZolgsDnj/7du3ixkzZoggCHY6dt9994mvf/3rIpfLCc/zxBtvvCHS6bQQQohLL71UfP/73xfZbFa0t7eLc845R9x3331CCCGeeOIJMWPGDLFu3ToRBIHYtGmT2LZtm3AcR5x++uni5z//uSgWi+Jvf/ubOOGEE8TGjRvLNj7xxBPFunXrhOu64pprrhFXXXWVEKJ3v5wnn3xSOI4j7rnnHjFhwgTxu9/9TgghxNVXXy1+9rOfCd/3RaFQKG/8pjg0UR6S4qDgiiuuIB6Pl9ecO/fcc6msrMS2ba644grefvvt8kKQH8Y0TS677DIsy2LWrFnE43Hef//9vTrX932efvpprrjiCmKxGMcccwyLFy/+xM91ySWXUFlZybHHHsu4ceOYPn06o0ePpqqqipkzZ/LWW28B8Nvf/pbzzz+fz3zmMxiGwRe+8AUsy+K1114b8LrPPfccp556KpqmDfiM3d3dbN68GcMwOP7446msrKS9vZ3nnnuO73znO8TjcWpra/nXf/1XHn/8cQB+//vfc8kllzBx4kQ0TeOII45g5MiRrFu3jlwux/Lly7Ftm1NOOYXZs2eXvwdw+umnM3HiREzTZOHCheUt0tesWcOxxx7LvHnzsCyLiy66qN+6Z6Zp0tzcTFtbG5FIhKlTp35imyuGLmqDPsVBQWNjY/n/vu9z66238tRTT5WXtwcZUquqqtrpu8lksl9iQSwWI5fLDXifjzq3s7MTz/P6ba+wL7Za6Nv4RiKRnf4uhdKam5t5+OGHuffee8vHXdelra1twOuuWbOGs88+e8BjixYtorW1lWuuuYZUKsXChQu5+uqraW5uxvM8ZsyYUT43CILyc7a0tDBmzJidrtfW1kZjY2P5dwAYMWIE27dvH/A5o9Fo2f6l75bQNK2fXa+99lpuv/12zj33XBKJBF/5ylc499xzB3wuxcGPEiTFQUHfnv4f/vAH/vznP3PPPfcwatQo0uk006ZN6zf2sK+pqanBNE1aW1s58sgjAfpt2bCr8u4LmpqaWLFiBd/4xjd2e67rurz44ov8+Mc/HvC4ZVlcfvnlXH755Wzbto3ly5dz5JFHMmvWLGzbZu3atQNmBjY1NfUb+ynR0NBAa2srQRCURamlpYWxY8futqz19fW0traW/xZC9LNrfX09K1euBODll1/mK1/5CtOmTeOII47Y7bUVBx8qZKcYUtTV1bF169ZdnpPNZrFtm+rqavL5PLfccst+L5dhGJxxxhnccccd5PN5Nm7cyCOPPPKR59fU1KDr+m6fZU9ZsmQJ999/P+vWrUMIQS6XY/Xq1WQymZ3O/cc//sH48eOprKwc8Fpr167lnXfewfd9KisrMU0TXddpaGhg+vTp/OQnPyGTyRAEAVu2bOHFF18EZJj07rvv5s0330QIwebNm/nggw+YOHEi0WiUX/3qV7iuywsvvMAzzzzD/Pnzd/tcs2bNYsOGDTz99NN4nsevf/3rslcI8OSTT5YFK5FIoGlaP09McWihflnFkGL58uX8/Oc/Z+rUqdx1110DnrN48WJGjBjBqaeeyoIFCzjhhBMOSNmuv/560uk006dP59///d9ZsGBBeVO/DxOLxVixYgVf/OIXmTp16keO9ewpn/70p7npppu48cYbmTZtGmeeeSYPPfTQgOc+99xzA2bXlWhvb+fKK69kypQpzJ8/nxNPPJFFixYBcPPNN+O6LvPnz2fatGlceeWV7NixA4CzzjqLFStW8M1vfpPJkydz2WWX0dPTg23b/OIXv2DNmjWcfPLJ3HDDDdx8880cffTRu32umpoabr/9dv7rv/6Lk046ic2bNzN58uTy8TfeeIMlS5YwadIkvvGNb/Dd736X0aNH743pFAcRamKsQvEx+elPf0p7ezurVq0a7KL0Y/78+fz3f/83xxxzzGAXRaHYK5SHpFDsIRs3buTtt99GCMHrr7/O73//e84444zBLlY/HMdh8eLFSowUByXKQ1Io9pDXX3+db37zm7S1tVFbW8v555/P8uXL93kCg0JxuKIESaFQKBRDAhWyUygUCsWQQAmSQqFQKIYESpAUCoVCMSRQgqRQKBSKIYESJIVCoVAMCZQgKRQKhWJI8P8B5KIhHa99aHcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the training process with confidence interval\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "df_plot = dfs1.loc[(dfs1['training time / seconds'] <= 500)]\n",
    "plt.figure()\n",
    "sns.lineplot(data=df_plot, x=\"training time / seconds\", y=\"validation loss\",hue='model')\n",
    "plt.tight_layout()\n",
    "plt.plot()\n",
    "plt.savefig('CharTrajectories/notebooks/CT_val_loss.png',format='png',dpi=350)\n",
    "plt.figure()\n",
    "sns.lineplot(data=df_plot, x=\"training time / seconds\", y=\"validation accuracy\",hue='model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('CharTrajectories/notebooks/CT_val_acc.png',format='png',dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lr_df(model,drop_rate,epochs,param,lr):\n",
    "    config_dir = 'CharTrajectories/configs/train_'+model+'.yaml'\n",
    "    with open(config_dir) as file:\n",
    "        config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    config.drop_rate = drop_rate\n",
    "    #config.param = 'orthogonal'\n",
    "    config.gamma = 1\n",
    "    config.lr = lr\n",
    "    config.epochs = epochs \n",
    "    config.param = param\n",
    "    test_acc = main(config=config,return_loss=False,return_test_acc=True)\n",
    "    return pd.DataFrame([[model+'_'+param,test_acc,lr]],columns=list(['model','test accuracy', 'learning rate']))\n",
    "\n",
    "\n",
    "def get_lr_acc(lr_list,models,params,runs):\n",
    "    dfs = []\n",
    "    for i in range(runs):\n",
    "        for model in models:\n",
    "            for param in params:\n",
    "                for lr in lr_list:\n",
    "                    df = create_lr_df(model,drop_rate=0.3,epochs=100,param=param,lr=lr)\n",
    "                    \n",
    "                    dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhangl\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kr0ri7r\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 02:12:45.921329\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.8066 Acc: 0.7860\n",
      "2022-01-23 02:12:48.500598\n",
      "validation Loss: 0.2281 Acc: 0.9324\n",
      "2022-01-23 02:12:48.877641\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2032 Acc: 0.9370\n",
      "2022-01-23 02:12:51.674180\n",
      "validation Loss: 0.1752 Acc: 0.9487\n",
      "2022-01-23 02:12:52.096551\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1702 Acc: 0.9415\n",
      "2022-01-23 02:12:54.819803\n",
      "validation Loss: 0.1644 Acc: 0.9417\n",
      "2022-01-23 02:12:55.262607\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0908 Acc: 0.9740\n",
      "2022-01-23 02:12:57.777615\n",
      "validation Loss: 0.1196 Acc: 0.9604\n",
      "2022-01-23 02:12:58.156376\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0768 Acc: 0.9740\n",
      "2022-01-23 02:13:00.909022\n",
      "validation Loss: 0.1271 Acc: 0.9557\n",
      "2022-01-23 02:13:01.314954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0646 Acc: 0.9815\n",
      "2022-01-23 02:13:03.677676\n",
      "validation Loss: 0.1017 Acc: 0.9744\n",
      "2022-01-23 02:13:04.057117\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0473 Acc: 0.9870\n",
      "2022-01-23 02:13:06.328979\n",
      "validation Loss: 0.0991 Acc: 0.9580\n",
      "2022-01-23 02:13:06.738111\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0611 Acc: 0.9780\n",
      "2022-01-23 02:13:09.200961\n",
      "validation Loss: 0.2167 Acc: 0.9394\n",
      "2022-01-23 02:13:09.640437\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0738 Acc: 0.9760\n",
      "2022-01-23 02:13:12.140586\n",
      "validation Loss: 0.1101 Acc: 0.9674\n",
      "2022-01-23 02:13:12.511161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0395 Acc: 0.9875\n",
      "2022-01-23 02:13:14.887106\n",
      "validation Loss: 0.0913 Acc: 0.9814\n",
      "2022-01-23 02:13:15.242025\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0440 Acc: 0.9855\n",
      "2022-01-23 02:13:18.002945\n",
      "validation Loss: 0.1303 Acc: 0.9510\n",
      "2022-01-23 02:13:18.367067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0313 Acc: 0.9905\n",
      "2022-01-23 02:13:20.832355\n",
      "validation Loss: 0.0658 Acc: 0.9790\n",
      "2022-01-23 02:13:21.189623\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0200 Acc: 0.9920\n",
      "2022-01-23 02:13:23.554449\n",
      "validation Loss: 0.0781 Acc: 0.9790\n",
      "2022-01-23 02:13:23.975849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0598 Acc: 0.9810\n",
      "2022-01-23 02:13:26.397347\n",
      "validation Loss: 0.1076 Acc: 0.9627\n",
      "2022-01-23 02:13:26.821089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0285 Acc: 0.9910\n",
      "2022-01-23 02:13:29.294361\n",
      "validation Loss: 0.0931 Acc: 0.9720\n",
      "2022-01-23 02:13:29.669434\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0198 Acc: 0.9940\n",
      "2022-01-23 02:13:32.105793\n",
      "validation Loss: 0.0743 Acc: 0.9744\n",
      "2022-01-23 02:13:32.520912\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0118 Acc: 0.9965\n",
      "2022-01-23 02:13:34.925622\n",
      "validation Loss: 0.0657 Acc: 0.9814\n",
      "2022-01-23 02:13:35.351874\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9945\n",
      "2022-01-23 02:13:38.210102\n",
      "validation Loss: 0.0818 Acc: 0.9720\n",
      "2022-01-23 02:13:38.566664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0148 Acc: 0.9950\n",
      "2022-01-23 02:13:41.012043\n",
      "validation Loss: 0.0987 Acc: 0.9744\n",
      "2022-01-23 02:13:41.432890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0778 Acc: 0.9740\n",
      "2022-01-23 02:13:43.948460\n",
      "validation Loss: 0.1464 Acc: 0.9650\n",
      "2022-01-23 02:13:44.363883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0550 Acc: 0.9810\n",
      "2022-01-23 02:13:46.823802\n",
      "validation Loss: 0.1070 Acc: 0.9650\n",
      "2022-01-23 02:13:47.238945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0609 Acc: 0.9835\n",
      "2022-01-23 02:13:49.683355\n",
      "validation Loss: 0.2151 Acc: 0.9441\n",
      "2022-01-23 02:13:50.060385\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0960 Acc: 0.9725\n",
      "2022-01-23 02:13:52.519975\n",
      "validation Loss: 0.1331 Acc: 0.9674\n",
      "2022-01-23 02:13:52.901339\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0703 Acc: 0.9785\n",
      "2022-01-23 02:13:55.480636\n",
      "validation Loss: 0.1548 Acc: 0.9580\n",
      "2022-01-23 02:13:55.844218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0256 Acc: 0.9935\n",
      "2022-01-23 02:13:58.405894\n",
      "validation Loss: 0.0932 Acc: 0.9767\n",
      "2022-01-23 02:13:58.772606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0277 Acc: 0.9900\n",
      "2022-01-23 02:14:01.213598\n",
      "validation Loss: 0.1069 Acc: 0.9837\n",
      "2022-01-23 02:14:01.597222\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0212 Acc: 0.9915\n",
      "2022-01-23 02:14:04.556093\n",
      "validation Loss: 0.1200 Acc: 0.9837\n",
      "2022-01-23 02:14:04.982997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0285 Acc: 0.9915\n",
      "2022-01-23 02:14:07.577445\n",
      "validation Loss: 0.1050 Acc: 0.9744\n",
      "2022-01-23 02:14:07.931576\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9975\n",
      "2022-01-23 02:14:10.308888\n",
      "validation Loss: 0.0588 Acc: 0.9860\n",
      "2022-01-23 02:14:10.661936\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 0.9985\n",
      "2022-01-23 02:14:13.498180\n",
      "validation Loss: 0.0868 Acc: 0.9767\n",
      "2022-01-23 02:14:13.897525\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "2022-01-23 02:14:16.439958\n",
      "validation Loss: 0.0557 Acc: 0.9814\n",
      "2022-01-23 02:14:16.830067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 0.9990\n",
      "2022-01-23 02:14:19.438842\n",
      "validation Loss: 0.0661 Acc: 0.9860\n",
      "2022-01-23 02:14:19.788330\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:14:22.248430\n",
      "validation Loss: 0.0579 Acc: 0.9883\n",
      "2022-01-23 02:14:22.600945\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:14:25.489322\n",
      "validation Loss: 0.0680 Acc: 0.9837\n",
      "2022-01-23 02:14:25.871146\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:14:28.355069\n",
      "validation Loss: 0.0711 Acc: 0.9860\n",
      "2022-01-23 02:14:28.749312\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:14:31.220023\n",
      "validation Loss: 0.0667 Acc: 0.9860\n",
      "2022-01-23 02:14:31.589706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:14:33.956121\n",
      "validation Loss: 0.0622 Acc: 0.9883\n",
      "2022-01-23 02:14:34.396564\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:14:36.809200\n",
      "validation Loss: 0.0656 Acc: 0.9860\n",
      "2022-01-23 02:14:37.177197\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:39.627136\n",
      "validation Loss: 0.0676 Acc: 0.9837\n",
      "2022-01-23 02:14:40.033006\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:41.419708\n",
      "validation Loss: 0.0661 Acc: 0.9860\n",
      "2022-01-23 02:14:41.838602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:44.278761\n",
      "validation Loss: 0.0705 Acc: 0.9837\n",
      "2022-01-23 02:14:44.705354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:47.212721\n",
      "validation Loss: 0.0667 Acc: 0.9860\n",
      "2022-01-23 02:14:47.625139\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:50.002232\n",
      "validation Loss: 0.0659 Acc: 0.9860\n",
      "2022-01-23 02:14:50.431688\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:52.989946\n",
      "validation Loss: 0.0683 Acc: 0.9837\n",
      "2022-01-23 02:14:53.357954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:55.806410\n",
      "validation Loss: 0.0689 Acc: 0.9837\n",
      "2022-01-23 02:14:56.190659\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:14:58.644141\n",
      "validation Loss: 0.0668 Acc: 0.9837\n",
      "2022-01-23 02:14:59.003296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:15:01.417004\n",
      "validation Loss: 0.0661 Acc: 0.9837\n",
      "2022-01-23 02:15:01.813940\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:04.308792\n",
      "validation Loss: 0.0668 Acc: 0.9837\n",
      "2022-01-23 02:15:04.652184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:07.039361\n",
      "validation Loss: 0.0675 Acc: 0.9837\n",
      "2022-01-23 02:15:07.456631\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:09.814776\n",
      "validation Loss: 0.0642 Acc: 0.9837\n",
      "2022-01-23 02:15:10.262628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:12.729519\n",
      "validation Loss: 0.0684 Acc: 0.9837\n",
      "2022-01-23 02:15:13.125000\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:15.527163\n",
      "validation Loss: 0.0692 Acc: 0.9837\n",
      "2022-01-23 02:15:15.913002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:18.296709\n",
      "validation Loss: 0.0718 Acc: 0.9837\n",
      "2022-01-23 02:15:18.729041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:21.092514\n",
      "validation Loss: 0.0667 Acc: 0.9837\n",
      "2022-01-23 02:15:21.466906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:23.830685\n",
      "validation Loss: 0.0713 Acc: 0.9837\n",
      "2022-01-23 02:15:24.184879\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:26.539646\n",
      "validation Loss: 0.0696 Acc: 0.9837\n",
      "2022-01-23 02:15:26.950110\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:29.435241\n",
      "validation Loss: 0.0695 Acc: 0.9837\n",
      "2022-01-23 02:15:29.808308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:32.193703\n",
      "validation Loss: 0.0677 Acc: 0.9837\n",
      "2022-01-23 02:15:32.579032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:34.896971\n",
      "validation Loss: 0.0683 Acc: 0.9837\n",
      "2022-01-23 02:15:35.270707\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:37.755203\n",
      "validation Loss: 0.0699 Acc: 0.9837\n",
      "2022-01-23 02:15:38.152358\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:40.659884\n",
      "validation Loss: 0.0674 Acc: 0.9837\n",
      "2022-01-23 02:15:41.029706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:43.468724\n",
      "validation Loss: 0.0693 Acc: 0.9837\n",
      "2022-01-23 02:15:43.813273\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:46.275727\n",
      "validation Loss: 0.0701 Acc: 0.9837\n",
      "2022-01-23 02:15:46.651157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:48.062551\n",
      "validation Loss: 0.0681 Acc: 0.9837\n",
      "2022-01-23 02:15:48.408843\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:50.805323\n",
      "validation Loss: 0.0693 Acc: 0.9837\n",
      "2022-01-23 02:15:51.163717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:53.632702\n",
      "validation Loss: 0.0708 Acc: 0.9837\n",
      "2022-01-23 02:15:54.015930\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:56.614494\n",
      "validation Loss: 0.0711 Acc: 0.9837\n",
      "2022-01-23 02:15:56.983583\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:15:59.610961\n",
      "validation Loss: 0.0675 Acc: 0.9837\n",
      "2022-01-23 02:16:00.002177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:02.513035\n",
      "validation Loss: 0.0717 Acc: 0.9837\n",
      "2022-01-23 02:16:02.895814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:05.544017\n",
      "validation Loss: 0.0684 Acc: 0.9837\n",
      "2022-01-23 02:16:05.975574\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:08.437385\n",
      "validation Loss: 0.0698 Acc: 0.9837\n",
      "2022-01-23 02:16:08.806029\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:11.299711\n",
      "validation Loss: 0.0704 Acc: 0.9837\n",
      "2022-01-23 02:16:11.646777\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:14.099968\n",
      "validation Loss: 0.0689 Acc: 0.9837\n",
      "2022-01-23 02:16:14.489383\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:17.075694\n",
      "validation Loss: 0.0699 Acc: 0.9837\n",
      "2022-01-23 02:16:17.464477\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:19.968203\n",
      "validation Loss: 0.0717 Acc: 0.9837\n",
      "2022-01-23 02:16:20.334315\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:22.785202\n",
      "validation Loss: 0.0711 Acc: 0.9860\n",
      "2022-01-23 02:16:23.172681\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:25.613370\n",
      "validation Loss: 0.0706 Acc: 0.9837\n",
      "2022-01-23 02:16:25.991427\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:28.466754\n",
      "validation Loss: 0.0700 Acc: 0.9837\n",
      "2022-01-23 02:16:28.869150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:31.339495\n",
      "validation Loss: 0.0693 Acc: 0.9837\n",
      "2022-01-23 02:16:31.767945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:34.219051\n",
      "validation Loss: 0.0708 Acc: 0.9860\n",
      "2022-01-23 02:16:34.589021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:16:37.086701\n",
      "validation Loss: 0.0722 Acc: 0.9837\n",
      "2022-01-23 02:16:37.477715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:39.945153\n",
      "validation Loss: 0.0707 Acc: 0.9837\n",
      "2022-01-23 02:16:40.317824\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:42.789752\n",
      "validation Loss: 0.0693 Acc: 0.9837\n",
      "2022-01-23 02:16:43.173532\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:45.688619\n",
      "validation Loss: 0.0708 Acc: 0.9837\n",
      "2022-01-23 02:16:46.064714\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:48.495911\n",
      "validation Loss: 0.0721 Acc: 0.9837\n",
      "2022-01-23 02:16:48.950833\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:50.330778\n",
      "validation Loss: 0.0711 Acc: 0.9837\n",
      "2022-01-23 02:16:50.709151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:53.108751\n",
      "validation Loss: 0.0744 Acc: 0.9860\n",
      "2022-01-23 02:16:53.483304\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:55.946546\n",
      "validation Loss: 0.0747 Acc: 0.9837\n",
      "2022-01-23 02:16:56.314883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:16:58.770473\n",
      "validation Loss: 0.0709 Acc: 0.9860\n",
      "2022-01-23 02:16:59.140290\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:01.601285\n",
      "validation Loss: 0.0730 Acc: 0.9860\n",
      "2022-01-23 02:17:01.992893\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:04.378606\n",
      "validation Loss: 0.0719 Acc: 0.9860\n",
      "2022-01-23 02:17:04.746753\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:07.204113\n",
      "validation Loss: 0.0737 Acc: 0.9837\n",
      "2022-01-23 02:17:07.587071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:09.981453\n",
      "validation Loss: 0.0735 Acc: 0.9837\n",
      "2022-01-23 02:17:10.364849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:12.801298\n",
      "validation Loss: 0.0723 Acc: 0.9860\n",
      "2022-01-23 02:17:13.212475\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:15.651319\n",
      "validation Loss: 0.0705 Acc: 0.9860\n",
      "2022-01-23 02:17:16.009150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:18.559294\n",
      "validation Loss: 0.0701 Acc: 0.9860\n",
      "2022-01-23 02:17:18.976425\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:21.529355\n",
      "validation Loss: 0.0714 Acc: 0.9837\n",
      "2022-01-23 02:17:21.929065\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:24.462719\n",
      "validation Loss: 0.0728 Acc: 0.9860\n",
      "2022-01-23 02:17:24.848679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:27.315731\n",
      "validation Loss: 0.0717 Acc: 0.9860\n",
      "2022-01-23 02:17:27.717581\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:17:30.051580\n",
      "validation Loss: 0.0721 Acc: 0.9860\n",
      "2022-01-23 02:17:30.442390\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3kr0ri7r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8960... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▁▄▆▇█▆▇█</td></tr><tr><td>accuracy_train</td><td>▁▆▇▇████▇▇██████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▂▆▂▃▇▆▆▅▆█▆▇███████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃█▄▂▂▂▃▄▃▃▁▂▁▁▂▂▁▁▂▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98601</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.05793</td></tr><tr><td>loss_train</td><td>3e-05</td></tr><tr><td>loss_validation</td><td>0.07209</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kr0ri7r\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3kr0ri7r</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_021238-3kr0ri7r/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3kr0ri7r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1i88kr12\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 02:17:40.324386\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.1624 Acc: 0.6985\n",
      "2022-01-23 02:17:42.880858\n",
      "validation Loss: 0.3452 Acc: 0.9138\n",
      "2022-01-23 02:17:43.243984\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2038 Acc: 0.9565\n",
      "2022-01-23 02:17:46.083494\n",
      "validation Loss: 0.1528 Acc: 0.9487\n",
      "2022-01-23 02:17:46.439076\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1202 Acc: 0.9705\n",
      "2022-01-23 02:17:49.217817\n",
      "validation Loss: 0.1191 Acc: 0.9650\n",
      "2022-01-23 02:17:49.598870\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0859 Acc: 0.9760\n",
      "2022-01-23 02:17:52.401774\n",
      "validation Loss: 0.1144 Acc: 0.9534\n",
      "2022-01-23 02:17:52.776249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0697 Acc: 0.9835\n",
      "2022-01-23 02:17:55.213557\n",
      "validation Loss: 0.1110 Acc: 0.9650\n",
      "2022-01-23 02:17:55.596581\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0904 Acc: 0.9705\n",
      "2022-01-23 02:17:58.460326\n",
      "validation Loss: 0.1134 Acc: 0.9650\n",
      "2022-01-23 02:17:58.841917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0655 Acc: 0.9795\n",
      "2022-01-23 02:18:01.385276\n",
      "validation Loss: 0.0823 Acc: 0.9720\n",
      "2022-01-23 02:18:01.788946\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0532 Acc: 0.9850\n",
      "2022-01-23 02:18:04.616213\n",
      "validation Loss: 0.0919 Acc: 0.9720\n",
      "2022-01-23 02:18:04.984828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0514 Acc: 0.9865\n",
      "2022-01-23 02:18:07.518861\n",
      "validation Loss: 0.0617 Acc: 0.9767\n",
      "2022-01-23 02:18:07.874546\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0242 Acc: 0.9940\n",
      "2022-01-23 02:18:10.800491\n",
      "validation Loss: 0.0612 Acc: 0.9790\n",
      "2022-01-23 02:18:11.181496\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0547 Acc: 0.9865\n",
      "2022-01-23 02:18:14.104154\n",
      "validation Loss: 0.0594 Acc: 0.9790\n",
      "2022-01-23 02:18:14.544227\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0174 Acc: 0.9965\n",
      "2022-01-23 02:18:17.579821\n",
      "validation Loss: 0.0803 Acc: 0.9744\n",
      "2022-01-23 02:18:17.959569\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0296 Acc: 0.9920\n",
      "2022-01-23 02:18:20.142418\n",
      "validation Loss: 0.0609 Acc: 0.9814\n",
      "2022-01-23 02:18:20.597743\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0186 Acc: 0.9950\n",
      "2022-01-23 02:18:23.466453\n",
      "validation Loss: 0.0815 Acc: 0.9744\n",
      "2022-01-23 02:18:23.961164\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0193 Acc: 0.9945\n",
      "2022-01-23 02:18:26.374712\n",
      "validation Loss: 0.0782 Acc: 0.9837\n",
      "2022-01-23 02:18:26.760813\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0321 Acc: 0.9915\n",
      "2022-01-23 02:18:29.611322\n",
      "validation Loss: 0.0863 Acc: 0.9697\n",
      "2022-01-23 02:18:29.984915\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0329 Acc: 0.9920\n",
      "2022-01-23 02:18:32.401980\n",
      "validation Loss: 0.0635 Acc: 0.9767\n",
      "2022-01-23 02:18:32.790375\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9960\n",
      "2022-01-23 02:18:35.214890\n",
      "validation Loss: 0.0479 Acc: 0.9837\n",
      "2022-01-23 02:18:35.614937\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0118 Acc: 0.9965\n",
      "2022-01-23 02:18:38.477044\n",
      "validation Loss: 0.0602 Acc: 0.9814\n",
      "2022-01-23 02:18:38.850865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0108 Acc: 0.9970\n",
      "2022-01-23 02:18:41.342966\n",
      "validation Loss: 0.0632 Acc: 0.9814\n",
      "2022-01-23 02:18:41.761208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0167 Acc: 0.9960\n",
      "2022-01-23 02:18:44.337104\n",
      "validation Loss: 0.0808 Acc: 0.9720\n",
      "2022-01-23 02:18:44.709561\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0092 Acc: 0.9980\n",
      "2022-01-23 02:18:47.197822\n",
      "validation Loss: 0.0693 Acc: 0.9790\n",
      "2022-01-23 02:18:47.571833\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0159 Acc: 0.9950\n",
      "2022-01-23 02:18:49.932079\n",
      "validation Loss: 0.1021 Acc: 0.9744\n",
      "2022-01-23 02:18:50.292106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0212 Acc: 0.9930\n",
      "2022-01-23 02:18:52.859818\n",
      "validation Loss: 0.1013 Acc: 0.9720\n",
      "2022-01-23 02:18:53.273764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0485 Acc: 0.9855\n",
      "2022-01-23 02:18:55.800981\n",
      "validation Loss: 0.0735 Acc: 0.9744\n",
      "2022-01-23 02:18:56.193054\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0164 Acc: 0.9940\n",
      "2022-01-23 02:18:58.803310\n",
      "validation Loss: 0.0537 Acc: 0.9814\n",
      "2022-01-23 02:18:59.218354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0123 Acc: 0.9955\n",
      "2022-01-23 02:19:01.890786\n",
      "validation Loss: 0.1081 Acc: 0.9720\n",
      "2022-01-23 02:19:02.263755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0198 Acc: 0.9950\n",
      "2022-01-23 02:19:04.715855\n",
      "validation Loss: 0.0662 Acc: 0.9720\n",
      "2022-01-23 02:19:05.117981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 0.9955\n",
      "2022-01-23 02:19:07.734041\n",
      "validation Loss: 0.0845 Acc: 0.9744\n",
      "2022-01-23 02:19:08.142627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9995\n",
      "2022-01-23 02:19:09.518596\n",
      "validation Loss: 0.0420 Acc: 0.9907\n",
      "2022-01-23 02:19:09.874551\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 02:19:12.818207\n",
      "validation Loss: 0.0417 Acc: 0.9907\n",
      "2022-01-23 02:19:13.176973\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 02:19:16.088899\n",
      "validation Loss: 0.0496 Acc: 0.9837\n",
      "2022-01-23 02:19:16.486953\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 02:19:18.947863\n",
      "validation Loss: 0.0449 Acc: 0.9883\n",
      "2022-01-23 02:19:19.308081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 02:19:21.795483\n",
      "validation Loss: 0.0450 Acc: 0.9883\n",
      "2022-01-23 02:19:22.282820\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:19:24.811450\n",
      "validation Loss: 0.0457 Acc: 0.9883\n",
      "2022-01-23 02:19:25.194714\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:19:27.761722\n",
      "validation Loss: 0.0441 Acc: 0.9883\n",
      "2022-01-23 02:19:28.197507\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:19:30.594480\n",
      "validation Loss: 0.0473 Acc: 0.9883\n",
      "2022-01-23 02:19:31.003141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:19:33.480839\n",
      "validation Loss: 0.0426 Acc: 0.9883\n",
      "2022-01-23 02:19:33.870129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:19:36.383921\n",
      "validation Loss: 0.0466 Acc: 0.9883\n",
      "2022-01-23 02:19:36.728332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:19:39.125610\n",
      "validation Loss: 0.0437 Acc: 0.9883\n",
      "2022-01-23 02:19:39.538673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:19:41.920030\n",
      "validation Loss: 0.0425 Acc: 0.9883\n",
      "2022-01-23 02:19:42.342390\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:19:44.726856\n",
      "validation Loss: 0.0449 Acc: 0.9883\n",
      "2022-01-23 02:19:45.124202\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:19:47.184449\n",
      "validation Loss: 0.0437 Acc: 0.9883\n",
      "2022-01-23 02:19:47.591988\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:19:50.035736\n",
      "validation Loss: 0.0464 Acc: 0.9883\n",
      "2022-01-23 02:19:50.503328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:19:52.853849\n",
      "validation Loss: 0.0461 Acc: 0.9883\n",
      "2022-01-23 02:19:53.250604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:19:54.638549\n",
      "validation Loss: 0.0428 Acc: 0.9883\n",
      "2022-01-23 02:19:55.026722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:19:57.574195\n",
      "validation Loss: 0.0427 Acc: 0.9883\n",
      "2022-01-23 02:19:57.942308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:20:00.574405\n",
      "validation Loss: 0.0433 Acc: 0.9883\n",
      "2022-01-23 02:20:00.945402\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:20:03.377176\n",
      "validation Loss: 0.0414 Acc: 0.9883\n",
      "2022-01-23 02:20:03.730842\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:20:06.372732\n",
      "validation Loss: 0.0440 Acc: 0.9883\n",
      "2022-01-23 02:20:06.787054\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:20:09.204102\n",
      "validation Loss: 0.0431 Acc: 0.9883\n",
      "2022-01-23 02:20:09.590335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:12.189138\n",
      "validation Loss: 0.0477 Acc: 0.9883\n",
      "2022-01-23 02:20:12.574245\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:15.057104\n",
      "validation Loss: 0.0471 Acc: 0.9883\n",
      "2022-01-23 02:20:15.418264\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:17.991242\n",
      "validation Loss: 0.0484 Acc: 0.9883\n",
      "2022-01-23 02:20:18.384121\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:20.927917\n",
      "validation Loss: 0.0443 Acc: 0.9883\n",
      "2022-01-23 02:20:21.298765\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:23.748827\n",
      "validation Loss: 0.0471 Acc: 0.9883\n",
      "2022-01-23 02:20:24.115657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:26.533124\n",
      "validation Loss: 0.0468 Acc: 0.9883\n",
      "2022-01-23 02:20:26.932252\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:29.377623\n",
      "validation Loss: 0.0447 Acc: 0.9883\n",
      "2022-01-23 02:20:29.775789\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:32.226110\n",
      "validation Loss: 0.0455 Acc: 0.9883\n",
      "2022-01-23 02:20:32.603923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:35.081560\n",
      "validation Loss: 0.0446 Acc: 0.9883\n",
      "2022-01-23 02:20:35.474119\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:38.019215\n",
      "validation Loss: 0.0434 Acc: 0.9883\n",
      "2022-01-23 02:20:38.436559\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:40.851713\n",
      "validation Loss: 0.0425 Acc: 0.9883\n",
      "2022-01-23 02:20:41.241442\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:43.646336\n",
      "validation Loss: 0.0510 Acc: 0.9883\n",
      "2022-01-23 02:20:44.055165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:46.675538\n",
      "validation Loss: 0.0471 Acc: 0.9883\n",
      "2022-01-23 02:20:47.074690\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:20:49.513748\n",
      "validation Loss: 0.0478 Acc: 0.9883\n",
      "2022-01-23 02:20:49.885390\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:20:52.373899\n",
      "validation Loss: 0.0453 Acc: 0.9883\n",
      "2022-01-23 02:20:52.733816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:20:55.146545\n",
      "validation Loss: 0.0469 Acc: 0.9860\n",
      "2022-01-23 02:20:55.547217\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:20:58.050965\n",
      "validation Loss: 0.0471 Acc: 0.9883\n",
      "2022-01-23 02:20:58.457050\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:01.022184\n",
      "validation Loss: 0.0446 Acc: 0.9883\n",
      "2022-01-23 02:21:01.440972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:03.884712\n",
      "validation Loss: 0.0425 Acc: 0.9860\n",
      "2022-01-23 02:21:04.242847\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:06.670410\n",
      "validation Loss: 0.0430 Acc: 0.9883\n",
      "2022-01-23 02:21:07.043115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:08.414624\n",
      "validation Loss: 0.0461 Acc: 0.9860\n",
      "2022-01-23 02:21:08.809231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:10.971435\n",
      "validation Loss: 0.0451 Acc: 0.9883\n",
      "2022-01-23 02:21:11.449720\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:13.913955\n",
      "validation Loss: 0.0434 Acc: 0.9860\n",
      "2022-01-23 02:21:14.265640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:16.772714\n",
      "validation Loss: 0.0414 Acc: 0.9883\n",
      "2022-01-23 02:21:17.140556\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:19.626283\n",
      "validation Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 02:21:19.985602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:22.652576\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 02:21:23.053482\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:25.426067\n",
      "validation Loss: 0.0449 Acc: 0.9860\n",
      "2022-01-23 02:21:25.837154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:28.183395\n",
      "validation Loss: 0.0473 Acc: 0.9860\n",
      "2022-01-23 02:21:28.531556\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:30.956749\n",
      "validation Loss: 0.0443 Acc: 0.9860\n",
      "2022-01-23 02:21:31.304713\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:33.714977\n",
      "validation Loss: 0.0456 Acc: 0.9860\n",
      "2022-01-23 02:21:34.109955\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:35.509287\n",
      "validation Loss: 0.0463 Acc: 0.9860\n",
      "2022-01-23 02:21:35.863887\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:38.240220\n",
      "validation Loss: 0.0434 Acc: 0.9860\n",
      "2022-01-23 02:21:38.609255\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:40.994036\n",
      "validation Loss: 0.0470 Acc: 0.9860\n",
      "2022-01-23 02:21:41.404496\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:43.801433\n",
      "validation Loss: 0.0472 Acc: 0.9860\n",
      "2022-01-23 02:21:44.176657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:46.541325\n",
      "validation Loss: 0.0417 Acc: 0.9860\n",
      "2022-01-23 02:21:46.992315\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:49.343738\n",
      "validation Loss: 0.0423 Acc: 0.9860\n",
      "2022-01-23 02:21:49.732961\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:52.319378\n",
      "validation Loss: 0.0470 Acc: 0.9860\n",
      "2022-01-23 02:21:52.665267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:55.064400\n",
      "validation Loss: 0.0451 Acc: 0.9860\n",
      "2022-01-23 02:21:55.414247\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:21:57.945233\n",
      "validation Loss: 0.0464 Acc: 0.9883\n",
      "2022-01-23 02:21:58.370470\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:00.879523\n",
      "validation Loss: 0.0467 Acc: 0.9860\n",
      "2022-01-23 02:22:01.285331\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:03.901053\n",
      "validation Loss: 0.0438 Acc: 0.9883\n",
      "2022-01-23 02:22:04.313768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:06.786552\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 02:22:07.162425\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:09.622446\n",
      "validation Loss: 0.0431 Acc: 0.9883\n",
      "2022-01-23 02:22:10.002633\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:12.576765\n",
      "validation Loss: 0.0429 Acc: 0.9883\n",
      "2022-01-23 02:22:13.010917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:15.502068\n",
      "validation Loss: 0.0475 Acc: 0.9860\n",
      "2022-01-23 02:22:15.866953\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:22:18.395333\n",
      "validation Loss: 0.0417 Acc: 0.9883\n",
      "2022-01-23 02:22:18.771867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:22:21.257688\n",
      "validation Loss: 0.0516 Acc: 0.9860\n",
      "2022-01-23 02:22:21.619731\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:22:24.289238\n",
      "validation Loss: 0.0457 Acc: 0.9860\n",
      "2022-01-23 02:22:24.681726\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:22:27.182399\n",
      "validation Loss: 0.0437 Acc: 0.9883\n",
      "2022-01-23 02:22:27.582516\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9907\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1i88kr12) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 88805... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▆▇▇▇▇▆▆███</td></tr><tr><td>accuracy_train</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▆▆▇▇▆▇▆▇▇▆████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▃▂▁▁▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98834</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99068</td></tr><tr><td>best_val_loss</td><td>0.04173</td></tr><tr><td>loss_train</td><td>4e-05</td></tr><tr><td>loss_validation</td><td>0.0437</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1i88kr12\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1i88kr12</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_021730-1i88kr12/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1i88kr12). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/330e9i5l\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 02:22:37.223880\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.4983 Acc: 0.6785\n",
      "2022-01-23 02:22:39.637135\n",
      "validation Loss: 0.4784 Acc: 0.9534\n",
      "2022-01-23 02:22:40.070105\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.3108 Acc: 0.9475\n",
      "2022-01-23 02:22:43.140322\n",
      "validation Loss: 0.1872 Acc: 0.9604\n",
      "2022-01-23 02:22:43.565110\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1542 Acc: 0.9695\n",
      "2022-01-23 02:22:46.416206\n",
      "validation Loss: 0.1205 Acc: 0.9814\n",
      "2022-01-23 02:22:46.797526\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1110 Acc: 0.9775\n",
      "2022-01-23 02:22:49.679255\n",
      "validation Loss: 0.0990 Acc: 0.9814\n",
      "2022-01-23 02:22:50.061651\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0762 Acc: 0.9830\n",
      "2022-01-23 02:22:52.866840\n",
      "validation Loss: 0.0924 Acc: 0.9720\n",
      "2022-01-23 02:22:53.281448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0605 Acc: 0.9880\n",
      "2022-01-23 02:22:55.728147\n",
      "validation Loss: 0.1159 Acc: 0.9580\n",
      "2022-01-23 02:22:56.116159\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0541 Acc: 0.9860\n",
      "2022-01-23 02:22:58.437377\n",
      "validation Loss: 0.0685 Acc: 0.9814\n",
      "2022-01-23 02:22:58.822411\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0469 Acc: 0.9885\n",
      "2022-01-23 02:23:01.696106\n",
      "validation Loss: 0.0807 Acc: 0.9767\n",
      "2022-01-23 02:23:02.058994\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0420 Acc: 0.9900\n",
      "2022-01-23 02:23:04.524474\n",
      "validation Loss: 0.1017 Acc: 0.9697\n",
      "2022-01-23 02:23:04.880808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0444 Acc: 0.9875\n",
      "2022-01-23 02:23:07.339939\n",
      "validation Loss: 0.0953 Acc: 0.9720\n",
      "2022-01-23 02:23:07.706903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0234 Acc: 0.9970\n",
      "2022-01-23 02:23:10.193396\n",
      "validation Loss: 0.0451 Acc: 0.9883\n",
      "2022-01-23 02:23:10.573972\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0290 Acc: 0.9925\n",
      "2022-01-23 02:23:13.479727\n",
      "validation Loss: 0.0737 Acc: 0.9767\n",
      "2022-01-23 02:23:13.873419\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0240 Acc: 0.9950\n",
      "2022-01-23 02:23:16.469854\n",
      "validation Loss: 0.0462 Acc: 0.9814\n",
      "2022-01-23 02:23:16.842367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0233 Acc: 0.9945\n",
      "2022-01-23 02:23:19.322009\n",
      "validation Loss: 0.0454 Acc: 0.9860\n",
      "2022-01-23 02:23:19.732025\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0173 Acc: 0.9970\n",
      "2022-01-23 02:23:22.190009\n",
      "validation Loss: 0.0331 Acc: 0.9883\n",
      "2022-01-23 02:23:22.599295\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9970\n",
      "2022-01-23 02:23:25.432535\n",
      "validation Loss: 0.0548 Acc: 0.9837\n",
      "2022-01-23 02:23:25.848240\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 0.9940\n",
      "2022-01-23 02:23:28.508803\n",
      "validation Loss: 0.0548 Acc: 0.9767\n",
      "2022-01-23 02:23:28.897705\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9920\n",
      "2022-01-23 02:23:31.322793\n",
      "validation Loss: 0.0571 Acc: 0.9860\n",
      "2022-01-23 02:23:31.749208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0215 Acc: 0.9940\n",
      "2022-01-23 02:23:34.130037\n",
      "validation Loss: 0.0509 Acc: 0.9860\n",
      "2022-01-23 02:23:34.523306\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9980\n",
      "2022-01-23 02:23:36.998436\n",
      "validation Loss: 0.0301 Acc: 0.9907\n",
      "2022-01-23 02:23:37.473063\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0079 Acc: 0.9985\n",
      "2022-01-23 02:23:40.346411\n",
      "validation Loss: 0.0330 Acc: 0.9930\n",
      "2022-01-23 02:23:40.744223\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 1.0000\n",
      "2022-01-23 02:23:43.535236\n",
      "validation Loss: 0.0414 Acc: 0.9907\n",
      "2022-01-23 02:23:43.902462\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0031 Acc: 1.0000\n",
      "2022-01-23 02:23:46.333510\n",
      "validation Loss: 0.0321 Acc: 0.9907\n",
      "2022-01-23 02:23:46.711204\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0031 Acc: 1.0000\n",
      "2022-01-23 02:23:49.121261\n",
      "validation Loss: 0.0483 Acc: 0.9837\n",
      "2022-01-23 02:23:49.466277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "2022-01-23 02:23:51.964484\n",
      "validation Loss: 0.0404 Acc: 0.9907\n",
      "2022-01-23 02:23:52.364852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 02:23:54.970105\n",
      "validation Loss: 0.0372 Acc: 0.9907\n",
      "2022-01-23 02:23:55.359056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 02:23:57.780891\n",
      "validation Loss: 0.0242 Acc: 0.9883\n",
      "2022-01-23 02:23:58.167968\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 02:24:00.648141\n",
      "validation Loss: 0.0315 Acc: 0.9930\n",
      "2022-01-23 02:24:01.004339\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 02:24:02.744050\n",
      "validation Loss: 0.0295 Acc: 0.9907\n",
      "2022-01-23 02:24:03.128368\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 02:24:05.689887\n",
      "validation Loss: 0.0405 Acc: 0.9883\n",
      "2022-01-23 02:24:06.157575\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:24:08.732736\n",
      "validation Loss: 0.0303 Acc: 0.9907\n",
      "2022-01-23 02:24:09.110250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:24:11.591982\n",
      "validation Loss: 0.0279 Acc: 0.9907\n",
      "2022-01-23 02:24:11.948450\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:24:14.486751\n",
      "validation Loss: 0.0326 Acc: 0.9883\n",
      "2022-01-23 02:24:14.890697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:24:17.376572\n",
      "validation Loss: 0.0460 Acc: 0.9860\n",
      "2022-01-23 02:24:17.742165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 02:24:20.177058\n",
      "validation Loss: 0.0209 Acc: 0.9930\n",
      "2022-01-23 02:24:20.511988\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 02:24:23.359971\n",
      "validation Loss: 0.0227 Acc: 0.9907\n",
      "2022-01-23 02:24:23.770049\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:24:26.359547\n",
      "validation Loss: 0.0371 Acc: 0.9883\n",
      "2022-01-23 02:24:26.795122\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9945\n",
      "2022-01-23 02:24:29.415162\n",
      "validation Loss: 0.0554 Acc: 0.9767\n",
      "2022-01-23 02:24:29.874947\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0341 Acc: 0.9930\n",
      "2022-01-23 02:24:32.436991\n",
      "validation Loss: 0.0429 Acc: 0.9837\n",
      "2022-01-23 02:24:32.795021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 0.9985\n",
      "2022-01-23 02:24:35.295194\n",
      "validation Loss: 0.0383 Acc: 0.9860\n",
      "2022-01-23 02:24:35.678210\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0598 Acc: 0.9810\n",
      "2022-01-23 02:24:38.161216\n",
      "validation Loss: 0.0541 Acc: 0.9790\n",
      "2022-01-23 02:24:38.535953\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9900\n",
      "2022-01-23 02:24:40.973393\n",
      "validation Loss: 0.0418 Acc: 0.9790\n",
      "2022-01-23 02:24:41.379641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0122 Acc: 0.9970\n",
      "2022-01-23 02:24:44.061621\n",
      "validation Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 02:24:44.418815\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 0.9985\n",
      "2022-01-23 02:24:46.968150\n",
      "validation Loss: 0.0340 Acc: 0.9883\n",
      "2022-01-23 02:24:47.383726\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:24:50.135050\n",
      "validation Loss: 0.0314 Acc: 0.9883\n",
      "2022-01-23 02:24:50.546834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 02:24:53.034857\n",
      "validation Loss: 0.0303 Acc: 0.9907\n",
      "2022-01-23 02:24:53.408775\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 02:24:55.901082\n",
      "validation Loss: 0.0338 Acc: 0.9907\n",
      "2022-01-23 02:24:56.252495\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 02:24:58.612793\n",
      "validation Loss: 0.0314 Acc: 0.9907\n",
      "2022-01-23 02:24:58.986250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 02:25:01.410993\n",
      "validation Loss: 0.0305 Acc: 0.9907\n",
      "2022-01-23 02:25:01.768026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 02:25:04.404058\n",
      "validation Loss: 0.0294 Acc: 0.9907\n",
      "2022-01-23 02:25:04.783967\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:25:07.235721\n",
      "validation Loss: 0.0291 Acc: 0.9907\n",
      "2022-01-23 02:25:07.608286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:25:10.203307\n",
      "validation Loss: 0.0271 Acc: 0.9907\n",
      "2022-01-23 02:25:10.564343\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 02:25:13.065549\n",
      "validation Loss: 0.0284 Acc: 0.9907\n",
      "2022-01-23 02:25:13.425878\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:25:15.599155\n",
      "validation Loss: 0.0274 Acc: 0.9907\n",
      "2022-01-23 02:25:15.982883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:25:18.393197\n",
      "validation Loss: 0.0304 Acc: 0.9930\n",
      "2022-01-23 02:25:18.788012\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:25:21.226306\n",
      "validation Loss: 0.0302 Acc: 0.9930\n",
      "2022-01-23 02:25:21.599281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 02:25:24.023879\n",
      "validation Loss: 0.0324 Acc: 0.9930\n",
      "2022-01-23 02:25:24.404463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:25:26.818520\n",
      "validation Loss: 0.0284 Acc: 0.9907\n",
      "2022-01-23 02:25:27.178908\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:25:29.753128\n",
      "validation Loss: 0.0275 Acc: 0.9907\n",
      "2022-01-23 02:25:30.213042\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:25:32.761758\n",
      "validation Loss: 0.0298 Acc: 0.9907\n",
      "2022-01-23 02:25:33.216397\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:25:35.799996\n",
      "validation Loss: 0.0282 Acc: 0.9930\n",
      "2022-01-23 02:25:36.169321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:25:38.427960\n",
      "validation Loss: 0.0302 Acc: 0.9930\n",
      "2022-01-23 02:25:38.815154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:41.158595\n",
      "validation Loss: 0.0275 Acc: 0.9883\n",
      "2022-01-23 02:25:41.507257\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:43.901644\n",
      "validation Loss: 0.0260 Acc: 0.9883\n",
      "2022-01-23 02:25:44.302296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:46.669335\n",
      "validation Loss: 0.0322 Acc: 0.9907\n",
      "2022-01-23 02:25:47.040626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:49.520644\n",
      "validation Loss: 0.0269 Acc: 0.9907\n",
      "2022-01-23 02:25:49.873330\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:52.245780\n",
      "validation Loss: 0.0285 Acc: 0.9907\n",
      "2022-01-23 02:25:52.662449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:55.014883\n",
      "validation Loss: 0.0277 Acc: 0.9907\n",
      "2022-01-23 02:25:55.353683\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:25:57.678711\n",
      "validation Loss: 0.0300 Acc: 0.9907\n",
      "2022-01-23 02:25:58.078892\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:26:00.407198\n",
      "validation Loss: 0.0282 Acc: 0.9907\n",
      "2022-01-23 02:26:00.802768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:03.177346\n",
      "validation Loss: 0.0293 Acc: 0.9907\n",
      "2022-01-23 02:26:03.546130\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:05.880709\n",
      "validation Loss: 0.0285 Acc: 0.9907\n",
      "2022-01-23 02:26:06.264875\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:08.540910\n",
      "validation Loss: 0.0274 Acc: 0.9907\n",
      "2022-01-23 02:26:08.905489\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:11.358686\n",
      "validation Loss: 0.0302 Acc: 0.9907\n",
      "2022-01-23 02:26:11.728242\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:14.178616\n",
      "validation Loss: 0.0269 Acc: 0.9907\n",
      "2022-01-23 02:26:14.596144\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:17.111893\n",
      "validation Loss: 0.0305 Acc: 0.9907\n",
      "2022-01-23 02:26:17.499852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:20.078351\n",
      "validation Loss: 0.0267 Acc: 0.9907\n",
      "2022-01-23 02:26:20.457705\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:22.901374\n",
      "validation Loss: 0.0272 Acc: 0.9907\n",
      "2022-01-23 02:26:23.265573\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:25.676590\n",
      "validation Loss: 0.0288 Acc: 0.9907\n",
      "2022-01-23 02:26:26.009353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:28.477619\n",
      "validation Loss: 0.0271 Acc: 0.9907\n",
      "2022-01-23 02:26:28.878942\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:31.589626\n",
      "validation Loss: 0.0274 Acc: 0.9907\n",
      "2022-01-23 02:26:32.008766\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:34.491222\n",
      "validation Loss: 0.0270 Acc: 0.9907\n",
      "2022-01-23 02:26:34.868519\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:37.280164\n",
      "validation Loss: 0.0276 Acc: 0.9907\n",
      "2022-01-23 02:26:37.644208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:40.120664\n",
      "validation Loss: 0.0272 Acc: 0.9907\n",
      "2022-01-23 02:26:40.496005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:26:42.988615\n",
      "validation Loss: 0.0266 Acc: 0.9907\n",
      "2022-01-23 02:26:43.366779\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:26:45.950319\n",
      "validation Loss: 0.0285 Acc: 0.9907\n",
      "2022-01-23 02:26:46.346980\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:26:48.873116\n",
      "validation Loss: 0.0277 Acc: 0.9907\n",
      "2022-01-23 02:26:49.241885\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:26:51.729139\n",
      "validation Loss: 0.0278 Acc: 0.9907\n",
      "2022-01-23 02:26:52.131775\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:26:54.570585\n",
      "validation Loss: 0.0272 Acc: 0.9907\n",
      "2022-01-23 02:26:54.936262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:26:57.353931\n",
      "validation Loss: 0.0246 Acc: 0.9907\n",
      "2022-01-23 02:26:57.709552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:00.252911\n",
      "validation Loss: 0.0276 Acc: 0.9907\n",
      "2022-01-23 02:27:00.667382\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:03.227027\n",
      "validation Loss: 0.0259 Acc: 0.9907\n",
      "2022-01-23 02:27:03.596709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:06.055750\n",
      "validation Loss: 0.0257 Acc: 0.9907\n",
      "2022-01-23 02:27:06.411026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:08.834995\n",
      "validation Loss: 0.0249 Acc: 0.9907\n",
      "2022-01-23 02:27:09.256250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:11.798219\n",
      "validation Loss: 0.0256 Acc: 0.9907\n",
      "2022-01-23 02:27:12.154360\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:14.602022\n",
      "validation Loss: 0.0267 Acc: 0.9907\n",
      "2022-01-23 02:27:15.001152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:17.500150\n",
      "validation Loss: 0.0273 Acc: 0.9907\n",
      "2022-01-23 02:27:17.876936\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:20.269582\n",
      "validation Loss: 0.0249 Acc: 0.9907\n",
      "2022-01-23 02:27:20.635501\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:23.191436\n",
      "validation Loss: 0.0267 Acc: 0.9907\n",
      "2022-01-23 02:27:23.549331\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:27:26.006372\n",
      "validation Loss: 0.0230 Acc: 0.9907\n",
      "2022-01-23 02:27:26.349902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9930\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:330e9i5l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 80884... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▅▅▇██████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▂▅▇▆▆▇█████▇█▆▆▇███████▇██████████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99068</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99301</td></tr><tr><td>best_val_loss</td><td>0.02088</td></tr><tr><td>loss_train</td><td>0.0001</td></tr><tr><td>loss_validation</td><td>0.02301</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/330e9i5l\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/330e9i5l</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_022227-330e9i5l/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:330e9i5l). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/22g2vri3\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 02:27:35.639238\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.5999 Acc: 0.3910\n",
      "2022-01-23 02:27:38.084394\n",
      "validation Loss: 2.0576 Acc: 0.7226\n",
      "2022-01-23 02:27:38.477907\n",
      "Accuracy of the network on the 429 test samples: 72.96037296037296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.6332 Acc: 0.8020\n",
      "2022-01-23 02:27:41.321582\n",
      "validation Loss: 1.2521 Acc: 0.8625\n",
      "2022-01-23 02:27:41.730545\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.0286 Acc: 0.8925\n",
      "2022-01-23 02:27:44.669073\n",
      "validation Loss: 0.8166 Acc: 0.9068\n",
      "2022-01-23 02:27:45.075013\n",
      "Accuracy of the network on the 429 test samples: 90.44289044289044\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.7035 Acc: 0.9195\n",
      "2022-01-23 02:27:47.866941\n",
      "validation Loss: 0.5816 Acc: 0.9347\n",
      "2022-01-23 02:27:48.261779\n",
      "Accuracy of the network on the 429 test samples: 91.14219114219114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.5166 Acc: 0.9350\n",
      "2022-01-23 02:27:51.192638\n",
      "validation Loss: 0.4383 Acc: 0.9487\n",
      "2022-01-23 02:27:51.589614\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3972 Acc: 0.9500\n",
      "2022-01-23 02:27:54.506629\n",
      "validation Loss: 0.3525 Acc: 0.9604\n",
      "2022-01-23 02:27:54.878898\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3213 Acc: 0.9570\n",
      "2022-01-23 02:27:57.807547\n",
      "validation Loss: 0.2918 Acc: 0.9604\n",
      "2022-01-23 02:27:58.155388\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2635 Acc: 0.9645\n",
      "2022-01-23 02:28:00.897358\n",
      "validation Loss: 0.2547 Acc: 0.9674\n",
      "2022-01-23 02:28:01.319150\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2226 Acc: 0.9700\n",
      "2022-01-23 02:28:04.055049\n",
      "validation Loss: 0.2200 Acc: 0.9650\n",
      "2022-01-23 02:28:04.487296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1931 Acc: 0.9735\n",
      "2022-01-23 02:28:06.872003\n",
      "validation Loss: 0.1981 Acc: 0.9674\n",
      "2022-01-23 02:28:07.242093\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1673 Acc: 0.9770\n",
      "2022-01-23 02:28:09.989058\n",
      "validation Loss: 0.1795 Acc: 0.9697\n",
      "2022-01-23 02:28:10.378438\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1493 Acc: 0.9800\n",
      "2022-01-23 02:28:13.230446\n",
      "validation Loss: 0.1595 Acc: 0.9697\n",
      "2022-01-23 02:28:13.632952\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1290 Acc: 0.9815\n",
      "2022-01-23 02:28:16.437247\n",
      "validation Loss: 0.1460 Acc: 0.9744\n",
      "2022-01-23 02:28:16.828595\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1171 Acc: 0.9865\n",
      "2022-01-23 02:28:19.722036\n",
      "validation Loss: 0.1392 Acc: 0.9697\n",
      "2022-01-23 02:28:20.109419\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1040 Acc: 0.9875\n",
      "2022-01-23 02:28:22.548832\n",
      "validation Loss: 0.1257 Acc: 0.9744\n",
      "2022-01-23 02:28:22.904802\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0932 Acc: 0.9900\n",
      "2022-01-23 02:28:25.623252\n",
      "validation Loss: 0.1195 Acc: 0.9720\n",
      "2022-01-23 02:28:26.028714\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9895\n",
      "2022-01-23 02:28:28.484868\n",
      "validation Loss: 0.1162 Acc: 0.9744\n",
      "2022-01-23 02:28:28.841121\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0769 Acc: 0.9910\n",
      "2022-01-23 02:28:31.713182\n",
      "validation Loss: 0.1068 Acc: 0.9744\n",
      "2022-01-23 02:28:32.077798\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0720 Acc: 0.9905\n",
      "2022-01-23 02:28:34.847918\n",
      "validation Loss: 0.1030 Acc: 0.9720\n",
      "2022-01-23 02:28:35.256976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0648 Acc: 0.9925\n",
      "2022-01-23 02:28:37.673211\n",
      "validation Loss: 0.0978 Acc: 0.9767\n",
      "2022-01-23 02:28:38.053983\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0626 Acc: 0.9910\n",
      "2022-01-23 02:28:40.956019\n",
      "validation Loss: 0.0934 Acc: 0.9767\n",
      "2022-01-23 02:28:41.354455\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0563 Acc: 0.9925\n",
      "2022-01-23 02:28:44.173719\n",
      "validation Loss: 0.0998 Acc: 0.9744\n",
      "2022-01-23 02:28:44.556794\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0542 Acc: 0.9925\n",
      "2022-01-23 02:28:47.150000\n",
      "validation Loss: 0.0857 Acc: 0.9790\n",
      "2022-01-23 02:28:47.547541\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0478 Acc: 0.9955\n",
      "2022-01-23 02:28:50.304267\n",
      "validation Loss: 0.0904 Acc: 0.9744\n",
      "2022-01-23 02:28:50.681760\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0462 Acc: 0.9935\n",
      "2022-01-23 02:28:53.116996\n",
      "validation Loss: 0.0870 Acc: 0.9767\n",
      "2022-01-23 02:28:53.535479\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0401 Acc: 0.9935\n",
      "2022-01-23 02:28:56.020973\n",
      "validation Loss: 0.0752 Acc: 0.9814\n",
      "2022-01-23 02:28:56.389637\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0374 Acc: 0.9970\n",
      "2022-01-23 02:28:59.182008\n",
      "validation Loss: 0.0758 Acc: 0.9814\n",
      "2022-01-23 02:28:59.556726\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0358 Acc: 0.9960\n",
      "2022-01-23 02:29:01.980822\n",
      "validation Loss: 0.0748 Acc: 0.9790\n",
      "2022-01-23 02:29:02.388630\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0334 Acc: 0.9970\n",
      "2022-01-23 02:29:04.849830\n",
      "validation Loss: 0.0734 Acc: 0.9790\n",
      "2022-01-23 02:29:05.218225\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0302 Acc: 0.9970\n",
      "2022-01-23 02:29:07.652799\n",
      "validation Loss: 0.0753 Acc: 0.9790\n",
      "2022-01-23 02:29:08.097626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0283 Acc: 0.9970\n",
      "2022-01-23 02:29:10.591450\n",
      "validation Loss: 0.0689 Acc: 0.9814\n",
      "2022-01-23 02:29:10.976777\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0267 Acc: 0.9980\n",
      "2022-01-23 02:29:13.790297\n",
      "validation Loss: 0.0634 Acc: 0.9860\n",
      "2022-01-23 02:29:14.169885\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0265 Acc: 0.9960\n",
      "2022-01-23 02:29:17.059999\n",
      "validation Loss: 0.0657 Acc: 0.9814\n",
      "2022-01-23 02:29:17.464985\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0226 Acc: 0.9985\n",
      "2022-01-23 02:29:19.984758\n",
      "validation Loss: 0.0713 Acc: 0.9744\n",
      "2022-01-23 02:29:20.344239\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0212 Acc: 1.0000\n",
      "2022-01-23 02:29:22.798934\n",
      "validation Loss: 0.0591 Acc: 0.9837\n",
      "2022-01-23 02:29:23.210171\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0246 Acc: 0.9970\n",
      "2022-01-23 02:29:24.646421\n",
      "validation Loss: 0.0740 Acc: 0.9744\n",
      "2022-01-23 02:29:24.989706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 0.9990\n",
      "2022-01-23 02:29:27.456507\n",
      "validation Loss: 0.0582 Acc: 0.9837\n",
      "2022-01-23 02:29:27.863527\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0174 Acc: 0.9995\n",
      "2022-01-23 02:29:30.373881\n",
      "validation Loss: 0.0552 Acc: 0.9837\n",
      "2022-01-23 02:29:30.721304\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0169 Acc: 1.0000\n",
      "2022-01-23 02:29:33.157014\n",
      "validation Loss: 0.0560 Acc: 0.9814\n",
      "2022-01-23 02:29:33.544988\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0160 Acc: 1.0000\n",
      "2022-01-23 02:29:35.928533\n",
      "validation Loss: 0.0698 Acc: 0.9767\n",
      "2022-01-23 02:29:36.324037\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0158 Acc: 0.9985\n",
      "2022-01-23 02:29:38.759514\n",
      "validation Loss: 0.0577 Acc: 0.9837\n",
      "2022-01-23 02:29:39.113604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 1.0000\n",
      "2022-01-23 02:29:41.523406\n",
      "validation Loss: 0.0559 Acc: 0.9837\n",
      "2022-01-23 02:29:41.916201\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 1.0000\n",
      "2022-01-23 02:29:43.284582\n",
      "validation Loss: 0.0514 Acc: 0.9860\n",
      "2022-01-23 02:29:43.641418\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0135 Acc: 1.0000\n",
      "2022-01-23 02:29:46.481422\n",
      "validation Loss: 0.0609 Acc: 0.9790\n",
      "2022-01-23 02:29:46.854189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0141 Acc: 1.0000\n",
      "2022-01-23 02:29:49.350304\n",
      "validation Loss: 0.0518 Acc: 0.9837\n",
      "2022-01-23 02:29:49.714353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 1.0000\n",
      "2022-01-23 02:29:52.072480\n",
      "validation Loss: 0.0541 Acc: 0.9837\n",
      "2022-01-23 02:29:52.470319\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 1.0000\n",
      "2022-01-23 02:29:55.046926\n",
      "validation Loss: 0.0579 Acc: 0.9837\n",
      "2022-01-23 02:29:55.508520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 1.0000\n",
      "2022-01-23 02:29:57.996287\n",
      "validation Loss: 0.0553 Acc: 0.9860\n",
      "2022-01-23 02:29:58.420550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0096 Acc: 1.0000\n",
      "2022-01-23 02:30:00.779790\n",
      "validation Loss: 0.0452 Acc: 0.9883\n",
      "2022-01-23 02:30:01.156482\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0104 Acc: 1.0000\n",
      "2022-01-23 02:30:03.883387\n",
      "validation Loss: 0.0525 Acc: 0.9860\n",
      "2022-01-23 02:30:04.270769\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 1.0000\n",
      "2022-01-23 02:30:06.568078\n",
      "validation Loss: 0.0486 Acc: 0.9860\n",
      "2022-01-23 02:30:06.966607\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0091 Acc: 1.0000\n",
      "2022-01-23 02:30:09.362839\n",
      "validation Loss: 0.0518 Acc: 0.9837\n",
      "2022-01-23 02:30:09.751772\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0084 Acc: 1.0000\n",
      "2022-01-23 02:30:12.119584\n",
      "validation Loss: 0.0459 Acc: 0.9860\n",
      "2022-01-23 02:30:12.493991\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0091 Acc: 0.9990\n",
      "2022-01-23 02:30:15.001174\n",
      "validation Loss: 0.0580 Acc: 0.9837\n",
      "2022-01-23 02:30:15.388439\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0072 Acc: 1.0000\n",
      "2022-01-23 02:30:17.715252\n",
      "validation Loss: 0.0423 Acc: 0.9930\n",
      "2022-01-23 02:30:18.073908\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0075 Acc: 0.9995\n",
      "2022-01-23 02:30:20.843221\n",
      "validation Loss: 0.0437 Acc: 0.9930\n",
      "2022-01-23 02:30:21.212354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0063 Acc: 1.0000\n",
      "2022-01-23 02:30:23.601161\n",
      "validation Loss: 0.0469 Acc: 0.9837\n",
      "2022-01-23 02:30:23.991249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 1.0000\n",
      "2022-01-23 02:30:26.341476\n",
      "validation Loss: 0.0470 Acc: 0.9860\n",
      "2022-01-23 02:30:26.706681\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 1.0000\n",
      "2022-01-23 02:30:29.204633\n",
      "validation Loss: 0.0472 Acc: 0.9860\n",
      "2022-01-23 02:30:29.644938\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0058 Acc: 1.0000\n",
      "2022-01-23 02:30:32.047532\n",
      "validation Loss: 0.0426 Acc: 0.9860\n",
      "2022-01-23 02:30:32.393410\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 1.0000\n",
      "2022-01-23 02:30:34.832464\n",
      "validation Loss: 0.0581 Acc: 0.9837\n",
      "2022-01-23 02:30:35.223947\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 1.0000\n",
      "2022-01-23 02:30:37.716772\n",
      "validation Loss: 0.0489 Acc: 0.9860\n",
      "2022-01-23 02:30:38.064155\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 02:30:40.473352\n",
      "validation Loss: 0.0435 Acc: 0.9860\n",
      "2022-01-23 02:30:40.851562\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 1.0000\n",
      "2022-01-23 02:30:43.295933\n",
      "validation Loss: 0.0392 Acc: 0.9883\n",
      "2022-01-23 02:30:43.659788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "2022-01-23 02:30:46.093635\n",
      "validation Loss: 0.0399 Acc: 0.9860\n",
      "2022-01-23 02:30:46.489921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0044 Acc: 1.0000\n",
      "2022-01-23 02:30:49.030332\n",
      "validation Loss: 0.0380 Acc: 0.9907\n",
      "2022-01-23 02:30:49.412710\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 1.0000\n",
      "2022-01-23 02:30:51.825782\n",
      "validation Loss: 0.0594 Acc: 0.9860\n",
      "2022-01-23 02:30:52.253136\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "2022-01-23 02:30:54.678935\n",
      "validation Loss: 0.0456 Acc: 0.9814\n",
      "2022-01-23 02:30:55.031283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 1.0000\n",
      "2022-01-23 02:30:57.434938\n",
      "validation Loss: 0.0400 Acc: 0.9883\n",
      "2022-01-23 02:30:57.859954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "2022-01-23 02:31:00.270446\n",
      "validation Loss: 0.0517 Acc: 0.9860\n",
      "2022-01-23 02:31:00.617965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0067 Acc: 0.9995\n",
      "2022-01-23 02:31:03.100596\n",
      "validation Loss: 0.0496 Acc: 0.9860\n",
      "2022-01-23 02:31:03.468749\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0140 Acc: 0.9975\n",
      "2022-01-23 02:31:05.922251\n",
      "validation Loss: 0.0589 Acc: 0.9837\n",
      "2022-01-23 02:31:06.299160\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "2022-01-23 02:31:08.840078\n",
      "validation Loss: 0.0411 Acc: 0.9860\n",
      "2022-01-23 02:31:09.208829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0033 Acc: 1.0000\n",
      "2022-01-23 02:31:11.634686\n",
      "validation Loss: 0.0341 Acc: 0.9907\n",
      "2022-01-23 02:31:12.031751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 1.0000\n",
      "2022-01-23 02:31:14.574861\n",
      "validation Loss: 0.0445 Acc: 0.9860\n",
      "2022-01-23 02:31:14.987834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0031 Acc: 1.0000\n",
      "2022-01-23 02:31:17.435705\n",
      "validation Loss: 0.0395 Acc: 0.9860\n",
      "2022-01-23 02:31:17.839891\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "2022-01-23 02:31:20.402102\n",
      "validation Loss: 0.0400 Acc: 0.9907\n",
      "2022-01-23 02:31:20.767061\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0025 Acc: 1.0000\n",
      "2022-01-23 02:31:23.171295\n",
      "validation Loss: 0.0410 Acc: 0.9883\n",
      "2022-01-23 02:31:23.544793\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0025 Acc: 1.0000\n",
      "2022-01-23 02:31:26.023864\n",
      "validation Loss: 0.0381 Acc: 0.9907\n",
      "2022-01-23 02:31:26.453975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "2022-01-23 02:31:28.917469\n",
      "validation Loss: 0.0384 Acc: 0.9907\n",
      "2022-01-23 02:31:29.275582\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "2022-01-23 02:31:31.733229\n",
      "validation Loss: 0.0362 Acc: 0.9930\n",
      "2022-01-23 02:31:32.157649\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 02:31:35.161181\n",
      "validation Loss: 0.0394 Acc: 0.9883\n",
      "2022-01-23 02:31:35.579968\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 02:31:38.097111\n",
      "validation Loss: 0.0424 Acc: 0.9907\n",
      "2022-01-23 02:31:38.454675\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 02:31:40.918383\n",
      "validation Loss: 0.0349 Acc: 0.9930\n",
      "2022-01-23 02:31:41.292990\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 02:31:44.091403\n",
      "validation Loss: 0.0418 Acc: 0.9883\n",
      "2022-01-23 02:31:44.509738\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 02:31:46.932190\n",
      "validation Loss: 0.0392 Acc: 0.9907\n",
      "2022-01-23 02:31:47.340931\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "2022-01-23 02:31:48.724388\n",
      "validation Loss: 0.0410 Acc: 0.9883\n",
      "2022-01-23 02:31:49.076511\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 02:31:51.542359\n",
      "validation Loss: 0.0404 Acc: 0.9883\n",
      "2022-01-23 02:31:51.954721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 02:31:54.439037\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 02:31:54.807281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 02:31:57.250589\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 02:31:57.661019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 02:32:00.157255\n",
      "validation Loss: 0.0390 Acc: 0.9883\n",
      "2022-01-23 02:32:00.548395\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:32:03.105460\n",
      "validation Loss: 0.0356 Acc: 0.9930\n",
      "2022-01-23 02:32:03.561755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:32:05.958746\n",
      "validation Loss: 0.0419 Acc: 0.9883\n",
      "2022-01-23 02:32:06.365492\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 02:32:08.848603\n",
      "validation Loss: 0.0418 Acc: 0.9907\n",
      "2022-01-23 02:32:09.210904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 02:32:11.596200\n",
      "validation Loss: 0.0330 Acc: 0.9953\n",
      "2022-01-23 02:32:12.012502\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 02:32:14.911382\n",
      "validation Loss: 0.0340 Acc: 0.9953\n",
      "2022-01-23 02:32:15.291195\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:32:17.732285\n",
      "validation Loss: 0.0360 Acc: 0.9930\n",
      "2022-01-23 02:32:18.126007\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 02:32:20.602102\n",
      "validation Loss: 0.0368 Acc: 0.9930\n",
      "2022-01-23 02:32:21.012844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:32:23.493666\n",
      "validation Loss: 0.0291 Acc: 0.9930\n",
      "2022-01-23 02:32:23.898200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 02:32:26.383446\n",
      "validation Loss: 0.0406 Acc: 0.9883\n",
      "2022-01-23 02:32:26.740512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:22g2vri3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 72467... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>accuracy_train</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇▇█▇█████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98834</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.03299</td></tr><tr><td>loss_train</td><td>0.00128</td></tr><tr><td>loss_validation</td><td>0.04059</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/22g2vri3\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/22g2vri3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_022726-22g2vri3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:22g2vri3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/138fjxhx\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 02:32:36.466166\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.9002 Acc: 0.1280\n",
      "2022-01-23 02:32:38.913518\n",
      "validation Loss: 2.7046 Acc: 0.3124\n",
      "2022-01-23 02:32:39.269959\n",
      "Accuracy of the network on the 429 test samples: 29.836829836829835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.4083 Acc: 0.5490\n",
      "2022-01-23 02:32:42.167145\n",
      "validation Loss: 2.0746 Acc: 0.7133\n",
      "2022-01-23 02:32:42.554846\n",
      "Accuracy of the network on the 429 test samples: 75.05827505827506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.8100 Acc: 0.7905\n",
      "2022-01-23 02:32:45.352156\n",
      "validation Loss: 1.5410 Acc: 0.8741\n",
      "2022-01-23 02:32:45.738708\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.3557 Acc: 0.8905\n",
      "2022-01-23 02:32:48.643255\n",
      "validation Loss: 1.1578 Acc: 0.9091\n",
      "2022-01-23 02:32:49.027469\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.0341 Acc: 0.9180\n",
      "2022-01-23 02:32:51.967129\n",
      "validation Loss: 0.8936 Acc: 0.9301\n",
      "2022-01-23 02:32:52.359879\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.8109 Acc: 0.9345\n",
      "2022-01-23 02:32:55.503046\n",
      "validation Loss: 0.7096 Acc: 0.9394\n",
      "2022-01-23 02:32:55.859097\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.6511 Acc: 0.9440\n",
      "2022-01-23 02:32:58.884253\n",
      "validation Loss: 0.5773 Acc: 0.9464\n",
      "2022-01-23 02:32:59.255913\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5377 Acc: 0.9510\n",
      "2022-01-23 02:33:02.347378\n",
      "validation Loss: 0.4864 Acc: 0.9464\n",
      "2022-01-23 02:33:02.714208\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4540 Acc: 0.9570\n",
      "2022-01-23 02:33:05.686106\n",
      "validation Loss: 0.4112 Acc: 0.9534\n",
      "2022-01-23 02:33:06.049805\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3871 Acc: 0.9610\n",
      "2022-01-23 02:33:08.892717\n",
      "validation Loss: 0.3561 Acc: 0.9580\n",
      "2022-01-23 02:33:09.261892\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3370 Acc: 0.9665\n",
      "2022-01-23 02:33:12.081281\n",
      "validation Loss: 0.3146 Acc: 0.9650\n",
      "2022-01-23 02:33:12.481229\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2957 Acc: 0.9695\n",
      "2022-01-23 02:33:15.382193\n",
      "validation Loss: 0.2772 Acc: 0.9627\n",
      "2022-01-23 02:33:15.769002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2614 Acc: 0.9720\n",
      "2022-01-23 02:33:18.247855\n",
      "validation Loss: 0.2494 Acc: 0.9627\n",
      "2022-01-23 02:33:18.691548\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2361 Acc: 0.9685\n",
      "2022-01-23 02:33:21.150102\n",
      "validation Loss: 0.2240 Acc: 0.9650\n",
      "2022-01-23 02:33:21.551716\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2123 Acc: 0.9725\n",
      "2022-01-23 02:33:24.393563\n",
      "validation Loss: 0.2055 Acc: 0.9650\n",
      "2022-01-23 02:33:24.750533\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1911 Acc: 0.9765\n",
      "2022-01-23 02:33:27.699438\n",
      "validation Loss: 0.1875 Acc: 0.9604\n",
      "2022-01-23 02:33:28.063560\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1750 Acc: 0.9775\n",
      "2022-01-23 02:33:30.520196\n",
      "validation Loss: 0.1740 Acc: 0.9674\n",
      "2022-01-23 02:33:30.902817\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1597 Acc: 0.9795\n",
      "2022-01-23 02:33:33.740433\n",
      "validation Loss: 0.1632 Acc: 0.9674\n",
      "2022-01-23 02:33:34.120095\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1461 Acc: 0.9820\n",
      "2022-01-23 02:33:36.956931\n",
      "validation Loss: 0.1518 Acc: 0.9697\n",
      "2022-01-23 02:33:37.330590\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1349 Acc: 0.9810\n",
      "2022-01-23 02:33:40.143117\n",
      "validation Loss: 0.1413 Acc: 0.9674\n",
      "2022-01-23 02:33:40.512154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1250 Acc: 0.9860\n",
      "2022-01-23 02:33:42.957215\n",
      "validation Loss: 0.1370 Acc: 0.9650\n",
      "2022-01-23 02:33:43.307154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1157 Acc: 0.9855\n",
      "2022-01-23 02:33:45.773095\n",
      "validation Loss: 0.1245 Acc: 0.9720\n",
      "2022-01-23 02:33:46.148659\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1070 Acc: 0.9880\n",
      "2022-01-23 02:33:48.908575\n",
      "validation Loss: 0.1172 Acc: 0.9697\n",
      "2022-01-23 02:33:49.331660\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0999 Acc: 0.9895\n",
      "2022-01-23 02:33:51.852784\n",
      "validation Loss: 0.1103 Acc: 0.9744\n",
      "2022-01-23 02:33:52.206569\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0939 Acc: 0.9875\n",
      "2022-01-23 02:33:55.156579\n",
      "validation Loss: 0.1079 Acc: 0.9674\n",
      "2022-01-23 02:33:55.496439\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0900 Acc: 0.9880\n",
      "2022-01-23 02:33:58.025886\n",
      "validation Loss: 0.1019 Acc: 0.9674\n",
      "2022-01-23 02:33:58.476795\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0821 Acc: 0.9895\n",
      "2022-01-23 02:34:00.971041\n",
      "validation Loss: 0.0992 Acc: 0.9720\n",
      "2022-01-23 02:34:01.345661\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0782 Acc: 0.9915\n",
      "2022-01-23 02:34:03.904414\n",
      "validation Loss: 0.0947 Acc: 0.9790\n",
      "2022-01-23 02:34:04.315479\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0718 Acc: 0.9925\n",
      "2022-01-23 02:34:07.183055\n",
      "validation Loss: 0.0879 Acc: 0.9790\n",
      "2022-01-23 02:34:07.665529\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0687 Acc: 0.9915\n",
      "2022-01-23 02:34:10.520011\n",
      "validation Loss: 0.0844 Acc: 0.9790\n",
      "2022-01-23 02:34:10.919203\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0636 Acc: 0.9930\n",
      "2022-01-23 02:34:13.711815\n",
      "validation Loss: 0.0852 Acc: 0.9767\n",
      "2022-01-23 02:34:14.092891\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0608 Acc: 0.9935\n",
      "2022-01-23 02:34:16.438099\n",
      "validation Loss: 0.0799 Acc: 0.9790\n",
      "2022-01-23 02:34:16.802242\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0579 Acc: 0.9945\n",
      "2022-01-23 02:34:19.449180\n",
      "validation Loss: 0.0769 Acc: 0.9837\n",
      "2022-01-23 02:34:19.836946\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0542 Acc: 0.9955\n",
      "2022-01-23 02:34:22.594768\n",
      "validation Loss: 0.0721 Acc: 0.9790\n",
      "2022-01-23 02:34:22.989262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0515 Acc: 0.9950\n",
      "2022-01-23 02:34:25.337993\n",
      "validation Loss: 0.0703 Acc: 0.9837\n",
      "2022-01-23 02:34:25.731975\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0501 Acc: 0.9935\n",
      "2022-01-23 02:34:28.561335\n",
      "validation Loss: 0.0675 Acc: 0.9790\n",
      "2022-01-23 02:34:28.931766\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0461 Acc: 0.9955\n",
      "2022-01-23 02:34:31.526333\n",
      "validation Loss: 0.0752 Acc: 0.9814\n",
      "2022-01-23 02:34:31.873974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0450 Acc: 0.9935\n",
      "2022-01-23 02:34:34.345208\n",
      "validation Loss: 0.0644 Acc: 0.9814\n",
      "2022-01-23 02:34:34.768311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0441 Acc: 0.9950\n",
      "2022-01-23 02:34:37.290731\n",
      "validation Loss: 0.0620 Acc: 0.9837\n",
      "2022-01-23 02:34:37.646354\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0400 Acc: 0.9960\n",
      "2022-01-23 02:34:40.419973\n",
      "validation Loss: 0.0629 Acc: 0.9814\n",
      "2022-01-23 02:34:40.798477\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0406 Acc: 0.9950\n",
      "2022-01-23 02:34:43.289025\n",
      "validation Loss: 0.0604 Acc: 0.9837\n",
      "2022-01-23 02:34:43.756244\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0372 Acc: 0.9955\n",
      "2022-01-23 02:34:46.641275\n",
      "validation Loss: 0.0579 Acc: 0.9883\n",
      "2022-01-23 02:34:47.055272\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0355 Acc: 0.9970\n",
      "2022-01-23 02:34:49.907357\n",
      "validation Loss: 0.0588 Acc: 0.9837\n",
      "2022-01-23 02:34:50.297899\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0354 Acc: 0.9960\n",
      "2022-01-23 02:34:52.748403\n",
      "validation Loss: 0.0575 Acc: 0.9907\n",
      "2022-01-23 02:34:53.158202\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0331 Acc: 0.9965\n",
      "2022-01-23 02:34:55.984223\n",
      "validation Loss: 0.0539 Acc: 0.9860\n",
      "2022-01-23 02:34:56.369955\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0329 Acc: 0.9965\n",
      "2022-01-23 02:34:58.815975\n",
      "validation Loss: 0.0563 Acc: 0.9883\n",
      "2022-01-23 02:34:59.215422\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0302 Acc: 0.9970\n",
      "2022-01-23 02:35:01.883679\n",
      "validation Loss: 0.0516 Acc: 0.9907\n",
      "2022-01-23 02:35:02.316249\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0292 Acc: 0.9985\n",
      "2022-01-23 02:35:05.105372\n",
      "validation Loss: 0.0551 Acc: 0.9883\n",
      "2022-01-23 02:35:05.485199\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0280 Acc: 0.9980\n",
      "2022-01-23 02:35:07.984764\n",
      "validation Loss: 0.0493 Acc: 0.9907\n",
      "2022-01-23 02:35:08.333756\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0267 Acc: 0.9975\n",
      "2022-01-23 02:35:11.208539\n",
      "validation Loss: 0.0485 Acc: 0.9860\n",
      "2022-01-23 02:35:11.629069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9970\n",
      "2022-01-23 02:35:14.170746\n",
      "validation Loss: 0.0518 Acc: 0.9883\n",
      "2022-01-23 02:35:14.588620\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9975\n",
      "2022-01-23 02:35:17.113062\n",
      "validation Loss: 0.0518 Acc: 0.9860\n",
      "2022-01-23 02:35:17.497983\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0251 Acc: 0.9975\n",
      "2022-01-23 02:35:20.127177\n",
      "validation Loss: 0.0471 Acc: 0.9907\n",
      "2022-01-23 02:35:20.501355\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0232 Acc: 0.9965\n",
      "2022-01-23 02:35:23.500290\n",
      "validation Loss: 0.0456 Acc: 0.9930\n",
      "2022-01-23 02:35:23.885423\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0237 Acc: 0.9975\n",
      "2022-01-23 02:35:26.944587\n",
      "validation Loss: 0.0442 Acc: 0.9930\n",
      "2022-01-23 02:35:27.309536\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0210 Acc: 0.9985\n",
      "2022-01-23 02:35:30.347666\n",
      "validation Loss: 0.0462 Acc: 0.9907\n",
      "2022-01-23 02:35:30.750428\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0200 Acc: 0.9980\n",
      "2022-01-23 02:35:33.271687\n",
      "validation Loss: 0.0455 Acc: 0.9907\n",
      "2022-01-23 02:35:33.642523\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 0.9980\n",
      "2022-01-23 02:35:36.176414\n",
      "validation Loss: 0.0422 Acc: 0.9907\n",
      "2022-01-23 02:35:36.559249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0190 Acc: 0.9985\n",
      "2022-01-23 02:35:38.993121\n",
      "validation Loss: 0.0390 Acc: 0.9953\n",
      "2022-01-23 02:35:39.361640\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0187 Acc: 0.9975\n",
      "2022-01-23 02:35:42.414287\n",
      "validation Loss: 0.0443 Acc: 0.9883\n",
      "2022-01-23 02:35:42.821362\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0183 Acc: 0.9975\n",
      "2022-01-23 02:35:45.263303\n",
      "validation Loss: 0.0425 Acc: 0.9907\n",
      "2022-01-23 02:35:45.700807\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0172 Acc: 0.9995\n",
      "2022-01-23 02:35:48.137803\n",
      "validation Loss: 0.0417 Acc: 0.9907\n",
      "2022-01-23 02:35:48.530396\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0185 Acc: 0.9970\n",
      "2022-01-23 02:35:51.052378\n",
      "validation Loss: 0.0399 Acc: 0.9883\n",
      "2022-01-23 02:35:51.508667\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0166 Acc: 0.9980\n",
      "2022-01-23 02:35:54.141353\n",
      "validation Loss: 0.0413 Acc: 0.9907\n",
      "2022-01-23 02:35:54.502472\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0162 Acc: 0.9980\n",
      "2022-01-23 02:35:56.911037\n",
      "validation Loss: 0.0383 Acc: 0.9883\n",
      "2022-01-23 02:35:57.285644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9990\n",
      "2022-01-23 02:35:59.692870\n",
      "validation Loss: 0.0385 Acc: 0.9953\n",
      "2022-01-23 02:36:00.094028\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0143 Acc: 0.9980\n",
      "2022-01-23 02:36:02.950296\n",
      "validation Loss: 0.0417 Acc: 0.9883\n",
      "2022-01-23 02:36:03.318960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0140 Acc: 0.9980\n",
      "2022-01-23 02:36:05.798055\n",
      "validation Loss: 0.0369 Acc: 0.9953\n",
      "2022-01-23 02:36:06.180649\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9985\n",
      "2022-01-23 02:36:09.075204\n",
      "validation Loss: 0.0347 Acc: 0.9953\n",
      "2022-01-23 02:36:09.441988\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9990\n",
      "2022-01-23 02:36:12.230871\n",
      "validation Loss: 0.0349 Acc: 0.9930\n",
      "2022-01-23 02:36:12.592274\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0120 Acc: 0.9995\n",
      "2022-01-23 02:36:15.012249\n",
      "validation Loss: 0.0357 Acc: 0.9953\n",
      "2022-01-23 02:36:15.392776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0120 Acc: 0.9995\n",
      "2022-01-23 02:36:17.750969\n",
      "validation Loss: 0.0378 Acc: 0.9930\n",
      "2022-01-23 02:36:18.104196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0115 Acc: 0.9995\n",
      "2022-01-23 02:36:20.389923\n",
      "validation Loss: 0.0373 Acc: 0.9907\n",
      "2022-01-23 02:36:20.759721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0118 Acc: 0.9990\n",
      "2022-01-23 02:36:23.181692\n",
      "validation Loss: 0.0396 Acc: 0.9907\n",
      "2022-01-23 02:36:23.562605\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9985\n",
      "2022-01-23 02:36:25.893095\n",
      "validation Loss: 0.0358 Acc: 0.9883\n",
      "2022-01-23 02:36:26.243239\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0105 Acc: 1.0000\n",
      "2022-01-23 02:36:28.599716\n",
      "validation Loss: 0.0323 Acc: 0.9977\n",
      "2022-01-23 02:36:29.000653\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0109 Acc: 0.9985\n",
      "2022-01-23 02:36:31.724057\n",
      "validation Loss: 0.0328 Acc: 0.9977\n",
      "2022-01-23 02:36:32.085837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0101 Acc: 0.9995\n",
      "2022-01-23 02:36:34.485427\n",
      "validation Loss: 0.0331 Acc: 0.9953\n",
      "2022-01-23 02:36:34.878464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9995\n",
      "2022-01-23 02:36:37.261107\n",
      "validation Loss: 0.0339 Acc: 0.9930\n",
      "2022-01-23 02:36:37.653412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9995\n",
      "2022-01-23 02:36:40.000844\n",
      "validation Loss: 0.0321 Acc: 0.9930\n",
      "2022-01-23 02:36:40.397367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0096 Acc: 0.9990\n",
      "2022-01-23 02:36:42.858803\n",
      "validation Loss: 0.0514 Acc: 0.9883\n",
      "2022-01-23 02:36:43.234513\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9990\n",
      "2022-01-23 02:36:45.601429\n",
      "validation Loss: 0.0311 Acc: 0.9953\n",
      "2022-01-23 02:36:45.953182\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 1.0000\n",
      "2022-01-23 02:36:48.438423\n",
      "validation Loss: 0.0315 Acc: 0.9953\n",
      "2022-01-23 02:36:48.902782\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 1.0000\n",
      "2022-01-23 02:36:51.420390\n",
      "validation Loss: 0.0304 Acc: 0.9930\n",
      "2022-01-23 02:36:51.794374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0084 Acc: 1.0000\n",
      "2022-01-23 02:36:54.270349\n",
      "validation Loss: 0.0299 Acc: 0.9930\n",
      "2022-01-23 02:36:54.664704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 0.9995\n",
      "2022-01-23 02:36:57.131820\n",
      "validation Loss: 0.0341 Acc: 0.9930\n",
      "2022-01-23 02:36:57.497452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9995\n",
      "2022-01-23 02:36:59.921307\n",
      "validation Loss: 0.0291 Acc: 0.9977\n",
      "2022-01-23 02:37:00.253606\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9990\n",
      "2022-01-23 02:37:03.042432\n",
      "validation Loss: 0.0293 Acc: 0.9953\n",
      "2022-01-23 02:37:03.481853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0066 Acc: 0.9995\n",
      "2022-01-23 02:37:06.027230\n",
      "validation Loss: 0.0393 Acc: 0.9883\n",
      "2022-01-23 02:37:06.381209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0075 Acc: 1.0000\n",
      "2022-01-23 02:37:08.951357\n",
      "validation Loss: 0.0319 Acc: 0.9907\n",
      "2022-01-23 02:37:09.330612\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 1.0000\n",
      "2022-01-23 02:37:11.850607\n",
      "validation Loss: 0.0280 Acc: 0.9953\n",
      "2022-01-23 02:37:12.203225\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 0.9995\n",
      "2022-01-23 02:37:14.653789\n",
      "validation Loss: 0.0310 Acc: 0.9953\n",
      "2022-01-23 02:37:15.058239\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0063 Acc: 1.0000\n",
      "2022-01-23 02:37:17.598991\n",
      "validation Loss: 0.0317 Acc: 0.9930\n",
      "2022-01-23 02:37:17.990002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9995\n",
      "2022-01-23 02:37:20.546202\n",
      "validation Loss: 0.0309 Acc: 0.9953\n",
      "2022-01-23 02:37:20.908639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 1.0000\n",
      "2022-01-23 02:37:23.435543\n",
      "validation Loss: 0.0319 Acc: 0.9930\n",
      "2022-01-23 02:37:23.819047\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 1.0000\n",
      "2022-01-23 02:37:26.405714\n",
      "validation Loss: 0.0298 Acc: 0.9953\n",
      "2022-01-23 02:37:26.758595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 1.0000\n",
      "2022-01-23 02:37:29.360574\n",
      "validation Loss: 0.0279 Acc: 0.9977\n",
      "2022-01-23 02:37:29.711672\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "2022-01-23 02:37:32.539816\n",
      "validation Loss: 0.0290 Acc: 0.9953\n",
      "2022-01-23 02:37:32.918205\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 0.9995\n",
      "2022-01-23 02:37:35.336108\n",
      "validation Loss: 0.0373 Acc: 0.9907\n",
      "2022-01-23 02:37:35.717805\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 1.0000\n",
      "2022-01-23 02:37:38.123983\n",
      "validation Loss: 0.0278 Acc: 0.9953\n",
      "2022-01-23 02:37:38.509904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9977\n",
      "Accuracy of the network on the 429 test samples: 99.76689976689977\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:138fjxhx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 69613... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99767</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99534</td></tr><tr><td>best_test_accuracy</td><td>0.99767</td></tr><tr><td>best_val_accuracy</td><td>0.99767</td></tr><tr><td>best_val_loss</td><td>0.0279</td></tr><tr><td>loss_train</td><td>0.00643</td></tr><tr><td>loss_validation</td><td>0.02779</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/138fjxhx\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/138fjxhx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_023227-138fjxhx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:138fjxhx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/30rfqlwu\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 02:37:48.697596\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9691 Acc: 0.0950\n",
      "2022-01-23 02:37:51.267817\n",
      "validation Loss: 2.9249 Acc: 0.1142\n",
      "2022-01-23 02:37:51.619454\n",
      "Accuracy of the network on the 429 test samples: 12.354312354312354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8792 Acc: 0.1360\n",
      "2022-01-23 02:37:54.382767\n",
      "validation Loss: 2.8298 Acc: 0.1748\n",
      "2022-01-23 02:37:54.779982\n",
      "Accuracy of the network on the 429 test samples: 19.114219114219114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.7747 Acc: 0.2530\n",
      "2022-01-23 02:37:57.651733\n",
      "validation Loss: 2.7175 Acc: 0.2960\n",
      "2022-01-23 02:37:58.015274\n",
      "Accuracy of the network on the 429 test samples: 30.76923076923077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6542 Acc: 0.3500\n",
      "2022-01-23 02:38:00.827518\n",
      "validation Loss: 2.5906 Acc: 0.4172\n",
      "2022-01-23 02:38:01.175029\n",
      "Accuracy of the network on the 429 test samples: 43.58974358974359\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5237 Acc: 0.5010\n",
      "2022-01-23 02:38:04.012505\n",
      "validation Loss: 2.4583 Acc: 0.5897\n",
      "2022-01-23 02:38:04.389863\n",
      "Accuracy of the network on the 429 test samples: 58.27505827505828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3909 Acc: 0.6495\n",
      "2022-01-23 02:38:07.184914\n",
      "validation Loss: 2.3252 Acc: 0.7016\n",
      "2022-01-23 02:38:07.543932\n",
      "Accuracy of the network on the 429 test samples: 70.16317016317016\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.2612 Acc: 0.7400\n",
      "2022-01-23 02:38:10.560176\n",
      "validation Loss: 2.1972 Acc: 0.7552\n",
      "2022-01-23 02:38:10.940461\n",
      "Accuracy of the network on the 429 test samples: 81.35198135198135\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1380 Acc: 0.7885\n",
      "2022-01-23 02:38:13.757418\n",
      "validation Loss: 2.0762 Acc: 0.8019\n",
      "2022-01-23 02:38:14.106458\n",
      "Accuracy of the network on the 429 test samples: 82.98368298368298\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.0211 Acc: 0.8145\n",
      "2022-01-23 02:38:17.105594\n",
      "validation Loss: 1.9620 Acc: 0.8275\n",
      "2022-01-23 02:38:17.482029\n",
      "Accuracy of the network on the 429 test samples: 83.91608391608392\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.9108 Acc: 0.8265\n",
      "2022-01-23 02:38:20.173961\n",
      "validation Loss: 1.8542 Acc: 0.8438\n",
      "2022-01-23 02:38:20.510854\n",
      "Accuracy of the network on the 429 test samples: 85.78088578088578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.8069 Acc: 0.8445\n",
      "2022-01-23 02:38:23.282291\n",
      "validation Loss: 1.7539 Acc: 0.8601\n",
      "2022-01-23 02:38:23.640484\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7094 Acc: 0.8570\n",
      "2022-01-23 02:38:26.494635\n",
      "validation Loss: 1.6584 Acc: 0.8625\n",
      "2022-01-23 02:38:26.860179\n",
      "Accuracy of the network on the 429 test samples: 87.17948717948718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.6182 Acc: 0.8660\n",
      "2022-01-23 02:38:29.557642\n",
      "validation Loss: 1.5697 Acc: 0.8788\n",
      "2022-01-23 02:38:29.915592\n",
      "Accuracy of the network on the 429 test samples: 88.34498834498834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5321 Acc: 0.8780\n",
      "2022-01-23 02:38:32.646176\n",
      "validation Loss: 1.4859 Acc: 0.8788\n",
      "2022-01-23 02:38:33.013411\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.4514 Acc: 0.8885\n",
      "2022-01-23 02:38:35.823789\n",
      "validation Loss: 1.4078 Acc: 0.8881\n",
      "2022-01-23 02:38:36.191822\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3751 Acc: 0.8930\n",
      "2022-01-23 02:38:38.924255\n",
      "validation Loss: 1.3340 Acc: 0.8974\n",
      "2022-01-23 02:38:39.307689\n",
      "Accuracy of the network on the 429 test samples: 90.44289044289044\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3037 Acc: 0.8985\n",
      "2022-01-23 02:38:42.105153\n",
      "validation Loss: 1.2652 Acc: 0.8998\n",
      "2022-01-23 02:38:42.475741\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2370 Acc: 0.9035\n",
      "2022-01-23 02:38:45.269393\n",
      "validation Loss: 1.2003 Acc: 0.9044\n",
      "2022-01-23 02:38:45.631648\n",
      "Accuracy of the network on the 429 test samples: 92.3076923076923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1740 Acc: 0.9105\n",
      "2022-01-23 02:38:48.454651\n",
      "validation Loss: 1.1394 Acc: 0.9068\n",
      "2022-01-23 02:38:48.809864\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1150 Acc: 0.9160\n",
      "2022-01-23 02:38:51.593448\n",
      "validation Loss: 1.0836 Acc: 0.9044\n",
      "2022-01-23 02:38:52.002737\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0597 Acc: 0.9190\n",
      "2022-01-23 02:38:54.449882\n",
      "validation Loss: 1.0294 Acc: 0.9068\n",
      "2022-01-23 02:38:54.849329\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0073 Acc: 0.9285\n",
      "2022-01-23 02:38:57.792008\n",
      "validation Loss: 0.9797 Acc: 0.9091\n",
      "2022-01-23 02:38:58.204314\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9584 Acc: 0.9265\n",
      "2022-01-23 02:39:01.079759\n",
      "validation Loss: 0.9330 Acc: 0.9184\n",
      "2022-01-23 02:39:01.454991\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9128 Acc: 0.9290\n",
      "2022-01-23 02:39:04.250683\n",
      "validation Loss: 0.8891 Acc: 0.9184\n",
      "2022-01-23 02:39:04.613436\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8696 Acc: 0.9330\n",
      "2022-01-23 02:39:07.582083\n",
      "validation Loss: 0.8471 Acc: 0.9254\n",
      "2022-01-23 02:39:07.978625\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8296 Acc: 0.9365\n",
      "2022-01-23 02:39:10.935721\n",
      "validation Loss: 0.8091 Acc: 0.9277\n",
      "2022-01-23 02:39:11.307371\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7916 Acc: 0.9385\n",
      "2022-01-23 02:39:14.193809\n",
      "validation Loss: 0.7724 Acc: 0.9301\n",
      "2022-01-23 02:39:14.600749\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7559 Acc: 0.9370\n",
      "2022-01-23 02:39:17.364244\n",
      "validation Loss: 0.7386 Acc: 0.9301\n",
      "2022-01-23 02:39:17.725912\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7222 Acc: 0.9405\n",
      "2022-01-23 02:39:20.595333\n",
      "validation Loss: 0.7064 Acc: 0.9301\n",
      "2022-01-23 02:39:21.021670\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6905 Acc: 0.9430\n",
      "2022-01-23 02:39:24.036485\n",
      "validation Loss: 0.6771 Acc: 0.9324\n",
      "2022-01-23 02:39:24.427696\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6611 Acc: 0.9435\n",
      "2022-01-23 02:39:27.463004\n",
      "validation Loss: 0.6488 Acc: 0.9371\n",
      "2022-01-23 02:39:27.846195\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6330 Acc: 0.9455\n",
      "2022-01-23 02:39:30.797023\n",
      "validation Loss: 0.6219 Acc: 0.9394\n",
      "2022-01-23 02:39:31.214254\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6072 Acc: 0.9470\n",
      "2022-01-23 02:39:34.136039\n",
      "validation Loss: 0.5973 Acc: 0.9417\n",
      "2022-01-23 02:39:34.480888\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5824 Acc: 0.9485\n",
      "2022-01-23 02:39:37.299014\n",
      "validation Loss: 0.5734 Acc: 0.9441\n",
      "2022-01-23 02:39:37.690147\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5588 Acc: 0.9485\n",
      "2022-01-23 02:39:40.565957\n",
      "validation Loss: 0.5513 Acc: 0.9417\n",
      "2022-01-23 02:39:40.930835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5368 Acc: 0.9490\n",
      "2022-01-23 02:39:43.405185\n",
      "validation Loss: 0.5306 Acc: 0.9417\n",
      "2022-01-23 02:39:43.752911\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5164 Acc: 0.9535\n",
      "2022-01-23 02:39:46.354008\n",
      "validation Loss: 0.5114 Acc: 0.9441\n",
      "2022-01-23 02:39:46.808228\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4969 Acc: 0.9540\n",
      "2022-01-23 02:39:49.722814\n",
      "validation Loss: 0.4927 Acc: 0.9441\n",
      "2022-01-23 02:39:50.083887\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4784 Acc: 0.9550\n",
      "2022-01-23 02:39:53.187088\n",
      "validation Loss: 0.4751 Acc: 0.9464\n",
      "2022-01-23 02:39:53.543545\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4610 Acc: 0.9550\n",
      "2022-01-23 02:39:56.538961\n",
      "validation Loss: 0.4599 Acc: 0.9464\n",
      "2022-01-23 02:39:56.909236\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4443 Acc: 0.9575\n",
      "2022-01-23 02:39:59.854721\n",
      "validation Loss: 0.4436 Acc: 0.9464\n",
      "2022-01-23 02:40:00.276605\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4291 Acc: 0.9575\n",
      "2022-01-23 02:40:03.289333\n",
      "validation Loss: 0.4288 Acc: 0.9464\n",
      "2022-01-23 02:40:03.660650\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4140 Acc: 0.9595\n",
      "2022-01-23 02:40:06.689365\n",
      "validation Loss: 0.4158 Acc: 0.9464\n",
      "2022-01-23 02:40:07.117049\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4002 Acc: 0.9590\n",
      "2022-01-23 02:40:09.896066\n",
      "validation Loss: 0.4017 Acc: 0.9487\n",
      "2022-01-23 02:40:10.241874\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3871 Acc: 0.9610\n",
      "2022-01-23 02:40:13.143879\n",
      "validation Loss: 0.3900 Acc: 0.9487\n",
      "2022-01-23 02:40:13.508502\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3742 Acc: 0.9625\n",
      "2022-01-23 02:40:16.367925\n",
      "validation Loss: 0.3787 Acc: 0.9487\n",
      "2022-01-23 02:40:16.734940\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3623 Acc: 0.9625\n",
      "2022-01-23 02:40:19.656835\n",
      "validation Loss: 0.3665 Acc: 0.9510\n",
      "2022-01-23 02:40:20.025576\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3509 Acc: 0.9640\n",
      "2022-01-23 02:40:22.933092\n",
      "validation Loss: 0.3559 Acc: 0.9510\n",
      "2022-01-23 02:40:23.321355\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3403 Acc: 0.9635\n",
      "2022-01-23 02:40:26.098945\n",
      "validation Loss: 0.3469 Acc: 0.9487\n",
      "2022-01-23 02:40:26.477692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3295 Acc: 0.9655\n",
      "2022-01-23 02:40:28.872654\n",
      "validation Loss: 0.3364 Acc: 0.9534\n",
      "2022-01-23 02:40:29.251387\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3199 Acc: 0.9650\n",
      "2022-01-23 02:40:32.056926\n",
      "validation Loss: 0.3271 Acc: 0.9534\n",
      "2022-01-23 02:40:32.478204\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3102 Acc: 0.9660\n",
      "2022-01-23 02:40:35.258009\n",
      "validation Loss: 0.3191 Acc: 0.9557\n",
      "2022-01-23 02:40:35.609984\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3012 Acc: 0.9670\n",
      "2022-01-23 02:40:38.376357\n",
      "validation Loss: 0.3102 Acc: 0.9557\n",
      "2022-01-23 02:40:38.749899\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2927 Acc: 0.9670\n",
      "2022-01-23 02:40:41.513771\n",
      "validation Loss: 0.3021 Acc: 0.9557\n",
      "2022-01-23 02:40:41.875561\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2849 Acc: 0.9675\n",
      "2022-01-23 02:40:44.642574\n",
      "validation Loss: 0.2949 Acc: 0.9557\n",
      "2022-01-23 02:40:45.036720\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2767 Acc: 0.9685\n",
      "2022-01-23 02:40:46.815028\n",
      "validation Loss: 0.2875 Acc: 0.9557\n",
      "2022-01-23 02:40:47.178990\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2693 Acc: 0.9700\n",
      "2022-01-23 02:40:49.888971\n",
      "validation Loss: 0.2804 Acc: 0.9580\n",
      "2022-01-23 02:40:50.250455\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2616 Acc: 0.9710\n",
      "2022-01-23 02:40:53.236365\n",
      "validation Loss: 0.2751 Acc: 0.9557\n",
      "2022-01-23 02:40:53.693758\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2549 Acc: 0.9715\n",
      "2022-01-23 02:40:56.246777\n",
      "validation Loss: 0.2679 Acc: 0.9557\n",
      "2022-01-23 02:40:56.619020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2480 Acc: 0.9725\n",
      "2022-01-23 02:40:59.231119\n",
      "validation Loss: 0.2619 Acc: 0.9557\n",
      "2022-01-23 02:40:59.624538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2416 Acc: 0.9725\n",
      "2022-01-23 02:41:02.092105\n",
      "validation Loss: 0.2566 Acc: 0.9557\n",
      "2022-01-23 02:41:02.508704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2356 Acc: 0.9720\n",
      "2022-01-23 02:41:04.923333\n",
      "validation Loss: 0.2512 Acc: 0.9580\n",
      "2022-01-23 02:41:05.317051\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2296 Acc: 0.9725\n",
      "2022-01-23 02:41:08.166918\n",
      "validation Loss: 0.2452 Acc: 0.9534\n",
      "2022-01-23 02:41:08.566788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2238 Acc: 0.9725\n",
      "2022-01-23 02:41:11.004982\n",
      "validation Loss: 0.2396 Acc: 0.9580\n",
      "2022-01-23 02:41:11.413508\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2181 Acc: 0.9715\n",
      "2022-01-23 02:41:14.236124\n",
      "validation Loss: 0.2346 Acc: 0.9604\n",
      "2022-01-23 02:41:14.600608\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2130 Acc: 0.9725\n",
      "2022-01-23 02:41:17.412802\n",
      "validation Loss: 0.2309 Acc: 0.9580\n",
      "2022-01-23 02:41:17.795778\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2081 Acc: 0.9735\n",
      "2022-01-23 02:41:20.328015\n",
      "validation Loss: 0.2248 Acc: 0.9604\n",
      "2022-01-23 02:41:20.707778\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2030 Acc: 0.9750\n",
      "2022-01-23 02:41:23.699901\n",
      "validation Loss: 0.2209 Acc: 0.9604\n",
      "2022-01-23 02:41:24.071396\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1980 Acc: 0.9750\n",
      "2022-01-23 02:41:26.903899\n",
      "validation Loss: 0.2183 Acc: 0.9604\n",
      "2022-01-23 02:41:27.248041\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1935 Acc: 0.9740\n",
      "2022-01-23 02:41:29.948230\n",
      "validation Loss: 0.2112 Acc: 0.9604\n",
      "2022-01-23 02:41:30.324369\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1889 Acc: 0.9745\n",
      "2022-01-23 02:41:33.235263\n",
      "validation Loss: 0.2099 Acc: 0.9627\n",
      "2022-01-23 02:41:33.656182\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1847 Acc: 0.9740\n",
      "2022-01-23 02:41:36.656623\n",
      "validation Loss: 0.2046 Acc: 0.9627\n",
      "2022-01-23 02:41:37.021116\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1806 Acc: 0.9750\n",
      "2022-01-23 02:41:39.870775\n",
      "validation Loss: 0.2003 Acc: 0.9627\n",
      "2022-01-23 02:41:40.288953\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1765 Acc: 0.9770\n",
      "2022-01-23 02:41:43.233896\n",
      "validation Loss: 0.1957 Acc: 0.9627\n",
      "2022-01-23 02:41:43.602113\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1726 Acc: 0.9765\n",
      "2022-01-23 02:41:46.464847\n",
      "validation Loss: 0.1928 Acc: 0.9627\n",
      "2022-01-23 02:41:46.857655\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1689 Acc: 0.9765\n",
      "2022-01-23 02:41:49.782036\n",
      "validation Loss: 0.1906 Acc: 0.9627\n",
      "2022-01-23 02:41:50.153344\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1648 Acc: 0.9775\n",
      "2022-01-23 02:41:52.952236\n",
      "validation Loss: 0.1870 Acc: 0.9627\n",
      "2022-01-23 02:41:53.310979\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1616 Acc: 0.9755\n",
      "2022-01-23 02:41:56.169263\n",
      "validation Loss: 0.1841 Acc: 0.9627\n",
      "2022-01-23 02:41:56.528193\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1578 Acc: 0.9790\n",
      "2022-01-23 02:41:59.404648\n",
      "validation Loss: 0.1805 Acc: 0.9627\n",
      "2022-01-23 02:41:59.740736\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1544 Acc: 0.9775\n",
      "2022-01-23 02:42:02.587811\n",
      "validation Loss: 0.1777 Acc: 0.9627\n",
      "2022-01-23 02:42:03.014023\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1510 Acc: 0.9800\n",
      "2022-01-23 02:42:05.818388\n",
      "validation Loss: 0.1746 Acc: 0.9650\n",
      "2022-01-23 02:42:06.200063\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1483 Acc: 0.9795\n",
      "2022-01-23 02:42:09.068742\n",
      "validation Loss: 0.1726 Acc: 0.9627\n",
      "2022-01-23 02:42:09.417804\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1449 Acc: 0.9790\n",
      "2022-01-23 02:42:11.837025\n",
      "validation Loss: 0.1694 Acc: 0.9627\n",
      "2022-01-23 02:42:12.260956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1417 Acc: 0.9795\n",
      "2022-01-23 02:42:14.631129\n",
      "validation Loss: 0.1681 Acc: 0.9627\n",
      "2022-01-23 02:42:15.059893\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1392 Acc: 0.9825\n",
      "2022-01-23 02:42:17.545841\n",
      "validation Loss: 0.1638 Acc: 0.9627\n",
      "2022-01-23 02:42:17.956660\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1370 Acc: 0.9815\n",
      "2022-01-23 02:42:20.426302\n",
      "validation Loss: 0.1609 Acc: 0.9627\n",
      "2022-01-23 02:42:20.830871\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1342 Acc: 0.9805\n",
      "2022-01-23 02:42:23.255028\n",
      "validation Loss: 0.1578 Acc: 0.9650\n",
      "2022-01-23 02:42:23.680715\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1310 Acc: 0.9830\n",
      "2022-01-23 02:42:26.632841\n",
      "validation Loss: 0.1553 Acc: 0.9627\n",
      "2022-01-23 02:42:27.065419\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1284 Acc: 0.9830\n",
      "2022-01-23 02:42:29.541385\n",
      "validation Loss: 0.1535 Acc: 0.9674\n",
      "2022-01-23 02:42:29.968970\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1259 Acc: 0.9835\n",
      "2022-01-23 02:42:32.875994\n",
      "validation Loss: 0.1505 Acc: 0.9674\n",
      "2022-01-23 02:42:33.232229\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1233 Acc: 0.9820\n",
      "2022-01-23 02:42:35.992843\n",
      "validation Loss: 0.1496 Acc: 0.9650\n",
      "2022-01-23 02:42:36.341875\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1207 Acc: 0.9830\n",
      "2022-01-23 02:42:38.595069\n",
      "validation Loss: 0.1467 Acc: 0.9674\n",
      "2022-01-23 02:42:38.962728\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1182 Acc: 0.9845\n",
      "2022-01-23 02:42:41.667947\n",
      "validation Loss: 0.1493 Acc: 0.9627\n",
      "2022-01-23 02:42:42.071585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1164 Acc: 0.9850\n",
      "2022-01-23 02:42:44.480651\n",
      "validation Loss: 0.1430 Acc: 0.9674\n",
      "2022-01-23 02:42:44.834737\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1142 Acc: 0.9850\n",
      "2022-01-23 02:42:47.574121\n",
      "validation Loss: 0.1425 Acc: 0.9650\n",
      "2022-01-23 02:42:47.972705\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1120 Acc: 0.9860\n",
      "2022-01-23 02:42:50.597124\n",
      "validation Loss: 0.1391 Acc: 0.9674\n",
      "2022-01-23 02:42:51.009298\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1099 Acc: 0.9860\n",
      "2022-01-23 02:42:53.325424\n",
      "validation Loss: 0.1371 Acc: 0.9674\n",
      "2022-01-23 02:42:53.666686\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1078 Acc: 0.9855\n",
      "2022-01-23 02:42:56.468324\n",
      "validation Loss: 0.1361 Acc: 0.9697\n",
      "2022-01-23 02:42:56.851259\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1055 Acc: 0.9865\n",
      "2022-01-23 02:42:59.722195\n",
      "validation Loss: 0.1338 Acc: 0.9697\n",
      "2022-01-23 02:43:00.115259\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1038 Acc: 0.9855\n",
      "2022-01-23 02:43:03.012700\n",
      "validation Loss: 0.1317 Acc: 0.9697\n",
      "2022-01-23 02:43:03.435964\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9697\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:30rfqlwu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 71136... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▂▅▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▂▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▂▆▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98368</td></tr><tr><td>accuracy_train</td><td>0.9855</td></tr><tr><td>accuracy_validation</td><td>0.9697</td></tr><tr><td>best_test_accuracy</td><td>0.98368</td></tr><tr><td>best_val_accuracy</td><td>0.9697</td></tr><tr><td>best_val_loss</td><td>0.13169</td></tr><tr><td>loss_train</td><td>0.10381</td></tr><tr><td>loss_validation</td><td>0.13169</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/30rfqlwu\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/30rfqlwu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_023738-30rfqlwu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:30rfqlwu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/fcr25c2s\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 02:43:14.450908\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 1.2717 Acc: 0.6210\n",
      "2022-01-23 02:43:16.910223\n",
      "validation Loss: 0.5603 Acc: 0.8531\n",
      "2022-01-23 02:43:17.265158\n",
      "Accuracy of the network on the 429 test samples: 85.54778554778555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.5759 Acc: 0.8465\n",
      "2022-01-23 02:43:20.168960\n",
      "validation Loss: 0.3468 Acc: 0.9021\n",
      "2022-01-23 02:43:20.530436\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2595 Acc: 0.9210\n",
      "2022-01-23 02:43:23.268579\n",
      "validation Loss: 0.1875 Acc: 0.9347\n",
      "2022-01-23 02:43:23.654217\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1880 Acc: 0.9470\n",
      "2022-01-23 02:43:26.483414\n",
      "validation Loss: 0.1511 Acc: 0.9441\n",
      "2022-01-23 02:43:26.880721\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1222 Acc: 0.9605\n",
      "2022-01-23 02:43:30.032502\n",
      "validation Loss: 0.1563 Acc: 0.9464\n",
      "2022-01-23 02:43:30.410862\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1094 Acc: 0.9700\n",
      "2022-01-23 02:43:33.220891\n",
      "validation Loss: 0.1968 Acc: 0.9464\n",
      "2022-01-23 02:43:33.591908\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0945 Acc: 0.9695\n",
      "2022-01-23 02:43:36.122433\n",
      "validation Loss: 0.1574 Acc: 0.9441\n",
      "2022-01-23 02:43:36.477555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1089 Acc: 0.9690\n",
      "2022-01-23 02:43:39.030062\n",
      "validation Loss: 0.0545 Acc: 0.9814\n",
      "2022-01-23 02:43:39.389058\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0581 Acc: 0.9795\n",
      "2022-01-23 02:43:42.342168\n",
      "validation Loss: 0.0565 Acc: 0.9767\n",
      "2022-01-23 02:43:42.707523\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0681 Acc: 0.9765\n",
      "2022-01-23 02:43:45.151743\n",
      "validation Loss: 0.1201 Acc: 0.9627\n",
      "2022-01-23 02:43:45.563781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0637 Acc: 0.9820\n",
      "2022-01-23 02:43:48.072240\n",
      "validation Loss: 0.0560 Acc: 0.9814\n",
      "2022-01-23 02:43:48.508610\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0422 Acc: 0.9860\n",
      "2022-01-23 02:43:51.043432\n",
      "validation Loss: 0.1291 Acc: 0.9744\n",
      "2022-01-23 02:43:51.426068\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0660 Acc: 0.9810\n",
      "2022-01-23 02:43:53.839493\n",
      "validation Loss: 0.0797 Acc: 0.9697\n",
      "2022-01-23 02:43:54.205283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0484 Acc: 0.9870\n",
      "2022-01-23 02:43:56.665865\n",
      "validation Loss: 0.1148 Acc: 0.9674\n",
      "2022-01-23 02:43:56.990435\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1182 Acc: 0.9695\n",
      "2022-01-23 02:43:59.460559\n",
      "validation Loss: 0.0939 Acc: 0.9697\n",
      "2022-01-23 02:43:59.834881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0389 Acc: 0.9875\n",
      "2022-01-23 02:44:02.271226\n",
      "validation Loss: 0.0815 Acc: 0.9697\n",
      "2022-01-23 02:44:02.649927\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0518 Acc: 0.9835\n",
      "2022-01-23 02:44:05.160502\n",
      "validation Loss: 0.1296 Acc: 0.9604\n",
      "2022-01-23 02:44:05.565389\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1523 Acc: 0.9560\n",
      "2022-01-23 02:44:08.018464\n",
      "validation Loss: 0.1211 Acc: 0.9650\n",
      "2022-01-23 02:44:08.428790\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0572 Acc: 0.9825\n",
      "2022-01-23 02:44:10.889597\n",
      "validation Loss: 0.2027 Acc: 0.9277\n",
      "2022-01-23 02:44:11.246185\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0497 Acc: 0.9815\n",
      "2022-01-23 02:44:13.623421\n",
      "validation Loss: 0.0789 Acc: 0.9720\n",
      "2022-01-23 02:44:14.004969\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0335 Acc: 0.9895\n",
      "2022-01-23 02:44:16.412958\n",
      "validation Loss: 0.1858 Acc: 0.9580\n",
      "2022-01-23 02:44:16.788771\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0655 Acc: 0.9795\n",
      "2022-01-23 02:44:19.231789\n",
      "validation Loss: 0.0888 Acc: 0.9814\n",
      "2022-01-23 02:44:19.604163\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0740 Acc: 0.9820\n",
      "2022-01-23 02:44:22.000659\n",
      "validation Loss: 0.4756 Acc: 0.8788\n",
      "2022-01-23 02:44:22.421681\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1132 Acc: 0.9695\n",
      "2022-01-23 02:44:24.881078\n",
      "validation Loss: 0.0705 Acc: 0.9790\n",
      "2022-01-23 02:44:25.252729\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0968 Acc: 0.9710\n",
      "2022-01-23 02:44:27.707195\n",
      "validation Loss: 0.2230 Acc: 0.9301\n",
      "2022-01-23 02:44:28.075763\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0374 Acc: 0.9855\n",
      "2022-01-23 02:44:30.687253\n",
      "validation Loss: 0.1054 Acc: 0.9790\n",
      "2022-01-23 02:44:31.046835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0565 Acc: 0.9805\n",
      "2022-01-23 02:44:33.443611\n",
      "validation Loss: 0.1932 Acc: 0.9557\n",
      "2022-01-23 02:44:33.797177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1085 Acc: 0.9670\n",
      "2022-01-23 02:44:36.211408\n",
      "validation Loss: 0.0255 Acc: 0.9860\n",
      "2022-01-23 02:44:36.566417\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0426 Acc: 0.9885\n",
      "2022-01-23 02:44:39.504321\n",
      "validation Loss: 0.2970 Acc: 0.9557\n",
      "2022-01-23 02:44:39.887251\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1550 Acc: 0.9535\n",
      "2022-01-23 02:44:42.308298\n",
      "validation Loss: 0.0586 Acc: 0.9767\n",
      "2022-01-23 02:44:42.696848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0520 Acc: 0.9855\n",
      "2022-01-23 02:44:45.022260\n",
      "validation Loss: 0.1190 Acc: 0.9650\n",
      "2022-01-23 02:44:45.455971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0372 Acc: 0.9900\n",
      "2022-01-23 02:44:47.823328\n",
      "validation Loss: 0.0513 Acc: 0.9837\n",
      "2022-01-23 02:44:48.207945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0124 Acc: 0.9970\n",
      "2022-01-23 02:44:50.554394\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 02:44:50.927082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 0.9975\n",
      "2022-01-23 02:44:53.327784\n",
      "validation Loss: 0.0243 Acc: 0.9860\n",
      "2022-01-23 02:44:53.704589\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0636 Acc: 0.9805\n",
      "2022-01-23 02:44:56.446253\n",
      "validation Loss: 0.1228 Acc: 0.9744\n",
      "2022-01-23 02:44:56.820860\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0508 Acc: 0.9830\n",
      "2022-01-23 02:44:59.218303\n",
      "validation Loss: 0.0676 Acc: 0.9790\n",
      "2022-01-23 02:44:59.593477\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0346 Acc: 0.9895\n",
      "2022-01-23 02:45:02.005024\n",
      "validation Loss: 0.0235 Acc: 0.9883\n",
      "2022-01-23 02:45:02.359383\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0226 Acc: 0.9925\n",
      "2022-01-23 02:45:04.267013\n",
      "validation Loss: 0.0527 Acc: 0.9814\n",
      "2022-01-23 02:45:04.631215\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0331 Acc: 0.9915\n",
      "2022-01-23 02:45:06.978052\n",
      "validation Loss: 0.0458 Acc: 0.9837\n",
      "2022-01-23 02:45:07.343987\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0206 Acc: 0.9925\n",
      "2022-01-23 02:45:09.759777\n",
      "validation Loss: 0.0625 Acc: 0.9837\n",
      "2022-01-23 02:45:10.114342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0091 Acc: 0.9975\n",
      "2022-01-23 02:45:12.485318\n",
      "validation Loss: 0.0214 Acc: 0.9883\n",
      "2022-01-23 02:45:12.864912\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 0.9985\n",
      "2022-01-23 02:45:15.623360\n",
      "validation Loss: 0.0270 Acc: 0.9907\n",
      "2022-01-23 02:45:15.975929\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0143 Acc: 0.9960\n",
      "2022-01-23 02:45:18.694520\n",
      "validation Loss: 0.0193 Acc: 0.9953\n",
      "2022-01-23 02:45:19.054064\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0025 Acc: 0.9990\n",
      "2022-01-23 02:45:21.847913\n",
      "validation Loss: 0.0236 Acc: 0.9907\n",
      "2022-01-23 02:45:22.217248\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 0.9995\n",
      "2022-01-23 02:45:24.689274\n",
      "validation Loss: 0.0190 Acc: 0.9907\n",
      "2022-01-23 02:45:25.104600\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 0.9985\n",
      "2022-01-23 02:45:27.571047\n",
      "validation Loss: 0.0218 Acc: 0.9907\n",
      "2022-01-23 02:45:27.943131\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 0.9990\n",
      "2022-01-23 02:45:30.352885\n",
      "validation Loss: 0.0242 Acc: 0.9930\n",
      "2022-01-23 02:45:30.758979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:45:33.277046\n",
      "validation Loss: 0.0254 Acc: 0.9907\n",
      "2022-01-23 02:45:33.687332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:45:36.207953\n",
      "validation Loss: 0.0264 Acc: 0.9930\n",
      "2022-01-23 02:45:36.569070\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:45:39.059959\n",
      "validation Loss: 0.0273 Acc: 0.9930\n",
      "2022-01-23 02:45:39.413289\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:41.816476\n",
      "validation Loss: 0.0280 Acc: 0.9930\n",
      "2022-01-23 02:45:42.198433\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:44.641101\n",
      "validation Loss: 0.0280 Acc: 0.9930\n",
      "2022-01-23 02:45:45.003438\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:47.467361\n",
      "validation Loss: 0.0280 Acc: 0.9930\n",
      "2022-01-23 02:45:47.826889\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:50.252999\n",
      "validation Loss: 0.0284 Acc: 0.9930\n",
      "2022-01-23 02:45:50.725253\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:53.229733\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 02:45:53.602750\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:56.169148\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 02:45:56.534069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:45:59.126736\n",
      "validation Loss: 0.0286 Acc: 0.9930\n",
      "2022-01-23 02:45:59.516132\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:02.239447\n",
      "validation Loss: 0.0289 Acc: 0.9930\n",
      "2022-01-23 02:46:02.607553\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:05.325450\n",
      "validation Loss: 0.0289 Acc: 0.9930\n",
      "2022-01-23 02:46:05.687925\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:08.129115\n",
      "validation Loss: 0.0289 Acc: 0.9930\n",
      "2022-01-23 02:46:08.514278\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:10.961947\n",
      "validation Loss: 0.0288 Acc: 0.9930\n",
      "2022-01-23 02:46:11.325706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:13.998485\n",
      "validation Loss: 0.0287 Acc: 0.9930\n",
      "2022-01-23 02:46:14.380087\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:16.964421\n",
      "validation Loss: 0.0291 Acc: 0.9930\n",
      "2022-01-23 02:46:17.354964\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:19.894594\n",
      "validation Loss: 0.0293 Acc: 0.9930\n",
      "2022-01-23 02:46:20.254904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:22.805066\n",
      "validation Loss: 0.0290 Acc: 0.9930\n",
      "2022-01-23 02:46:23.185457\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:25.640948\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 02:46:25.994842\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:28.465154\n",
      "validation Loss: 0.0290 Acc: 0.9930\n",
      "2022-01-23 02:46:28.839822\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:31.240687\n",
      "validation Loss: 0.0292 Acc: 0.9930\n",
      "2022-01-23 02:46:31.608566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:34.068122\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 02:46:34.449796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:37.052057\n",
      "validation Loss: 0.0296 Acc: 0.9930\n",
      "2022-01-23 02:46:37.420004\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:39.906130\n",
      "validation Loss: 0.0297 Acc: 0.9930\n",
      "2022-01-23 02:46:40.302091\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:43.060465\n",
      "validation Loss: 0.0298 Acc: 0.9930\n",
      "2022-01-23 02:46:43.415954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:46.223797\n",
      "validation Loss: 0.0299 Acc: 0.9930\n",
      "2022-01-23 02:46:46.589350\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:49.197392\n",
      "validation Loss: 0.0301 Acc: 0.9930\n",
      "2022-01-23 02:46:49.571296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:52.179238\n",
      "validation Loss: 0.0296 Acc: 0.9930\n",
      "2022-01-23 02:46:52.560525\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:53.991915\n",
      "validation Loss: 0.0300 Acc: 0.9930\n",
      "2022-01-23 02:46:54.357538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:56.742336\n",
      "validation Loss: 0.0302 Acc: 0.9930\n",
      "2022-01-23 02:46:57.091859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:46:59.638484\n",
      "validation Loss: 0.0300 Acc: 0.9930\n",
      "2022-01-23 02:47:00.022566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:02.533623\n",
      "validation Loss: 0.0305 Acc: 0.9930\n",
      "2022-01-23 02:47:02.937412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:05.412903\n",
      "validation Loss: 0.0303 Acc: 0.9930\n",
      "2022-01-23 02:47:05.811610\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:08.186238\n",
      "validation Loss: 0.0302 Acc: 0.9930\n",
      "2022-01-23 02:47:08.549328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:10.919016\n",
      "validation Loss: 0.0308 Acc: 0.9930\n",
      "2022-01-23 02:47:11.327221\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:13.724330\n",
      "validation Loss: 0.0306 Acc: 0.9930\n",
      "2022-01-23 02:47:14.130449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:16.605148\n",
      "validation Loss: 0.0310 Acc: 0.9930\n",
      "2022-01-23 02:47:17.005554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:19.215334\n",
      "validation Loss: 0.0307 Acc: 0.9907\n",
      "2022-01-23 02:47:19.597294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:22.028482\n",
      "validation Loss: 0.0308 Acc: 0.9907\n",
      "2022-01-23 02:47:22.466717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:24.932372\n",
      "validation Loss: 0.0314 Acc: 0.9907\n",
      "2022-01-23 02:47:25.335948\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:27.628804\n",
      "validation Loss: 0.0314 Acc: 0.9907\n",
      "2022-01-23 02:47:28.032546\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:30.444816\n",
      "validation Loss: 0.0316 Acc: 0.9907\n",
      "2022-01-23 02:47:30.821057\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:33.397283\n",
      "validation Loss: 0.0317 Acc: 0.9907\n",
      "2022-01-23 02:47:33.815189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:36.247637\n",
      "validation Loss: 0.0317 Acc: 0.9907\n",
      "2022-01-23 02:47:36.665502\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:39.228014\n",
      "validation Loss: 0.0316 Acc: 0.9907\n",
      "2022-01-23 02:47:39.606977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:42.075653\n",
      "validation Loss: 0.0324 Acc: 0.9907\n",
      "2022-01-23 02:47:42.478005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:44.912830\n",
      "validation Loss: 0.0320 Acc: 0.9907\n",
      "2022-01-23 02:47:45.270939\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:47.767902\n",
      "validation Loss: 0.0323 Acc: 0.9907\n",
      "2022-01-23 02:47:48.169173\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:50.599790\n",
      "validation Loss: 0.0328 Acc: 0.9930\n",
      "2022-01-23 02:47:50.952687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:53.344823\n",
      "validation Loss: 0.0327 Acc: 0.9930\n",
      "2022-01-23 02:47:53.737067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:56.146769\n",
      "validation Loss: 0.0330 Acc: 0.9930\n",
      "2022-01-23 02:47:56.549887\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:47:59.021157\n",
      "validation Loss: 0.0329 Acc: 0.9930\n",
      "2022-01-23 02:47:59.431957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:48:01.991025\n",
      "validation Loss: 0.0331 Acc: 0.9930\n",
      "2022-01-23 02:48:02.370001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fcr25c2s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 89506... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▃▆▅▅▇██████</td></tr><tr><td>accuracy_train</td><td>▁▇▇▇███▇███▇████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▅▆▇▇▇▇▇▆▂▇█▇█▇█████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▃▁▁▂▂▂▃▇▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.01933</td></tr><tr><td>loss_train</td><td>0.0</td></tr><tr><td>loss_validation</td><td>0.0331</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/fcr25c2s\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/fcr25c2s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_024304-fcr25c2s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fcr25c2s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/rl94xcet\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 02:48:12.351390\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.3868 Acc: 0.5720\n",
      "2022-01-23 02:48:14.954561\n",
      "validation Loss: 0.4631 Acc: 0.8415\n",
      "2022-01-23 02:48:15.343294\n",
      "Accuracy of the network on the 429 test samples: 84.14918414918415\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.4765 Acc: 0.8525\n",
      "2022-01-23 02:48:18.360446\n",
      "validation Loss: 0.4448 Acc: 0.8671\n",
      "2022-01-23 02:48:18.761684\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2475 Acc: 0.9185\n",
      "2022-01-23 02:48:21.683858\n",
      "validation Loss: 0.2816 Acc: 0.9091\n",
      "2022-01-23 02:48:22.070626\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.3037 Acc: 0.9225\n",
      "2022-01-23 02:48:24.867086\n",
      "validation Loss: 0.2196 Acc: 0.9254\n",
      "2022-01-23 02:48:25.248845\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1887 Acc: 0.9460\n",
      "2022-01-23 02:48:28.081576\n",
      "validation Loss: 0.2173 Acc: 0.9394\n",
      "2022-01-23 02:48:28.495136\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0903 Acc: 0.9670\n",
      "2022-01-23 02:48:30.997067\n",
      "validation Loss: 0.1706 Acc: 0.9557\n",
      "2022-01-23 02:48:31.371045\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1790 Acc: 0.9395\n",
      "2022-01-23 02:48:34.301009\n",
      "validation Loss: 0.1598 Acc: 0.9417\n",
      "2022-01-23 02:48:34.736198\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1061 Acc: 0.9660\n",
      "2022-01-23 02:48:37.354327\n",
      "validation Loss: 0.1117 Acc: 0.9627\n",
      "2022-01-23 02:48:37.790825\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1075 Acc: 0.9650\n",
      "2022-01-23 02:48:40.681459\n",
      "validation Loss: 0.1372 Acc: 0.9580\n",
      "2022-01-23 02:48:41.063500\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1199 Acc: 0.9635\n",
      "2022-01-23 02:48:43.526556\n",
      "validation Loss: 0.1295 Acc: 0.9627\n",
      "2022-01-23 02:48:43.932294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0766 Acc: 0.9770\n",
      "2022-01-23 02:48:46.460414\n",
      "validation Loss: 0.4242 Acc: 0.8671\n",
      "2022-01-23 02:48:46.860350\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.3841 Acc: 0.9050\n",
      "2022-01-23 02:48:49.281232\n",
      "validation Loss: 0.3992 Acc: 0.8951\n",
      "2022-01-23 02:48:49.639865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1607 Acc: 0.9480\n",
      "2022-01-23 02:48:52.103467\n",
      "validation Loss: 0.1123 Acc: 0.9627\n",
      "2022-01-23 02:48:52.490056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0835 Acc: 0.9710\n",
      "2022-01-23 02:48:55.015526\n",
      "validation Loss: 0.1344 Acc: 0.9487\n",
      "2022-01-23 02:48:55.413216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1487 Acc: 0.9610\n",
      "2022-01-23 02:48:57.225331\n",
      "validation Loss: 0.1830 Acc: 0.9604\n",
      "2022-01-23 02:48:57.642945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1116 Acc: 0.9730\n",
      "2022-01-23 02:49:00.066031\n",
      "validation Loss: 0.1086 Acc: 0.9650\n",
      "2022-01-23 02:49:00.474538\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0508 Acc: 0.9815\n",
      "2022-01-23 02:49:03.323710\n",
      "validation Loss: 0.1208 Acc: 0.9650\n",
      "2022-01-23 02:49:03.677974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0452 Acc: 0.9840\n",
      "2022-01-23 02:49:06.031364\n",
      "validation Loss: 0.1035 Acc: 0.9744\n",
      "2022-01-23 02:49:06.456106\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0455 Acc: 0.9870\n",
      "2022-01-23 02:49:09.341866\n",
      "validation Loss: 0.0861 Acc: 0.9790\n",
      "2022-01-23 02:49:09.714004\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0183 Acc: 0.9930\n",
      "2022-01-23 02:49:12.506524\n",
      "validation Loss: 0.1952 Acc: 0.9650\n",
      "2022-01-23 02:49:12.878901\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0661 Acc: 0.9795\n",
      "2022-01-23 02:49:15.225017\n",
      "validation Loss: 0.1185 Acc: 0.9580\n",
      "2022-01-23 02:49:15.594677\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0318 Acc: 0.9895\n",
      "2022-01-23 02:49:17.964023\n",
      "validation Loss: 0.0887 Acc: 0.9697\n",
      "2022-01-23 02:49:18.376502\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0150 Acc: 0.9955\n",
      "2022-01-23 02:49:20.803310\n",
      "validation Loss: 0.0882 Acc: 0.9720\n",
      "2022-01-23 02:49:21.191722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1479 Acc: 0.9640\n",
      "2022-01-23 02:49:23.646374\n",
      "validation Loss: 0.2215 Acc: 0.9464\n",
      "2022-01-23 02:49:24.047946\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1196 Acc: 0.9645\n",
      "2022-01-23 02:49:26.455513\n",
      "validation Loss: 0.0907 Acc: 0.9720\n",
      "2022-01-23 02:49:26.837314\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0962 Acc: 0.9695\n",
      "2022-01-23 02:49:29.215584\n",
      "validation Loss: 0.0964 Acc: 0.9720\n",
      "2022-01-23 02:49:29.610538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0372 Acc: 0.9895\n",
      "2022-01-23 02:49:31.994760\n",
      "validation Loss: 0.0666 Acc: 0.9767\n",
      "2022-01-23 02:49:32.401603\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0238 Acc: 0.9905\n",
      "2022-01-23 02:49:34.795515\n",
      "validation Loss: 0.0523 Acc: 0.9790\n",
      "2022-01-23 02:49:35.159839\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0428 Acc: 0.9890\n",
      "2022-01-23 02:49:37.977859\n",
      "validation Loss: 0.0415 Acc: 0.9837\n",
      "2022-01-23 02:49:38.386722\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0210 Acc: 0.9915\n",
      "2022-01-23 02:49:41.268970\n",
      "validation Loss: 0.0457 Acc: 0.9860\n",
      "2022-01-23 02:49:41.652311\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9970\n",
      "2022-01-23 02:49:44.491837\n",
      "validation Loss: 0.0707 Acc: 0.9790\n",
      "2022-01-23 02:49:44.844577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 0.9975\n",
      "2022-01-23 02:49:47.311219\n",
      "validation Loss: 0.1269 Acc: 0.9674\n",
      "2022-01-23 02:49:47.711161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0297 Acc: 0.9905\n",
      "2022-01-23 02:49:50.305660\n",
      "validation Loss: 0.0495 Acc: 0.9837\n",
      "2022-01-23 02:49:50.706473\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0076 Acc: 0.9975\n",
      "2022-01-23 02:49:53.202997\n",
      "validation Loss: 0.0462 Acc: 0.9814\n",
      "2022-01-23 02:49:53.598436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 0.9990\n",
      "2022-01-23 02:49:56.056033\n",
      "validation Loss: 0.0463 Acc: 0.9860\n",
      "2022-01-23 02:49:56.407163\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 0.9990\n",
      "2022-01-23 02:49:58.899623\n",
      "validation Loss: 0.0644 Acc: 0.9814\n",
      "2022-01-23 02:49:59.309966\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0314 Acc: 0.9890\n",
      "2022-01-23 02:50:01.747124\n",
      "validation Loss: 0.0929 Acc: 0.9650\n",
      "2022-01-23 02:50:02.128247\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0427 Acc: 0.9875\n",
      "2022-01-23 02:50:03.573120\n",
      "validation Loss: 0.0716 Acc: 0.9790\n",
      "2022-01-23 02:50:03.960544\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0274 Acc: 0.9925\n",
      "2022-01-23 02:50:06.357132\n",
      "validation Loss: 0.0833 Acc: 0.9720\n",
      "2022-01-23 02:50:06.722848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9925\n",
      "2022-01-23 02:50:08.940074\n",
      "validation Loss: 0.1004 Acc: 0.9720\n",
      "2022-01-23 02:50:09.279137\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 0.9970\n",
      "2022-01-23 02:50:11.756379\n",
      "validation Loss: 0.0512 Acc: 0.9837\n",
      "2022-01-23 02:50:12.153057\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0539 Acc: 0.9930\n",
      "2022-01-23 02:50:13.544980\n",
      "validation Loss: 0.0789 Acc: 0.9790\n",
      "2022-01-23 02:50:13.957943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 0.9975\n",
      "2022-01-23 02:50:16.379044\n",
      "validation Loss: 0.0738 Acc: 0.9790\n",
      "2022-01-23 02:50:16.797908\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0363 Acc: 0.9875\n",
      "2022-01-23 02:50:19.288028\n",
      "validation Loss: 0.0763 Acc: 0.9814\n",
      "2022-01-23 02:50:19.680360\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0162 Acc: 0.9955\n",
      "2022-01-23 02:50:22.242438\n",
      "validation Loss: 0.0506 Acc: 0.9767\n",
      "2022-01-23 02:50:22.664134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1051 Acc: 0.9685\n",
      "2022-01-23 02:50:25.241745\n",
      "validation Loss: 0.0871 Acc: 0.9627\n",
      "2022-01-23 02:50:25.628840\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0642 Acc: 0.9775\n",
      "2022-01-23 02:50:27.907623\n",
      "validation Loss: 0.1389 Acc: 0.9627\n",
      "2022-01-23 02:50:28.257454\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0714 Acc: 0.9805\n",
      "2022-01-23 02:50:30.614431\n",
      "validation Loss: 0.0792 Acc: 0.9790\n",
      "2022-01-23 02:50:31.010045\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0100 Acc: 0.9970\n",
      "2022-01-23 02:50:33.447096\n",
      "validation Loss: 0.1003 Acc: 0.9790\n",
      "2022-01-23 02:50:33.815922\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 0.9980\n",
      "2022-01-23 02:50:36.497387\n",
      "validation Loss: 0.0815 Acc: 0.9814\n",
      "2022-01-23 02:50:36.914993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0259 Acc: 0.9905\n",
      "2022-01-23 02:50:39.485282\n",
      "validation Loss: 0.1824 Acc: 0.9674\n",
      "2022-01-23 02:50:39.850718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0183 Acc: 0.9935\n",
      "2022-01-23 02:50:42.264005\n",
      "validation Loss: 0.0947 Acc: 0.9790\n",
      "2022-01-23 02:50:42.630777\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 0.9950\n",
      "2022-01-23 02:50:45.057706\n",
      "validation Loss: 0.0865 Acc: 0.9767\n",
      "2022-01-23 02:50:45.427552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0219 Acc: 0.9920\n",
      "2022-01-23 02:50:48.098813\n",
      "validation Loss: 0.1026 Acc: 0.9814\n",
      "2022-01-23 02:50:48.481158\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0264 Acc: 0.9915\n",
      "2022-01-23 02:50:50.957923\n",
      "validation Loss: 0.1642 Acc: 0.9510\n",
      "2022-01-23 02:50:51.345601\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0262 Acc: 0.9925\n",
      "2022-01-23 02:50:53.895397\n",
      "validation Loss: 0.0921 Acc: 0.9790\n",
      "2022-01-23 02:50:54.258161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0087 Acc: 0.9970\n",
      "2022-01-23 02:50:56.744561\n",
      "validation Loss: 0.0829 Acc: 0.9790\n",
      "2022-01-23 02:50:57.109276\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0512 Acc: 0.9880\n",
      "2022-01-23 02:50:59.610232\n",
      "validation Loss: 0.1061 Acc: 0.9767\n",
      "2022-01-23 02:50:59.976595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0610 Acc: 0.9870\n",
      "2022-01-23 02:51:02.463729\n",
      "validation Loss: 0.0651 Acc: 0.9767\n",
      "2022-01-23 02:51:02.860712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0118 Acc: 0.9975\n",
      "2022-01-23 02:51:05.533011\n",
      "validation Loss: 0.0846 Acc: 0.9790\n",
      "2022-01-23 02:51:05.982968\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 0.9995\n",
      "2022-01-23 02:51:08.570494\n",
      "validation Loss: 0.0675 Acc: 0.9814\n",
      "2022-01-23 02:51:08.960472\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 02:51:11.349332\n",
      "validation Loss: 0.0641 Acc: 0.9814\n",
      "2022-01-23 02:51:11.789550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 02:51:14.235118\n",
      "validation Loss: 0.0703 Acc: 0.9814\n",
      "2022-01-23 02:51:14.637354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:51:17.116994\n",
      "validation Loss: 0.0759 Acc: 0.9790\n",
      "2022-01-23 02:51:17.500593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:51:19.918869\n",
      "validation Loss: 0.0763 Acc: 0.9767\n",
      "2022-01-23 02:51:20.261672\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:51:22.651472\n",
      "validation Loss: 0.0823 Acc: 0.9790\n",
      "2022-01-23 02:51:23.014033\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:25.396716\n",
      "validation Loss: 0.0845 Acc: 0.9790\n",
      "2022-01-23 02:51:25.764666\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:28.105866\n",
      "validation Loss: 0.0872 Acc: 0.9790\n",
      "2022-01-23 02:51:28.466721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:30.877320\n",
      "validation Loss: 0.0910 Acc: 0.9767\n",
      "2022-01-23 02:51:31.289542\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:33.754683\n",
      "validation Loss: 0.0933 Acc: 0.9767\n",
      "2022-01-23 02:51:34.122618\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:36.355568\n",
      "validation Loss: 0.0959 Acc: 0.9767\n",
      "2022-01-23 02:51:36.707887\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:39.140966\n",
      "validation Loss: 0.0982 Acc: 0.9767\n",
      "2022-01-23 02:51:39.484187\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:41.851457\n",
      "validation Loss: 0.0996 Acc: 0.9767\n",
      "2022-01-23 02:51:42.217560\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:44.637111\n",
      "validation Loss: 0.1025 Acc: 0.9790\n",
      "2022-01-23 02:51:45.036136\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:51:47.061756\n",
      "validation Loss: 0.1059 Acc: 0.9767\n",
      "2022-01-23 02:51:47.445956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:51:49.959791\n",
      "validation Loss: 0.1092 Acc: 0.9767\n",
      "2022-01-23 02:51:50.311625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:51:52.733404\n",
      "validation Loss: 0.1152 Acc: 0.9767\n",
      "2022-01-23 02:51:53.227572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:51:55.883993\n",
      "validation Loss: 0.1180 Acc: 0.9767\n",
      "2022-01-23 02:51:56.287026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:51:58.767933\n",
      "validation Loss: 0.1234 Acc: 0.9767\n",
      "2022-01-23 02:51:59.143667\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:01.399579\n",
      "validation Loss: 0.1269 Acc: 0.9767\n",
      "2022-01-23 02:52:01.739232\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:03.124420\n",
      "validation Loss: 0.1330 Acc: 0.9767\n",
      "2022-01-23 02:52:03.512288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:05.865361\n",
      "validation Loss: 0.1365 Acc: 0.9767\n",
      "2022-01-23 02:52:06.289264\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:08.839406\n",
      "validation Loss: 0.1402 Acc: 0.9767\n",
      "2022-01-23 02:52:09.238380\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:11.776214\n",
      "validation Loss: 0.1449 Acc: 0.9767\n",
      "2022-01-23 02:52:12.137798\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:14.619968\n",
      "validation Loss: 0.1472 Acc: 0.9767\n",
      "2022-01-23 02:52:15.013303\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:17.582437\n",
      "validation Loss: 0.1510 Acc: 0.9767\n",
      "2022-01-23 02:52:17.984402\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:20.413384\n",
      "validation Loss: 0.1562 Acc: 0.9767\n",
      "2022-01-23 02:52:20.777462\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:23.317511\n",
      "validation Loss: 0.1600 Acc: 0.9767\n",
      "2022-01-23 02:52:23.745169\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:26.055509\n",
      "validation Loss: 0.1622 Acc: 0.9767\n",
      "2022-01-23 02:52:26.438560\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:28.854694\n",
      "validation Loss: 0.1664 Acc: 0.9767\n",
      "2022-01-23 02:52:29.272951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:31.687073\n",
      "validation Loss: 0.1705 Acc: 0.9767\n",
      "2022-01-23 02:52:32.106800\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:34.554885\n",
      "validation Loss: 0.1741 Acc: 0.9767\n",
      "2022-01-23 02:52:34.920884\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:37.368086\n",
      "validation Loss: 0.1777 Acc: 0.9767\n",
      "2022-01-23 02:52:37.732034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:40.150676\n",
      "validation Loss: 0.1811 Acc: 0.9767\n",
      "2022-01-23 02:52:40.527695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:43.059532\n",
      "validation Loss: 0.1854 Acc: 0.9767\n",
      "2022-01-23 02:52:43.536593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:46.027957\n",
      "validation Loss: 0.1886 Acc: 0.9767\n",
      "2022-01-23 02:52:46.399591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:48.907956\n",
      "validation Loss: 0.1920 Acc: 0.9767\n",
      "2022-01-23 02:52:49.293534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:51.569169\n",
      "validation Loss: 0.1946 Acc: 0.9767\n",
      "2022-01-23 02:52:51.969694\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:54.323107\n",
      "validation Loss: 0.1985 Acc: 0.9767\n",
      "2022-01-23 02:52:54.666488\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:52:57.012484\n",
      "validation Loss: 0.2022 Acc: 0.9767\n",
      "2022-01-23 02:52:57.420462\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9860\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:rl94xcet) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 81874... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▃▅▆▆▇▇██████</td></tr><tr><td>accuracy_train</td><td>▁▇▇▇█▇████████████▇█████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▇▇▂▇▇█▇▇▇████▇██▇█▇███████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃▂▇▂▂▂▂▂▂▁▁▁▁▂▁▂▂▂▃▂▂▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98135</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.97669</td></tr><tr><td>best_test_accuracy</td><td>0.98135</td></tr><tr><td>best_val_accuracy</td><td>0.98601</td></tr><tr><td>best_val_loss</td><td>0.04571</td></tr><tr><td>loss_train</td><td>1e-05</td></tr><tr><td>loss_validation</td><td>0.20221</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/rl94xcet\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/rl94xcet</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_024802-rl94xcet/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:rl94xcet). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2a33brtb\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 02:53:06.868942\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.5813 Acc: 0.5320\n",
      "2022-01-23 02:53:09.301343\n",
      "validation Loss: 0.4374 Acc: 0.8881\n",
      "2022-01-23 02:53:09.715165\n",
      "Accuracy of the network on the 429 test samples: 88.81118881118881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.4643 Acc: 0.8920\n",
      "2022-01-23 02:53:12.653751\n",
      "validation Loss: 1.1013 Acc: 0.6643\n",
      "2022-01-23 02:53:13.081839\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.5390 Acc: 0.8445\n",
      "2022-01-23 02:53:15.504228\n",
      "validation Loss: 0.2451 Acc: 0.9277\n",
      "2022-01-23 02:53:15.932376\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1934 Acc: 0.9410\n",
      "2022-01-23 02:53:18.882654\n",
      "validation Loss: 0.1969 Acc: 0.9487\n",
      "2022-01-23 02:53:19.386733\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2958 Acc: 0.9260\n",
      "2022-01-23 02:53:22.378511\n",
      "validation Loss: 0.2900 Acc: 0.9254\n",
      "2022-01-23 02:53:22.808333\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2778 Acc: 0.9295\n",
      "2022-01-23 02:53:25.048866\n",
      "validation Loss: 0.2250 Acc: 0.9394\n",
      "2022-01-23 02:53:25.450998\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1645 Acc: 0.9505\n",
      "2022-01-23 02:53:27.600655\n",
      "validation Loss: 0.2330 Acc: 0.9580\n",
      "2022-01-23 02:53:27.984620\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1024 Acc: 0.9695\n",
      "2022-01-23 02:53:30.793381\n",
      "validation Loss: 0.2159 Acc: 0.9627\n",
      "2022-01-23 02:53:31.199032\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0915 Acc: 0.9745\n",
      "2022-01-23 02:53:34.038996\n",
      "validation Loss: 0.1604 Acc: 0.9720\n",
      "2022-01-23 02:53:34.449675\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0968 Acc: 0.9695\n",
      "2022-01-23 02:53:37.238690\n",
      "validation Loss: 0.2661 Acc: 0.9580\n",
      "2022-01-23 02:53:37.844916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0830 Acc: 0.9775\n",
      "2022-01-23 02:53:40.090857\n",
      "validation Loss: 0.2140 Acc: 0.9580\n",
      "2022-01-23 02:53:40.556773\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0824 Acc: 0.9760\n",
      "2022-01-23 02:53:43.019229\n",
      "validation Loss: 0.3189 Acc: 0.9114\n",
      "2022-01-23 02:53:43.712310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1101 Acc: 0.9680\n",
      "2022-01-23 02:53:46.230514\n",
      "validation Loss: 0.1649 Acc: 0.9627\n",
      "2022-01-23 02:53:46.618736\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0631 Acc: 0.9810\n",
      "2022-01-23 02:53:48.978841\n",
      "validation Loss: 0.1010 Acc: 0.9767\n",
      "2022-01-23 02:53:49.391115\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0497 Acc: 0.9810\n",
      "2022-01-23 02:53:52.204725\n",
      "validation Loss: 0.2289 Acc: 0.9534\n",
      "2022-01-23 02:53:52.642023\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0327 Acc: 0.9895\n",
      "2022-01-23 02:53:55.070372\n",
      "validation Loss: 0.1390 Acc: 0.9767\n",
      "2022-01-23 02:53:55.495566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0301 Acc: 0.9885\n",
      "2022-01-23 02:53:57.893114\n",
      "validation Loss: 0.1786 Acc: 0.9627\n",
      "2022-01-23 02:53:58.304482\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1462 Acc: 0.9600\n",
      "2022-01-23 02:54:00.720819\n",
      "validation Loss: 0.1143 Acc: 0.9627\n",
      "2022-01-23 02:54:01.073016\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0689 Acc: 0.9805\n",
      "2022-01-23 02:54:03.538806\n",
      "validation Loss: 0.0851 Acc: 0.9814\n",
      "2022-01-23 02:54:03.957676\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0445 Acc: 0.9865\n",
      "2022-01-23 02:54:06.918756\n",
      "validation Loss: 0.0991 Acc: 0.9790\n",
      "2022-01-23 02:54:07.364497\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0750 Acc: 0.9765\n",
      "2022-01-23 02:54:09.912607\n",
      "validation Loss: 0.1556 Acc: 0.9580\n",
      "2022-01-23 02:54:10.381782\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0425 Acc: 0.9850\n",
      "2022-01-23 02:54:12.848431\n",
      "validation Loss: 0.1461 Acc: 0.9627\n",
      "2022-01-23 02:54:13.241554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9850\n",
      "2022-01-23 02:54:15.701595\n",
      "validation Loss: 0.1145 Acc: 0.9814\n",
      "2022-01-23 02:54:16.074340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0264 Acc: 0.9920\n",
      "2022-01-23 02:54:18.512595\n",
      "validation Loss: 0.0996 Acc: 0.9720\n",
      "2022-01-23 02:54:18.960244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0464 Acc: 0.9855\n",
      "2022-01-23 02:54:21.412589\n",
      "validation Loss: 0.0854 Acc: 0.9837\n",
      "2022-01-23 02:54:21.890543\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0214 Acc: 0.9915\n",
      "2022-01-23 02:54:24.793287\n",
      "validation Loss: 0.1126 Acc: 0.9790\n",
      "2022-01-23 02:54:25.272335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0144 Acc: 0.9980\n",
      "2022-01-23 02:54:27.835307\n",
      "validation Loss: 0.1565 Acc: 0.9674\n",
      "2022-01-23 02:54:28.327774\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0181 Acc: 0.9930\n",
      "2022-01-23 02:54:30.765681\n",
      "validation Loss: 0.1650 Acc: 0.9744\n",
      "2022-01-23 02:54:31.175292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0232 Acc: 0.9915\n",
      "2022-01-23 02:54:33.691787\n",
      "validation Loss: 0.1328 Acc: 0.9720\n",
      "2022-01-23 02:54:34.123993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9985\n",
      "2022-01-23 02:54:36.354087\n",
      "validation Loss: 0.2184 Acc: 0.9814\n",
      "2022-01-23 02:54:36.762267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0202 Acc: 0.9955\n",
      "2022-01-23 02:54:39.085171\n",
      "validation Loss: 0.1465 Acc: 0.9557\n",
      "2022-01-23 02:54:39.516105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0464 Acc: 0.9865\n",
      "2022-01-23 02:54:41.840280\n",
      "validation Loss: 0.0780 Acc: 0.9814\n",
      "2022-01-23 02:54:42.255273\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0143 Acc: 0.9950\n",
      "2022-01-23 02:54:44.398655\n",
      "validation Loss: 0.1217 Acc: 0.9790\n",
      "2022-01-23 02:54:44.803322\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0092 Acc: 0.9965\n",
      "2022-01-23 02:54:47.408063\n",
      "validation Loss: 0.1094 Acc: 0.9837\n",
      "2022-01-23 02:54:47.843365\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 0.9990\n",
      "2022-01-23 02:54:49.219764\n",
      "validation Loss: 0.1454 Acc: 0.9883\n",
      "2022-01-23 02:54:49.599915\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0092 Acc: 0.9955\n",
      "2022-01-23 02:54:52.416258\n",
      "validation Loss: 0.1162 Acc: 0.9790\n",
      "2022-01-23 02:54:52.783002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9950\n",
      "2022-01-23 02:54:55.186650\n",
      "validation Loss: 0.1656 Acc: 0.9697\n",
      "2022-01-23 02:54:55.620403\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1450 Acc: 0.9670\n",
      "2022-01-23 02:54:58.044165\n",
      "validation Loss: 0.1748 Acc: 0.9487\n",
      "2022-01-23 02:54:58.470714\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1182 Acc: 0.9655\n",
      "2022-01-23 02:55:00.903855\n",
      "validation Loss: 0.1615 Acc: 0.9744\n",
      "2022-01-23 02:55:01.324111\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0418 Acc: 0.9880\n",
      "2022-01-23 02:55:03.944480\n",
      "validation Loss: 0.1778 Acc: 0.9650\n",
      "2022-01-23 02:55:04.347985\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0310 Acc: 0.9910\n",
      "2022-01-23 02:55:06.893788\n",
      "validation Loss: 0.2445 Acc: 0.9767\n",
      "2022-01-23 02:55:07.299950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0165 Acc: 0.9965\n",
      "2022-01-23 02:55:09.744368\n",
      "validation Loss: 0.2009 Acc: 0.9930\n",
      "2022-01-23 02:55:10.172312\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0184 Acc: 0.9950\n",
      "2022-01-23 02:55:13.021059\n",
      "validation Loss: 0.2542 Acc: 0.9790\n",
      "2022-01-23 02:55:13.426034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 0.9960\n",
      "2022-01-23 02:55:16.081938\n",
      "validation Loss: 0.3011 Acc: 0.9860\n",
      "2022-01-23 02:55:16.480554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9970\n",
      "2022-01-23 02:55:18.924680\n",
      "validation Loss: 0.2933 Acc: 0.9814\n",
      "2022-01-23 02:55:19.310755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0520 Acc: 0.9860\n",
      "2022-01-23 02:55:21.725616\n",
      "validation Loss: 0.1483 Acc: 0.9674\n",
      "2022-01-23 02:55:22.144440\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0246 Acc: 0.9920\n",
      "2022-01-23 02:55:24.616959\n",
      "validation Loss: 0.1464 Acc: 0.9767\n",
      "2022-01-23 02:55:25.100301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0215 Acc: 0.9925\n",
      "2022-01-23 02:55:27.506627\n",
      "validation Loss: 0.1321 Acc: 0.9790\n",
      "2022-01-23 02:55:27.942781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0510 Acc: 0.9855\n",
      "2022-01-23 02:55:30.314319\n",
      "validation Loss: 0.1238 Acc: 0.9650\n",
      "2022-01-23 02:55:30.738868\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0578 Acc: 0.9845\n",
      "2022-01-23 02:55:33.124977\n",
      "validation Loss: 0.0680 Acc: 0.9720\n",
      "2022-01-23 02:55:33.511458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0387 Acc: 0.9915\n",
      "2022-01-23 02:55:35.822574\n",
      "validation Loss: 0.0751 Acc: 0.9790\n",
      "2022-01-23 02:55:36.261404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0359 Acc: 0.9890\n",
      "2022-01-23 02:55:38.691117\n",
      "validation Loss: 0.0498 Acc: 0.9883\n",
      "2022-01-23 02:55:39.106932\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0189 Acc: 0.9945\n",
      "2022-01-23 02:55:41.522470\n",
      "validation Loss: 0.0624 Acc: 0.9744\n",
      "2022-01-23 02:55:41.928019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0220 Acc: 0.9915\n",
      "2022-01-23 02:55:44.280179\n",
      "validation Loss: 0.1629 Acc: 0.9674\n",
      "2022-01-23 02:55:44.634285\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0584 Acc: 0.9835\n",
      "2022-01-23 02:55:47.038169\n",
      "validation Loss: 0.0384 Acc: 0.9837\n",
      "2022-01-23 02:55:47.444732\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0119 Acc: 0.9950\n",
      "2022-01-23 02:55:49.895788\n",
      "validation Loss: 0.0307 Acc: 0.9883\n",
      "2022-01-23 02:55:50.318901\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9990\n",
      "2022-01-23 02:55:52.737097\n",
      "validation Loss: 0.0339 Acc: 0.9883\n",
      "2022-01-23 02:55:53.122518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 02:55:55.442711\n",
      "validation Loss: 0.0232 Acc: 0.9907\n",
      "2022-01-23 02:55:55.846813\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 0.9980\n",
      "2022-01-23 02:55:58.303296\n",
      "validation Loss: 0.0532 Acc: 0.9814\n",
      "2022-01-23 02:55:58.771258\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0321 Acc: 0.9925\n",
      "2022-01-23 02:56:01.287294\n",
      "validation Loss: 0.0383 Acc: 0.9860\n",
      "2022-01-23 02:56:01.681337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0091 Acc: 0.9970\n",
      "2022-01-23 02:56:04.244772\n",
      "validation Loss: 0.0494 Acc: 0.9860\n",
      "2022-01-23 02:56:04.685725\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 02:56:07.134578\n",
      "validation Loss: 0.0682 Acc: 0.9837\n",
      "2022-01-23 02:56:07.523650\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 02:56:09.906580\n",
      "validation Loss: 0.1052 Acc: 0.9837\n",
      "2022-01-23 02:56:10.326074\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 02:56:12.789641\n",
      "validation Loss: 0.1068 Acc: 0.9837\n",
      "2022-01-23 02:56:13.158174\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 02:56:15.730583\n",
      "validation Loss: 0.1294 Acc: 0.9860\n",
      "2022-01-23 02:56:16.216085\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:56:18.830334\n",
      "validation Loss: 0.1289 Acc: 0.9860\n",
      "2022-01-23 02:56:19.222085\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 02:56:21.674031\n",
      "validation Loss: 0.1410 Acc: 0.9860\n",
      "2022-01-23 02:56:22.062425\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:24.465113\n",
      "validation Loss: 0.1476 Acc: 0.9860\n",
      "2022-01-23 02:56:24.861464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:27.441855\n",
      "validation Loss: 0.1643 Acc: 0.9860\n",
      "2022-01-23 02:56:27.933071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:30.437476\n",
      "validation Loss: 0.1642 Acc: 0.9860\n",
      "2022-01-23 02:56:30.880724\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:33.329400\n",
      "validation Loss: 0.1725 Acc: 0.9860\n",
      "2022-01-23 02:56:33.704514\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:36.116444\n",
      "validation Loss: 0.1793 Acc: 0.9837\n",
      "2022-01-23 02:56:36.509689\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:38.962376\n",
      "validation Loss: 0.1846 Acc: 0.9837\n",
      "2022-01-23 02:56:39.374275\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:41.850677\n",
      "validation Loss: 0.1895 Acc: 0.9837\n",
      "2022-01-23 02:56:42.228990\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 02:56:44.761867\n",
      "validation Loss: 0.1969 Acc: 0.9837\n",
      "2022-01-23 02:56:45.194828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:56:47.696499\n",
      "validation Loss: 0.2009 Acc: 0.9837\n",
      "2022-01-23 02:56:48.091080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:56:50.514387\n",
      "validation Loss: 0.2082 Acc: 0.9837\n",
      "2022-01-23 02:56:50.946427\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:56:53.404665\n",
      "validation Loss: 0.2121 Acc: 0.9837\n",
      "2022-01-23 02:56:53.818578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:56:56.265564\n",
      "validation Loss: 0.2135 Acc: 0.9837\n",
      "2022-01-23 02:56:56.689845\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:56:59.122407\n",
      "validation Loss: 0.2220 Acc: 0.9837\n",
      "2022-01-23 02:56:59.565030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:01.981937\n",
      "validation Loss: 0.2261 Acc: 0.9837\n",
      "2022-01-23 02:57:02.385663\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:04.830754\n",
      "validation Loss: 0.2292 Acc: 0.9837\n",
      "2022-01-23 02:57:05.256789\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:07.727046\n",
      "validation Loss: 0.2339 Acc: 0.9837\n",
      "2022-01-23 02:57:08.134841\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:10.578493\n",
      "validation Loss: 0.2393 Acc: 0.9837\n",
      "2022-01-23 02:57:10.990180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:13.440412\n",
      "validation Loss: 0.2409 Acc: 0.9837\n",
      "2022-01-23 02:57:13.814750\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:16.021720\n",
      "validation Loss: 0.2487 Acc: 0.9837\n",
      "2022-01-23 02:57:16.530389\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:19.100205\n",
      "validation Loss: 0.2519 Acc: 0.9837\n",
      "2022-01-23 02:57:19.528978\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:21.985458\n",
      "validation Loss: 0.2542 Acc: 0.9837\n",
      "2022-01-23 02:57:22.435549\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:24.900294\n",
      "validation Loss: 0.2586 Acc: 0.9837\n",
      "2022-01-23 02:57:25.316999\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:27.833615\n",
      "validation Loss: 0.2628 Acc: 0.9837\n",
      "2022-01-23 02:57:28.239972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:30.780365\n",
      "validation Loss: 0.2670 Acc: 0.9837\n",
      "2022-01-23 02:57:31.206719\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:33.611224\n",
      "validation Loss: 0.2712 Acc: 0.9837\n",
      "2022-01-23 02:57:33.985256\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:36.501771\n",
      "validation Loss: 0.2755 Acc: 0.9837\n",
      "2022-01-23 02:57:36.884420\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:39.264696\n",
      "validation Loss: 0.2787 Acc: 0.9837\n",
      "2022-01-23 02:57:39.659704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:42.075064\n",
      "validation Loss: 0.2827 Acc: 0.9837\n",
      "2022-01-23 02:57:42.489234\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:44.890245\n",
      "validation Loss: 0.2860 Acc: 0.9837\n",
      "2022-01-23 02:57:45.280316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:47.722312\n",
      "validation Loss: 0.2911 Acc: 0.9837\n",
      "2022-01-23 02:57:48.132440\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:50.514648\n",
      "validation Loss: 0.2946 Acc: 0.9837\n",
      "2022-01-23 02:57:50.922640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:53.238610\n",
      "validation Loss: 0.2986 Acc: 0.9837\n",
      "2022-01-23 02:57:53.617859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 02:57:56.001479\n",
      "validation Loss: 0.3026 Acc: 0.9837\n",
      "2022-01-23 02:57:56.389284\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9930\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2a33brtb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 75904... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▆▆▆▆▇████</td></tr><tr><td>accuracy_train</td><td>▁▆▇████▇███████▇████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▅▆▆▆▇▆▆█▇▇▆█▇▇▇█▇▆▇▇██████████████████</td></tr><tr><td>loss_train</td><td>█▃▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▄▄▄▃▃▂▃▂▂▃▃▂▂▃▅▆▃▃▂▃▁▁▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▆</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98368</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99301</td></tr><tr><td>best_val_loss</td><td>0.20089</td></tr><tr><td>loss_train</td><td>1e-05</td></tr><tr><td>loss_validation</td><td>0.30257</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2a33brtb\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2a33brtb</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_025257-2a33brtb/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2a33brtb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3qlo6l1q\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 02:58:06.541364\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.6961 Acc: 0.1610\n",
      "2022-01-23 02:58:08.928736\n",
      "validation Loss: 1.6041 Acc: 0.4172\n",
      "2022-01-23 02:58:09.336084\n",
      "Accuracy of the network on the 429 test samples: 42.19114219114219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.7847 Acc: 0.7960\n",
      "2022-01-23 02:58:12.259105\n",
      "validation Loss: 0.5668 Acc: 0.8531\n",
      "2022-01-23 02:58:12.685225\n",
      "Accuracy of the network on the 429 test samples: 87.17948717948718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3492 Acc: 0.9100\n",
      "2022-01-23 02:58:15.545626\n",
      "validation Loss: 0.3356 Acc: 0.9021\n",
      "2022-01-23 02:58:15.919975\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2010 Acc: 0.9405\n",
      "2022-01-23 02:58:18.785645\n",
      "validation Loss: 0.2863 Acc: 0.9044\n",
      "2022-01-23 02:58:19.159593\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2012 Acc: 0.9395\n",
      "2022-01-23 02:58:22.224798\n",
      "validation Loss: 0.2132 Acc: 0.9371\n",
      "2022-01-23 02:58:22.634169\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1361 Acc: 0.9605\n",
      "2022-01-23 02:58:25.475848\n",
      "validation Loss: 0.2735 Acc: 0.9371\n",
      "2022-01-23 02:58:25.885665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1165 Acc: 0.9610\n",
      "2022-01-23 02:58:28.331568\n",
      "validation Loss: 0.1901 Acc: 0.9464\n",
      "2022-01-23 02:58:28.774840\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0929 Acc: 0.9680\n",
      "2022-01-23 02:58:31.614301\n",
      "validation Loss: 0.2001 Acc: 0.9487\n",
      "2022-01-23 02:58:32.010423\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0887 Acc: 0.9715\n",
      "2022-01-23 02:58:34.865668\n",
      "validation Loss: 0.2334 Acc: 0.9441\n",
      "2022-01-23 02:58:35.249014\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1183 Acc: 0.9690\n",
      "2022-01-23 02:58:36.623957\n",
      "validation Loss: 0.2100 Acc: 0.9441\n",
      "2022-01-23 02:58:37.070125\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0617 Acc: 0.9805\n",
      "2022-01-23 02:58:39.514464\n",
      "validation Loss: 0.2433 Acc: 0.9487\n",
      "2022-01-23 02:58:39.898605\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0793 Acc: 0.9715\n",
      "2022-01-23 02:58:42.403322\n",
      "validation Loss: 0.2285 Acc: 0.9301\n",
      "2022-01-23 02:58:42.811009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0487 Acc: 0.9840\n",
      "2022-01-23 02:58:45.307005\n",
      "validation Loss: 0.1802 Acc: 0.9604\n",
      "2022-01-23 02:58:45.703741\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0423 Acc: 0.9875\n",
      "2022-01-23 02:58:48.696599\n",
      "validation Loss: 0.2370 Acc: 0.9464\n",
      "2022-01-23 02:58:49.157861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0543 Acc: 0.9805\n",
      "2022-01-23 02:58:51.644984\n",
      "validation Loss: 0.2142 Acc: 0.9580\n",
      "2022-01-23 02:58:52.078726\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0387 Acc: 0.9875\n",
      "2022-01-23 02:58:53.484589\n",
      "validation Loss: 0.2033 Acc: 0.9394\n",
      "2022-01-23 02:58:53.877079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0487 Acc: 0.9835\n",
      "2022-01-23 02:58:56.291672\n",
      "validation Loss: 0.2170 Acc: 0.9487\n",
      "2022-01-23 02:58:56.699807\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1003 Acc: 0.9675\n",
      "2022-01-23 02:58:59.139492\n",
      "validation Loss: 0.1455 Acc: 0.9510\n",
      "2022-01-23 02:58:59.511082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0933 Acc: 0.9760\n",
      "2022-01-23 02:59:01.938175\n",
      "validation Loss: 0.1999 Acc: 0.9557\n",
      "2022-01-23 02:59:02.352510\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0287 Acc: 0.9910\n",
      "2022-01-23 02:59:04.849237\n",
      "validation Loss: 0.2492 Acc: 0.9557\n",
      "2022-01-23 02:59:05.248423\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0211 Acc: 0.9930\n",
      "2022-01-23 02:59:07.728354\n",
      "validation Loss: 0.2600 Acc: 0.9394\n",
      "2022-01-23 02:59:08.100001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0564 Acc: 0.9820\n",
      "2022-01-23 02:59:10.547253\n",
      "validation Loss: 0.2005 Acc: 0.9674\n",
      "2022-01-23 02:59:10.971926\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0249 Acc: 0.9925\n",
      "2022-01-23 02:59:13.774584\n",
      "validation Loss: 0.1980 Acc: 0.9557\n",
      "2022-01-23 02:59:14.157471\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0336 Acc: 0.9885\n",
      "2022-01-23 02:59:16.588398\n",
      "validation Loss: 0.1500 Acc: 0.9604\n",
      "2022-01-23 02:59:16.966134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0294 Acc: 0.9900\n",
      "2022-01-23 02:59:19.422145\n",
      "validation Loss: 0.2133 Acc: 0.9604\n",
      "2022-01-23 02:59:19.886859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9920\n",
      "2022-01-23 02:59:22.304407\n",
      "validation Loss: 0.1822 Acc: 0.9604\n",
      "2022-01-23 02:59:22.712490\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0146 Acc: 0.9955\n",
      "2022-01-23 02:59:25.139095\n",
      "validation Loss: 0.2044 Acc: 0.9720\n",
      "2022-01-23 02:59:25.575202\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9970\n",
      "2022-01-23 02:59:28.433128\n",
      "validation Loss: 0.2242 Acc: 0.9604\n",
      "2022-01-23 02:59:28.815762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0170 Acc: 0.9940\n",
      "2022-01-23 02:59:31.252907\n",
      "validation Loss: 0.1994 Acc: 0.9674\n",
      "2022-01-23 02:59:31.672841\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0189 Acc: 0.9930\n",
      "2022-01-23 02:59:34.129793\n",
      "validation Loss: 0.2454 Acc: 0.9627\n",
      "2022-01-23 02:59:34.551593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0173 Acc: 0.9945\n",
      "2022-01-23 02:59:36.373948\n",
      "validation Loss: 0.1660 Acc: 0.9720\n",
      "2022-01-23 02:59:36.846844\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0132 Acc: 0.9955\n",
      "2022-01-23 02:59:39.667463\n",
      "validation Loss: 0.2274 Acc: 0.9674\n",
      "2022-01-23 02:59:40.052172\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0101 Acc: 0.9960\n",
      "2022-01-23 02:59:42.397908\n",
      "validation Loss: 0.2717 Acc: 0.9487\n",
      "2022-01-23 02:59:42.801834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0112 Acc: 0.9960\n",
      "2022-01-23 02:59:45.185769\n",
      "validation Loss: 0.2877 Acc: 0.9604\n",
      "2022-01-23 02:59:45.595554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0216 Acc: 0.9905\n",
      "2022-01-23 02:59:47.977109\n",
      "validation Loss: 0.1404 Acc: 0.9650\n",
      "2022-01-23 02:59:48.400927\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0645 Acc: 0.9835\n",
      "2022-01-23 02:59:50.774258\n",
      "validation Loss: 0.1388 Acc: 0.9650\n",
      "2022-01-23 02:59:51.193933\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0219 Acc: 0.9930\n",
      "2022-01-23 02:59:53.543797\n",
      "validation Loss: 0.1698 Acc: 0.9627\n",
      "2022-01-23 02:59:53.920248\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9945\n",
      "2022-01-23 02:59:56.469039\n",
      "validation Loss: 0.2687 Acc: 0.9580\n",
      "2022-01-23 02:59:56.861192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0258 Acc: 0.9930\n",
      "2022-01-23 02:59:59.262167\n",
      "validation Loss: 0.1829 Acc: 0.9627\n",
      "2022-01-23 02:59:59.686950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0578 Acc: 0.9855\n",
      "2022-01-23 03:00:02.198633\n",
      "validation Loss: 0.1472 Acc: 0.9744\n",
      "2022-01-23 03:00:02.590487\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9965\n",
      "2022-01-23 03:00:05.497682\n",
      "validation Loss: 0.1306 Acc: 0.9744\n",
      "2022-01-23 03:00:05.922323\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9970\n",
      "2022-01-23 03:00:08.771062\n",
      "validation Loss: 0.2294 Acc: 0.9744\n",
      "2022-01-23 03:00:09.168030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3247 Acc: 0.9280\n",
      "2022-01-23 03:00:11.529145\n",
      "validation Loss: 0.1724 Acc: 0.9441\n",
      "2022-01-23 03:00:11.978144\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0932 Acc: 0.9725\n",
      "2022-01-23 03:00:14.551060\n",
      "validation Loss: 0.1331 Acc: 0.9580\n",
      "2022-01-23 03:00:15.057272\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0477 Acc: 0.9840\n",
      "2022-01-23 03:00:17.609035\n",
      "validation Loss: 0.1323 Acc: 0.9697\n",
      "2022-01-23 03:00:18.027345\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0326 Acc: 0.9900\n",
      "2022-01-23 03:00:20.448203\n",
      "validation Loss: 0.1477 Acc: 0.9744\n",
      "2022-01-23 03:00:20.871666\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0378 Acc: 0.9875\n",
      "2022-01-23 03:00:23.190750\n",
      "validation Loss: 0.1685 Acc: 0.9697\n",
      "2022-01-23 03:00:23.579203\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0588 Acc: 0.9825\n",
      "2022-01-23 03:00:26.000188\n",
      "validation Loss: 0.1169 Acc: 0.9720\n",
      "2022-01-23 03:00:26.431036\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0213 Acc: 0.9940\n",
      "2022-01-23 03:00:29.018943\n",
      "validation Loss: 0.1473 Acc: 0.9720\n",
      "2022-01-23 03:00:29.435900\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0164 Acc: 0.9945\n",
      "2022-01-23 03:00:31.823726\n",
      "validation Loss: 0.1915 Acc: 0.9720\n",
      "2022-01-23 03:00:32.213331\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0157 Acc: 0.9965\n",
      "2022-01-23 03:00:34.693200\n",
      "validation Loss: 0.1643 Acc: 0.9650\n",
      "2022-01-23 03:00:35.134566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0209 Acc: 0.9935\n",
      "2022-01-23 03:00:37.704618\n",
      "validation Loss: 0.1391 Acc: 0.9627\n",
      "2022-01-23 03:00:38.205030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0390 Acc: 0.9905\n",
      "2022-01-23 03:00:40.866852\n",
      "validation Loss: 0.1356 Acc: 0.9697\n",
      "2022-01-23 03:00:41.272304\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9965\n",
      "2022-01-23 03:00:43.692659\n",
      "validation Loss: 0.1408 Acc: 0.9720\n",
      "2022-01-23 03:00:44.111069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9960\n",
      "2022-01-23 03:00:46.548701\n",
      "validation Loss: 0.2303 Acc: 0.9441\n",
      "2022-01-23 03:00:46.992295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0377 Acc: 0.9880\n",
      "2022-01-23 03:00:49.424625\n",
      "validation Loss: 0.1211 Acc: 0.9744\n",
      "2022-01-23 03:00:49.855509\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0161 Acc: 0.9930\n",
      "2022-01-23 03:00:52.778658\n",
      "validation Loss: 0.1654 Acc: 0.9697\n",
      "2022-01-23 03:00:53.183572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9975\n",
      "2022-01-23 03:00:55.656581\n",
      "validation Loss: 0.1597 Acc: 0.9697\n",
      "2022-01-23 03:00:56.081645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 0.9985\n",
      "2022-01-23 03:00:58.570181\n",
      "validation Loss: 0.2000 Acc: 0.9697\n",
      "2022-01-23 03:00:59.024471\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 0.9990\n",
      "2022-01-23 03:01:01.496576\n",
      "validation Loss: 0.2191 Acc: 0.9627\n",
      "2022-01-23 03:01:01.913986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0067 Acc: 0.9975\n",
      "2022-01-23 03:01:04.318396\n",
      "validation Loss: 0.2423 Acc: 0.9650\n",
      "2022-01-23 03:01:04.713663\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0063 Acc: 0.9970\n",
      "2022-01-23 03:01:07.168368\n",
      "validation Loss: 0.2530 Acc: 0.9650\n",
      "2022-01-23 03:01:07.589492\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0200 Acc: 0.9945\n",
      "2022-01-23 03:01:10.245272\n",
      "validation Loss: 0.1220 Acc: 0.9720\n",
      "2022-01-23 03:01:10.673005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 0.9995\n",
      "2022-01-23 03:01:13.125424\n",
      "validation Loss: 0.1465 Acc: 0.9697\n",
      "2022-01-23 03:01:13.527283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 03:01:15.779429\n",
      "validation Loss: 0.2029 Acc: 0.9650\n",
      "2022-01-23 03:01:16.210098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9960\n",
      "2022-01-23 03:01:18.629307\n",
      "validation Loss: 0.1722 Acc: 0.9720\n",
      "2022-01-23 03:01:19.080043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0028 Acc: 0.9990\n",
      "2022-01-23 03:01:21.526528\n",
      "validation Loss: 0.2064 Acc: 0.9674\n",
      "2022-01-23 03:01:21.932309\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 0.9995\n",
      "2022-01-23 03:01:24.191762\n",
      "validation Loss: 0.1966 Acc: 0.9720\n",
      "2022-01-23 03:01:24.617055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:01:27.131681\n",
      "validation Loss: 0.2207 Acc: 0.9674\n",
      "2022-01-23 03:01:27.538386\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 03:01:30.037915\n",
      "validation Loss: 0.2430 Acc: 0.9697\n",
      "2022-01-23 03:01:30.478689\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 0.9990\n",
      "2022-01-23 03:01:32.963183\n",
      "validation Loss: 0.2905 Acc: 0.9674\n",
      "2022-01-23 03:01:33.377661\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 0.9985\n",
      "2022-01-23 03:01:35.936832\n",
      "validation Loss: 0.2945 Acc: 0.9697\n",
      "2022-01-23 03:01:36.366448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1034 Acc: 0.9740\n",
      "2022-01-23 03:01:38.869503\n",
      "validation Loss: 0.1881 Acc: 0.9674\n",
      "2022-01-23 03:01:39.290365\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0181 Acc: 0.9950\n",
      "2022-01-23 03:01:41.799764\n",
      "validation Loss: 0.2054 Acc: 0.9697\n",
      "2022-01-23 03:01:42.211518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0110 Acc: 0.9960\n",
      "2022-01-23 03:01:44.647695\n",
      "validation Loss: 0.2010 Acc: 0.9744\n",
      "2022-01-23 03:01:45.071825\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 0.9980\n",
      "2022-01-23 03:01:47.470267\n",
      "validation Loss: 0.2467 Acc: 0.9674\n",
      "2022-01-23 03:01:47.890241\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 0.9980\n",
      "2022-01-23 03:01:50.373255\n",
      "validation Loss: 0.2977 Acc: 0.9767\n",
      "2022-01-23 03:01:50.831757\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 0.9980\n",
      "2022-01-23 03:01:53.725875\n",
      "validation Loss: 0.2763 Acc: 0.9744\n",
      "2022-01-23 03:01:54.151306\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 0.9990\n",
      "2022-01-23 03:01:56.569160\n",
      "validation Loss: 0.3363 Acc: 0.9790\n",
      "2022-01-23 03:01:57.006769\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 03:01:59.917522\n",
      "validation Loss: 0.2878 Acc: 0.9767\n",
      "2022-01-23 03:02:00.333491\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 03:02:02.788174\n",
      "validation Loss: 0.2761 Acc: 0.9837\n",
      "2022-01-23 03:02:03.192011\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0159 Acc: 0.9955\n",
      "2022-01-23 03:02:06.087156\n",
      "validation Loss: 0.1659 Acc: 0.9744\n",
      "2022-01-23 03:02:06.502702\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0291 Acc: 0.9935\n",
      "2022-01-23 03:02:08.984056\n",
      "validation Loss: 0.0983 Acc: 0.9697\n",
      "2022-01-23 03:02:09.389457\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 0.9985\n",
      "2022-01-23 03:02:11.973801\n",
      "validation Loss: 0.1366 Acc: 0.9767\n",
      "2022-01-23 03:02:12.406940\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0033 Acc: 0.9995\n",
      "2022-01-23 03:02:15.096966\n",
      "validation Loss: 0.1835 Acc: 0.9720\n",
      "2022-01-23 03:02:15.519661\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 0.9995\n",
      "2022-01-23 03:02:17.805288\n",
      "validation Loss: 0.2299 Acc: 0.9744\n",
      "2022-01-23 03:02:18.246964\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 03:02:20.659331\n",
      "validation Loss: 0.2583 Acc: 0.9744\n",
      "2022-01-23 03:02:21.078056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:02:23.585921\n",
      "validation Loss: 0.2918 Acc: 0.9720\n",
      "2022-01-23 03:02:24.033003\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:02:26.584035\n",
      "validation Loss: 0.3101 Acc: 0.9674\n",
      "2022-01-23 03:02:27.020936\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:02:29.550331\n",
      "validation Loss: 0.3291 Acc: 0.9674\n",
      "2022-01-23 03:02:29.994941\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:02:32.669579\n",
      "validation Loss: 0.3470 Acc: 0.9674\n",
      "2022-01-23 03:02:33.114379\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:02:35.795278\n",
      "validation Loss: 0.3659 Acc: 0.9674\n",
      "2022-01-23 03:02:36.224918\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:02:38.744919\n",
      "validation Loss: 0.3787 Acc: 0.9674\n",
      "2022-01-23 03:02:39.192251\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:02:41.903074\n",
      "validation Loss: 0.3925 Acc: 0.9674\n",
      "2022-01-23 03:02:42.438446\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:45.051211\n",
      "validation Loss: 0.4050 Acc: 0.9697\n",
      "2022-01-23 03:02:45.469648\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:48.030191\n",
      "validation Loss: 0.4230 Acc: 0.9674\n",
      "2022-01-23 03:02:48.440822\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:49.946036\n",
      "validation Loss: 0.4364 Acc: 0.9674\n",
      "2022-01-23 03:02:50.369160\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:53.052978\n",
      "validation Loss: 0.4485 Acc: 0.9674\n",
      "2022-01-23 03:02:53.498200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:56.082002\n",
      "validation Loss: 0.4633 Acc: 0.9674\n",
      "2022-01-23 03:02:56.531832\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:02:59.166741\n",
      "validation Loss: 0.4768 Acc: 0.9674\n",
      "2022-01-23 03:02:59.619269\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9837\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qlo6l1q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 68233... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▇▇▇█████████████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▂▂▁▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▂▂▁▁▂▂▂▂▂▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.96737</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.96737</td></tr><tr><td>best_test_accuracy</td><td>0.96737</td></tr><tr><td>best_val_accuracy</td><td>0.98368</td></tr><tr><td>best_val_loss</td><td>0.27612</td></tr><tr><td>loss_train</td><td>8e-05</td></tr><tr><td>loss_validation</td><td>0.47676</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3qlo6l1q\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3qlo6l1q</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_025756-3qlo6l1q/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3qlo6l1q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1128u2j4\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 03:03:10.509929\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.9682 Acc: 0.0670\n",
      "2022-01-23 03:03:12.993176\n",
      "validation Loss: 2.8684 Acc: 0.1259\n",
      "2022-01-23 03:03:13.421052\n",
      "Accuracy of the network on the 429 test samples: 11.888111888111888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.2859 Acc: 0.3070\n",
      "2022-01-23 03:03:16.198919\n",
      "validation Loss: 1.3876 Acc: 0.6317\n",
      "2022-01-23 03:03:16.634305\n",
      "Accuracy of the network on the 429 test samples: 63.4032634032634\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.0045 Acc: 0.7480\n",
      "2022-01-23 03:03:19.545763\n",
      "validation Loss: 0.6351 Acc: 0.8531\n",
      "2022-01-23 03:03:19.976810\n",
      "Accuracy of the network on the 429 test samples: 85.08158508158508\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5437 Acc: 0.8515\n",
      "2022-01-23 03:03:23.264489\n",
      "validation Loss: 0.4581 Acc: 0.9114\n",
      "2022-01-23 03:03:23.703654\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3647 Acc: 0.9015\n",
      "2022-01-23 03:03:26.918576\n",
      "validation Loss: 0.3483 Acc: 0.9394\n",
      "2022-01-23 03:03:27.334407\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3290 Acc: 0.9155\n",
      "2022-01-23 03:03:30.515835\n",
      "validation Loss: 0.3891 Acc: 0.8881\n",
      "2022-01-23 03:03:30.981004\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2457 Acc: 0.9285\n",
      "2022-01-23 03:03:33.644970\n",
      "validation Loss: 0.2504 Acc: 0.9441\n",
      "2022-01-23 03:03:34.064361\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1930 Acc: 0.9420\n",
      "2022-01-23 03:03:37.100086\n",
      "validation Loss: 0.2421 Acc: 0.9487\n",
      "2022-01-23 03:03:37.528962\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1825 Acc: 0.9475\n",
      "2022-01-23 03:03:40.638339\n",
      "validation Loss: 0.2930 Acc: 0.9324\n",
      "2022-01-23 03:03:41.123808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2251 Acc: 0.9380\n",
      "2022-01-23 03:03:43.752944\n",
      "validation Loss: 0.2093 Acc: 0.9394\n",
      "2022-01-23 03:03:44.186543\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1406 Acc: 0.9560\n",
      "2022-01-23 03:03:46.751553\n",
      "validation Loss: 0.2326 Acc: 0.9487\n",
      "2022-01-23 03:03:47.152484\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1691 Acc: 0.9520\n",
      "2022-01-23 03:03:50.223177\n",
      "validation Loss: 0.1945 Acc: 0.9487\n",
      "2022-01-23 03:03:50.656459\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1266 Acc: 0.9575\n",
      "2022-01-23 03:03:53.649997\n",
      "validation Loss: 0.1673 Acc: 0.9580\n",
      "2022-01-23 03:03:54.055694\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1168 Acc: 0.9630\n",
      "2022-01-23 03:03:57.161160\n",
      "validation Loss: 0.1753 Acc: 0.9580\n",
      "2022-01-23 03:03:57.735143\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0998 Acc: 0.9655\n",
      "2022-01-23 03:04:00.297742\n",
      "validation Loss: 0.1802 Acc: 0.9557\n",
      "2022-01-23 03:04:00.764422\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1366 Acc: 0.9575\n",
      "2022-01-23 03:04:03.274473\n",
      "validation Loss: 0.2271 Acc: 0.9580\n",
      "2022-01-23 03:04:03.710273\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0943 Acc: 0.9735\n",
      "2022-01-23 03:04:06.199276\n",
      "validation Loss: 0.1503 Acc: 0.9650\n",
      "2022-01-23 03:04:06.632126\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0830 Acc: 0.9730\n",
      "2022-01-23 03:04:09.769960\n",
      "validation Loss: 0.2054 Acc: 0.9534\n",
      "2022-01-23 03:04:10.282082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1829 Acc: 0.9560\n",
      "2022-01-23 03:04:12.851287\n",
      "validation Loss: 0.5180 Acc: 0.8765\n",
      "2022-01-23 03:04:13.282640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1918 Acc: 0.9465\n",
      "2022-01-23 03:04:15.814718\n",
      "validation Loss: 0.2313 Acc: 0.9580\n",
      "2022-01-23 03:04:16.274444\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1176 Acc: 0.9710\n",
      "2022-01-23 03:04:18.778278\n",
      "validation Loss: 0.2345 Acc: 0.9650\n",
      "2022-01-23 03:04:19.173087\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0824 Acc: 0.9745\n",
      "2022-01-23 03:04:21.706525\n",
      "validation Loss: 0.2628 Acc: 0.9604\n",
      "2022-01-23 03:04:22.110236\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0899 Acc: 0.9725\n",
      "2022-01-23 03:04:24.689674\n",
      "validation Loss: 0.2319 Acc: 0.9720\n",
      "2022-01-23 03:04:25.180515\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0726 Acc: 0.9790\n",
      "2022-01-23 03:04:28.139459\n",
      "validation Loss: 0.2484 Acc: 0.9650\n",
      "2022-01-23 03:04:28.687409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0806 Acc: 0.9735\n",
      "2022-01-23 03:04:31.315703\n",
      "validation Loss: 0.2531 Acc: 0.9557\n",
      "2022-01-23 03:04:31.818617\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0681 Acc: 0.9790\n",
      "2022-01-23 03:04:34.355515\n",
      "validation Loss: 0.2429 Acc: 0.9720\n",
      "2022-01-23 03:04:34.786157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0741 Acc: 0.9755\n",
      "2022-01-23 03:04:37.242685\n",
      "validation Loss: 0.2487 Acc: 0.9580\n",
      "2022-01-23 03:04:37.684988\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0527 Acc: 0.9835\n",
      "2022-01-23 03:04:40.185491\n",
      "validation Loss: 0.2273 Acc: 0.9744\n",
      "2022-01-23 03:04:40.645548\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0520 Acc: 0.9835\n",
      "2022-01-23 03:04:43.666101\n",
      "validation Loss: 0.2936 Acc: 0.9697\n",
      "2022-01-23 03:04:44.202639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0435 Acc: 0.9845\n",
      "2022-01-23 03:04:46.843046\n",
      "validation Loss: 0.2916 Acc: 0.9674\n",
      "2022-01-23 03:04:47.416739\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0417 Acc: 0.9870\n",
      "2022-01-23 03:04:50.192435\n",
      "validation Loss: 0.3024 Acc: 0.9604\n",
      "2022-01-23 03:04:50.678495\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0484 Acc: 0.9845\n",
      "2022-01-23 03:04:53.417081\n",
      "validation Loss: 0.2917 Acc: 0.9650\n",
      "2022-01-23 03:04:53.895261\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0678 Acc: 0.9800\n",
      "2022-01-23 03:04:56.679445\n",
      "validation Loss: 0.2939 Acc: 0.9580\n",
      "2022-01-23 03:04:57.209539\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1253 Acc: 0.9670\n",
      "2022-01-23 03:04:59.995467\n",
      "validation Loss: 0.1785 Acc: 0.9674\n",
      "2022-01-23 03:05:00.504693\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0466 Acc: 0.9880\n",
      "2022-01-23 03:05:03.134955\n",
      "validation Loss: 0.2075 Acc: 0.9697\n",
      "2022-01-23 03:05:03.594861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0370 Acc: 0.9885\n",
      "2022-01-23 03:05:05.235943\n",
      "validation Loss: 0.2321 Acc: 0.9720\n",
      "2022-01-23 03:05:05.695166\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0383 Acc: 0.9895\n",
      "2022-01-23 03:05:08.350694\n",
      "validation Loss: 0.2572 Acc: 0.9720\n",
      "2022-01-23 03:05:08.779780\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0299 Acc: 0.9905\n",
      "2022-01-23 03:05:11.420620\n",
      "validation Loss: 0.2548 Acc: 0.9720\n",
      "2022-01-23 03:05:11.822524\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0358 Acc: 0.9860\n",
      "2022-01-23 03:05:14.531842\n",
      "validation Loss: 0.2547 Acc: 0.9674\n",
      "2022-01-23 03:05:15.017463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0379 Acc: 0.9875\n",
      "2022-01-23 03:05:17.777667\n",
      "validation Loss: 0.2967 Acc: 0.9697\n",
      "2022-01-23 03:05:18.239804\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0270 Acc: 0.9895\n",
      "2022-01-23 03:05:20.811229\n",
      "validation Loss: 0.2732 Acc: 0.9674\n",
      "2022-01-23 03:05:21.219094\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0312 Acc: 0.9905\n",
      "2022-01-23 03:05:23.857877\n",
      "validation Loss: 0.2159 Acc: 0.9674\n",
      "2022-01-23 03:05:24.279932\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0507 Acc: 0.9830\n",
      "2022-01-23 03:05:26.977177\n",
      "validation Loss: 0.1811 Acc: 0.9720\n",
      "2022-01-23 03:05:27.427652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0251 Acc: 0.9910\n",
      "2022-01-23 03:05:30.035647\n",
      "validation Loss: 0.2451 Acc: 0.9674\n",
      "2022-01-23 03:05:30.490320\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0300 Acc: 0.9935\n",
      "2022-01-23 03:05:33.063417\n",
      "validation Loss: 0.2249 Acc: 0.9767\n",
      "2022-01-23 03:05:33.560134\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3071 Acc: 0.9545\n",
      "2022-01-23 03:05:36.608168\n",
      "validation Loss: 0.3793 Acc: 0.9044\n",
      "2022-01-23 03:05:37.110090\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1196 Acc: 0.9735\n",
      "2022-01-23 03:05:39.856407\n",
      "validation Loss: 0.0836 Acc: 0.9697\n",
      "2022-01-23 03:05:40.315105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0483 Acc: 0.9865\n",
      "2022-01-23 03:05:42.674179\n",
      "validation Loss: 0.0667 Acc: 0.9767\n",
      "2022-01-23 03:05:43.204332\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0360 Acc: 0.9885\n",
      "2022-01-23 03:05:46.246633\n",
      "validation Loss: 0.0774 Acc: 0.9720\n",
      "2022-01-23 03:05:46.707447\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0414 Acc: 0.9870\n",
      "2022-01-23 03:05:49.432051\n",
      "validation Loss: 0.0652 Acc: 0.9814\n",
      "2022-01-23 03:05:49.868181\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0238 Acc: 0.9930\n",
      "2022-01-23 03:05:52.924038\n",
      "validation Loss: 0.0796 Acc: 0.9720\n",
      "2022-01-23 03:05:53.318781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0291 Acc: 0.9900\n",
      "2022-01-23 03:05:55.891677\n",
      "validation Loss: 0.0712 Acc: 0.9814\n",
      "2022-01-23 03:05:56.293969\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0200 Acc: 0.9945\n",
      "2022-01-23 03:05:58.886068\n",
      "validation Loss: 0.0697 Acc: 0.9767\n",
      "2022-01-23 03:05:59.321374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0207 Acc: 0.9925\n",
      "2022-01-23 03:06:01.894095\n",
      "validation Loss: 0.0706 Acc: 0.9790\n",
      "2022-01-23 03:06:02.367072\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9945\n",
      "2022-01-23 03:06:05.035891\n",
      "validation Loss: 0.0845 Acc: 0.9744\n",
      "2022-01-23 03:06:05.618751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0177 Acc: 0.9950\n",
      "2022-01-23 03:06:08.315905\n",
      "validation Loss: 0.0861 Acc: 0.9744\n",
      "2022-01-23 03:06:08.864047\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0141 Acc: 0.9965\n",
      "2022-01-23 03:06:11.459819\n",
      "validation Loss: 0.0876 Acc: 0.9767\n",
      "2022-01-23 03:06:11.888365\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0208 Acc: 0.9925\n",
      "2022-01-23 03:06:14.531776\n",
      "validation Loss: 0.0654 Acc: 0.9790\n",
      "2022-01-23 03:06:14.966900\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0181 Acc: 0.9950\n",
      "2022-01-23 03:06:17.523900\n",
      "validation Loss: 0.0781 Acc: 0.9790\n",
      "2022-01-23 03:06:17.918834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9975\n",
      "2022-01-23 03:06:19.504862\n",
      "validation Loss: 0.0651 Acc: 0.9837\n",
      "2022-01-23 03:06:19.912373\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 0.9985\n",
      "2022-01-23 03:06:22.917173\n",
      "validation Loss: 0.0684 Acc: 0.9814\n",
      "2022-01-23 03:06:23.399880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0086 Acc: 0.9980\n",
      "2022-01-23 03:06:26.049477\n",
      "validation Loss: 0.0735 Acc: 0.9814\n",
      "2022-01-23 03:06:26.575554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0069 Acc: 0.9985\n",
      "2022-01-23 03:06:29.112484\n",
      "validation Loss: 0.0876 Acc: 0.9744\n",
      "2022-01-23 03:06:29.524295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9980\n",
      "2022-01-23 03:06:32.004660\n",
      "validation Loss: 0.0646 Acc: 0.9837\n",
      "2022-01-23 03:06:32.554893\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9985\n",
      "2022-01-23 03:06:35.679995\n",
      "validation Loss: 0.1823 Acc: 0.9650\n",
      "2022-01-23 03:06:36.107163\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1221 Acc: 0.9780\n",
      "2022-01-23 03:06:38.609096\n",
      "validation Loss: 0.0940 Acc: 0.9697\n",
      "2022-01-23 03:06:39.012067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0425 Acc: 0.9885\n",
      "2022-01-23 03:06:41.478820\n",
      "validation Loss: 0.0616 Acc: 0.9790\n",
      "2022-01-23 03:06:41.917362\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9945\n",
      "2022-01-23 03:06:44.595550\n",
      "validation Loss: 0.0596 Acc: 0.9767\n",
      "2022-01-23 03:06:45.134818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0135 Acc: 0.9975\n",
      "2022-01-23 03:06:47.614268\n",
      "validation Loss: 0.0648 Acc: 0.9814\n",
      "2022-01-23 03:06:48.063687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9965\n",
      "2022-01-23 03:06:50.635909\n",
      "validation Loss: 0.0637 Acc: 0.9790\n",
      "2022-01-23 03:06:51.065956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0093 Acc: 0.9985\n",
      "2022-01-23 03:06:53.634231\n",
      "validation Loss: 0.0686 Acc: 0.9837\n",
      "2022-01-23 03:06:54.113174\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0104 Acc: 0.9975\n",
      "2022-01-23 03:06:56.678369\n",
      "validation Loss: 0.0726 Acc: 0.9790\n",
      "2022-01-23 03:06:57.088033\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0138 Acc: 0.9975\n",
      "2022-01-23 03:06:59.888750\n",
      "validation Loss: 0.0701 Acc: 0.9790\n",
      "2022-01-23 03:07:00.306865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9930\n",
      "2022-01-23 03:07:02.899665\n",
      "validation Loss: 0.0942 Acc: 0.9744\n",
      "2022-01-23 03:07:03.324775\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0240 Acc: 0.9935\n",
      "2022-01-23 03:07:06.147263\n",
      "validation Loss: 0.0638 Acc: 0.9837\n",
      "2022-01-23 03:07:06.595773\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0066 Acc: 0.9975\n",
      "2022-01-23 03:07:09.792049\n",
      "validation Loss: 0.0650 Acc: 0.9837\n",
      "2022-01-23 03:07:10.202839\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 0.9990\n",
      "2022-01-23 03:07:12.869629\n",
      "validation Loss: 0.0631 Acc: 0.9837\n",
      "2022-01-23 03:07:13.375515\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9995\n",
      "2022-01-23 03:07:16.458999\n",
      "validation Loss: 0.0791 Acc: 0.9790\n",
      "2022-01-23 03:07:16.866436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0120 Acc: 0.9970\n",
      "2022-01-23 03:07:19.499306\n",
      "validation Loss: 0.1334 Acc: 0.9744\n",
      "2022-01-23 03:07:19.949068\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 0.9980\n",
      "2022-01-23 03:07:22.542129\n",
      "validation Loss: 0.0819 Acc: 0.9837\n",
      "2022-01-23 03:07:23.037973\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0199 Acc: 0.9950\n",
      "2022-01-23 03:07:25.659749\n",
      "validation Loss: 0.0779 Acc: 0.9790\n",
      "2022-01-23 03:07:26.159569\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0396 Acc: 0.9890\n",
      "2022-01-23 03:07:28.946576\n",
      "validation Loss: 0.0552 Acc: 0.9860\n",
      "2022-01-23 03:07:29.423575\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0110 Acc: 0.9975\n",
      "2022-01-23 03:07:32.631146\n",
      "validation Loss: 0.0645 Acc: 0.9837\n",
      "2022-01-23 03:07:33.052341\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0079 Acc: 0.9980\n",
      "2022-01-23 03:07:35.853946\n",
      "validation Loss: 0.0645 Acc: 0.9860\n",
      "2022-01-23 03:07:36.366674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 0.9990\n",
      "2022-01-23 03:07:39.069164\n",
      "validation Loss: 0.0706 Acc: 0.9814\n",
      "2022-01-23 03:07:39.638514\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 0.9995\n",
      "2022-01-23 03:07:42.247673\n",
      "validation Loss: 0.0749 Acc: 0.9837\n",
      "2022-01-23 03:07:42.668360\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 0.9990\n",
      "2022-01-23 03:07:45.282151\n",
      "validation Loss: 0.0812 Acc: 0.9814\n",
      "2022-01-23 03:07:45.739141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0130 Acc: 0.9955\n",
      "2022-01-23 03:07:48.281361\n",
      "validation Loss: 0.1215 Acc: 0.9744\n",
      "2022-01-23 03:07:48.720222\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0155 Acc: 0.9960\n",
      "2022-01-23 03:07:51.319527\n",
      "validation Loss: 0.0638 Acc: 0.9837\n",
      "2022-01-23 03:07:51.717217\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 0.9990\n",
      "2022-01-23 03:07:54.483579\n",
      "validation Loss: 0.0700 Acc: 0.9837\n",
      "2022-01-23 03:07:54.946839\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 0.9985\n",
      "2022-01-23 03:07:57.519692\n",
      "validation Loss: 0.0770 Acc: 0.9837\n",
      "2022-01-23 03:07:57.934692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 03:08:00.524008\n",
      "validation Loss: 0.0884 Acc: 0.9744\n",
      "2022-01-23 03:08:00.947431\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0026 Acc: 0.9995\n",
      "2022-01-23 03:08:03.367037\n",
      "validation Loss: 0.0705 Acc: 0.9814\n",
      "2022-01-23 03:08:03.764031\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0669 Acc: 0.9910\n",
      "2022-01-23 03:08:06.476446\n",
      "validation Loss: 0.1009 Acc: 0.9720\n",
      "2022-01-23 03:08:06.906237\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1222 Acc: 0.9820\n",
      "2022-01-23 03:08:09.430768\n",
      "validation Loss: 0.0516 Acc: 0.9814\n",
      "2022-01-23 03:08:09.926861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0205 Acc: 0.9960\n",
      "2022-01-23 03:08:12.632391\n",
      "validation Loss: 0.0512 Acc: 0.9814\n",
      "2022-01-23 03:08:13.094982\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 0.9995\n",
      "2022-01-23 03:08:15.723526\n",
      "validation Loss: 0.0391 Acc: 0.9860\n",
      "2022-01-23 03:08:16.155862\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 0.9990\n",
      "2022-01-23 03:08:19.215700\n",
      "validation Loss: 0.0458 Acc: 0.9860\n",
      "2022-01-23 03:08:19.704459\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9975\n",
      "2022-01-23 03:08:22.192919\n",
      "validation Loss: 0.0385 Acc: 0.9883\n",
      "2022-01-23 03:08:22.616295\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 0.9995\n",
      "2022-01-23 03:08:25.402762\n",
      "validation Loss: 0.0404 Acc: 0.9860\n",
      "2022-01-23 03:08:25.844473\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1128u2j4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 79456... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▇▇▇▇█████████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇███████████████▇█████████████████████</td></tr><tr><td>loss_train</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▂▂▂▁▁▁▁▁▁▂▁▂▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.97902</td></tr><tr><td>accuracy_train</td><td>0.9995</td></tr><tr><td>accuracy_validation</td><td>0.98601</td></tr><tr><td>best_test_accuracy</td><td>0.97902</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.03854</td></tr><tr><td>loss_train</td><td>0.00363</td></tr><tr><td>loss_validation</td><td>0.04039</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1128u2j4\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1128u2j4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_030300-1128u2j4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1128u2j4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2ipze433\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 03:08:36.186879\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9924 Acc: 0.0650\n",
      "2022-01-23 03:08:38.622057\n",
      "validation Loss: 2.9849 Acc: 0.0653\n",
      "2022-01-23 03:08:39.044308\n",
      "Accuracy of the network on the 429 test samples: 6.526806526806526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9762 Acc: 0.0650\n",
      "2022-01-23 03:08:42.002070\n",
      "validation Loss: 2.9656 Acc: 0.0653\n",
      "2022-01-23 03:08:42.439688\n",
      "Accuracy of the network on the 429 test samples: 6.526806526806526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9484 Acc: 0.0650\n",
      "2022-01-23 03:08:45.608342\n",
      "validation Loss: 2.9247 Acc: 0.0653\n",
      "2022-01-23 03:08:45.987508\n",
      "Accuracy of the network on the 429 test samples: 6.526806526806526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8785 Acc: 0.0890\n",
      "2022-01-23 03:08:48.970314\n",
      "validation Loss: 2.8103 Acc: 0.1562\n",
      "2022-01-23 03:08:49.353397\n",
      "Accuracy of the network on the 429 test samples: 14.452214452214452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6919 Acc: 0.1560\n",
      "2022-01-23 03:08:52.339926\n",
      "validation Loss: 2.5400 Acc: 0.2168\n",
      "2022-01-23 03:08:52.764629\n",
      "Accuracy of the network on the 429 test samples: 20.745920745920746\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3273 Acc: 0.3115\n",
      "2022-01-23 03:08:55.562057\n",
      "validation Loss: 2.0254 Acc: 0.3613\n",
      "2022-01-23 03:08:55.948712\n",
      "Accuracy of the network on the 429 test samples: 38.92773892773892\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7248 Acc: 0.4805\n",
      "2022-01-23 03:08:58.985000\n",
      "validation Loss: 1.4414 Acc: 0.6364\n",
      "2022-01-23 03:08:59.414066\n",
      "Accuracy of the network on the 429 test samples: 62.004662004662\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3406 Acc: 0.6550\n",
      "2022-01-23 03:09:02.333585\n",
      "validation Loss: 1.2312 Acc: 0.7133\n",
      "2022-01-23 03:09:02.776736\n",
      "Accuracy of the network on the 429 test samples: 71.56177156177156\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1275 Acc: 0.7450\n",
      "2022-01-23 03:09:05.872460\n",
      "validation Loss: 1.0296 Acc: 0.7529\n",
      "2022-01-23 03:09:06.278848\n",
      "Accuracy of the network on the 429 test samples: 77.85547785547784\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9812 Acc: 0.7820\n",
      "2022-01-23 03:09:09.150467\n",
      "validation Loss: 0.9040 Acc: 0.8135\n",
      "2022-01-23 03:09:09.554747\n",
      "Accuracy of the network on the 429 test samples: 83.21678321678321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8741 Acc: 0.8210\n",
      "2022-01-23 03:09:11.402519\n",
      "validation Loss: 0.8620 Acc: 0.8252\n",
      "2022-01-23 03:09:11.858048\n",
      "Accuracy of the network on the 429 test samples: 83.21678321678321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8290 Acc: 0.8225\n",
      "2022-01-23 03:09:15.218145\n",
      "validation Loss: 0.7993 Acc: 0.8368\n",
      "2022-01-23 03:09:15.656870\n",
      "Accuracy of the network on the 429 test samples: 85.3146853146853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7173 Acc: 0.8505\n",
      "2022-01-23 03:09:18.777187\n",
      "validation Loss: 0.7342 Acc: 0.8508\n",
      "2022-01-23 03:09:19.330486\n",
      "Accuracy of the network on the 429 test samples: 87.41258741258741\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6805 Acc: 0.8575\n",
      "2022-01-23 03:09:22.381913\n",
      "validation Loss: 0.7372 Acc: 0.8648\n",
      "2022-01-23 03:09:22.804910\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6346 Acc: 0.8630\n",
      "2022-01-23 03:09:25.852472\n",
      "validation Loss: 0.6964 Acc: 0.8392\n",
      "2022-01-23 03:09:26.403436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5878 Acc: 0.8645\n",
      "2022-01-23 03:09:29.000365\n",
      "validation Loss: 0.6528 Acc: 0.8765\n",
      "2022-01-23 03:09:29.444307\n",
      "Accuracy of the network on the 429 test samples: 88.34498834498834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5371 Acc: 0.8750\n",
      "2022-01-23 03:09:32.676881\n",
      "validation Loss: 0.6580 Acc: 0.8788\n",
      "2022-01-23 03:09:33.302902\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5174 Acc: 0.8795\n",
      "2022-01-23 03:09:36.531395\n",
      "validation Loss: 0.5853 Acc: 0.8834\n",
      "2022-01-23 03:09:36.970042\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4839 Acc: 0.8895\n",
      "2022-01-23 03:09:40.278489\n",
      "validation Loss: 0.5796 Acc: 0.8928\n",
      "2022-01-23 03:09:40.711395\n",
      "Accuracy of the network on the 429 test samples: 90.20979020979021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4715 Acc: 0.8860\n",
      "2022-01-23 03:09:43.755475\n",
      "validation Loss: 0.5318 Acc: 0.8974\n",
      "2022-01-23 03:09:44.149226\n",
      "Accuracy of the network on the 429 test samples: 90.67599067599068\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4355 Acc: 0.8960\n",
      "2022-01-23 03:09:47.262424\n",
      "validation Loss: 0.5019 Acc: 0.8904\n",
      "2022-01-23 03:09:47.733789\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4144 Acc: 0.9000\n",
      "2022-01-23 03:09:50.325058\n",
      "validation Loss: 0.4534 Acc: 0.9068\n",
      "2022-01-23 03:09:50.726270\n",
      "Accuracy of the network on the 429 test samples: 90.9090909090909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4069 Acc: 0.8920\n",
      "2022-01-23 03:09:53.746137\n",
      "validation Loss: 0.5068 Acc: 0.9044\n",
      "2022-01-23 03:09:54.408336\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3814 Acc: 0.9015\n",
      "2022-01-23 03:09:57.003525\n",
      "validation Loss: 0.4539 Acc: 0.9091\n",
      "2022-01-23 03:09:57.400400\n",
      "Accuracy of the network on the 429 test samples: 91.37529137529138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3556 Acc: 0.9070\n",
      "2022-01-23 03:10:00.376151\n",
      "validation Loss: 0.4649 Acc: 0.9068\n",
      "2022-01-23 03:10:00.785187\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3540 Acc: 0.9120\n",
      "2022-01-23 03:10:03.396259\n",
      "validation Loss: 0.4946 Acc: 0.9091\n",
      "2022-01-23 03:10:03.819080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3329 Acc: 0.9100\n",
      "2022-01-23 03:10:05.220051\n",
      "validation Loss: 0.4152 Acc: 0.9138\n",
      "2022-01-23 03:10:05.597566\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3218 Acc: 0.9125\n",
      "2022-01-23 03:10:08.768601\n",
      "validation Loss: 0.4022 Acc: 0.9161\n",
      "2022-01-23 03:10:09.189040\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3097 Acc: 0.9190\n",
      "2022-01-23 03:10:12.427897\n",
      "validation Loss: 0.4311 Acc: 0.9044\n",
      "2022-01-23 03:10:13.052328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3136 Acc: 0.9125\n",
      "2022-01-23 03:10:15.920717\n",
      "validation Loss: 0.3687 Acc: 0.9044\n",
      "2022-01-23 03:10:16.336888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2920 Acc: 0.9205\n",
      "2022-01-23 03:10:18.909292\n",
      "validation Loss: 0.4310 Acc: 0.9161\n",
      "2022-01-23 03:10:19.323440\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2692 Acc: 0.9265\n",
      "2022-01-23 03:10:21.898326\n",
      "validation Loss: 0.3773 Acc: 0.9231\n",
      "2022-01-23 03:10:22.423049\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2602 Acc: 0.9285\n",
      "2022-01-23 03:10:25.424827\n",
      "validation Loss: 0.3823 Acc: 0.9138\n",
      "2022-01-23 03:10:25.846806\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2670 Acc: 0.9245\n",
      "2022-01-23 03:10:28.462117\n",
      "validation Loss: 0.3558 Acc: 0.9277\n",
      "2022-01-23 03:10:28.854542\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2410 Acc: 0.9315\n",
      "2022-01-23 03:10:32.168725\n",
      "validation Loss: 0.3207 Acc: 0.9207\n",
      "2022-01-23 03:10:32.609840\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2353 Acc: 0.9355\n",
      "2022-01-23 03:10:35.189492\n",
      "validation Loss: 0.3432 Acc: 0.9231\n",
      "2022-01-23 03:10:35.567124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2314 Acc: 0.9340\n",
      "2022-01-23 03:10:38.188175\n",
      "validation Loss: 0.3073 Acc: 0.9277\n",
      "2022-01-23 03:10:38.637330\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2178 Acc: 0.9420\n",
      "2022-01-23 03:10:41.851207\n",
      "validation Loss: 0.3332 Acc: 0.9207\n",
      "2022-01-23 03:10:42.295819\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2217 Acc: 0.9420\n",
      "2022-01-23 03:10:44.957236\n",
      "validation Loss: 0.3247 Acc: 0.9301\n",
      "2022-01-23 03:10:45.546812\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2204 Acc: 0.9375\n",
      "2022-01-23 03:10:48.651534\n",
      "validation Loss: 0.2898 Acc: 0.9254\n",
      "2022-01-23 03:10:49.052570\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2045 Acc: 0.9425\n",
      "2022-01-23 03:10:51.704533\n",
      "validation Loss: 0.3046 Acc: 0.9394\n",
      "2022-01-23 03:10:52.181565\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2088 Acc: 0.9445\n",
      "2022-01-23 03:10:55.253695\n",
      "validation Loss: 0.2718 Acc: 0.9347\n",
      "2022-01-23 03:10:55.629974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2113 Acc: 0.9400\n",
      "2022-01-23 03:10:57.272635\n",
      "validation Loss: 0.3607 Acc: 0.9231\n",
      "2022-01-23 03:10:57.669526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2207 Acc: 0.9380\n",
      "2022-01-23 03:11:00.129200\n",
      "validation Loss: 0.3049 Acc: 0.9277\n",
      "2022-01-23 03:11:00.537143\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1838 Acc: 0.9490\n",
      "2022-01-23 03:11:03.260203\n",
      "validation Loss: 0.3125 Acc: 0.9324\n",
      "2022-01-23 03:11:03.712862\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1767 Acc: 0.9485\n",
      "2022-01-23 03:11:05.124615\n",
      "validation Loss: 0.2954 Acc: 0.9441\n",
      "2022-01-23 03:11:05.645697\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1669 Acc: 0.9515\n",
      "2022-01-23 03:11:08.597790\n",
      "validation Loss: 0.2987 Acc: 0.9394\n",
      "2022-01-23 03:11:09.040486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1738 Acc: 0.9505\n",
      "2022-01-23 03:11:11.586406\n",
      "validation Loss: 0.2750 Acc: 0.9394\n",
      "2022-01-23 03:11:12.078026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1873 Acc: 0.9525\n",
      "2022-01-23 03:11:14.760282\n",
      "validation Loss: 0.2959 Acc: 0.9324\n",
      "2022-01-23 03:11:15.210021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1633 Acc: 0.9510\n",
      "2022-01-23 03:11:17.875258\n",
      "validation Loss: 0.3337 Acc: 0.9394\n",
      "2022-01-23 03:11:18.392365\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1742 Acc: 0.9500\n",
      "2022-01-23 03:11:21.109535\n",
      "validation Loss: 0.2630 Acc: 0.9394\n",
      "2022-01-23 03:11:21.766435\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1496 Acc: 0.9575\n",
      "2022-01-23 03:11:24.444594\n",
      "validation Loss: 0.2767 Acc: 0.9417\n",
      "2022-01-23 03:11:24.849355\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1532 Acc: 0.9580\n",
      "2022-01-23 03:11:27.406148\n",
      "validation Loss: 0.2838 Acc: 0.9371\n",
      "2022-01-23 03:11:27.838788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1393 Acc: 0.9575\n",
      "2022-01-23 03:11:30.474815\n",
      "validation Loss: 0.2946 Acc: 0.9441\n",
      "2022-01-23 03:11:30.915749\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1591 Acc: 0.9540\n",
      "2022-01-23 03:11:34.170259\n",
      "validation Loss: 0.2636 Acc: 0.9394\n",
      "2022-01-23 03:11:34.717192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1368 Acc: 0.9610\n",
      "2022-01-23 03:11:37.342082\n",
      "validation Loss: 0.2732 Acc: 0.9487\n",
      "2022-01-23 03:11:37.745945\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1307 Acc: 0.9605\n",
      "2022-01-23 03:11:40.875232\n",
      "validation Loss: 0.2775 Acc: 0.9487\n",
      "2022-01-23 03:11:41.349688\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1272 Acc: 0.9575\n",
      "2022-01-23 03:11:43.030702\n",
      "validation Loss: 0.2645 Acc: 0.9487\n",
      "2022-01-23 03:11:43.533875\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1284 Acc: 0.9635\n",
      "2022-01-23 03:11:46.690260\n",
      "validation Loss: 0.2564 Acc: 0.9417\n",
      "2022-01-23 03:11:47.101243\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1287 Acc: 0.9615\n",
      "2022-01-23 03:11:49.991846\n",
      "validation Loss: 0.2618 Acc: 0.9534\n",
      "2022-01-23 03:11:50.446331\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1348 Acc: 0.9555\n",
      "2022-01-23 03:11:53.524421\n",
      "validation Loss: 0.2666 Acc: 0.9464\n",
      "2022-01-23 03:11:53.944518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1206 Acc: 0.9620\n",
      "2022-01-23 03:11:56.759697\n",
      "validation Loss: 0.2400 Acc: 0.9510\n",
      "2022-01-23 03:11:57.161132\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1177 Acc: 0.9640\n",
      "2022-01-23 03:11:59.824754\n",
      "validation Loss: 0.2487 Acc: 0.9534\n",
      "2022-01-23 03:12:00.320547\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1161 Acc: 0.9645\n",
      "2022-01-23 03:12:03.395527\n",
      "validation Loss: 0.2361 Acc: 0.9534\n",
      "2022-01-23 03:12:03.880065\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1243 Acc: 0.9615\n",
      "2022-01-23 03:12:07.261823\n",
      "validation Loss: 0.2848 Acc: 0.9301\n",
      "2022-01-23 03:12:07.701469\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1517 Acc: 0.9575\n",
      "2022-01-23 03:12:10.320186\n",
      "validation Loss: 0.2287 Acc: 0.9534\n",
      "2022-01-23 03:12:10.740742\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1138 Acc: 0.9670\n",
      "2022-01-23 03:12:13.800033\n",
      "validation Loss: 0.2377 Acc: 0.9510\n",
      "2022-01-23 03:12:14.244679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1084 Acc: 0.9690\n",
      "2022-01-23 03:12:16.882112\n",
      "validation Loss: 0.2352 Acc: 0.9557\n",
      "2022-01-23 03:12:17.309313\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1062 Acc: 0.9665\n",
      "2022-01-23 03:12:20.724222\n",
      "validation Loss: 0.2195 Acc: 0.9580\n",
      "2022-01-23 03:12:21.154941\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1049 Acc: 0.9675\n",
      "2022-01-23 03:12:24.291508\n",
      "validation Loss: 0.2292 Acc: 0.9510\n",
      "2022-01-23 03:12:24.687542\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1039 Acc: 0.9690\n",
      "2022-01-23 03:12:27.279825\n",
      "validation Loss: 0.2176 Acc: 0.9580\n",
      "2022-01-23 03:12:27.689232\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0996 Acc: 0.9705\n",
      "2022-01-23 03:12:30.785044\n",
      "validation Loss: 0.2423 Acc: 0.9627\n",
      "2022-01-23 03:12:31.379656\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0969 Acc: 0.9695\n",
      "2022-01-23 03:12:34.502735\n",
      "validation Loss: 0.1820 Acc: 0.9534\n",
      "2022-01-23 03:12:34.949001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1068 Acc: 0.9700\n",
      "2022-01-23 03:12:37.625394\n",
      "validation Loss: 0.2151 Acc: 0.9604\n",
      "2022-01-23 03:12:38.175031\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0913 Acc: 0.9730\n",
      "2022-01-23 03:12:40.871741\n",
      "validation Loss: 0.1746 Acc: 0.9487\n",
      "2022-01-23 03:12:41.277406\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1395 Acc: 0.9625\n",
      "2022-01-23 03:12:44.040027\n",
      "validation Loss: 0.1624 Acc: 0.9580\n",
      "2022-01-23 03:12:44.484005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0922 Acc: 0.9720\n",
      "2022-01-23 03:12:47.086447\n",
      "validation Loss: 0.2042 Acc: 0.9627\n",
      "2022-01-23 03:12:47.507784\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0836 Acc: 0.9765\n",
      "2022-01-23 03:12:50.632422\n",
      "validation Loss: 0.2269 Acc: 0.9580\n",
      "2022-01-23 03:12:51.072621\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0820 Acc: 0.9765\n",
      "2022-01-23 03:12:53.743350\n",
      "validation Loss: 0.2157 Acc: 0.9650\n",
      "2022-01-23 03:12:54.205609\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0761 Acc: 0.9795\n",
      "2022-01-23 03:12:57.338067\n",
      "validation Loss: 0.2247 Acc: 0.9510\n",
      "2022-01-23 03:12:57.756947\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0837 Acc: 0.9755\n",
      "2022-01-23 03:13:00.404912\n",
      "validation Loss: 0.1926 Acc: 0.9604\n",
      "2022-01-23 03:13:00.836072\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0981 Acc: 0.9660\n",
      "2022-01-23 03:13:03.476637\n",
      "validation Loss: 0.1719 Acc: 0.9627\n",
      "2022-01-23 03:13:03.957112\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0883 Acc: 0.9720\n",
      "2022-01-23 03:13:06.738739\n",
      "validation Loss: 0.2259 Acc: 0.9627\n",
      "2022-01-23 03:13:07.283686\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0825 Acc: 0.9780\n",
      "2022-01-23 03:13:09.980546\n",
      "validation Loss: 0.2033 Acc: 0.9674\n",
      "2022-01-23 03:13:10.408410\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0731 Acc: 0.9795\n",
      "2022-01-23 03:13:13.481470\n",
      "validation Loss: 0.1830 Acc: 0.9674\n",
      "2022-01-23 03:13:14.057951\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0687 Acc: 0.9800\n",
      "2022-01-23 03:13:17.296192\n",
      "validation Loss: 0.2110 Acc: 0.9627\n",
      "2022-01-23 03:13:17.807944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0849 Acc: 0.9745\n",
      "2022-01-23 03:13:20.496284\n",
      "validation Loss: 0.1792 Acc: 0.9650\n",
      "2022-01-23 03:13:20.894664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0803 Acc: 0.9750\n",
      "2022-01-23 03:13:23.752321\n",
      "validation Loss: 0.1701 Acc: 0.9697\n",
      "2022-01-23 03:13:24.252181\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0672 Acc: 0.9805\n",
      "2022-01-23 03:13:27.314165\n",
      "validation Loss: 0.1787 Acc: 0.9580\n",
      "2022-01-23 03:13:27.713069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1049 Acc: 0.9705\n",
      "2022-01-23 03:13:30.269667\n",
      "validation Loss: 0.2508 Acc: 0.9417\n",
      "2022-01-23 03:13:30.807640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1289 Acc: 0.9655\n",
      "2022-01-23 03:13:33.371681\n",
      "validation Loss: 0.1237 Acc: 0.9674\n",
      "2022-01-23 03:13:33.764663\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0819 Acc: 0.9740\n",
      "2022-01-23 03:13:36.444733\n",
      "validation Loss: 0.1431 Acc: 0.9604\n",
      "2022-01-23 03:13:36.922440\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0728 Acc: 0.9770\n",
      "2022-01-23 03:13:39.649322\n",
      "validation Loss: 0.1493 Acc: 0.9650\n",
      "2022-01-23 03:13:40.083389\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0640 Acc: 0.9805\n",
      "2022-01-23 03:13:42.655989\n",
      "validation Loss: 0.1594 Acc: 0.9650\n",
      "2022-01-23 03:13:43.178277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0634 Acc: 0.9810\n",
      "2022-01-23 03:13:45.752378\n",
      "validation Loss: 0.1690 Acc: 0.9674\n",
      "2022-01-23 03:13:46.270264\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0606 Acc: 0.9795\n",
      "2022-01-23 03:13:48.807800\n",
      "validation Loss: 0.1623 Acc: 0.9650\n",
      "2022-01-23 03:13:49.291391\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0563 Acc: 0.9820\n",
      "2022-01-23 03:13:51.984072\n",
      "validation Loss: 0.1684 Acc: 0.9650\n",
      "2022-01-23 03:13:52.410976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0648 Acc: 0.9765\n",
      "2022-01-23 03:13:55.011882\n",
      "validation Loss: 0.2156 Acc: 0.9650\n",
      "2022-01-23 03:13:55.438909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0625 Acc: 0.9805\n",
      "2022-01-23 03:13:57.763296\n",
      "validation Loss: 0.1880 Acc: 0.9627\n",
      "2022-01-23 03:13:58.163816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0552 Acc: 0.9835\n",
      "2022-01-23 03:14:00.722054\n",
      "validation Loss: 0.1859 Acc: 0.9650\n",
      "2022-01-23 03:14:01.149715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9697\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ipze433) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 33526... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▁▁▂▂▄▅▆▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▁▃▅▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▁▃▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>loss_train</td><td>██▆▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▆▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.9697</td></tr><tr><td>accuracy_train</td><td>0.9835</td></tr><tr><td>accuracy_validation</td><td>0.96503</td></tr><tr><td>best_test_accuracy</td><td>0.9697</td></tr><tr><td>best_val_accuracy</td><td>0.9697</td></tr><tr><td>best_val_loss</td><td>0.1701</td></tr><tr><td>loss_train</td><td>0.05524</td></tr><tr><td>loss_validation</td><td>0.18589</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2ipze433\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2ipze433</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_030826-2ipze433/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ipze433). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/199i1sux\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 03:14:11.843455\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.7927 Acc: 0.7860\n",
      "2022-01-23 03:14:14.398748\n",
      "validation Loss: 0.2011 Acc: 0.9417\n",
      "2022-01-23 03:14:14.824021\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1809 Acc: 0.9465\n",
      "2022-01-23 03:14:17.856751\n",
      "validation Loss: 0.1409 Acc: 0.9557\n",
      "2022-01-23 03:14:18.239436\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0925 Acc: 0.9720\n",
      "2022-01-23 03:14:21.168134\n",
      "validation Loss: 0.1099 Acc: 0.9744\n",
      "2022-01-23 03:14:21.631912\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0962 Acc: 0.9715\n",
      "2022-01-23 03:14:25.004486\n",
      "validation Loss: 0.1369 Acc: 0.9487\n",
      "2022-01-23 03:14:25.550082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0711 Acc: 0.9765\n",
      "2022-01-23 03:14:28.118041\n",
      "validation Loss: 0.1105 Acc: 0.9580\n",
      "2022-01-23 03:14:28.543638\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0536 Acc: 0.9845\n",
      "2022-01-23 03:14:31.119796\n",
      "validation Loss: 0.0628 Acc: 0.9837\n",
      "2022-01-23 03:14:31.539876\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9730\n",
      "2022-01-23 03:14:34.508237\n",
      "validation Loss: 0.2020 Acc: 0.9301\n",
      "2022-01-23 03:14:35.019624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0571 Acc: 0.9795\n",
      "2022-01-23 03:14:37.901768\n",
      "validation Loss: 0.0729 Acc: 0.9767\n",
      "2022-01-23 03:14:38.328713\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0373 Acc: 0.9880\n",
      "2022-01-23 03:14:40.944726\n",
      "validation Loss: 0.0755 Acc: 0.9790\n",
      "2022-01-23 03:14:41.367204\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0363 Acc: 0.9880\n",
      "2022-01-23 03:14:43.948442\n",
      "validation Loss: 0.0808 Acc: 0.9697\n",
      "2022-01-23 03:14:44.322543\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0406 Acc: 0.9865\n",
      "2022-01-23 03:14:47.067325\n",
      "validation Loss: 0.1800 Acc: 0.9464\n",
      "2022-01-23 03:14:47.456022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0388 Acc: 0.9880\n",
      "2022-01-23 03:14:50.072471\n",
      "validation Loss: 0.0654 Acc: 0.9837\n",
      "2022-01-23 03:14:50.447557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0172 Acc: 0.9955\n",
      "2022-01-23 03:14:52.959440\n",
      "validation Loss: 0.0933 Acc: 0.9627\n",
      "2022-01-23 03:14:53.401992\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0386 Acc: 0.9860\n",
      "2022-01-23 03:14:55.978765\n",
      "validation Loss: 0.0868 Acc: 0.9697\n",
      "2022-01-23 03:14:56.382280\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0206 Acc: 0.9925\n",
      "2022-01-23 03:14:59.039291\n",
      "validation Loss: 0.1039 Acc: 0.9650\n",
      "2022-01-23 03:14:59.565014\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0304 Acc: 0.9910\n",
      "2022-01-23 03:15:02.145577\n",
      "validation Loss: 0.0501 Acc: 0.9883\n",
      "2022-01-23 03:15:02.609922\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0158 Acc: 0.9950\n",
      "2022-01-23 03:15:05.882112\n",
      "validation Loss: 0.0488 Acc: 0.9907\n",
      "2022-01-23 03:15:06.307713\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0193 Acc: 0.9940\n",
      "2022-01-23 03:15:09.551536\n",
      "validation Loss: 0.0961 Acc: 0.9744\n",
      "2022-01-23 03:15:10.058504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0440 Acc: 0.9870\n",
      "2022-01-23 03:15:12.959789\n",
      "validation Loss: 0.0961 Acc: 0.9814\n",
      "2022-01-23 03:15:13.365049\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9920\n",
      "2022-01-23 03:15:15.901920\n",
      "validation Loss: 0.0818 Acc: 0.9837\n",
      "2022-01-23 03:15:16.291834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0435 Acc: 0.9870\n",
      "2022-01-23 03:15:18.874840\n",
      "validation Loss: 0.1202 Acc: 0.9650\n",
      "2022-01-23 03:15:19.285073\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0277 Acc: 0.9890\n",
      "2022-01-23 03:15:21.889507\n",
      "validation Loss: 0.0847 Acc: 0.9744\n",
      "2022-01-23 03:15:22.290737\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0364 Acc: 0.9890\n",
      "2022-01-23 03:15:24.842849\n",
      "validation Loss: 0.0982 Acc: 0.9697\n",
      "2022-01-23 03:15:25.230751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0197 Acc: 0.9945\n",
      "2022-01-23 03:15:27.806939\n",
      "validation Loss: 0.0922 Acc: 0.9744\n",
      "2022-01-23 03:15:28.331754\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0068 Acc: 0.9980\n",
      "2022-01-23 03:15:30.869236\n",
      "validation Loss: 0.0627 Acc: 0.9860\n",
      "2022-01-23 03:15:31.330345\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0154 Acc: 0.9960\n",
      "2022-01-23 03:15:33.900076\n",
      "validation Loss: 0.0508 Acc: 0.9837\n",
      "2022-01-23 03:15:34.321954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0044 Acc: 0.9990\n",
      "2022-01-23 03:15:36.934689\n",
      "validation Loss: 0.0505 Acc: 0.9837\n",
      "2022-01-23 03:15:37.332902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0056 Acc: 0.9980\n",
      "2022-01-23 03:15:39.907661\n",
      "validation Loss: 0.0429 Acc: 0.9837\n",
      "2022-01-23 03:15:40.341017\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0085 Acc: 0.9975\n",
      "2022-01-23 03:15:42.848401\n",
      "validation Loss: 0.0742 Acc: 0.9744\n",
      "2022-01-23 03:15:43.358742\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0566 Acc: 0.9810\n",
      "2022-01-23 03:15:46.052272\n",
      "validation Loss: 0.1089 Acc: 0.9697\n",
      "2022-01-23 03:15:46.522024\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0278 Acc: 0.9890\n",
      "2022-01-23 03:15:49.025393\n",
      "validation Loss: 0.1075 Acc: 0.9720\n",
      "2022-01-23 03:15:49.424595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0214 Acc: 0.9935\n",
      "2022-01-23 03:15:51.919275\n",
      "validation Loss: 0.0585 Acc: 0.9814\n",
      "2022-01-23 03:15:52.356771\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0079 Acc: 0.9975\n",
      "2022-01-23 03:15:54.869912\n",
      "validation Loss: 0.0694 Acc: 0.9814\n",
      "2022-01-23 03:15:55.255308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 0.9970\n",
      "2022-01-23 03:15:57.806988\n",
      "validation Loss: 0.0827 Acc: 0.9767\n",
      "2022-01-23 03:15:58.218464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0066 Acc: 0.9970\n",
      "2022-01-23 03:16:00.709122\n",
      "validation Loss: 0.0866 Acc: 0.9650\n",
      "2022-01-23 03:16:01.194389\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 0.9955\n",
      "2022-01-23 03:16:03.717090\n",
      "validation Loss: 0.0910 Acc: 0.9744\n",
      "2022-01-23 03:16:04.118755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9940\n",
      "2022-01-23 03:16:06.610818\n",
      "validation Loss: 0.0693 Acc: 0.9790\n",
      "2022-01-23 03:16:07.037228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0775 Acc: 0.9785\n",
      "2022-01-23 03:16:09.762939\n",
      "validation Loss: 0.1920 Acc: 0.9534\n",
      "2022-01-23 03:16:10.216580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0238 Acc: 0.9915\n",
      "2022-01-23 03:16:12.808028\n",
      "validation Loss: 0.1018 Acc: 0.9744\n",
      "2022-01-23 03:16:13.212813\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0521 Acc: 0.9830\n",
      "2022-01-23 03:16:15.686898\n",
      "validation Loss: 0.0881 Acc: 0.9767\n",
      "2022-01-23 03:16:16.077238\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0445 Acc: 0.9880\n",
      "2022-01-23 03:16:18.781536\n",
      "validation Loss: 0.1249 Acc: 0.9697\n",
      "2022-01-23 03:16:19.253289\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0281 Acc: 0.9930\n",
      "2022-01-23 03:16:21.914990\n",
      "validation Loss: 0.0654 Acc: 0.9720\n",
      "2022-01-23 03:16:22.320765\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0046 Acc: 0.9990\n",
      "2022-01-23 03:16:24.944648\n",
      "validation Loss: 0.0447 Acc: 0.9860\n",
      "2022-01-23 03:16:25.523842\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0211 Acc: 0.9935\n",
      "2022-01-23 03:16:27.760053\n",
      "validation Loss: 0.1006 Acc: 0.9697\n",
      "2022-01-23 03:16:28.244921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0032 Acc: 0.9995\n",
      "2022-01-23 03:16:30.819797\n",
      "validation Loss: 0.0606 Acc: 0.9814\n",
      "2022-01-23 03:16:31.215327\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 0.9985\n",
      "2022-01-23 03:16:33.803584\n",
      "validation Loss: 0.0575 Acc: 0.9860\n",
      "2022-01-23 03:16:34.314500\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 03:16:37.063190\n",
      "validation Loss: 0.0544 Acc: 0.9860\n",
      "2022-01-23 03:16:37.496089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:16:40.145150\n",
      "validation Loss: 0.0520 Acc: 0.9837\n",
      "2022-01-23 03:16:40.536060\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:16:43.102033\n",
      "validation Loss: 0.0515 Acc: 0.9837\n",
      "2022-01-23 03:16:43.509470\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:16:46.034538\n",
      "validation Loss: 0.0511 Acc: 0.9837\n",
      "2022-01-23 03:16:46.419860\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:16:49.059126\n",
      "validation Loss: 0.0507 Acc: 0.9860\n",
      "2022-01-23 03:16:49.463001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:16:52.164672\n",
      "validation Loss: 0.0500 Acc: 0.9860\n",
      "2022-01-23 03:16:52.600742\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:16:55.184406\n",
      "validation Loss: 0.0496 Acc: 0.9860\n",
      "2022-01-23 03:16:55.628545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:16:58.265445\n",
      "validation Loss: 0.0489 Acc: 0.9860\n",
      "2022-01-23 03:16:58.662690\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:01.429261\n",
      "validation Loss: 0.0489 Acc: 0.9860\n",
      "2022-01-23 03:17:01.874598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:04.501090\n",
      "validation Loss: 0.0482 Acc: 0.9883\n",
      "2022-01-23 03:17:04.884253\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:07.477421\n",
      "validation Loss: 0.0479 Acc: 0.9883\n",
      "2022-01-23 03:17:08.016586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:10.605240\n",
      "validation Loss: 0.0481 Acc: 0.9883\n",
      "2022-01-23 03:17:11.041177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:13.917726\n",
      "validation Loss: 0.0472 Acc: 0.9883\n",
      "2022-01-23 03:17:14.306409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:17.245930\n",
      "validation Loss: 0.0469 Acc: 0.9883\n",
      "2022-01-23 03:17:17.676255\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:20.532166\n",
      "validation Loss: 0.0469 Acc: 0.9883\n",
      "2022-01-23 03:17:20.932338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:23.513932\n",
      "validation Loss: 0.0465 Acc: 0.9883\n",
      "2022-01-23 03:17:24.141845\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:26.778959\n",
      "validation Loss: 0.0464 Acc: 0.9883\n",
      "2022-01-23 03:17:27.197826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:29.757404\n",
      "validation Loss: 0.0458 Acc: 0.9883\n",
      "2022-01-23 03:17:30.124048\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:32.759001\n",
      "validation Loss: 0.0459 Acc: 0.9883\n",
      "2022-01-23 03:17:33.255316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:17:35.883108\n",
      "validation Loss: 0.0456 Acc: 0.9883\n",
      "2022-01-23 03:17:36.307751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:38.958768\n",
      "validation Loss: 0.0456 Acc: 0.9883\n",
      "2022-01-23 03:17:39.373212\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:41.968406\n",
      "validation Loss: 0.0455 Acc: 0.9883\n",
      "2022-01-23 03:17:42.382602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:45.060881\n",
      "validation Loss: 0.0454 Acc: 0.9883\n",
      "2022-01-23 03:17:45.469351\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:48.144213\n",
      "validation Loss: 0.0453 Acc: 0.9883\n",
      "2022-01-23 03:17:48.546782\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:51.237438\n",
      "validation Loss: 0.0448 Acc: 0.9883\n",
      "2022-01-23 03:17:51.666351\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:54.203299\n",
      "validation Loss: 0.0450 Acc: 0.9883\n",
      "2022-01-23 03:17:54.706486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:17:57.260001\n",
      "validation Loss: 0.0446 Acc: 0.9883\n",
      "2022-01-23 03:17:57.669009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:00.227701\n",
      "validation Loss: 0.0444 Acc: 0.9883\n",
      "2022-01-23 03:18:00.709337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:03.355318\n",
      "validation Loss: 0.0443 Acc: 0.9883\n",
      "2022-01-23 03:18:03.759426\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:06.292035\n",
      "validation Loss: 0.0443 Acc: 0.9883\n",
      "2022-01-23 03:18:06.712630\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:09.251570\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 03:18:09.635999\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:12.313769\n",
      "validation Loss: 0.0441 Acc: 0.9883\n",
      "2022-01-23 03:18:12.710029\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:15.381807\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 03:18:15.818955\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:17.353849\n",
      "validation Loss: 0.0439 Acc: 0.9883\n",
      "2022-01-23 03:18:17.995586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:20.455670\n",
      "validation Loss: 0.0436 Acc: 0.9907\n",
      "2022-01-23 03:18:20.887532\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:23.788831\n",
      "validation Loss: 0.0435 Acc: 0.9907\n",
      "2022-01-23 03:18:24.167794\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:27.171665\n",
      "validation Loss: 0.0436 Acc: 0.9907\n",
      "2022-01-23 03:18:27.530703\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:30.116527\n",
      "validation Loss: 0.0439 Acc: 0.9907\n",
      "2022-01-23 03:18:30.532091\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:33.152776\n",
      "validation Loss: 0.0435 Acc: 0.9907\n",
      "2022-01-23 03:18:33.673900\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:36.777026\n",
      "validation Loss: 0.0432 Acc: 0.9907\n",
      "2022-01-23 03:18:37.205269\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:40.303686\n",
      "validation Loss: 0.0435 Acc: 0.9907\n",
      "2022-01-23 03:18:40.732591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:43.364433\n",
      "validation Loss: 0.0432 Acc: 0.9907\n",
      "2022-01-23 03:18:43.789488\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:46.348909\n",
      "validation Loss: 0.0430 Acc: 0.9907\n",
      "2022-01-23 03:18:46.750945\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:49.884535\n",
      "validation Loss: 0.0429 Acc: 0.9907\n",
      "2022-01-23 03:18:50.351630\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:53.434011\n",
      "validation Loss: 0.0431 Acc: 0.9907\n",
      "2022-01-23 03:18:54.052577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:18:56.708743\n",
      "validation Loss: 0.0426 Acc: 0.9907\n",
      "2022-01-23 03:18:57.142900\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:00.218441\n",
      "validation Loss: 0.0431 Acc: 0.9907\n",
      "2022-01-23 03:19:00.604781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:03.373702\n",
      "validation Loss: 0.0429 Acc: 0.9907\n",
      "2022-01-23 03:19:03.779721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:06.405245\n",
      "validation Loss: 0.0427 Acc: 0.9907\n",
      "2022-01-23 03:19:06.805145\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:09.458059\n",
      "validation Loss: 0.0428 Acc: 0.9907\n",
      "2022-01-23 03:19:09.919592\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:12.566581\n",
      "validation Loss: 0.0428 Acc: 0.9907\n",
      "2022-01-23 03:19:13.046449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:15.654779\n",
      "validation Loss: 0.0431 Acc: 0.9907\n",
      "2022-01-23 03:19:16.133328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:18.866204\n",
      "validation Loss: 0.0425 Acc: 0.9907\n",
      "2022-01-23 03:19:19.387744\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:19:22.712749\n",
      "validation Loss: 0.0424 Acc: 0.9907\n",
      "2022-01-23 03:19:23.128545\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9907\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:199i1sux) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 71102... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▄▆▆▇█████████</td></tr><tr><td>accuracy_train</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▆▂▄█▆▄▅▇▇▅▆▆▆▅▅▇▇▇▇██████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▂▂▇▃▁▃▄▃▁▁▄▃▃▄▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99068</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99068</td></tr><tr><td>best_val_loss</td><td>0.04244</td></tr><tr><td>loss_train</td><td>2e-05</td></tr><tr><td>loss_validation</td><td>0.04244</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/199i1sux\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/199i1sux</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_031401-199i1sux/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:199i1sux). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2a3jk5gi\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 03:19:33.700001\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.0575 Acc: 0.7535\n",
      "2022-01-23 03:19:36.327181\n",
      "validation Loss: 0.2536 Acc: 0.9371\n",
      "2022-01-23 03:19:36.762498\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1696 Acc: 0.9575\n",
      "2022-01-23 03:19:39.744851\n",
      "validation Loss: 0.1389 Acc: 0.9604\n",
      "2022-01-23 03:19:40.202030\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1245 Acc: 0.9695\n",
      "2022-01-23 03:19:43.329258\n",
      "validation Loss: 0.1419 Acc: 0.9510\n",
      "2022-01-23 03:19:43.795106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0791 Acc: 0.9785\n",
      "2022-01-23 03:19:46.374189\n",
      "validation Loss: 0.0928 Acc: 0.9767\n",
      "2022-01-23 03:19:46.857247\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0629 Acc: 0.9820\n",
      "2022-01-23 03:19:49.955880\n",
      "validation Loss: 0.0997 Acc: 0.9744\n",
      "2022-01-23 03:19:50.393134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0427 Acc: 0.9880\n",
      "2022-01-23 03:19:52.625718\n",
      "validation Loss: 0.1096 Acc: 0.9580\n",
      "2022-01-23 03:19:53.069442\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0463 Acc: 0.9900\n",
      "2022-01-23 03:19:55.661635\n",
      "validation Loss: 0.0832 Acc: 0.9744\n",
      "2022-01-23 03:19:56.234651\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0512 Acc: 0.9835\n",
      "2022-01-23 03:19:58.852781\n",
      "validation Loss: 0.0997 Acc: 0.9674\n",
      "2022-01-23 03:19:59.295535\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0423 Acc: 0.9865\n",
      "2022-01-23 03:20:01.923227\n",
      "validation Loss: 0.1389 Acc: 0.9510\n",
      "2022-01-23 03:20:02.419977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0462 Acc: 0.9895\n",
      "2022-01-23 03:20:05.049429\n",
      "validation Loss: 0.0582 Acc: 0.9814\n",
      "2022-01-23 03:20:05.452283\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0214 Acc: 0.9945\n",
      "2022-01-23 03:20:08.544447\n",
      "validation Loss: 0.0652 Acc: 0.9814\n",
      "2022-01-23 03:20:09.030522\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0335 Acc: 0.9900\n",
      "2022-01-23 03:20:11.552523\n",
      "validation Loss: 0.0913 Acc: 0.9720\n",
      "2022-01-23 03:20:12.033946\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0272 Acc: 0.9925\n",
      "2022-01-23 03:20:14.671092\n",
      "validation Loss: 0.0544 Acc: 0.9860\n",
      "2022-01-23 03:20:15.066312\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0359 Acc: 0.9905\n",
      "2022-01-23 03:20:18.334041\n",
      "validation Loss: 0.0677 Acc: 0.9767\n",
      "2022-01-23 03:20:18.806445\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9975\n",
      "2022-01-23 03:20:21.398626\n",
      "validation Loss: 0.0523 Acc: 0.9767\n",
      "2022-01-23 03:20:21.806231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0098 Acc: 0.9990\n",
      "2022-01-23 03:20:24.325991\n",
      "validation Loss: 0.0627 Acc: 0.9837\n",
      "2022-01-23 03:20:24.737814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0275 Acc: 0.9925\n",
      "2022-01-23 03:20:27.276407\n",
      "validation Loss: 0.0597 Acc: 0.9767\n",
      "2022-01-23 03:20:27.695182\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0212 Acc: 0.9930\n",
      "2022-01-23 03:20:30.248026\n",
      "validation Loss: 0.0907 Acc: 0.9674\n",
      "2022-01-23 03:20:30.677520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0375 Acc: 0.9895\n",
      "2022-01-23 03:20:33.330561\n",
      "validation Loss: 0.0609 Acc: 0.9767\n",
      "2022-01-23 03:20:33.734483\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9980\n",
      "2022-01-23 03:20:36.476163\n",
      "validation Loss: 0.0645 Acc: 0.9837\n",
      "2022-01-23 03:20:36.906673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0216 Acc: 0.9945\n",
      "2022-01-23 03:20:39.620155\n",
      "validation Loss: 0.0778 Acc: 0.9720\n",
      "2022-01-23 03:20:40.069123\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0122 Acc: 0.9970\n",
      "2022-01-23 03:20:42.834455\n",
      "validation Loss: 0.0554 Acc: 0.9860\n",
      "2022-01-23 03:20:43.283012\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 0.9975\n",
      "2022-01-23 03:20:46.044983\n",
      "validation Loss: 0.0565 Acc: 0.9860\n",
      "2022-01-23 03:20:46.565129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0066 Acc: 0.9985\n",
      "2022-01-23 03:20:49.526818\n",
      "validation Loss: 0.0607 Acc: 0.9837\n",
      "2022-01-23 03:20:50.090749\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 0.9995\n",
      "2022-01-23 03:20:52.926848\n",
      "validation Loss: 0.0554 Acc: 0.9860\n",
      "2022-01-23 03:20:53.394010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 0.9990\n",
      "2022-01-23 03:20:56.196104\n",
      "validation Loss: 0.0425 Acc: 0.9883\n",
      "2022-01-23 03:20:56.632046\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:20:59.930181\n",
      "validation Loss: 0.0468 Acc: 0.9883\n",
      "2022-01-23 03:21:00.342394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 03:21:03.033203\n",
      "validation Loss: 0.0545 Acc: 0.9860\n",
      "2022-01-23 03:21:03.523451\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 03:21:06.111088\n",
      "validation Loss: 0.0495 Acc: 0.9860\n",
      "2022-01-23 03:21:06.628081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:21:09.295490\n",
      "validation Loss: 0.0421 Acc: 0.9883\n",
      "2022-01-23 03:21:09.689205\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 03:21:11.626891\n",
      "validation Loss: 0.0463 Acc: 0.9883\n",
      "2022-01-23 03:21:12.019020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 03:21:14.553652\n",
      "validation Loss: 0.0455 Acc: 0.9883\n",
      "2022-01-23 03:21:14.998879\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:21:17.705495\n",
      "validation Loss: 0.0444 Acc: 0.9860\n",
      "2022-01-23 03:21:18.120967\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:21:20.692069\n",
      "validation Loss: 0.0405 Acc: 0.9907\n",
      "2022-01-23 03:21:21.107130\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:21:24.298633\n",
      "validation Loss: 0.0405 Acc: 0.9907\n",
      "2022-01-23 03:21:24.707744\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:21:27.312666\n",
      "validation Loss: 0.0439 Acc: 0.9883\n",
      "2022-01-23 03:21:27.724098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:30.361856\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:21:30.785960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:33.378000\n",
      "validation Loss: 0.0415 Acc: 0.9883\n",
      "2022-01-23 03:21:33.767574\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:36.369660\n",
      "validation Loss: 0.0426 Acc: 0.9883\n",
      "2022-01-23 03:21:36.786546\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:39.370155\n",
      "validation Loss: 0.0426 Acc: 0.9883\n",
      "2022-01-23 03:21:39.914979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:42.576870\n",
      "validation Loss: 0.0454 Acc: 0.9883\n",
      "2022-01-23 03:21:42.999758\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:21:45.640160\n",
      "validation Loss: 0.0425 Acc: 0.9883\n",
      "2022-01-23 03:21:46.055951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:21:48.752965\n",
      "validation Loss: 0.0428 Acc: 0.9883\n",
      "2022-01-23 03:21:49.186105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:21:51.834666\n",
      "validation Loss: 0.0413 Acc: 0.9907\n",
      "2022-01-23 03:21:52.311706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:21:54.985918\n",
      "validation Loss: 0.0485 Acc: 0.9883\n",
      "2022-01-23 03:21:55.620274\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:21:58.211463\n",
      "validation Loss: 0.0399 Acc: 0.9907\n",
      "2022-01-23 03:21:58.621050\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:22:01.615891\n",
      "validation Loss: 0.0394 Acc: 0.9907\n",
      "2022-01-23 03:22:02.016554\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:22:05.087513\n",
      "validation Loss: 0.0406 Acc: 0.9883\n",
      "2022-01-23 03:22:05.508472\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:22:08.243251\n",
      "validation Loss: 0.0386 Acc: 0.9907\n",
      "2022-01-23 03:22:08.716398\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:22:11.809534\n",
      "validation Loss: 0.0402 Acc: 0.9907\n",
      "2022-01-23 03:22:12.243540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:14.879648\n",
      "validation Loss: 0.0441 Acc: 0.9883\n",
      "2022-01-23 03:22:15.661183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:18.309249\n",
      "validation Loss: 0.0396 Acc: 0.9907\n",
      "2022-01-23 03:22:18.743475\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:21.371105\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:22:21.795244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:24.469748\n",
      "validation Loss: 0.0410 Acc: 0.9907\n",
      "2022-01-23 03:22:24.925622\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:27.559003\n",
      "validation Loss: 0.0402 Acc: 0.9907\n",
      "2022-01-23 03:22:27.989898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:30.539692\n",
      "validation Loss: 0.0407 Acc: 0.9883\n",
      "2022-01-23 03:22:30.941708\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:33.420532\n",
      "validation Loss: 0.0400 Acc: 0.9907\n",
      "2022-01-23 03:22:34.047861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:36.690345\n",
      "validation Loss: 0.0439 Acc: 0.9883\n",
      "2022-01-23 03:22:37.167640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:38.804358\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 03:22:39.175960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:41.664029\n",
      "validation Loss: 0.0395 Acc: 0.9907\n",
      "2022-01-23 03:22:42.080113\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:44.652136\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:22:45.253673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:47.829438\n",
      "validation Loss: 0.0447 Acc: 0.9883\n",
      "2022-01-23 03:22:48.228568\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:50.834116\n",
      "validation Loss: 0.0424 Acc: 0.9883\n",
      "2022-01-23 03:22:51.245338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:22:53.824600\n",
      "validation Loss: 0.0417 Acc: 0.9907\n",
      "2022-01-23 03:22:54.268991\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:22:56.795560\n",
      "validation Loss: 0.0423 Acc: 0.9883\n",
      "2022-01-23 03:22:57.185989\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:22:59.688067\n",
      "validation Loss: 0.0403 Acc: 0.9907\n",
      "2022-01-23 03:23:00.078733\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:02.632395\n",
      "validation Loss: 0.0411 Acc: 0.9883\n",
      "2022-01-23 03:23:03.066064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:05.558345\n",
      "validation Loss: 0.0388 Acc: 0.9907\n",
      "2022-01-23 03:23:06.026573\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:08.628050\n",
      "validation Loss: 0.0424 Acc: 0.9883\n",
      "2022-01-23 03:23:09.084406\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:11.766024\n",
      "validation Loss: 0.0384 Acc: 0.9907\n",
      "2022-01-23 03:23:12.168647\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:15.333806\n",
      "validation Loss: 0.0430 Acc: 0.9883\n",
      "2022-01-23 03:23:15.711591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:18.419773\n",
      "validation Loss: 0.0418 Acc: 0.9883\n",
      "2022-01-23 03:23:18.858243\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:21.576743\n",
      "validation Loss: 0.0473 Acc: 0.9883\n",
      "2022-01-23 03:23:21.985271\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:24.704104\n",
      "validation Loss: 0.0412 Acc: 0.9883\n",
      "2022-01-23 03:23:25.086635\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:27.753310\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:23:28.197934\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:30.877986\n",
      "validation Loss: 0.0395 Acc: 0.9907\n",
      "2022-01-23 03:23:31.429449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:34.081666\n",
      "validation Loss: 0.0380 Acc: 0.9907\n",
      "2022-01-23 03:23:34.482621\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:37.658131\n",
      "validation Loss: 0.0393 Acc: 0.9907\n",
      "2022-01-23 03:23:38.343605\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:40.984991\n",
      "validation Loss: 0.0426 Acc: 0.9883\n",
      "2022-01-23 03:23:41.399773\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:44.038750\n",
      "validation Loss: 0.0399 Acc: 0.9907\n",
      "2022-01-23 03:23:44.450290\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:46.184822\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:23:46.686201\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:49.290465\n",
      "validation Loss: 0.0390 Acc: 0.9907\n",
      "2022-01-23 03:23:49.721231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:52.399005\n",
      "validation Loss: 0.0445 Acc: 0.9883\n",
      "2022-01-23 03:23:52.809293\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:55.466459\n",
      "validation Loss: 0.0422 Acc: 0.9883\n",
      "2022-01-23 03:23:55.868898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:23:58.489217\n",
      "validation Loss: 0.0447 Acc: 0.9883\n",
      "2022-01-23 03:23:58.901237\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:01.552643\n",
      "validation Loss: 0.0413 Acc: 0.9907\n",
      "2022-01-23 03:24:02.138903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:04.787209\n",
      "validation Loss: 0.0365 Acc: 0.9907\n",
      "2022-01-23 03:24:05.186936\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:08.244263\n",
      "validation Loss: 0.0438 Acc: 0.9883\n",
      "2022-01-23 03:24:08.850818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:11.438501\n",
      "validation Loss: 0.0414 Acc: 0.9883\n",
      "2022-01-23 03:24:11.855218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:14.501220\n",
      "validation Loss: 0.0390 Acc: 0.9907\n",
      "2022-01-23 03:24:14.903326\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:17.437823\n",
      "validation Loss: 0.0392 Acc: 0.9907\n",
      "2022-01-23 03:24:18.036952\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:20.649443\n",
      "validation Loss: 0.0451 Acc: 0.9883\n",
      "2022-01-23 03:24:21.071288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:23.702730\n",
      "validation Loss: 0.0407 Acc: 0.9907\n",
      "2022-01-23 03:24:24.136943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:26.869154\n",
      "validation Loss: 0.0459 Acc: 0.9883\n",
      "2022-01-23 03:24:27.453165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:24:30.160497\n",
      "validation Loss: 0.0615 Acc: 0.9860\n",
      "2022-01-23 03:24:30.580109\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2175 Acc: 0.9290\n",
      "2022-01-23 03:24:33.215842\n",
      "validation Loss: 0.1796 Acc: 0.9394\n",
      "2022-01-23 03:24:33.607167\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1709 Acc: 0.9415\n",
      "2022-01-23 03:24:36.314808\n",
      "validation Loss: 0.1108 Acc: 0.9604\n",
      "2022-01-23 03:24:36.880889\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0602 Acc: 0.9805\n",
      "2022-01-23 03:24:39.523184\n",
      "validation Loss: 0.0972 Acc: 0.9650\n",
      "2022-01-23 03:24:39.962177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0439 Acc: 0.9870\n",
      "2022-01-23 03:24:42.611220\n",
      "validation Loss: 0.0643 Acc: 0.9790\n",
      "2022-01-23 03:24:43.024958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9945\n",
      "2022-01-23 03:24:45.664345\n",
      "validation Loss: 0.0401 Acc: 0.9837\n",
      "2022-01-23 03:24:46.124881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9907\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2a3jk5gi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 63147... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▅▇▇▇████████</td></tr><tr><td>accuracy_train</td><td>▁▇████████████████████████████████████▆█</td></tr><tr><td>accuracy_validation</td><td>▁▃▄▅▇▇▇▅▆▇█▇██████████████████████████▄▇</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>loss_validation</td><td>█▄▃▃▂▂▂▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>0.9945</td></tr><tr><td>accuracy_validation</td><td>0.98368</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99068</td></tr><tr><td>best_val_loss</td><td>0.03654</td></tr><tr><td>loss_train</td><td>0.0196</td></tr><tr><td>loss_validation</td><td>0.04011</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2a3jk5gi\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2a3jk5gi</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_031923-2a3jk5gi/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2a3jk5gi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kphx4ff\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 03:24:56.920794\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.4177 Acc: 0.7110\n",
      "2022-01-23 03:24:59.489492\n",
      "validation Loss: 0.4775 Acc: 0.9301\n",
      "2022-01-23 03:24:59.966189\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.3058 Acc: 0.9535\n",
      "2022-01-23 03:25:02.876553\n",
      "validation Loss: 0.2055 Acc: 0.9580\n",
      "2022-01-23 03:25:03.303101\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1477 Acc: 0.9765\n",
      "2022-01-23 03:25:06.527746\n",
      "validation Loss: 0.1476 Acc: 0.9627\n",
      "2022-01-23 03:25:06.972107\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1032 Acc: 0.9820\n",
      "2022-01-23 03:25:09.834335\n",
      "validation Loss: 0.1232 Acc: 0.9697\n",
      "2022-01-23 03:25:10.420486\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0899 Acc: 0.9780\n",
      "2022-01-23 03:25:13.353296\n",
      "validation Loss: 0.1240 Acc: 0.9650\n",
      "2022-01-23 03:25:13.765941\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0750 Acc: 0.9795\n",
      "2022-01-23 03:25:16.245642\n",
      "validation Loss: 0.0893 Acc: 0.9790\n",
      "2022-01-23 03:25:16.643747\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0434 Acc: 0.9905\n",
      "2022-01-23 03:25:19.788580\n",
      "validation Loss: 0.0732 Acc: 0.9814\n",
      "2022-01-23 03:25:20.190745\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0421 Acc: 0.9910\n",
      "2022-01-23 03:25:23.221531\n",
      "validation Loss: 0.0956 Acc: 0.9697\n",
      "2022-01-23 03:25:23.642446\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0407 Acc: 0.9920\n",
      "2022-01-23 03:25:26.191712\n",
      "validation Loss: 0.0768 Acc: 0.9767\n",
      "2022-01-23 03:25:26.746322\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0535 Acc: 0.9845\n",
      "2022-01-23 03:25:29.325715\n",
      "validation Loss: 0.0826 Acc: 0.9837\n",
      "2022-01-23 03:25:29.760435\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0518 Acc: 0.9850\n",
      "2022-01-23 03:25:32.740776\n",
      "validation Loss: 0.0708 Acc: 0.9790\n",
      "2022-01-23 03:25:33.386409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9955\n",
      "2022-01-23 03:25:34.781431\n",
      "validation Loss: 0.0566 Acc: 0.9814\n",
      "2022-01-23 03:25:35.259552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0166 Acc: 0.9980\n",
      "2022-01-23 03:25:37.787225\n",
      "validation Loss: 0.0520 Acc: 0.9860\n",
      "2022-01-23 03:25:38.205602\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 0.9975\n",
      "2022-01-23 03:25:41.300603\n",
      "validation Loss: 0.0724 Acc: 0.9790\n",
      "2022-01-23 03:25:41.718840\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9980\n",
      "2022-01-23 03:25:44.341601\n",
      "validation Loss: 0.0460 Acc: 0.9930\n",
      "2022-01-23 03:25:44.757877\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0159 Acc: 0.9945\n",
      "2022-01-23 03:25:47.791184\n",
      "validation Loss: 0.0544 Acc: 0.9883\n",
      "2022-01-23 03:25:48.207962\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0275 Acc: 0.9930\n",
      "2022-01-23 03:25:50.824606\n",
      "validation Loss: 0.0634 Acc: 0.9814\n",
      "2022-01-23 03:25:51.414744\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0299 Acc: 0.9935\n",
      "2022-01-23 03:25:54.056808\n",
      "validation Loss: 0.0883 Acc: 0.9674\n",
      "2022-01-23 03:25:54.445380\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0157 Acc: 0.9975\n",
      "2022-01-23 03:25:57.177675\n",
      "validation Loss: 0.0483 Acc: 0.9907\n",
      "2022-01-23 03:25:57.573020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9990\n",
      "2022-01-23 03:26:00.265147\n",
      "validation Loss: 0.0373 Acc: 0.9930\n",
      "2022-01-23 03:26:00.954996\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 1.0000\n",
      "2022-01-23 03:26:03.961986\n",
      "validation Loss: 0.0499 Acc: 0.9860\n",
      "2022-01-23 03:26:04.363160\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 0.9995\n",
      "2022-01-23 03:26:06.997694\n",
      "validation Loss: 0.0347 Acc: 0.9930\n",
      "2022-01-23 03:26:07.405433\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 1.0000\n",
      "2022-01-23 03:26:10.543332\n",
      "validation Loss: 0.0551 Acc: 0.9860\n",
      "2022-01-23 03:26:10.973872\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0242 Acc: 0.9925\n",
      "2022-01-23 03:26:13.574618\n",
      "validation Loss: 0.0795 Acc: 0.9814\n",
      "2022-01-23 03:26:13.983491\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9960\n",
      "2022-01-23 03:26:16.613784\n",
      "validation Loss: 0.0473 Acc: 0.9907\n",
      "2022-01-23 03:26:17.184407\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 0.9995\n",
      "2022-01-23 03:26:19.796278\n",
      "validation Loss: 0.0471 Acc: 0.9907\n",
      "2022-01-23 03:26:20.215940\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "2022-01-23 03:26:22.810801\n",
      "validation Loss: 0.0589 Acc: 0.9860\n",
      "2022-01-23 03:26:23.217818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 0.9985\n",
      "2022-01-23 03:26:25.948899\n",
      "validation Loss: 0.0346 Acc: 0.9930\n",
      "2022-01-23 03:26:26.568655\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "2022-01-23 03:26:29.669771\n",
      "validation Loss: 0.0405 Acc: 0.9907\n",
      "2022-01-23 03:26:30.082338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 03:26:32.750253\n",
      "validation Loss: 0.0372 Acc: 0.9930\n",
      "2022-01-23 03:26:33.150613\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 03:26:35.820330\n",
      "validation Loss: 0.0351 Acc: 0.9953\n",
      "2022-01-23 03:26:36.320762\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:26:39.371776\n",
      "validation Loss: 0.0532 Acc: 0.9883\n",
      "2022-01-23 03:26:39.779283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:26:42.394240\n",
      "validation Loss: 0.0365 Acc: 0.9907\n",
      "2022-01-23 03:26:42.813897\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 03:26:45.414645\n",
      "validation Loss: 0.0383 Acc: 0.9907\n",
      "2022-01-23 03:26:45.834903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 03:26:48.485253\n",
      "validation Loss: 0.0426 Acc: 0.9907\n",
      "2022-01-23 03:26:48.949835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:26:51.563126\n",
      "validation Loss: 0.0347 Acc: 0.9953\n",
      "2022-01-23 03:26:51.947743\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:26:55.110503\n",
      "validation Loss: 0.0471 Acc: 0.9883\n",
      "2022-01-23 03:26:55.555826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 03:26:58.132852\n",
      "validation Loss: 0.0388 Acc: 0.9907\n",
      "2022-01-23 03:26:58.531121\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 03:27:01.179706\n",
      "validation Loss: 0.0433 Acc: 0.9883\n",
      "2022-01-23 03:27:01.615400\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 03:27:04.439095\n",
      "validation Loss: 0.0447 Acc: 0.9907\n",
      "2022-01-23 03:27:04.851498\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 03:27:07.433273\n",
      "validation Loss: 0.0392 Acc: 0.9930\n",
      "2022-01-23 03:27:07.905538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 03:27:10.516133\n",
      "validation Loss: 0.0433 Acc: 0.9907\n",
      "2022-01-23 03:27:10.926330\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 03:27:13.572011\n",
      "validation Loss: 0.0333 Acc: 0.9930\n",
      "2022-01-23 03:27:14.033735\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:27:16.602787\n",
      "validation Loss: 0.0376 Acc: 0.9907\n",
      "2022-01-23 03:27:17.006802\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 03:27:19.492897\n",
      "validation Loss: 0.0440 Acc: 0.9907\n",
      "2022-01-23 03:27:19.911287\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:27:22.400059\n",
      "validation Loss: 0.0373 Acc: 0.9907\n",
      "2022-01-23 03:27:22.863262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 03:27:25.330311\n",
      "validation Loss: 0.0402 Acc: 0.9907\n",
      "2022-01-23 03:27:25.785629\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 03:27:28.336349\n",
      "validation Loss: 0.0405 Acc: 0.9907\n",
      "2022-01-23 03:27:28.746171\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:31.284039\n",
      "validation Loss: 0.0428 Acc: 0.9907\n",
      "2022-01-23 03:27:31.704045\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:34.252027\n",
      "validation Loss: 0.0387 Acc: 0.9930\n",
      "2022-01-23 03:27:34.659231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:37.269493\n",
      "validation Loss: 0.0399 Acc: 0.9907\n",
      "2022-01-23 03:27:37.645160\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:39.073101\n",
      "validation Loss: 0.0432 Acc: 0.9907\n",
      "2022-01-23 03:27:39.700874\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:42.253979\n",
      "validation Loss: 0.0555 Acc: 0.9860\n",
      "2022-01-23 03:27:42.648494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:27:45.200483\n",
      "validation Loss: 0.0432 Acc: 0.9907\n",
      "2022-01-23 03:27:45.612308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:27:48.192854\n",
      "validation Loss: 0.0413 Acc: 0.9907\n",
      "2022-01-23 03:27:48.606434\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:27:51.236186\n",
      "validation Loss: 0.0382 Acc: 0.9930\n",
      "2022-01-23 03:27:51.670665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:27:54.256221\n",
      "validation Loss: 0.0464 Acc: 0.9907\n",
      "2022-01-23 03:27:54.706523\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:27:57.261742\n",
      "validation Loss: 0.0390 Acc: 0.9930\n",
      "2022-01-23 03:27:57.674550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:00.280716\n",
      "validation Loss: 0.0414 Acc: 0.9907\n",
      "2022-01-23 03:28:00.671890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:03.243539\n",
      "validation Loss: 0.0419 Acc: 0.9907\n",
      "2022-01-23 03:28:03.681695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:06.221066\n",
      "validation Loss: 0.0459 Acc: 0.9907\n",
      "2022-01-23 03:28:06.602018\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:09.218065\n",
      "validation Loss: 0.0466 Acc: 0.9907\n",
      "2022-01-23 03:28:09.645702\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:12.184707\n",
      "validation Loss: 0.0389 Acc: 0.9930\n",
      "2022-01-23 03:28:12.590115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:28:15.186533\n",
      "validation Loss: 0.0345 Acc: 0.9930\n",
      "2022-01-23 03:28:15.594625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:18.309026\n",
      "validation Loss: 0.0497 Acc: 0.9883\n",
      "2022-01-23 03:28:18.880690\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:28:21.427097\n",
      "validation Loss: 0.0434 Acc: 0.9930\n",
      "2022-01-23 03:28:21.836272\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:28:24.399482\n",
      "validation Loss: 0.0413 Acc: 0.9930\n",
      "2022-01-23 03:28:24.808897\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:28:27.483636\n",
      "validation Loss: 0.0376 Acc: 0.9930\n",
      "2022-01-23 03:28:28.030606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0848 Acc: 0.9740\n",
      "2022-01-23 03:28:30.615249\n",
      "validation Loss: 0.1320 Acc: 0.9674\n",
      "2022-01-23 03:28:31.003383\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0856 Acc: 0.9750\n",
      "2022-01-23 03:28:33.616022\n",
      "validation Loss: 0.0795 Acc: 0.9814\n",
      "2022-01-23 03:28:34.029360\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0371 Acc: 0.9870\n",
      "2022-01-23 03:28:36.649723\n",
      "validation Loss: 0.1159 Acc: 0.9510\n",
      "2022-01-23 03:28:37.215391\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9930\n",
      "2022-01-23 03:28:39.922695\n",
      "validation Loss: 0.0602 Acc: 0.9814\n",
      "2022-01-23 03:28:40.355475\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 0.9995\n",
      "2022-01-23 03:28:43.181069\n",
      "validation Loss: 0.0470 Acc: 0.9907\n",
      "2022-01-23 03:28:43.603256\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:28:46.512306\n",
      "validation Loss: 0.0494 Acc: 0.9907\n",
      "2022-01-23 03:28:46.905397\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:28:49.730987\n",
      "validation Loss: 0.0486 Acc: 0.9930\n",
      "2022-01-23 03:28:50.134712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 03:28:53.055635\n",
      "validation Loss: 0.0504 Acc: 0.9930\n",
      "2022-01-23 03:28:53.632518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:28:56.411500\n",
      "validation Loss: 0.0465 Acc: 0.9930\n",
      "2022-01-23 03:28:56.833290\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 03:28:59.724546\n",
      "validation Loss: 0.0547 Acc: 0.9930\n",
      "2022-01-23 03:29:00.113190\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 03:29:03.077492\n",
      "validation Loss: 0.0497 Acc: 0.9930\n",
      "2022-01-23 03:29:03.475138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:29:06.300291\n",
      "validation Loss: 0.0518 Acc: 0.9930\n",
      "2022-01-23 03:29:06.685694\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:29:09.478075\n",
      "validation Loss: 0.0464 Acc: 0.9930\n",
      "2022-01-23 03:29:10.081487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:29:12.897320\n",
      "validation Loss: 0.0499 Acc: 0.9930\n",
      "2022-01-23 03:29:13.316083\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:29:16.107690\n",
      "validation Loss: 0.0465 Acc: 0.9930\n",
      "2022-01-23 03:29:16.504279\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 03:29:19.503797\n",
      "validation Loss: 0.0458 Acc: 0.9930\n",
      "2022-01-23 03:29:19.899172\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:29:22.676233\n",
      "validation Loss: 0.0475 Acc: 0.9930\n",
      "2022-01-23 03:29:23.082214\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:29:25.712725\n",
      "validation Loss: 0.0450 Acc: 0.9930\n",
      "2022-01-23 03:29:26.310445\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:29:29.129266\n",
      "validation Loss: 0.0445 Acc: 0.9930\n",
      "2022-01-23 03:29:29.596580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:29:32.113947\n",
      "validation Loss: 0.0444 Acc: 0.9930\n",
      "2022-01-23 03:29:32.529981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 03:29:35.080373\n",
      "validation Loss: 0.0502 Acc: 0.9930\n",
      "2022-01-23 03:29:35.513206\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:38.069548\n",
      "validation Loss: 0.0458 Acc: 0.9930\n",
      "2022-01-23 03:29:38.505218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:41.060763\n",
      "validation Loss: 0.0487 Acc: 0.9930\n",
      "2022-01-23 03:29:41.496590\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:44.060826\n",
      "validation Loss: 0.0468 Acc: 0.9930\n",
      "2022-01-23 03:29:44.466160\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:47.024856\n",
      "validation Loss: 0.0430 Acc: 0.9930\n",
      "2022-01-23 03:29:47.471712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:50.027572\n",
      "validation Loss: 0.0462 Acc: 0.9930\n",
      "2022-01-23 03:29:50.422078\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:29:53.068763\n",
      "validation Loss: 0.0439 Acc: 0.9930\n",
      "2022-01-23 03:29:53.471182\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:29:56.024656\n",
      "validation Loss: 0.0445 Acc: 0.9930\n",
      "2022-01-23 03:29:56.585292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:29:59.131228\n",
      "validation Loss: 0.0484 Acc: 0.9930\n",
      "2022-01-23 03:29:59.530114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:30:02.151436\n",
      "validation Loss: 0.0461 Acc: 0.9907\n",
      "2022-01-23 03:30:02.572030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:30:05.186187\n",
      "validation Loss: 0.0454 Acc: 0.9930\n",
      "2022-01-23 03:30:05.617561\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:30:08.248561\n",
      "validation Loss: 0.0472 Acc: 0.9930\n",
      "2022-01-23 03:30:08.655879\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3kphx4ff) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 55173... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▆█▇▇████▇██</td></tr><tr><td>accuracy_train</td><td>▁▇█████████████████████████▇████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▆▅▆▇▇▅▇▇▇██▇█▇█▇▇▇▇▇█▇▇██▅▆▇██████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.03466</td></tr><tr><td>loss_train</td><td>0.00021</td></tr><tr><td>loss_validation</td><td>0.04725</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kphx4ff\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3kphx4ff</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_032446-3kphx4ff/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3kphx4ff). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3qtvwif9\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 03:30:18.906845\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.6309 Acc: 0.3675\n",
      "2022-01-23 03:30:21.492021\n",
      "validation Loss: 2.0805 Acc: 0.6993\n",
      "2022-01-23 03:30:21.897953\n",
      "Accuracy of the network on the 429 test samples: 65.96736596736596\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.6292 Acc: 0.8235\n",
      "2022-01-23 03:30:24.843151\n",
      "validation Loss: 1.2033 Acc: 0.8951\n",
      "2022-01-23 03:30:25.311048\n",
      "Accuracy of the network on the 429 test samples: 89.04428904428904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.9757 Acc: 0.9185\n",
      "2022-01-23 03:30:28.502659\n",
      "validation Loss: 0.7504 Acc: 0.9417\n",
      "2022-01-23 03:30:28.964204\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.6328 Acc: 0.9425\n",
      "2022-01-23 03:30:31.996375\n",
      "validation Loss: 0.5120 Acc: 0.9487\n",
      "2022-01-23 03:30:32.523525\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4497 Acc: 0.9565\n",
      "2022-01-23 03:30:35.653874\n",
      "validation Loss: 0.4031 Acc: 0.9487\n",
      "2022-01-23 03:30:36.054408\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3362 Acc: 0.9665\n",
      "2022-01-23 03:30:39.132485\n",
      "validation Loss: 0.2960 Acc: 0.9557\n",
      "2022-01-23 03:30:39.710046\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2669 Acc: 0.9715\n",
      "2022-01-23 03:30:42.706841\n",
      "validation Loss: 0.2419 Acc: 0.9604\n",
      "2022-01-23 03:30:43.131451\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2155 Acc: 0.9765\n",
      "2022-01-23 03:30:46.201135\n",
      "validation Loss: 0.2027 Acc: 0.9674\n",
      "2022-01-23 03:30:46.861626\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1794 Acc: 0.9810\n",
      "2022-01-23 03:30:49.875559\n",
      "validation Loss: 0.1791 Acc: 0.9627\n",
      "2022-01-23 03:30:50.304243\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1514 Acc: 0.9815\n",
      "2022-01-23 03:30:52.858136\n",
      "validation Loss: 0.1561 Acc: 0.9674\n",
      "2022-01-23 03:30:53.307575\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1309 Acc: 0.9850\n",
      "2022-01-23 03:30:56.404125\n",
      "validation Loss: 0.1404 Acc: 0.9650\n",
      "2022-01-23 03:30:56.882011\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1227 Acc: 0.9845\n",
      "2022-01-23 03:30:59.465274\n",
      "validation Loss: 0.1351 Acc: 0.9650\n",
      "2022-01-23 03:31:00.018002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1042 Acc: 0.9895\n",
      "2022-01-23 03:31:02.670237\n",
      "validation Loss: 0.1192 Acc: 0.9674\n",
      "2022-01-23 03:31:03.075569\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0923 Acc: 0.9880\n",
      "2022-01-23 03:31:06.022423\n",
      "validation Loss: 0.1083 Acc: 0.9674\n",
      "2022-01-23 03:31:06.435099\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0837 Acc: 0.9880\n",
      "2022-01-23 03:31:09.716823\n",
      "validation Loss: 0.1002 Acc: 0.9744\n",
      "2022-01-23 03:31:10.122028\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0764 Acc: 0.9910\n",
      "2022-01-23 03:31:13.094922\n",
      "validation Loss: 0.0941 Acc: 0.9744\n",
      "2022-01-23 03:31:13.571799\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0697 Acc: 0.9905\n",
      "2022-01-23 03:31:16.626937\n",
      "validation Loss: 0.0884 Acc: 0.9814\n",
      "2022-01-23 03:31:17.040291\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0634 Acc: 0.9915\n",
      "2022-01-23 03:31:20.110435\n",
      "validation Loss: 0.0843 Acc: 0.9790\n",
      "2022-01-23 03:31:20.639973\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0595 Acc: 0.9905\n",
      "2022-01-23 03:31:23.250574\n",
      "validation Loss: 0.0888 Acc: 0.9790\n",
      "2022-01-23 03:31:23.663503\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0559 Acc: 0.9900\n",
      "2022-01-23 03:31:26.289257\n",
      "validation Loss: 0.0792 Acc: 0.9790\n",
      "2022-01-23 03:31:26.770681\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0485 Acc: 0.9940\n",
      "2022-01-23 03:31:29.424199\n",
      "validation Loss: 0.0721 Acc: 0.9790\n",
      "2022-01-23 03:31:29.813167\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0458 Acc: 0.9935\n",
      "2022-01-23 03:31:32.468657\n",
      "validation Loss: 0.0710 Acc: 0.9814\n",
      "2022-01-23 03:31:32.888983\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0425 Acc: 0.9945\n",
      "2022-01-23 03:31:36.046915\n",
      "validation Loss: 0.0830 Acc: 0.9697\n",
      "2022-01-23 03:31:36.419732\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0410 Acc: 0.9935\n",
      "2022-01-23 03:31:39.033489\n",
      "validation Loss: 0.0746 Acc: 0.9744\n",
      "2022-01-23 03:31:39.413203\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0370 Acc: 0.9935\n",
      "2022-01-23 03:31:41.947342\n",
      "validation Loss: 0.0622 Acc: 0.9860\n",
      "2022-01-23 03:31:42.467778\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0347 Acc: 0.9955\n",
      "2022-01-23 03:31:45.560402\n",
      "validation Loss: 0.0579 Acc: 0.9837\n",
      "2022-01-23 03:31:46.027489\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0375 Acc: 0.9930\n",
      "2022-01-23 03:31:48.578342\n",
      "validation Loss: 0.0615 Acc: 0.9790\n",
      "2022-01-23 03:31:49.083148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0323 Acc: 0.9945\n",
      "2022-01-23 03:31:51.624441\n",
      "validation Loss: 0.0570 Acc: 0.9860\n",
      "2022-01-23 03:31:52.054924\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0267 Acc: 0.9975\n",
      "2022-01-23 03:31:55.016482\n",
      "validation Loss: 0.0679 Acc: 0.9814\n",
      "2022-01-23 03:31:55.461602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0319 Acc: 0.9935\n",
      "2022-01-23 03:31:58.010585\n",
      "validation Loss: 0.0659 Acc: 0.9744\n",
      "2022-01-23 03:31:58.420497\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0238 Acc: 0.9985\n",
      "2022-01-23 03:32:00.925237\n",
      "validation Loss: 0.0527 Acc: 0.9860\n",
      "2022-01-23 03:32:01.312176\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0242 Acc: 0.9980\n",
      "2022-01-23 03:32:04.260537\n",
      "validation Loss: 0.0530 Acc: 0.9883\n",
      "2022-01-23 03:32:04.664992\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0209 Acc: 0.9980\n",
      "2022-01-23 03:32:07.625935\n",
      "validation Loss: 0.0510 Acc: 0.9860\n",
      "2022-01-23 03:32:08.013284\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0192 Acc: 0.9990\n",
      "2022-01-23 03:32:10.633344\n",
      "validation Loss: 0.0554 Acc: 0.9837\n",
      "2022-01-23 03:32:11.091865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0201 Acc: 0.9980\n",
      "2022-01-23 03:32:13.782662\n",
      "validation Loss: 0.0545 Acc: 0.9860\n",
      "2022-01-23 03:32:14.311775\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0217 Acc: 0.9985\n",
      "2022-01-23 03:32:16.937928\n",
      "validation Loss: 0.0446 Acc: 0.9883\n",
      "2022-01-23 03:32:17.371857\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0175 Acc: 0.9980\n",
      "2022-01-23 03:32:20.358333\n",
      "validation Loss: 0.0411 Acc: 0.9907\n",
      "2022-01-23 03:32:20.818795\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0155 Acc: 0.9990\n",
      "2022-01-23 03:32:23.734685\n",
      "validation Loss: 0.0471 Acc: 0.9860\n",
      "2022-01-23 03:32:24.118215\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 0.9985\n",
      "2022-01-23 03:32:26.738707\n",
      "validation Loss: 0.0424 Acc: 0.9837\n",
      "2022-01-23 03:32:27.128888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9990\n",
      "2022-01-23 03:32:29.766145\n",
      "validation Loss: 0.0441 Acc: 0.9837\n",
      "2022-01-23 03:32:30.157366\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9985\n",
      "2022-01-23 03:32:32.800025\n",
      "validation Loss: 0.0380 Acc: 0.9907\n",
      "2022-01-23 03:32:33.293118\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0146 Acc: 0.9995\n",
      "2022-01-23 03:32:36.407176\n",
      "validation Loss: 0.0446 Acc: 0.9837\n",
      "2022-01-23 03:32:36.852675\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9985\n",
      "2022-01-23 03:32:39.495552\n",
      "validation Loss: 0.0437 Acc: 0.9860\n",
      "2022-01-23 03:32:39.962801\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 1.0000\n",
      "2022-01-23 03:32:42.623234\n",
      "validation Loss: 0.0526 Acc: 0.9837\n",
      "2022-01-23 03:32:43.036151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9990\n",
      "2022-01-23 03:32:45.836893\n",
      "validation Loss: 0.0428 Acc: 0.9837\n",
      "2022-01-23 03:32:46.235080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0137 Acc: 0.9980\n",
      "2022-01-23 03:32:48.834876\n",
      "validation Loss: 0.0374 Acc: 0.9860\n",
      "2022-01-23 03:32:49.245687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0110 Acc: 0.9995\n",
      "2022-01-23 03:32:50.755181\n",
      "validation Loss: 0.0362 Acc: 0.9883\n",
      "2022-01-23 03:32:51.253471\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 1.0000\n",
      "2022-01-23 03:32:53.786645\n",
      "validation Loss: 0.0434 Acc: 0.9860\n",
      "2022-01-23 03:32:54.175699\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0191 Acc: 0.9950\n",
      "2022-01-23 03:32:56.802612\n",
      "validation Loss: 0.0504 Acc: 0.9790\n",
      "2022-01-23 03:32:57.198374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0144 Acc: 0.9985\n",
      "2022-01-23 03:32:59.789097\n",
      "validation Loss: 0.0368 Acc: 0.9930\n",
      "2022-01-23 03:33:00.232588\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0088 Acc: 1.0000\n",
      "2022-01-23 03:33:03.246020\n",
      "validation Loss: 0.0350 Acc: 0.9907\n",
      "2022-01-23 03:33:03.768979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 1.0000\n",
      "2022-01-23 03:33:06.386241\n",
      "validation Loss: 0.0330 Acc: 0.9907\n",
      "2022-01-23 03:33:06.865457\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 1.0000\n",
      "2022-01-23 03:33:09.560827\n",
      "validation Loss: 0.0434 Acc: 0.9860\n",
      "2022-01-23 03:33:09.970809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 0.9995\n",
      "2022-01-23 03:33:12.676387\n",
      "validation Loss: 0.0376 Acc: 0.9883\n",
      "2022-01-23 03:33:13.158660\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9990\n",
      "2022-01-23 03:33:15.838493\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 03:33:16.261040\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 0.9995\n",
      "2022-01-23 03:33:18.871634\n",
      "validation Loss: 0.0531 Acc: 0.9860\n",
      "2022-01-23 03:33:19.415642\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9985\n",
      "2022-01-23 03:33:21.984047\n",
      "validation Loss: 0.0331 Acc: 0.9907\n",
      "2022-01-23 03:33:22.479251\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 1.0000\n",
      "2022-01-23 03:33:25.055323\n",
      "validation Loss: 0.0341 Acc: 0.9883\n",
      "2022-01-23 03:33:25.465157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0082 Acc: 0.9990\n",
      "2022-01-23 03:33:28.065824\n",
      "validation Loss: 0.0417 Acc: 0.9860\n",
      "2022-01-23 03:33:28.481643\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 0.9995\n",
      "2022-01-23 03:33:31.066155\n",
      "validation Loss: 0.0353 Acc: 0.9860\n",
      "2022-01-23 03:33:31.466826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 03:33:34.040056\n",
      "validation Loss: 0.0304 Acc: 0.9907\n",
      "2022-01-23 03:33:34.458701\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 03:33:37.111397\n",
      "validation Loss: 0.0348 Acc: 0.9883\n",
      "2022-01-23 03:33:37.563090\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 1.0000\n",
      "2022-01-23 03:33:40.185208\n",
      "validation Loss: 0.0301 Acc: 0.9883\n",
      "2022-01-23 03:33:40.600819\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 03:33:43.216685\n",
      "validation Loss: 0.0337 Acc: 0.9883\n",
      "2022-01-23 03:33:43.633996\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0044 Acc: 1.0000\n",
      "2022-01-23 03:33:46.231275\n",
      "validation Loss: 0.0303 Acc: 0.9930\n",
      "2022-01-23 03:33:46.668114\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 03:33:49.657401\n",
      "validation Loss: 0.0336 Acc: 0.9907\n",
      "2022-01-23 03:33:50.052140\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 1.0000\n",
      "2022-01-23 03:33:52.634474\n",
      "validation Loss: 0.0333 Acc: 0.9883\n",
      "2022-01-23 03:33:53.182397\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "2022-01-23 03:33:55.810831\n",
      "validation Loss: 0.0369 Acc: 0.9883\n",
      "2022-01-23 03:33:56.234043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 1.0000\n",
      "2022-01-23 03:33:58.869923\n",
      "validation Loss: 0.0293 Acc: 0.9930\n",
      "2022-01-23 03:33:59.246077\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0069 Acc: 0.9990\n",
      "2022-01-23 03:34:02.525491\n",
      "validation Loss: 0.0282 Acc: 0.9907\n",
      "2022-01-23 03:34:02.941667\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 1.0000\n",
      "2022-01-23 03:34:05.786840\n",
      "validation Loss: 0.0296 Acc: 0.9907\n",
      "2022-01-23 03:34:06.224462\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0033 Acc: 1.0000\n",
      "2022-01-23 03:34:08.832751\n",
      "validation Loss: 0.0302 Acc: 0.9883\n",
      "2022-01-23 03:34:09.306682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 03:34:11.821912\n",
      "validation Loss: 0.0284 Acc: 0.9883\n",
      "2022-01-23 03:34:12.268179\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 03:34:14.773729\n",
      "validation Loss: 0.0397 Acc: 0.9883\n",
      "2022-01-23 03:34:15.195652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0033 Acc: 1.0000\n",
      "2022-01-23 03:34:17.740341\n",
      "validation Loss: 0.0392 Acc: 0.9883\n",
      "2022-01-23 03:34:18.350506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0032 Acc: 1.0000\n",
      "2022-01-23 03:34:20.827085\n",
      "validation Loss: 0.0247 Acc: 0.9883\n",
      "2022-01-23 03:34:21.251648\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 03:34:23.761969\n",
      "validation Loss: 0.0358 Acc: 0.9837\n",
      "2022-01-23 03:34:24.152317\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "2022-01-23 03:34:26.692454\n",
      "validation Loss: 0.0268 Acc: 0.9907\n",
      "2022-01-23 03:34:27.068783\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 03:34:29.640613\n",
      "validation Loss: 0.0257 Acc: 0.9953\n",
      "2022-01-23 03:34:30.136667\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 03:34:33.266604\n",
      "validation Loss: 0.0308 Acc: 0.9883\n",
      "2022-01-23 03:34:33.695538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "2022-01-23 03:34:36.208104\n",
      "validation Loss: 0.0265 Acc: 0.9907\n",
      "2022-01-23 03:34:36.806848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 03:34:39.322075\n",
      "validation Loss: 0.0233 Acc: 0.9907\n",
      "2022-01-23 03:34:39.739242\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0232 Acc: 0.9930\n",
      "2022-01-23 03:34:42.318268\n",
      "validation Loss: 0.0332 Acc: 0.9930\n",
      "2022-01-23 03:34:42.740700\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0059 Acc: 0.9990\n",
      "2022-01-23 03:34:45.375506\n",
      "validation Loss: 0.0267 Acc: 0.9930\n",
      "2022-01-23 03:34:45.794411\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "2022-01-23 03:34:48.390204\n",
      "validation Loss: 0.0288 Acc: 0.9907\n",
      "2022-01-23 03:34:48.773526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 03:34:51.374317\n",
      "validation Loss: 0.0300 Acc: 0.9907\n",
      "2022-01-23 03:34:51.771367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0023 Acc: 1.0000\n",
      "2022-01-23 03:34:54.377728\n",
      "validation Loss: 0.0292 Acc: 0.9907\n",
      "2022-01-23 03:34:54.779326\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 03:34:57.361230\n",
      "validation Loss: 0.0267 Acc: 0.9930\n",
      "2022-01-23 03:34:57.776286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 03:35:00.414619\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 03:35:00.820730\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 03:35:03.403300\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 03:35:03.810225\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:35:06.472225\n",
      "validation Loss: 0.0276 Acc: 0.9930\n",
      "2022-01-23 03:35:07.033848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:35:09.624645\n",
      "validation Loss: 0.0256 Acc: 0.9930\n",
      "2022-01-23 03:35:10.034696\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 03:35:12.595291\n",
      "validation Loss: 0.0259 Acc: 0.9953\n",
      "2022-01-23 03:35:13.005350\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 03:35:15.639789\n",
      "validation Loss: 0.0323 Acc: 0.9883\n",
      "2022-01-23 03:35:16.298446\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 03:35:19.012332\n",
      "validation Loss: 0.0318 Acc: 0.9907\n",
      "2022-01-23 03:35:19.414257\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 03:35:22.038896\n",
      "validation Loss: 0.0274 Acc: 0.9930\n",
      "2022-01-23 03:35:22.453348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 03:35:25.026028\n",
      "validation Loss: 0.0260 Acc: 0.9930\n",
      "2022-01-23 03:35:25.568808\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 03:35:28.178164\n",
      "validation Loss: 0.0254 Acc: 0.9930\n",
      "2022-01-23 03:35:28.592238\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:35:31.239112\n",
      "validation Loss: 0.0284 Acc: 0.9930\n",
      "2022-01-23 03:35:31.637983\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 03:35:34.310298\n",
      "validation Loss: 0.0248 Acc: 0.9930\n",
      "2022-01-23 03:35:34.849328\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qtvwif9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 47546... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇▇▇▇▇▇██████████████████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇▇▇▇███▇██████████████████████████████</td></tr><tr><td>loss_train</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.02575</td></tr><tr><td>loss_train</td><td>0.00116</td></tr><tr><td>loss_validation</td><td>0.02477</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3qtvwif9\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3qtvwif9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_033009-3qtvwif9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3qtvwif9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/kfhyn0pk\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 03:35:46.700767\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.7970 Acc: 0.2880\n",
      "2022-01-23 03:35:49.430949\n",
      "validation Loss: 2.5351 Acc: 0.5338\n",
      "2022-01-23 03:35:49.798041\n",
      "Accuracy of the network on the 429 test samples: 50.116550116550115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.2371 Acc: 0.6355\n",
      "2022-01-23 03:35:52.685048\n",
      "validation Loss: 1.9325 Acc: 0.7716\n",
      "2022-01-23 03:35:53.048585\n",
      "Accuracy of the network on the 429 test samples: 76.92307692307693\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.6999 Acc: 0.8130\n",
      "2022-01-23 03:35:55.989882\n",
      "validation Loss: 1.4634 Acc: 0.8648\n",
      "2022-01-23 03:35:56.392697\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.2878 Acc: 0.8945\n",
      "2022-01-23 03:35:59.368570\n",
      "validation Loss: 1.1108 Acc: 0.9254\n",
      "2022-01-23 03:35:59.736125\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.9873 Acc: 0.9315\n",
      "2022-01-23 03:36:02.703244\n",
      "validation Loss: 0.8601 Acc: 0.9510\n",
      "2022-01-23 03:36:03.049899\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.7738 Acc: 0.9475\n",
      "2022-01-23 03:36:05.966572\n",
      "validation Loss: 0.6832 Acc: 0.9580\n",
      "2022-01-23 03:36:06.311463\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.6186 Acc: 0.9590\n",
      "2022-01-23 03:36:09.557183\n",
      "validation Loss: 0.5504 Acc: 0.9650\n",
      "2022-01-23 03:36:09.928885\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5070 Acc: 0.9630\n",
      "2022-01-23 03:36:12.949706\n",
      "validation Loss: 0.4572 Acc: 0.9650\n",
      "2022-01-23 03:36:13.312456\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4233 Acc: 0.9660\n",
      "2022-01-23 03:36:16.276030\n",
      "validation Loss: 0.3908 Acc: 0.9674\n",
      "2022-01-23 03:36:16.653065\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3628 Acc: 0.9705\n",
      "2022-01-23 03:36:19.841083\n",
      "validation Loss: 0.3342 Acc: 0.9650\n",
      "2022-01-23 03:36:20.211487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3110 Acc: 0.9730\n",
      "2022-01-23 03:36:22.754861\n",
      "validation Loss: 0.2947 Acc: 0.9650\n",
      "2022-01-23 03:36:23.178110\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2719 Acc: 0.9755\n",
      "2022-01-23 03:36:25.734335\n",
      "validation Loss: 0.2573 Acc: 0.9650\n",
      "2022-01-23 03:36:26.186271\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2398 Acc: 0.9805\n",
      "2022-01-23 03:36:28.634152\n",
      "validation Loss: 0.2304 Acc: 0.9674\n",
      "2022-01-23 03:36:29.005456\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2127 Acc: 0.9835\n",
      "2022-01-23 03:36:31.868234\n",
      "validation Loss: 0.2072 Acc: 0.9674\n",
      "2022-01-23 03:36:32.271020\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1906 Acc: 0.9840\n",
      "2022-01-23 03:36:35.123480\n",
      "validation Loss: 0.1884 Acc: 0.9697\n",
      "2022-01-23 03:36:35.488279\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1718 Acc: 0.9835\n",
      "2022-01-23 03:36:38.337607\n",
      "validation Loss: 0.1748 Acc: 0.9720\n",
      "2022-01-23 03:36:38.773416\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1566 Acc: 0.9870\n",
      "2022-01-23 03:36:41.741434\n",
      "validation Loss: 0.1634 Acc: 0.9744\n",
      "2022-01-23 03:36:42.097813\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1440 Acc: 0.9880\n",
      "2022-01-23 03:36:44.909790\n",
      "validation Loss: 0.1487 Acc: 0.9744\n",
      "2022-01-23 03:36:45.426074\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1295 Acc: 0.9895\n",
      "2022-01-23 03:36:48.368089\n",
      "validation Loss: 0.1369 Acc: 0.9767\n",
      "2022-01-23 03:36:48.699801\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1197 Acc: 0.9905\n",
      "2022-01-23 03:36:51.732592\n",
      "validation Loss: 0.1334 Acc: 0.9697\n",
      "2022-01-23 03:36:52.241393\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1101 Acc: 0.9915\n",
      "2022-01-23 03:36:54.808820\n",
      "validation Loss: 0.1238 Acc: 0.9744\n",
      "2022-01-23 03:36:55.177641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1031 Acc: 0.9905\n",
      "2022-01-23 03:36:57.745026\n",
      "validation Loss: 0.1148 Acc: 0.9744\n",
      "2022-01-23 03:36:58.122109\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0947 Acc: 0.9925\n",
      "2022-01-23 03:37:00.826527\n",
      "validation Loss: 0.1072 Acc: 0.9767\n",
      "2022-01-23 03:37:01.331462\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0892 Acc: 0.9930\n",
      "2022-01-23 03:37:04.298124\n",
      "validation Loss: 0.1035 Acc: 0.9767\n",
      "2022-01-23 03:37:04.635974\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0825 Acc: 0.9920\n",
      "2022-01-23 03:37:07.520106\n",
      "validation Loss: 0.0990 Acc: 0.9697\n",
      "2022-01-23 03:37:08.076008\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0769 Acc: 0.9955\n",
      "2022-01-23 03:37:10.713558\n",
      "validation Loss: 0.0896 Acc: 0.9790\n",
      "2022-01-23 03:37:11.156217\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0722 Acc: 0.9940\n",
      "2022-01-23 03:37:14.065265\n",
      "validation Loss: 0.0991 Acc: 0.9720\n",
      "2022-01-23 03:37:14.421680\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0681 Acc: 0.9955\n",
      "2022-01-23 03:37:16.987614\n",
      "validation Loss: 0.0860 Acc: 0.9790\n",
      "2022-01-23 03:37:17.551296\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0632 Acc: 0.9965\n",
      "2022-01-23 03:37:20.627728\n",
      "validation Loss: 0.0771 Acc: 0.9814\n",
      "2022-01-23 03:37:20.995992\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0603 Acc: 0.9955\n",
      "2022-01-23 03:37:23.950309\n",
      "validation Loss: 0.0805 Acc: 0.9767\n",
      "2022-01-23 03:37:24.326714\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0571 Acc: 0.9955\n",
      "2022-01-23 03:37:26.869778\n",
      "validation Loss: 0.0744 Acc: 0.9883\n",
      "2022-01-23 03:37:27.228373\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0530 Acc: 0.9965\n",
      "2022-01-23 03:37:30.238037\n",
      "validation Loss: 0.0783 Acc: 0.9790\n",
      "2022-01-23 03:37:30.625374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0502 Acc: 0.9965\n",
      "2022-01-23 03:37:33.154188\n",
      "validation Loss: 0.0788 Acc: 0.9744\n",
      "2022-01-23 03:37:33.530031\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0481 Acc: 0.9970\n",
      "2022-01-23 03:37:36.065325\n",
      "validation Loss: 0.0622 Acc: 0.9837\n",
      "2022-01-23 03:37:36.612755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0451 Acc: 0.9955\n",
      "2022-01-23 03:37:39.176921\n",
      "validation Loss: 0.0654 Acc: 0.9814\n",
      "2022-01-23 03:37:39.622181\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0430 Acc: 0.9960\n",
      "2022-01-23 03:37:42.195944\n",
      "validation Loss: 0.0593 Acc: 0.9907\n",
      "2022-01-23 03:37:42.560883\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0416 Acc: 0.9970\n",
      "2022-01-23 03:37:45.466452\n",
      "validation Loss: 0.0684 Acc: 0.9790\n",
      "2022-01-23 03:37:46.039792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0389 Acc: 0.9960\n",
      "2022-01-23 03:37:48.574985\n",
      "validation Loss: 0.0546 Acc: 0.9883\n",
      "2022-01-23 03:37:48.942796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0365 Acc: 0.9970\n",
      "2022-01-23 03:37:50.296632\n",
      "validation Loss: 0.0508 Acc: 0.9930\n",
      "2022-01-23 03:37:50.853911\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0363 Acc: 0.9970\n",
      "2022-01-23 03:37:53.850599\n",
      "validation Loss: 0.0550 Acc: 0.9860\n",
      "2022-01-23 03:37:54.285010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0330 Acc: 0.9980\n",
      "2022-01-23 03:37:56.888498\n",
      "validation Loss: 0.0509 Acc: 0.9907\n",
      "2022-01-23 03:37:57.254917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0325 Acc: 0.9980\n",
      "2022-01-23 03:37:59.868360\n",
      "validation Loss: 0.0485 Acc: 0.9907\n",
      "2022-01-23 03:38:00.375991\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0311 Acc: 0.9980\n",
      "2022-01-23 03:38:02.933402\n",
      "validation Loss: 0.0612 Acc: 0.9814\n",
      "2022-01-23 03:38:03.351238\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0304 Acc: 0.9970\n",
      "2022-01-23 03:38:06.091244\n",
      "validation Loss: 0.0597 Acc: 0.9790\n",
      "2022-01-23 03:38:06.524548\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0280 Acc: 0.9995\n",
      "2022-01-23 03:38:08.110399\n",
      "validation Loss: 0.0519 Acc: 0.9860\n",
      "2022-01-23 03:38:08.462544\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0263 Acc: 0.9995\n",
      "2022-01-23 03:38:11.008877\n",
      "validation Loss: 0.0408 Acc: 0.9907\n",
      "2022-01-23 03:38:11.391846\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0249 Acc: 0.9985\n",
      "2022-01-23 03:38:13.950047\n",
      "validation Loss: 0.0395 Acc: 0.9907\n",
      "2022-01-23 03:38:14.557550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0244 Acc: 0.9990\n",
      "2022-01-23 03:38:17.084851\n",
      "validation Loss: 0.0403 Acc: 0.9930\n",
      "2022-01-23 03:38:17.450490\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0223 Acc: 0.9990\n",
      "2022-01-23 03:38:20.338277\n",
      "validation Loss: 0.0465 Acc: 0.9860\n",
      "2022-01-23 03:38:20.702335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0227 Acc: 0.9995\n",
      "2022-01-23 03:38:23.301970\n",
      "validation Loss: 0.0407 Acc: 0.9907\n",
      "2022-01-23 03:38:23.853956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0216 Acc: 0.9995\n",
      "2022-01-23 03:38:26.321532\n",
      "validation Loss: 0.0437 Acc: 0.9907\n",
      "2022-01-23 03:38:26.668914\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0204 Acc: 0.9995\n",
      "2022-01-23 03:38:29.155063\n",
      "validation Loss: 0.0420 Acc: 0.9883\n",
      "2022-01-23 03:38:29.520910\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0191 Acc: 0.9990\n",
      "2022-01-23 03:38:32.112111\n",
      "validation Loss: 0.0403 Acc: 0.9930\n",
      "2022-01-23 03:38:32.476670\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0188 Acc: 1.0000\n",
      "2022-01-23 03:38:35.440918\n",
      "validation Loss: 0.0376 Acc: 0.9907\n",
      "2022-01-23 03:38:35.929481\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0190 Acc: 0.9995\n",
      "2022-01-23 03:38:38.497129\n",
      "validation Loss: 0.0343 Acc: 0.9907\n",
      "2022-01-23 03:38:38.869437\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0181 Acc: 0.9990\n",
      "2022-01-23 03:38:41.523220\n",
      "validation Loss: 0.0376 Acc: 0.9930\n",
      "2022-01-23 03:38:41.886059\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0169 Acc: 0.9995\n",
      "2022-01-23 03:38:44.869150\n",
      "validation Loss: 0.0348 Acc: 0.9907\n",
      "2022-01-23 03:38:45.272404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0160 Acc: 0.9995\n",
      "2022-01-23 03:38:47.838047\n",
      "validation Loss: 0.0350 Acc: 0.9930\n",
      "2022-01-23 03:38:48.194205\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 1.0000\n",
      "2022-01-23 03:38:50.975408\n",
      "validation Loss: 0.0282 Acc: 0.9930\n",
      "2022-01-23 03:38:51.307678\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0144 Acc: 1.0000\n",
      "2022-01-23 03:38:54.185702\n",
      "validation Loss: 0.0301 Acc: 0.9907\n",
      "2022-01-23 03:38:54.625166\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0143 Acc: 1.0000\n",
      "2022-01-23 03:38:57.183530\n",
      "validation Loss: 0.0403 Acc: 0.9907\n",
      "2022-01-23 03:38:57.542228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0150 Acc: 0.9995\n",
      "2022-01-23 03:39:00.284061\n",
      "validation Loss: 0.0419 Acc: 0.9883\n",
      "2022-01-23 03:39:00.677002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0131 Acc: 0.9995\n",
      "2022-01-23 03:39:02.331672\n",
      "validation Loss: 0.0315 Acc: 0.9930\n",
      "2022-01-23 03:39:02.695464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0131 Acc: 0.9995\n",
      "2022-01-23 03:39:05.100366\n",
      "validation Loss: 0.0441 Acc: 0.9907\n",
      "2022-01-23 03:39:05.507890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0119 Acc: 1.0000\n",
      "2022-01-23 03:39:08.052506\n",
      "validation Loss: 0.0350 Acc: 0.9930\n",
      "2022-01-23 03:39:08.632443\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 1.0000\n",
      "2022-01-23 03:39:10.968267\n",
      "validation Loss: 0.0273 Acc: 0.9930\n",
      "2022-01-23 03:39:11.356806\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0111 Acc: 1.0000\n",
      "2022-01-23 03:39:14.271354\n",
      "validation Loss: 0.0333 Acc: 0.9907\n",
      "2022-01-23 03:39:14.632310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0108 Acc: 1.0000\n",
      "2022-01-23 03:39:17.232516\n",
      "validation Loss: 0.0536 Acc: 0.9860\n",
      "2022-01-23 03:39:17.727207\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0110 Acc: 0.9995\n",
      "2022-01-23 03:39:20.107055\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 03:39:20.441354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 1.0000\n",
      "2022-01-23 03:39:22.883872\n",
      "validation Loss: 0.0304 Acc: 0.9930\n",
      "2022-01-23 03:39:23.269326\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 1.0000\n",
      "2022-01-23 03:39:25.907451\n",
      "validation Loss: 0.0286 Acc: 0.9907\n",
      "2022-01-23 03:39:26.284769\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 1.0000\n",
      "2022-01-23 03:39:28.933367\n",
      "validation Loss: 0.0295 Acc: 0.9930\n",
      "2022-01-23 03:39:29.320972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0101 Acc: 0.9995\n",
      "2022-01-23 03:39:32.023846\n",
      "validation Loss: 0.0256 Acc: 0.9930\n",
      "2022-01-23 03:39:32.392688\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0085 Acc: 1.0000\n",
      "2022-01-23 03:39:35.232263\n",
      "validation Loss: 0.0396 Acc: 0.9907\n",
      "2022-01-23 03:39:35.590745\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 1.0000\n",
      "2022-01-23 03:39:38.425965\n",
      "validation Loss: 0.0222 Acc: 0.9953\n",
      "2022-01-23 03:39:38.847087\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 1.0000\n",
      "2022-01-23 03:39:41.809394\n",
      "validation Loss: 0.0217 Acc: 0.9953\n",
      "2022-01-23 03:39:42.182020\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 1.0000\n",
      "2022-01-23 03:39:45.346433\n",
      "validation Loss: 0.0204 Acc: 0.9953\n",
      "2022-01-23 03:39:45.722466\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 1.0000\n",
      "2022-01-23 03:39:48.670518\n",
      "validation Loss: 0.0379 Acc: 0.9907\n",
      "2022-01-23 03:39:49.086372\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 1.0000\n",
      "2022-01-23 03:39:51.688342\n",
      "validation Loss: 0.0273 Acc: 0.9930\n",
      "2022-01-23 03:39:52.030945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 1.0000\n",
      "2022-01-23 03:39:54.497121\n",
      "validation Loss: 0.0308 Acc: 0.9930\n",
      "2022-01-23 03:39:54.884853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 1.0000\n",
      "2022-01-23 03:39:57.372854\n",
      "validation Loss: 0.0317 Acc: 0.9930\n",
      "2022-01-23 03:39:57.746978\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 1.0000\n",
      "2022-01-23 03:40:00.444626\n",
      "validation Loss: 0.0313 Acc: 0.9907\n",
      "2022-01-23 03:40:00.829611\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0066 Acc: 1.0000\n",
      "2022-01-23 03:40:03.355701\n",
      "validation Loss: 0.0214 Acc: 0.9953\n",
      "2022-01-23 03:40:03.942623\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 1.0000\n",
      "2022-01-23 03:40:06.404457\n",
      "validation Loss: 0.0359 Acc: 0.9907\n",
      "2022-01-23 03:40:06.776562\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0059 Acc: 1.0000\n",
      "2022-01-23 03:40:09.282391\n",
      "validation Loss: 0.0200 Acc: 0.9953\n",
      "2022-01-23 03:40:09.640132\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 1.0000\n",
      "2022-01-23 03:40:12.566043\n",
      "validation Loss: 0.0348 Acc: 0.9930\n",
      "2022-01-23 03:40:13.141628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 1.0000\n",
      "2022-01-23 03:40:15.693229\n",
      "validation Loss: 0.0250 Acc: 0.9930\n",
      "2022-01-23 03:40:16.059528\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0059 Acc: 1.0000\n",
      "2022-01-23 03:40:18.601781\n",
      "validation Loss: 0.0315 Acc: 0.9930\n",
      "2022-01-23 03:40:18.966034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 1.0000\n",
      "2022-01-23 03:40:21.566117\n",
      "validation Loss: 0.0207 Acc: 0.9930\n",
      "2022-01-23 03:40:21.970385\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 1.0000\n",
      "2022-01-23 03:40:24.721440\n",
      "validation Loss: 0.0270 Acc: 0.9930\n",
      "2022-01-23 03:40:25.124932\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 03:40:27.686813\n",
      "validation Loss: 0.0401 Acc: 0.9907\n",
      "2022-01-23 03:40:28.041945\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0046 Acc: 1.0000\n",
      "2022-01-23 03:40:30.479312\n",
      "validation Loss: 0.0258 Acc: 0.9930\n",
      "2022-01-23 03:40:30.836508\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 1.0000\n",
      "2022-01-23 03:40:33.377471\n",
      "validation Loss: 0.0202 Acc: 0.9953\n",
      "2022-01-23 03:40:33.735264\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "2022-01-23 03:40:36.422389\n",
      "validation Loss: 0.0227 Acc: 0.9930\n",
      "2022-01-23 03:40:36.788325\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 0.9995\n",
      "2022-01-23 03:40:39.307432\n",
      "validation Loss: 0.0250 Acc: 0.9930\n",
      "2022-01-23 03:40:39.706335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 1.0000\n",
      "2022-01-23 03:40:42.313491\n",
      "validation Loss: 0.0187 Acc: 0.9953\n",
      "2022-01-23 03:40:42.679065\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 03:40:45.613402\n",
      "validation Loss: 0.0241 Acc: 0.9930\n",
      "2022-01-23 03:40:46.062055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "2022-01-23 03:40:48.592147\n",
      "validation Loss: 0.0179 Acc: 0.9953\n",
      "2022-01-23 03:40:48.941009\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "2022-01-23 03:40:50.959977\n",
      "validation Loss: 0.0258 Acc: 0.9930\n",
      "2022-01-23 03:40:51.288503\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "2022-01-23 03:40:53.818241\n",
      "validation Loss: 0.0272 Acc: 0.9930\n",
      "2022-01-23 03:40:54.190398\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kfhyn0pk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 43586... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.01787</td></tr><tr><td>loss_train</td><td>0.00355</td></tr><tr><td>loss_validation</td><td>0.02723</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/kfhyn0pk\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/kfhyn0pk</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_033535-kfhyn0pk/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:kfhyn0pk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2fq0lyvx\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 03:41:04.556989\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9670 Acc: 0.0845\n",
      "2022-01-23 03:41:06.995868\n",
      "validation Loss: 2.9261 Acc: 0.1142\n",
      "2022-01-23 03:41:07.350033\n",
      "Accuracy of the network on the 429 test samples: 10.955710955710956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8781 Acc: 0.1800\n",
      "2022-01-23 03:41:10.325517\n",
      "validation Loss: 2.8297 Acc: 0.2541\n",
      "2022-01-23 03:41:10.698523\n",
      "Accuracy of the network on the 429 test samples: 29.836829836829835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.7701 Acc: 0.2895\n",
      "2022-01-23 03:41:13.665476\n",
      "validation Loss: 2.7129 Acc: 0.3636\n",
      "2022-01-23 03:41:14.029893\n",
      "Accuracy of the network on the 429 test samples: 39.62703962703963\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6458 Acc: 0.4640\n",
      "2022-01-23 03:41:16.942259\n",
      "validation Loss: 2.5842 Acc: 0.5408\n",
      "2022-01-23 03:41:17.339111\n",
      "Accuracy of the network on the 429 test samples: 55.94405594405595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5156 Acc: 0.6110\n",
      "2022-01-23 03:41:20.249677\n",
      "validation Loss: 2.4520 Acc: 0.6387\n",
      "2022-01-23 03:41:20.615590\n",
      "Accuracy of the network on the 429 test samples: 69.93006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3849 Acc: 0.6955\n",
      "2022-01-23 03:41:22.483325\n",
      "validation Loss: 2.3203 Acc: 0.7110\n",
      "2022-01-23 03:41:22.837797\n",
      "Accuracy of the network on the 429 test samples: 74.12587412587412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.2559 Acc: 0.7435\n",
      "2022-01-23 03:41:25.719758\n",
      "validation Loss: 2.1928 Acc: 0.7599\n",
      "2022-01-23 03:41:26.087947\n",
      "Accuracy of the network on the 429 test samples: 77.15617715617715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1322 Acc: 0.7780\n",
      "2022-01-23 03:41:28.978617\n",
      "validation Loss: 2.0717 Acc: 0.8112\n",
      "2022-01-23 03:41:29.374831\n",
      "Accuracy of the network on the 429 test samples: 80.65268065268066\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.0155 Acc: 0.8095\n",
      "2022-01-23 03:41:31.192757\n",
      "validation Loss: 1.9579 Acc: 0.8275\n",
      "2022-01-23 03:41:31.725919\n",
      "Accuracy of the network on the 429 test samples: 83.44988344988346\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.9063 Acc: 0.8285\n",
      "2022-01-23 03:41:34.575586\n",
      "validation Loss: 1.8513 Acc: 0.8578\n",
      "2022-01-23 03:41:34.976374\n",
      "Accuracy of the network on the 429 test samples: 85.3146853146853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.8036 Acc: 0.8495\n",
      "2022-01-23 03:41:37.844566\n",
      "validation Loss: 1.7507 Acc: 0.8741\n",
      "2022-01-23 03:41:38.185628\n",
      "Accuracy of the network on the 429 test samples: 86.01398601398601\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7066 Acc: 0.8690\n",
      "2022-01-23 03:41:41.112874\n",
      "validation Loss: 1.6567 Acc: 0.8858\n",
      "2022-01-23 03:41:41.489109\n",
      "Accuracy of the network on the 429 test samples: 88.34498834498834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.6157 Acc: 0.8825\n",
      "2022-01-23 03:41:44.458226\n",
      "validation Loss: 1.5673 Acc: 0.8904\n",
      "2022-01-23 03:41:44.816100\n",
      "Accuracy of the network on the 429 test samples: 89.27738927738928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5300 Acc: 0.8905\n",
      "2022-01-23 03:41:47.788248\n",
      "validation Loss: 1.4838 Acc: 0.8951\n",
      "2022-01-23 03:41:48.165584\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.4493 Acc: 0.8970\n",
      "2022-01-23 03:41:51.148618\n",
      "validation Loss: 1.4055 Acc: 0.9114\n",
      "2022-01-23 03:41:51.499537\n",
      "Accuracy of the network on the 429 test samples: 91.37529137529138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3731 Acc: 0.9010\n",
      "2022-01-23 03:41:54.635549\n",
      "validation Loss: 1.3305 Acc: 0.9184\n",
      "2022-01-23 03:41:55.014113\n",
      "Accuracy of the network on the 429 test samples: 91.37529137529138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3012 Acc: 0.9065\n",
      "2022-01-23 03:41:57.998254\n",
      "validation Loss: 1.2614 Acc: 0.9231\n",
      "2022-01-23 03:41:58.399123\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2336 Acc: 0.9140\n",
      "2022-01-23 03:42:01.390966\n",
      "validation Loss: 1.1944 Acc: 0.9277\n",
      "2022-01-23 03:42:01.797120\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1698 Acc: 0.9175\n",
      "2022-01-23 03:42:04.725354\n",
      "validation Loss: 1.1328 Acc: 0.9277\n",
      "2022-01-23 03:42:05.088783\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1103 Acc: 0.9205\n",
      "2022-01-23 03:42:08.193943\n",
      "validation Loss: 1.0753 Acc: 0.9371\n",
      "2022-01-23 03:42:08.700945\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0544 Acc: 0.9260\n",
      "2022-01-23 03:42:11.651011\n",
      "validation Loss: 1.0197 Acc: 0.9394\n",
      "2022-01-23 03:42:12.031018\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0010 Acc: 0.9365\n",
      "2022-01-23 03:42:15.006858\n",
      "validation Loss: 0.9681 Acc: 0.9417\n",
      "2022-01-23 03:42:15.395077\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9513 Acc: 0.9385\n",
      "2022-01-23 03:42:18.223810\n",
      "validation Loss: 0.9198 Acc: 0.9464\n",
      "2022-01-23 03:42:18.578940\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9044 Acc: 0.9405\n",
      "2022-01-23 03:42:21.746120\n",
      "validation Loss: 0.8757 Acc: 0.9417\n",
      "2022-01-23 03:42:22.089065\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8610 Acc: 0.9440\n",
      "2022-01-23 03:42:24.562204\n",
      "validation Loss: 0.8319 Acc: 0.9557\n",
      "2022-01-23 03:42:24.924832\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8193 Acc: 0.9465\n",
      "2022-01-23 03:42:27.905119\n",
      "validation Loss: 0.7916 Acc: 0.9580\n",
      "2022-01-23 03:42:28.294194\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7805 Acc: 0.9490\n",
      "2022-01-23 03:42:31.348042\n",
      "validation Loss: 0.7545 Acc: 0.9604\n",
      "2022-01-23 03:42:31.706790\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7439 Acc: 0.9510\n",
      "2022-01-23 03:42:33.610412\n",
      "validation Loss: 0.7187 Acc: 0.9627\n",
      "2022-01-23 03:42:33.951131\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7097 Acc: 0.9535\n",
      "2022-01-23 03:42:36.999109\n",
      "validation Loss: 0.6859 Acc: 0.9674\n",
      "2022-01-23 03:42:37.413939\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6772 Acc: 0.9580\n",
      "2022-01-23 03:42:40.449420\n",
      "validation Loss: 0.6550 Acc: 0.9627\n",
      "2022-01-23 03:42:40.843473\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6469 Acc: 0.9570\n",
      "2022-01-23 03:42:43.327289\n",
      "validation Loss: 0.6262 Acc: 0.9674\n",
      "2022-01-23 03:42:43.826117\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6179 Acc: 0.9580\n",
      "2022-01-23 03:42:46.802127\n",
      "validation Loss: 0.5980 Acc: 0.9650\n",
      "2022-01-23 03:42:47.153161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5911 Acc: 0.9600\n",
      "2022-01-23 03:42:49.651121\n",
      "validation Loss: 0.5733 Acc: 0.9627\n",
      "2022-01-23 03:42:50.019350\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5659 Acc: 0.9590\n",
      "2022-01-23 03:42:52.559799\n",
      "validation Loss: 0.5475 Acc: 0.9697\n",
      "2022-01-23 03:42:52.911321\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5418 Acc: 0.9600\n",
      "2022-01-23 03:42:55.875789\n",
      "validation Loss: 0.5249 Acc: 0.9650\n",
      "2022-01-23 03:42:56.268464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5192 Acc: 0.9630\n",
      "2022-01-23 03:42:58.830687\n",
      "validation Loss: 0.5042 Acc: 0.9650\n",
      "2022-01-23 03:42:59.235560\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4982 Acc: 0.9630\n",
      "2022-01-23 03:43:01.749684\n",
      "validation Loss: 0.4851 Acc: 0.9627\n",
      "2022-01-23 03:43:02.136785\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4780 Acc: 0.9635\n",
      "2022-01-23 03:43:04.620049\n",
      "validation Loss: 0.4639 Acc: 0.9674\n",
      "2022-01-23 03:43:04.993202\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4591 Acc: 0.9655\n",
      "2022-01-23 03:43:07.545443\n",
      "validation Loss: 0.4459 Acc: 0.9674\n",
      "2022-01-23 03:43:07.891833\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4409 Acc: 0.9670\n",
      "2022-01-23 03:43:10.647087\n",
      "validation Loss: 0.4297 Acc: 0.9674\n",
      "2022-01-23 03:43:11.102596\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4244 Acc: 0.9675\n",
      "2022-01-23 03:43:13.670097\n",
      "validation Loss: 0.4142 Acc: 0.9674\n",
      "2022-01-23 03:43:14.062452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4083 Acc: 0.9670\n",
      "2022-01-23 03:43:16.553275\n",
      "validation Loss: 0.3987 Acc: 0.9674\n",
      "2022-01-23 03:43:16.920603\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3927 Acc: 0.9675\n",
      "2022-01-23 03:43:19.549125\n",
      "validation Loss: 0.3847 Acc: 0.9674\n",
      "2022-01-23 03:43:19.957286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3783 Acc: 0.9700\n",
      "2022-01-23 03:43:22.320427\n",
      "validation Loss: 0.3720 Acc: 0.9674\n",
      "2022-01-23 03:43:22.659383\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3647 Acc: 0.9680\n",
      "2022-01-23 03:43:25.228232\n",
      "validation Loss: 0.3588 Acc: 0.9674\n",
      "2022-01-23 03:43:25.565540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3517 Acc: 0.9700\n",
      "2022-01-23 03:43:28.181494\n",
      "validation Loss: 0.3470 Acc: 0.9674\n",
      "2022-01-23 03:43:28.747220\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3393 Acc: 0.9695\n",
      "2022-01-23 03:43:31.175317\n",
      "validation Loss: 0.3356 Acc: 0.9674\n",
      "2022-01-23 03:43:31.593826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3276 Acc: 0.9720\n",
      "2022-01-23 03:43:34.067321\n",
      "validation Loss: 0.3250 Acc: 0.9674\n",
      "2022-01-23 03:43:34.490029\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3166 Acc: 0.9710\n",
      "2022-01-23 03:43:36.947105\n",
      "validation Loss: 0.3144 Acc: 0.9697\n",
      "2022-01-23 03:43:37.352405\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3058 Acc: 0.9735\n",
      "2022-01-23 03:43:40.544188\n",
      "validation Loss: 0.3039 Acc: 0.9720\n",
      "2022-01-23 03:43:40.937424\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2959 Acc: 0.9735\n",
      "2022-01-23 03:43:43.920360\n",
      "validation Loss: 0.2962 Acc: 0.9697\n",
      "2022-01-23 03:43:44.294383\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2863 Acc: 0.9735\n",
      "2022-01-23 03:43:46.761663\n",
      "validation Loss: 0.2864 Acc: 0.9697\n",
      "2022-01-23 03:43:47.253580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2769 Acc: 0.9745\n",
      "2022-01-23 03:43:49.723187\n",
      "validation Loss: 0.2775 Acc: 0.9697\n",
      "2022-01-23 03:43:50.093191\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2681 Acc: 0.9760\n",
      "2022-01-23 03:43:52.533524\n",
      "validation Loss: 0.2699 Acc: 0.9720\n",
      "2022-01-23 03:43:52.867685\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2599 Acc: 0.9760\n",
      "2022-01-23 03:43:55.865421\n",
      "validation Loss: 0.2623 Acc: 0.9697\n",
      "2022-01-23 03:43:56.394009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2517 Acc: 0.9770\n",
      "2022-01-23 03:43:58.850426\n",
      "validation Loss: 0.2563 Acc: 0.9674\n",
      "2022-01-23 03:43:59.241577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2441 Acc: 0.9790\n",
      "2022-01-23 03:44:01.717413\n",
      "validation Loss: 0.2478 Acc: 0.9720\n",
      "2022-01-23 03:44:02.131798\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2369 Acc: 0.9790\n",
      "2022-01-23 03:44:05.097084\n",
      "validation Loss: 0.2416 Acc: 0.9720\n",
      "2022-01-23 03:44:05.444826\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2296 Acc: 0.9805\n",
      "2022-01-23 03:44:08.502281\n",
      "validation Loss: 0.2355 Acc: 0.9720\n",
      "2022-01-23 03:44:08.848476\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2229 Acc: 0.9800\n",
      "2022-01-23 03:44:11.758188\n",
      "validation Loss: 0.2304 Acc: 0.9697\n",
      "2022-01-23 03:44:12.104159\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2166 Acc: 0.9795\n",
      "2022-01-23 03:44:14.575371\n",
      "validation Loss: 0.2239 Acc: 0.9744\n",
      "2022-01-23 03:44:15.240553\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2105 Acc: 0.9800\n",
      "2022-01-23 03:44:18.124905\n",
      "validation Loss: 0.2212 Acc: 0.9674\n",
      "2022-01-23 03:44:18.457105\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2042 Acc: 0.9795\n",
      "2022-01-23 03:44:19.963827\n",
      "validation Loss: 0.2131 Acc: 0.9720\n",
      "2022-01-23 03:44:20.341778\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1985 Acc: 0.9815\n",
      "2022-01-23 03:44:22.811467\n",
      "validation Loss: 0.2100 Acc: 0.9674\n",
      "2022-01-23 03:44:23.160829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1934 Acc: 0.9815\n",
      "2022-01-23 03:44:25.709571\n",
      "validation Loss: 0.2034 Acc: 0.9720\n",
      "2022-01-23 03:44:26.105776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1876 Acc: 0.9815\n",
      "2022-01-23 03:44:28.668518\n",
      "validation Loss: 0.1995 Acc: 0.9720\n",
      "2022-01-23 03:44:29.255037\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1825 Acc: 0.9845\n",
      "2022-01-23 03:44:31.795099\n",
      "validation Loss: 0.1940 Acc: 0.9720\n",
      "2022-01-23 03:44:32.142431\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1776 Acc: 0.9845\n",
      "2022-01-23 03:44:34.695290\n",
      "validation Loss: 0.1900 Acc: 0.9720\n",
      "2022-01-23 03:44:35.071099\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1729 Acc: 0.9845\n",
      "2022-01-23 03:44:37.765226\n",
      "validation Loss: 0.1856 Acc: 0.9720\n",
      "2022-01-23 03:44:38.187995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1684 Acc: 0.9845\n",
      "2022-01-23 03:44:40.822773\n",
      "validation Loss: 0.1819 Acc: 0.9720\n",
      "2022-01-23 03:44:41.192364\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1642 Acc: 0.9845\n",
      "2022-01-23 03:44:43.758315\n",
      "validation Loss: 0.1781 Acc: 0.9720\n",
      "2022-01-23 03:44:44.123802\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1598 Acc: 0.9845\n",
      "2022-01-23 03:44:46.643378\n",
      "validation Loss: 0.1764 Acc: 0.9720\n",
      "2022-01-23 03:44:47.065824\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1557 Acc: 0.9845\n",
      "2022-01-23 03:44:49.648698\n",
      "validation Loss: 0.1702 Acc: 0.9697\n",
      "2022-01-23 03:44:50.056591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1522 Acc: 0.9860\n",
      "2022-01-23 03:44:52.687254\n",
      "validation Loss: 0.1693 Acc: 0.9697\n",
      "2022-01-23 03:44:53.032753\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1480 Acc: 0.9870\n",
      "2022-01-23 03:44:55.717001\n",
      "validation Loss: 0.1659 Acc: 0.9697\n",
      "2022-01-23 03:44:56.078764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1443 Acc: 0.9865\n",
      "2022-01-23 03:44:58.861760\n",
      "validation Loss: 0.1623 Acc: 0.9720\n",
      "2022-01-23 03:44:59.319110\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1406 Acc: 0.9875\n",
      "2022-01-23 03:45:02.078901\n",
      "validation Loss: 0.1583 Acc: 0.9744\n",
      "2022-01-23 03:45:02.445693\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1370 Acc: 0.9865\n",
      "2022-01-23 03:45:05.499290\n",
      "validation Loss: 0.1564 Acc: 0.9720\n",
      "2022-01-23 03:45:05.862733\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1336 Acc: 0.9885\n",
      "2022-01-23 03:45:08.499028\n",
      "validation Loss: 0.1521 Acc: 0.9744\n",
      "2022-01-23 03:45:08.873181\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1308 Acc: 0.9875\n",
      "2022-01-23 03:45:11.958776\n",
      "validation Loss: 0.1500 Acc: 0.9744\n",
      "2022-01-23 03:45:12.373562\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1279 Acc: 0.9885\n",
      "2022-01-23 03:45:15.360734\n",
      "validation Loss: 0.1473 Acc: 0.9697\n",
      "2022-01-23 03:45:15.781967\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1244 Acc: 0.9875\n",
      "2022-01-23 03:45:18.481471\n",
      "validation Loss: 0.1451 Acc: 0.9720\n",
      "2022-01-23 03:45:18.865496\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1213 Acc: 0.9885\n",
      "2022-01-23 03:45:21.334611\n",
      "validation Loss: 0.1432 Acc: 0.9720\n",
      "2022-01-23 03:45:21.722148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1187 Acc: 0.9895\n",
      "2022-01-23 03:45:24.304347\n",
      "validation Loss: 0.1390 Acc: 0.9697\n",
      "2022-01-23 03:45:24.662558\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1160 Acc: 0.9900\n",
      "2022-01-23 03:45:27.153918\n",
      "validation Loss: 0.1373 Acc: 0.9744\n",
      "2022-01-23 03:45:27.586703\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1132 Acc: 0.9890\n",
      "2022-01-23 03:45:30.602493\n",
      "validation Loss: 0.1354 Acc: 0.9720\n",
      "2022-01-23 03:45:30.991563\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1107 Acc: 0.9895\n",
      "2022-01-23 03:45:33.751090\n",
      "validation Loss: 0.1329 Acc: 0.9720\n",
      "2022-01-23 03:45:34.343722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1082 Acc: 0.9895\n",
      "2022-01-23 03:45:36.837247\n",
      "validation Loss: 0.1321 Acc: 0.9720\n",
      "2022-01-23 03:45:37.171414\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1058 Acc: 0.9900\n",
      "2022-01-23 03:45:39.647916\n",
      "validation Loss: 0.1294 Acc: 0.9767\n",
      "2022-01-23 03:45:40.041254\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1035 Acc: 0.9895\n",
      "2022-01-23 03:45:42.903436\n",
      "validation Loss: 0.1290 Acc: 0.9744\n",
      "2022-01-23 03:45:43.410158\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1012 Acc: 0.9915\n",
      "2022-01-23 03:45:45.849856\n",
      "validation Loss: 0.1271 Acc: 0.9697\n",
      "2022-01-23 03:45:46.179742\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0990 Acc: 0.9910\n",
      "2022-01-23 03:45:48.604497\n",
      "validation Loss: 0.1225 Acc: 0.9744\n",
      "2022-01-23 03:45:48.984509\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0969 Acc: 0.9920\n",
      "2022-01-23 03:45:51.363466\n",
      "validation Loss: 0.1209 Acc: 0.9767\n",
      "2022-01-23 03:45:51.763723\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0947 Acc: 0.9910\n",
      "2022-01-23 03:45:54.662348\n",
      "validation Loss: 0.1197 Acc: 0.9767\n",
      "2022-01-23 03:45:55.114166\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0926 Acc: 0.9905\n",
      "2022-01-23 03:45:57.986810\n",
      "validation Loss: 0.1168 Acc: 0.9744\n",
      "2022-01-23 03:45:58.344128\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0908 Acc: 0.9915\n",
      "2022-01-23 03:46:00.807804\n",
      "validation Loss: 0.1158 Acc: 0.9767\n",
      "2022-01-23 03:46:01.207819\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0886 Acc: 0.9915\n",
      "2022-01-23 03:46:04.021453\n",
      "validation Loss: 0.1146 Acc: 0.9767\n",
      "2022-01-23 03:46:04.443161\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0869 Acc: 0.9915\n",
      "2022-01-23 03:46:06.197602\n",
      "validation Loss: 0.1150 Acc: 0.9767\n",
      "2022-01-23 03:46:06.803374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9920\n",
      "2022-01-23 03:46:09.241928\n",
      "validation Loss: 0.1118 Acc: 0.9767\n",
      "2022-01-23 03:46:09.593222\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0833 Acc: 0.9925\n",
      "2022-01-23 03:46:12.610378\n",
      "validation Loss: 0.1107 Acc: 0.9767\n",
      "2022-01-23 03:46:12.969479\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9767\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2fq0lyvx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 43643... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▃▃▅▆▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▃▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▃▆▇▇▇██████████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98135</td></tr><tr><td>accuracy_train</td><td>0.9925</td></tr><tr><td>accuracy_validation</td><td>0.97669</td></tr><tr><td>best_test_accuracy</td><td>0.98135</td></tr><tr><td>best_val_accuracy</td><td>0.97669</td></tr><tr><td>best_val_loss</td><td>0.11067</td></tr><tr><td>loss_train</td><td>0.0833</td></tr><tr><td>loss_validation</td><td>0.11067</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2fq0lyvx\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2fq0lyvx</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_034054-2fq0lyvx/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2fq0lyvx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ua2fpb0\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 03:46:23.160282\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 1.4088 Acc: 0.5800\n",
      "2022-01-23 03:46:26.008221\n",
      "validation Loss: 0.5682 Acc: 0.8065\n",
      "2022-01-23 03:46:26.407726\n",
      "Accuracy of the network on the 429 test samples: 82.75058275058275\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.3528 Acc: 0.8880\n",
      "2022-01-23 03:46:29.279907\n",
      "validation Loss: 0.2605 Acc: 0.9044\n",
      "2022-01-23 03:46:29.650137\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.3192 Acc: 0.8995\n",
      "2022-01-23 03:46:32.662130\n",
      "validation Loss: 0.5314 Acc: 0.8974\n",
      "2022-01-23 03:46:33.019387\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2757 Acc: 0.9110\n",
      "2022-01-23 03:46:35.502402\n",
      "validation Loss: 0.2621 Acc: 0.9254\n",
      "2022-01-23 03:46:35.884609\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1878 Acc: 0.9360\n",
      "2022-01-23 03:46:38.854530\n",
      "validation Loss: 0.1707 Acc: 0.9371\n",
      "2022-01-23 03:46:39.253175\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1610 Acc: 0.9490\n",
      "2022-01-23 03:46:42.078890\n",
      "validation Loss: 0.1279 Acc: 0.9580\n",
      "2022-01-23 03:46:42.445322\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0995 Acc: 0.9665\n",
      "2022-01-23 03:46:45.329738\n",
      "validation Loss: 0.1604 Acc: 0.9534\n",
      "2022-01-23 03:46:45.746956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1381 Acc: 0.9645\n",
      "2022-01-23 03:46:48.320607\n",
      "validation Loss: 0.0837 Acc: 0.9720\n",
      "2022-01-23 03:46:48.773809\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1243 Acc: 0.9650\n",
      "2022-01-23 03:46:51.812989\n",
      "validation Loss: 0.1070 Acc: 0.9650\n",
      "2022-01-23 03:46:52.145900\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1095 Acc: 0.9630\n",
      "2022-01-23 03:46:54.689016\n",
      "validation Loss: 0.1088 Acc: 0.9604\n",
      "2022-01-23 03:46:55.065598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1024 Acc: 0.9710\n",
      "2022-01-23 03:46:57.539912\n",
      "validation Loss: 0.1352 Acc: 0.9650\n",
      "2022-01-23 03:46:57.887461\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0638 Acc: 0.9780\n",
      "2022-01-23 03:47:00.513963\n",
      "validation Loss: 0.0872 Acc: 0.9697\n",
      "2022-01-23 03:47:00.926586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0907 Acc: 0.9700\n",
      "2022-01-23 03:47:03.745575\n",
      "validation Loss: 0.1247 Acc: 0.9627\n",
      "2022-01-23 03:47:04.111501\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0652 Acc: 0.9800\n",
      "2022-01-23 03:47:06.752727\n",
      "validation Loss: 0.0963 Acc: 0.9674\n",
      "2022-01-23 03:47:07.096821\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0432 Acc: 0.9825\n",
      "2022-01-23 03:47:09.715228\n",
      "validation Loss: 0.1166 Acc: 0.9650\n",
      "2022-01-23 03:47:10.075765\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0342 Acc: 0.9910\n",
      "2022-01-23 03:47:12.633028\n",
      "validation Loss: 0.0452 Acc: 0.9837\n",
      "2022-01-23 03:47:12.993164\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0265 Acc: 0.9885\n",
      "2022-01-23 03:47:15.820787\n",
      "validation Loss: 0.0507 Acc: 0.9767\n",
      "2022-01-23 03:47:16.177458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0253 Acc: 0.9910\n",
      "2022-01-23 03:47:18.689280\n",
      "validation Loss: 0.0618 Acc: 0.9744\n",
      "2022-01-23 03:47:19.051024\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0601 Acc: 0.9800\n",
      "2022-01-23 03:47:21.620712\n",
      "validation Loss: 0.1526 Acc: 0.9510\n",
      "2022-01-23 03:47:22.005557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0782 Acc: 0.9775\n",
      "2022-01-23 03:47:24.547034\n",
      "validation Loss: 0.0902 Acc: 0.9720\n",
      "2022-01-23 03:47:24.905517\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0714 Acc: 0.9785\n",
      "2022-01-23 03:47:27.507426\n",
      "validation Loss: 0.1084 Acc: 0.9744\n",
      "2022-01-23 03:47:27.838919\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1827 Acc: 0.9505\n",
      "2022-01-23 03:47:30.513647\n",
      "validation Loss: 0.4690 Acc: 0.8415\n",
      "2022-01-23 03:47:30.887612\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2553 Acc: 0.9230\n",
      "2022-01-23 03:47:33.515433\n",
      "validation Loss: 0.1502 Acc: 0.9580\n",
      "2022-01-23 03:47:33.875755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0853 Acc: 0.9750\n",
      "2022-01-23 03:47:36.544979\n",
      "validation Loss: 0.1821 Acc: 0.9441\n",
      "2022-01-23 03:47:37.076616\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1081 Acc: 0.9650\n",
      "2022-01-23 03:47:39.788019\n",
      "validation Loss: 0.3112 Acc: 0.9441\n",
      "2022-01-23 03:47:40.141009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0871 Acc: 0.9760\n",
      "2022-01-23 03:47:42.634732\n",
      "validation Loss: 0.1408 Acc: 0.9697\n",
      "2022-01-23 03:47:43.043362\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0336 Acc: 0.9885\n",
      "2022-01-23 03:47:45.650850\n",
      "validation Loss: 0.0738 Acc: 0.9790\n",
      "2022-01-23 03:47:46.003333\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0633 Acc: 0.9795\n",
      "2022-01-23 03:47:48.508301\n",
      "validation Loss: 0.0959 Acc: 0.9697\n",
      "2022-01-23 03:47:48.856130\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0379 Acc: 0.9885\n",
      "2022-01-23 03:47:51.306337\n",
      "validation Loss: 0.0601 Acc: 0.9767\n",
      "2022-01-23 03:47:51.671959\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0103 Acc: 0.9970\n",
      "2022-01-23 03:47:54.382309\n",
      "validation Loss: 0.0894 Acc: 0.9814\n",
      "2022-01-23 03:47:54.791217\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9940\n",
      "2022-01-23 03:47:57.389555\n",
      "validation Loss: 0.0702 Acc: 0.9837\n",
      "2022-01-23 03:47:57.750097\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0127 Acc: 0.9940\n",
      "2022-01-23 03:48:00.219963\n",
      "validation Loss: 0.0661 Acc: 0.9837\n",
      "2022-01-23 03:48:00.595582\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0404 Acc: 0.9865\n",
      "2022-01-23 03:48:03.045836\n",
      "validation Loss: 0.0820 Acc: 0.9720\n",
      "2022-01-23 03:48:03.399585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0706 Acc: 0.9745\n",
      "2022-01-23 03:48:05.992407\n",
      "validation Loss: 0.0546 Acc: 0.9837\n",
      "2022-01-23 03:48:06.405760\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0688 Acc: 0.9825\n",
      "2022-01-23 03:48:08.813811\n",
      "validation Loss: 0.4451 Acc: 0.8695\n",
      "2022-01-23 03:48:09.200496\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1488 Acc: 0.9515\n",
      "2022-01-23 03:48:11.717053\n",
      "validation Loss: 0.1217 Acc: 0.9534\n",
      "2022-01-23 03:48:12.174755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0318 Acc: 0.9880\n",
      "2022-01-23 03:48:14.707927\n",
      "validation Loss: 0.0469 Acc: 0.9883\n",
      "2022-01-23 03:48:15.051540\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0534 Acc: 0.9805\n",
      "2022-01-23 03:48:17.986999\n",
      "validation Loss: 0.0831 Acc: 0.9860\n",
      "2022-01-23 03:48:18.335632\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0653 Acc: 0.9800\n",
      "2022-01-23 03:48:20.884155\n",
      "validation Loss: 0.0506 Acc: 0.9837\n",
      "2022-01-23 03:48:21.267137\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0520 Acc: 0.9805\n",
      "2022-01-23 03:48:23.898390\n",
      "validation Loss: 0.0642 Acc: 0.9790\n",
      "2022-01-23 03:48:24.258037\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0350 Acc: 0.9880\n",
      "2022-01-23 03:48:26.809077\n",
      "validation Loss: 0.2265 Acc: 0.9487\n",
      "2022-01-23 03:48:27.150526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0557 Acc: 0.9845\n",
      "2022-01-23 03:48:29.767305\n",
      "validation Loss: 0.1795 Acc: 0.9371\n",
      "2022-01-23 03:48:30.366478\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1091 Acc: 0.9660\n",
      "2022-01-23 03:48:33.015736\n",
      "validation Loss: 0.0677 Acc: 0.9790\n",
      "2022-01-23 03:48:33.474635\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0591 Acc: 0.9825\n",
      "2022-01-23 03:48:36.049101\n",
      "validation Loss: 0.1146 Acc: 0.9720\n",
      "2022-01-23 03:48:36.452070\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0281 Acc: 0.9900\n",
      "2022-01-23 03:48:39.184782\n",
      "validation Loss: 0.0526 Acc: 0.9814\n",
      "2022-01-23 03:48:39.545498\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0313 Acc: 0.9895\n",
      "2022-01-23 03:48:42.038984\n",
      "validation Loss: 0.0853 Acc: 0.9790\n",
      "2022-01-23 03:48:42.404950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0090 Acc: 0.9975\n",
      "2022-01-23 03:48:45.080916\n",
      "validation Loss: 0.0333 Acc: 0.9930\n",
      "2022-01-23 03:48:45.529722\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0187 Acc: 0.9950\n",
      "2022-01-23 03:48:48.479113\n",
      "validation Loss: 0.0424 Acc: 0.9883\n",
      "2022-01-23 03:48:48.842708\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0198 Acc: 0.9940\n",
      "2022-01-23 03:48:50.599277\n",
      "validation Loss: 0.0540 Acc: 0.9837\n",
      "2022-01-23 03:48:50.975573\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 0.9995\n",
      "2022-01-23 03:48:53.463188\n",
      "validation Loss: 0.0279 Acc: 0.9930\n",
      "2022-01-23 03:48:53.813808\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0092 Acc: 0.9955\n",
      "2022-01-23 03:48:56.933651\n",
      "validation Loss: 0.0398 Acc: 0.9883\n",
      "2022-01-23 03:48:57.288136\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 0.9990\n",
      "2022-01-23 03:49:00.158976\n",
      "validation Loss: 0.0423 Acc: 0.9860\n",
      "2022-01-23 03:49:00.549361\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 03:49:03.106162\n",
      "validation Loss: 0.0574 Acc: 0.9883\n",
      "2022-01-23 03:49:03.586700\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:49:06.293861\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 03:49:06.662884\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:49:09.184593\n",
      "validation Loss: 0.0466 Acc: 0.9883\n",
      "2022-01-23 03:49:09.626653\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:12.192424\n",
      "validation Loss: 0.0475 Acc: 0.9883\n",
      "2022-01-23 03:49:12.602449\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:15.133464\n",
      "validation Loss: 0.0475 Acc: 0.9883\n",
      "2022-01-23 03:49:15.479924\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:18.037572\n",
      "validation Loss: 0.0479 Acc: 0.9883\n",
      "2022-01-23 03:49:18.534219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:21.115120\n",
      "validation Loss: 0.0497 Acc: 0.9883\n",
      "2022-01-23 03:49:21.531553\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:24.017377\n",
      "validation Loss: 0.0498 Acc: 0.9883\n",
      "2022-01-23 03:49:24.385111\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:26.902760\n",
      "validation Loss: 0.0510 Acc: 0.9883\n",
      "2022-01-23 03:49:27.400973\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:29.959283\n",
      "validation Loss: 0.0518 Acc: 0.9883\n",
      "2022-01-23 03:49:30.379777\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:49:33.034808\n",
      "validation Loss: 0.0525 Acc: 0.9883\n",
      "2022-01-23 03:49:33.400626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:35.947541\n",
      "validation Loss: 0.0518 Acc: 0.9883\n",
      "2022-01-23 03:49:36.397307\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:39.025034\n",
      "validation Loss: 0.0543 Acc: 0.9883\n",
      "2022-01-23 03:49:39.368271\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:41.930172\n",
      "validation Loss: 0.0535 Acc: 0.9883\n",
      "2022-01-23 03:49:42.288012\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:44.829169\n",
      "validation Loss: 0.0546 Acc: 0.9883\n",
      "2022-01-23 03:49:45.234734\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:47.828508\n",
      "validation Loss: 0.0548 Acc: 0.9883\n",
      "2022-01-23 03:49:48.177228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:50.611088\n",
      "validation Loss: 0.0556 Acc: 0.9883\n",
      "2022-01-23 03:49:51.033842\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:53.612324\n",
      "validation Loss: 0.0561 Acc: 0.9883\n",
      "2022-01-23 03:49:54.016461\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:56.800262\n",
      "validation Loss: 0.0573 Acc: 0.9883\n",
      "2022-01-23 03:49:57.167873\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:49:59.681541\n",
      "validation Loss: 0.0579 Acc: 0.9883\n",
      "2022-01-23 03:50:00.054046\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:02.593674\n",
      "validation Loss: 0.0582 Acc: 0.9883\n",
      "2022-01-23 03:50:03.039089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:05.572880\n",
      "validation Loss: 0.0589 Acc: 0.9883\n",
      "2022-01-23 03:50:05.945890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:08.448948\n",
      "validation Loss: 0.0590 Acc: 0.9883\n",
      "2022-01-23 03:50:08.835233\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:11.442479\n",
      "validation Loss: 0.0594 Acc: 0.9883\n",
      "2022-01-23 03:50:11.854586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:14.404171\n",
      "validation Loss: 0.0609 Acc: 0.9860\n",
      "2022-01-23 03:50:14.786592\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:17.265322\n",
      "validation Loss: 0.0614 Acc: 0.9860\n",
      "2022-01-23 03:50:17.699796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:20.224290\n",
      "validation Loss: 0.0623 Acc: 0.9860\n",
      "2022-01-23 03:50:20.722836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:23.349433\n",
      "validation Loss: 0.0627 Acc: 0.9860\n",
      "2022-01-23 03:50:23.686631\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:26.220566\n",
      "validation Loss: 0.0631 Acc: 0.9860\n",
      "2022-01-23 03:50:26.618339\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:29.083859\n",
      "validation Loss: 0.0636 Acc: 0.9860\n",
      "2022-01-23 03:50:29.573648\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:32.116631\n",
      "validation Loss: 0.0648 Acc: 0.9860\n",
      "2022-01-23 03:50:32.460444\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:34.950577\n",
      "validation Loss: 0.0654 Acc: 0.9860\n",
      "2022-01-23 03:50:35.418242\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:37.956599\n",
      "validation Loss: 0.0659 Acc: 0.9860\n",
      "2022-01-23 03:50:38.442832\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:41.010611\n",
      "validation Loss: 0.0666 Acc: 0.9860\n",
      "2022-01-23 03:50:41.421969\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:43.835497\n",
      "validation Loss: 0.0673 Acc: 0.9860\n",
      "2022-01-23 03:50:44.190784\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:46.653985\n",
      "validation Loss: 0.0682 Acc: 0.9860\n",
      "2022-01-23 03:50:46.999591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:49.468388\n",
      "validation Loss: 0.0679 Acc: 0.9860\n",
      "2022-01-23 03:50:49.861396\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:52.385073\n",
      "validation Loss: 0.0689 Acc: 0.9860\n",
      "2022-01-23 03:50:52.804081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:55.332368\n",
      "validation Loss: 0.0693 Acc: 0.9860\n",
      "2022-01-23 03:50:55.678670\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:50:58.238690\n",
      "validation Loss: 0.0706 Acc: 0.9860\n",
      "2022-01-23 03:50:58.622797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:01.229250\n",
      "validation Loss: 0.0712 Acc: 0.9860\n",
      "2022-01-23 03:51:01.573080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:04.132325\n",
      "validation Loss: 0.0717 Acc: 0.9860\n",
      "2022-01-23 03:51:04.508481\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:07.109815\n",
      "validation Loss: 0.0721 Acc: 0.9860\n",
      "2022-01-23 03:51:07.545921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:10.140839\n",
      "validation Loss: 0.0730 Acc: 0.9860\n",
      "2022-01-23 03:51:10.511199\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:13.267728\n",
      "validation Loss: 0.0732 Acc: 0.9860\n",
      "2022-01-23 03:51:13.635831\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:16.181308\n",
      "validation Loss: 0.0744 Acc: 0.9860\n",
      "2022-01-23 03:51:16.583034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:19.152612\n",
      "validation Loss: 0.0755 Acc: 0.9860\n",
      "2022-01-23 03:51:19.495816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:51:22.020647\n",
      "validation Loss: 0.0757 Acc: 0.9837\n",
      "2022-01-23 03:51:22.404691\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9930\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1ua2fpb0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 48825... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▅▆█▇████</td></tr><tr><td>accuracy_train</td><td>▁▆▇▇█████▇████▇█████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▅▇▇▇▇█▇▇▇▇▇██▇█▆▇██████████████████████</td></tr><tr><td>loss_train</td><td>█▃▂▂▂▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▂▂▂▂▁▁▂▂▂▂▁▁▂▁▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98368</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98368</td></tr><tr><td>best_test_accuracy</td><td>0.98368</td></tr><tr><td>best_val_accuracy</td><td>0.99301</td></tr><tr><td>best_val_loss</td><td>0.02795</td></tr><tr><td>loss_train</td><td>1e-05</td></tr><tr><td>loss_validation</td><td>0.07567</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ua2fpb0\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1ua2fpb0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_034613-1ua2fpb0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1ua2fpb0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2mc6he8u\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 03:51:31.891537\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.2473 Acc: 0.6190\n",
      "2022-01-23 03:51:34.422944\n",
      "validation Loss: 0.3881 Acc: 0.8485\n",
      "2022-01-23 03:51:34.789833\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.4678 Acc: 0.8655\n",
      "2022-01-23 03:51:37.840037\n",
      "validation Loss: 0.2909 Acc: 0.9301\n",
      "2022-01-23 03:51:38.206297\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.4789 Acc: 0.8705\n",
      "2022-01-23 03:51:41.208324\n",
      "validation Loss: 0.3207 Acc: 0.8904\n",
      "2022-01-23 03:51:41.555639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2144 Acc: 0.9430\n",
      "2022-01-23 03:51:44.023461\n",
      "validation Loss: 0.2381 Acc: 0.9138\n",
      "2022-01-23 03:51:44.384347\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1254 Acc: 0.9590\n",
      "2022-01-23 03:51:46.901953\n",
      "validation Loss: 0.1366 Acc: 0.9604\n",
      "2022-01-23 03:51:47.318542\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1145 Acc: 0.9670\n",
      "2022-01-23 03:51:50.206753\n",
      "validation Loss: 0.1745 Acc: 0.9417\n",
      "2022-01-23 03:51:50.571109\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1225 Acc: 0.9640\n",
      "2022-01-23 03:51:53.089724\n",
      "validation Loss: 0.1080 Acc: 0.9627\n",
      "2022-01-23 03:51:53.440596\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0677 Acc: 0.9775\n",
      "2022-01-23 03:51:56.429631\n",
      "validation Loss: 0.0861 Acc: 0.9814\n",
      "2022-01-23 03:51:56.888431\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1005 Acc: 0.9660\n",
      "2022-01-23 03:51:59.828531\n",
      "validation Loss: 0.1435 Acc: 0.9627\n",
      "2022-01-23 03:52:00.210055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1176 Acc: 0.9660\n",
      "2022-01-23 03:52:02.977632\n",
      "validation Loss: 0.3480 Acc: 0.9417\n",
      "2022-01-23 03:52:03.323878\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0872 Acc: 0.9705\n",
      "2022-01-23 03:52:06.045603\n",
      "validation Loss: 0.1361 Acc: 0.9557\n",
      "2022-01-23 03:52:06.517530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1135 Acc: 0.9625\n",
      "2022-01-23 03:52:09.210363\n",
      "validation Loss: 0.1122 Acc: 0.9604\n",
      "2022-01-23 03:52:09.683646\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0501 Acc: 0.9850\n",
      "2022-01-23 03:52:12.424741\n",
      "validation Loss: 0.1530 Acc: 0.9674\n",
      "2022-01-23 03:52:12.793190\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0502 Acc: 0.9845\n",
      "2022-01-23 03:52:15.545687\n",
      "validation Loss: 0.1189 Acc: 0.9604\n",
      "2022-01-23 03:52:15.903277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0333 Acc: 0.9900\n",
      "2022-01-23 03:52:18.771740\n",
      "validation Loss: 0.1845 Acc: 0.9674\n",
      "2022-01-23 03:52:19.122536\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0338 Acc: 0.9880\n",
      "2022-01-23 03:52:21.841286\n",
      "validation Loss: 0.1620 Acc: 0.9720\n",
      "2022-01-23 03:52:22.212097\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0621 Acc: 0.9800\n",
      "2022-01-23 03:52:24.951967\n",
      "validation Loss: 0.1672 Acc: 0.9580\n",
      "2022-01-23 03:52:25.300221\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1083 Acc: 0.9705\n",
      "2022-01-23 03:52:27.740013\n",
      "validation Loss: 0.1781 Acc: 0.9371\n",
      "2022-01-23 03:52:28.280579\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0631 Acc: 0.9780\n",
      "2022-01-23 03:52:30.785206\n",
      "validation Loss: 0.1053 Acc: 0.9674\n",
      "2022-01-23 03:52:31.181266\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0472 Acc: 0.9820\n",
      "2022-01-23 03:52:33.615299\n",
      "validation Loss: 0.1351 Acc: 0.9767\n",
      "2022-01-23 03:52:34.120376\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0295 Acc: 0.9880\n",
      "2022-01-23 03:52:36.558524\n",
      "validation Loss: 0.2290 Acc: 0.9744\n",
      "2022-01-23 03:52:36.932881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0341 Acc: 0.9920\n",
      "2022-01-23 03:52:39.711752\n",
      "validation Loss: 0.2431 Acc: 0.9650\n",
      "2022-01-23 03:52:40.070308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1024 Acc: 0.9685\n",
      "2022-01-23 03:52:42.514744\n",
      "validation Loss: 0.1905 Acc: 0.9487\n",
      "2022-01-23 03:52:42.970920\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0983 Acc: 0.9700\n",
      "2022-01-23 03:52:45.454374\n",
      "validation Loss: 0.2679 Acc: 0.9394\n",
      "2022-01-23 03:52:45.850588\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0608 Acc: 0.9820\n",
      "2022-01-23 03:52:47.526383\n",
      "validation Loss: 0.0984 Acc: 0.9627\n",
      "2022-01-23 03:52:47.886101\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0549 Acc: 0.9825\n",
      "2022-01-23 03:52:50.294663\n",
      "validation Loss: 0.1176 Acc: 0.9697\n",
      "2022-01-23 03:52:50.828646\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0337 Acc: 0.9870\n",
      "2022-01-23 03:52:53.278962\n",
      "validation Loss: 0.1360 Acc: 0.9697\n",
      "2022-01-23 03:52:53.620995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0260 Acc: 0.9895\n",
      "2022-01-23 03:52:56.080821\n",
      "validation Loss: 0.1245 Acc: 0.9720\n",
      "2022-01-23 03:52:56.441614\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0205 Acc: 0.9935\n",
      "2022-01-23 03:52:58.867916\n",
      "validation Loss: 0.0956 Acc: 0.9790\n",
      "2022-01-23 03:52:59.269866\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9950\n",
      "2022-01-23 03:53:01.965026\n",
      "validation Loss: 0.0884 Acc: 0.9767\n",
      "2022-01-23 03:53:02.305022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0238 Acc: 0.9935\n",
      "2022-01-23 03:53:03.697140\n",
      "validation Loss: 0.2782 Acc: 0.9417\n",
      "2022-01-23 03:53:04.153307\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0719 Acc: 0.9850\n",
      "2022-01-23 03:53:06.591919\n",
      "validation Loss: 0.0963 Acc: 0.9627\n",
      "2022-01-23 03:53:07.061652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0292 Acc: 0.9935\n",
      "2022-01-23 03:53:09.573818\n",
      "validation Loss: 0.1467 Acc: 0.9604\n",
      "2022-01-23 03:53:09.937963\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9925\n",
      "2022-01-23 03:53:11.444535\n",
      "validation Loss: 0.1167 Acc: 0.9720\n",
      "2022-01-23 03:53:11.820898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0264 Acc: 0.9945\n",
      "2022-01-23 03:53:14.256472\n",
      "validation Loss: 0.1176 Acc: 0.9720\n",
      "2022-01-23 03:53:14.599986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 0.9995\n",
      "2022-01-23 03:53:17.059875\n",
      "validation Loss: 0.1175 Acc: 0.9674\n",
      "2022-01-23 03:53:17.415791\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 0.9980\n",
      "2022-01-23 03:53:19.916276\n",
      "validation Loss: 0.1020 Acc: 0.9720\n",
      "2022-01-23 03:53:20.293611\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0132 Acc: 0.9960\n",
      "2022-01-23 03:53:22.899754\n",
      "validation Loss: 0.1057 Acc: 0.9790\n",
      "2022-01-23 03:53:23.303398\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0091 Acc: 0.9970\n",
      "2022-01-23 03:53:26.134494\n",
      "validation Loss: 0.0971 Acc: 0.9744\n",
      "2022-01-23 03:53:26.620050\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 0.9980\n",
      "2022-01-23 03:53:29.143063\n",
      "validation Loss: 0.0977 Acc: 0.9720\n",
      "2022-01-23 03:53:29.644295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0843 Acc: 0.9745\n",
      "2022-01-23 03:53:32.111921\n",
      "validation Loss: 0.1429 Acc: 0.9674\n",
      "2022-01-23 03:53:32.483955\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0501 Acc: 0.9860\n",
      "2022-01-23 03:53:35.112854\n",
      "validation Loss: 0.1490 Acc: 0.9650\n",
      "2022-01-23 03:53:35.569421\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0657 Acc: 0.9870\n",
      "2022-01-23 03:53:38.109063\n",
      "validation Loss: 0.3474 Acc: 0.9091\n",
      "2022-01-23 03:53:38.600409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0973 Acc: 0.9765\n",
      "2022-01-23 03:53:41.390904\n",
      "validation Loss: 0.1478 Acc: 0.9441\n",
      "2022-01-23 03:53:41.780227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0659 Acc: 0.9790\n",
      "2022-01-23 03:53:44.294968\n",
      "validation Loss: 0.1649 Acc: 0.9487\n",
      "2022-01-23 03:53:44.735407\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0323 Acc: 0.9890\n",
      "2022-01-23 03:53:47.301713\n",
      "validation Loss: 0.1054 Acc: 0.9744\n",
      "2022-01-23 03:53:47.745294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0168 Acc: 0.9950\n",
      "2022-01-23 03:53:50.479986\n",
      "validation Loss: 0.0807 Acc: 0.9744\n",
      "2022-01-23 03:53:50.924414\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 0.9975\n",
      "2022-01-23 03:53:53.473643\n",
      "validation Loss: 0.1182 Acc: 0.9720\n",
      "2022-01-23 03:53:53.814530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0142 Acc: 0.9940\n",
      "2022-01-23 03:53:56.365363\n",
      "validation Loss: 0.0708 Acc: 0.9767\n",
      "2022-01-23 03:53:56.747992\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0296 Acc: 0.9890\n",
      "2022-01-23 03:53:59.317143\n",
      "validation Loss: 0.1187 Acc: 0.9744\n",
      "2022-01-23 03:53:59.705298\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 0.9970\n",
      "2022-01-23 03:54:02.245273\n",
      "validation Loss: 0.0879 Acc: 0.9790\n",
      "2022-01-23 03:54:02.655269\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0270 Acc: 0.9930\n",
      "2022-01-23 03:54:05.139113\n",
      "validation Loss: 0.1844 Acc: 0.9557\n",
      "2022-01-23 03:54:05.517152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0300 Acc: 0.9910\n",
      "2022-01-23 03:54:08.008148\n",
      "validation Loss: 0.0910 Acc: 0.9604\n",
      "2022-01-23 03:54:08.362379\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0391 Acc: 0.9895\n",
      "2022-01-23 03:54:10.891937\n",
      "validation Loss: 0.2865 Acc: 0.9394\n",
      "2022-01-23 03:54:11.277036\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0765 Acc: 0.9780\n",
      "2022-01-23 03:54:13.833065\n",
      "validation Loss: 0.0981 Acc: 0.9674\n",
      "2022-01-23 03:54:14.275737\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9955\n",
      "2022-01-23 03:54:16.743807\n",
      "validation Loss: 0.0850 Acc: 0.9744\n",
      "2022-01-23 03:54:17.140003\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9970\n",
      "2022-01-23 03:54:19.737859\n",
      "validation Loss: 0.1498 Acc: 0.9674\n",
      "2022-01-23 03:54:20.132504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0046 Acc: 0.9990\n",
      "2022-01-23 03:54:22.934954\n",
      "validation Loss: 0.0984 Acc: 0.9767\n",
      "2022-01-23 03:54:23.374878\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9985\n",
      "2022-01-23 03:54:25.969578\n",
      "validation Loss: 0.1276 Acc: 0.9767\n",
      "2022-01-23 03:54:26.396567\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0076 Acc: 0.9975\n",
      "2022-01-23 03:54:28.942428\n",
      "validation Loss: 0.0532 Acc: 0.9860\n",
      "2022-01-23 03:54:29.343137\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 03:54:32.281306\n",
      "validation Loss: 0.0736 Acc: 0.9814\n",
      "2022-01-23 03:54:32.614213\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 0.9995\n",
      "2022-01-23 03:54:35.121901\n",
      "validation Loss: 0.1692 Acc: 0.9650\n",
      "2022-01-23 03:54:35.495835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0063 Acc: 0.9985\n",
      "2022-01-23 03:54:37.969861\n",
      "validation Loss: 0.0869 Acc: 0.9814\n",
      "2022-01-23 03:54:38.438394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:54:41.016624\n",
      "validation Loss: 0.1036 Acc: 0.9790\n",
      "2022-01-23 03:54:41.411983\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:54:44.079268\n",
      "validation Loss: 0.1016 Acc: 0.9767\n",
      "2022-01-23 03:54:44.444716\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:54:46.939220\n",
      "validation Loss: 0.1069 Acc: 0.9767\n",
      "2022-01-23 03:54:47.485953\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:54:50.142968\n",
      "validation Loss: 0.1099 Acc: 0.9767\n",
      "2022-01-23 03:54:50.485813\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:54:52.969920\n",
      "validation Loss: 0.1125 Acc: 0.9767\n",
      "2022-01-23 03:54:53.322434\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:54:55.799426\n",
      "validation Loss: 0.1149 Acc: 0.9767\n",
      "2022-01-23 03:54:56.160376\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:54:58.905035\n",
      "validation Loss: 0.1160 Acc: 0.9767\n",
      "2022-01-23 03:54:59.378948\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 03:55:00.706980\n",
      "validation Loss: 0.1183 Acc: 0.9767\n",
      "2022-01-23 03:55:01.082747\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:03.460604\n",
      "validation Loss: 0.1196 Acc: 0.9767\n",
      "2022-01-23 03:55:03.995079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:06.675334\n",
      "validation Loss: 0.1214 Acc: 0.9767\n",
      "2022-01-23 03:55:07.017019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:09.471646\n",
      "validation Loss: 0.1230 Acc: 0.9767\n",
      "2022-01-23 03:55:09.862236\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:12.453674\n",
      "validation Loss: 0.1243 Acc: 0.9767\n",
      "2022-01-23 03:55:12.810859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:15.295707\n",
      "validation Loss: 0.1249 Acc: 0.9744\n",
      "2022-01-23 03:55:15.788742\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:18.289244\n",
      "validation Loss: 0.1261 Acc: 0.9744\n",
      "2022-01-23 03:55:18.660227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:21.139412\n",
      "validation Loss: 0.1275 Acc: 0.9744\n",
      "2022-01-23 03:55:21.496709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:24.119376\n",
      "validation Loss: 0.1286 Acc: 0.9744\n",
      "2022-01-23 03:55:24.578903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:27.044261\n",
      "validation Loss: 0.1294 Acc: 0.9744\n",
      "2022-01-23 03:55:27.608964\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:30.184255\n",
      "validation Loss: 0.1303 Acc: 0.9744\n",
      "2022-01-23 03:55:30.549986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:33.045129\n",
      "validation Loss: 0.1324 Acc: 0.9720\n",
      "2022-01-23 03:55:33.410056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:35.003564\n",
      "validation Loss: 0.1335 Acc: 0.9720\n",
      "2022-01-23 03:55:35.359179\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:37.938018\n",
      "validation Loss: 0.1348 Acc: 0.9720\n",
      "2022-01-23 03:55:38.325888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:40.946649\n",
      "validation Loss: 0.1362 Acc: 0.9720\n",
      "2022-01-23 03:55:41.438034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:43.950459\n",
      "validation Loss: 0.1374 Acc: 0.9720\n",
      "2022-01-23 03:55:44.308954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:45.621097\n",
      "validation Loss: 0.1393 Acc: 0.9697\n",
      "2022-01-23 03:55:45.969911\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:48.486306\n",
      "validation Loss: 0.1406 Acc: 0.9697\n",
      "2022-01-23 03:55:48.881590\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:51.366632\n",
      "validation Loss: 0.1422 Acc: 0.9697\n",
      "2022-01-23 03:55:51.763067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:54.394947\n",
      "validation Loss: 0.1435 Acc: 0.9697\n",
      "2022-01-23 03:55:54.749606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:55:57.360472\n",
      "validation Loss: 0.1447 Acc: 0.9697\n",
      "2022-01-23 03:55:57.722527\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:00.455877\n",
      "validation Loss: 0.1467 Acc: 0.9697\n",
      "2022-01-23 03:56:00.930369\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:03.496182\n",
      "validation Loss: 0.1483 Acc: 0.9697\n",
      "2022-01-23 03:56:03.820362\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:06.323276\n",
      "validation Loss: 0.1495 Acc: 0.9697\n",
      "2022-01-23 03:56:06.678009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:09.215466\n",
      "validation Loss: 0.1518 Acc: 0.9697\n",
      "2022-01-23 03:56:09.581950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:12.172080\n",
      "validation Loss: 0.1530 Acc: 0.9697\n",
      "2022-01-23 03:56:12.621943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:15.210113\n",
      "validation Loss: 0.1541 Acc: 0.9697\n",
      "2022-01-23 03:56:15.587457\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:18.162998\n",
      "validation Loss: 0.1559 Acc: 0.9697\n",
      "2022-01-23 03:56:18.530909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:21.080137\n",
      "validation Loss: 0.1571 Acc: 0.9697\n",
      "2022-01-23 03:56:21.421682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 03:56:24.012690\n",
      "validation Loss: 0.1586 Acc: 0.9697\n",
      "2022-01-23 03:56:24.436966\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9860\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2mc6he8u) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38964... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▇███</td></tr><tr><td>accuracy_train</td><td>▁▆▇█▇██▇█▇██████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▃▆█▇▇█▆█▆▇█▆█▇█▇▆███▆████████████▇▇▇▇▇▇</td></tr><tr><td>loss_train</td><td>█▄▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▇▃▁▂▃▃▃▄▄▂▂▆▂▂▂▃▃▂▁▁▆▁▂▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.97436</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.9697</td></tr><tr><td>best_test_accuracy</td><td>0.97436</td></tr><tr><td>best_val_accuracy</td><td>0.98601</td></tr><tr><td>best_val_loss</td><td>0.05318</td></tr><tr><td>loss_train</td><td>1e-05</td></tr><tr><td>loss_validation</td><td>0.15864</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2mc6he8u\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2mc6he8u</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_035122-2mc6he8u/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2mc6he8u). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1m2ncy3r\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 03:56:34.632334\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.6946 Acc: 0.4975\n",
      "2022-01-23 03:56:37.236800\n",
      "validation Loss: 0.5871 Acc: 0.8019\n",
      "2022-01-23 03:56:37.715907\n",
      "Accuracy of the network on the 429 test samples: 83.44988344988346\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.4953 Acc: 0.8695\n",
      "2022-01-23 03:56:40.762060\n",
      "validation Loss: 0.3003 Acc: 0.9068\n",
      "2022-01-23 03:56:41.146223\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2949 Acc: 0.9210\n",
      "2022-01-23 03:56:44.092837\n",
      "validation Loss: 0.2980 Acc: 0.8928\n",
      "2022-01-23 03:56:44.478194\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1926 Acc: 0.9350\n",
      "2022-01-23 03:56:47.011869\n",
      "validation Loss: 0.1878 Acc: 0.9417\n",
      "2022-01-23 03:56:47.378023\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1488 Acc: 0.9575\n",
      "2022-01-23 03:56:50.290345\n",
      "validation Loss: 0.1670 Acc: 0.9534\n",
      "2022-01-23 03:56:50.756778\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1030 Acc: 0.9695\n",
      "2022-01-23 03:56:53.571269\n",
      "validation Loss: 0.2033 Acc: 0.9417\n",
      "2022-01-23 03:56:53.944348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0782 Acc: 0.9770\n",
      "2022-01-23 03:56:56.474567\n",
      "validation Loss: 0.1612 Acc: 0.9510\n",
      "2022-01-23 03:56:56.829809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1593 Acc: 0.9540\n",
      "2022-01-23 03:56:59.459801\n",
      "validation Loss: 0.1522 Acc: 0.9487\n",
      "2022-01-23 03:56:59.872505\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0987 Acc: 0.9680\n",
      "2022-01-23 03:57:02.409959\n",
      "validation Loss: 0.1102 Acc: 0.9604\n",
      "2022-01-23 03:57:02.832796\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0619 Acc: 0.9780\n",
      "2022-01-23 03:57:05.713948\n",
      "validation Loss: 0.0780 Acc: 0.9697\n",
      "2022-01-23 03:57:06.093201\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0598 Acc: 0.9835\n",
      "2022-01-23 03:57:08.955081\n",
      "validation Loss: 0.0736 Acc: 0.9720\n",
      "2022-01-23 03:57:09.345230\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0364 Acc: 0.9885\n",
      "2022-01-23 03:57:12.282423\n",
      "validation Loss: 0.0776 Acc: 0.9744\n",
      "2022-01-23 03:57:12.633791\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0439 Acc: 0.9860\n",
      "2022-01-23 03:57:15.463353\n",
      "validation Loss: 0.1434 Acc: 0.9441\n",
      "2022-01-23 03:57:15.807124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0494 Acc: 0.9820\n",
      "2022-01-23 03:57:18.267715\n",
      "validation Loss: 0.0941 Acc: 0.9650\n",
      "2022-01-23 03:57:18.661216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9745\n",
      "2022-01-23 03:57:21.128736\n",
      "validation Loss: 0.2003 Acc: 0.9394\n",
      "2022-01-23 03:57:21.498710\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0532 Acc: 0.9865\n",
      "2022-01-23 03:57:23.959705\n",
      "validation Loss: 0.1587 Acc: 0.9510\n",
      "2022-01-23 03:57:24.351967\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1429 Acc: 0.9610\n",
      "2022-01-23 03:57:26.857934\n",
      "validation Loss: 0.1396 Acc: 0.9510\n",
      "2022-01-23 03:57:27.365119\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1110 Acc: 0.9760\n",
      "2022-01-23 03:57:29.811944\n",
      "validation Loss: 0.1125 Acc: 0.9580\n",
      "2022-01-23 03:57:30.158984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0454 Acc: 0.9850\n",
      "2022-01-23 03:57:31.519376\n",
      "validation Loss: 0.1450 Acc: 0.9441\n",
      "2022-01-23 03:57:32.049312\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0618 Acc: 0.9800\n",
      "2022-01-23 03:57:34.426191\n",
      "validation Loss: 0.1075 Acc: 0.9580\n",
      "2022-01-23 03:57:34.780669\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0352 Acc: 0.9885\n",
      "2022-01-23 03:57:37.509624\n",
      "validation Loss: 0.0627 Acc: 0.9744\n",
      "2022-01-23 03:57:37.873281\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0166 Acc: 0.9950\n",
      "2022-01-23 03:57:40.672730\n",
      "validation Loss: 0.0460 Acc: 0.9837\n",
      "2022-01-23 03:57:41.136795\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0275 Acc: 0.9890\n",
      "2022-01-23 03:57:43.967743\n",
      "validation Loss: 0.1126 Acc: 0.9580\n",
      "2022-01-23 03:57:44.326826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0392 Acc: 0.9875\n",
      "2022-01-23 03:57:46.857816\n",
      "validation Loss: 0.1043 Acc: 0.9697\n",
      "2022-01-23 03:57:47.209250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0336 Acc: 0.9920\n",
      "2022-01-23 03:57:49.821780\n",
      "validation Loss: 0.0706 Acc: 0.9790\n",
      "2022-01-23 03:57:50.235644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9965\n",
      "2022-01-23 03:57:53.013442\n",
      "validation Loss: 0.0507 Acc: 0.9860\n",
      "2022-01-23 03:57:53.352337\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0109 Acc: 0.9965\n",
      "2022-01-23 03:57:56.351632\n",
      "validation Loss: 0.0655 Acc: 0.9790\n",
      "2022-01-23 03:57:56.699510\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0497 Acc: 0.9850\n",
      "2022-01-23 03:57:59.264220\n",
      "validation Loss: 0.1558 Acc: 0.9557\n",
      "2022-01-23 03:57:59.791590\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0376 Acc: 0.9855\n",
      "2022-01-23 03:58:02.282153\n",
      "validation Loss: 0.0619 Acc: 0.9883\n",
      "2022-01-23 03:58:02.619065\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0207 Acc: 0.9925\n",
      "2022-01-23 03:58:05.596894\n",
      "validation Loss: 0.0704 Acc: 0.9744\n",
      "2022-01-23 03:58:05.960957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0241 Acc: 0.9915\n",
      "2022-01-23 03:58:08.478861\n",
      "validation Loss: 0.0620 Acc: 0.9744\n",
      "2022-01-23 03:58:08.835166\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0173 Acc: 0.9945\n",
      "2022-01-23 03:58:11.451929\n",
      "validation Loss: 0.1458 Acc: 0.9557\n",
      "2022-01-23 03:58:11.963729\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9955\n",
      "2022-01-23 03:58:14.476354\n",
      "validation Loss: 0.0792 Acc: 0.9767\n",
      "2022-01-23 03:58:14.826475\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 0.9975\n",
      "2022-01-23 03:58:17.374874\n",
      "validation Loss: 0.0892 Acc: 0.9814\n",
      "2022-01-23 03:58:17.725586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0250 Acc: 0.9925\n",
      "2022-01-23 03:58:19.277361\n",
      "validation Loss: 0.0628 Acc: 0.9790\n",
      "2022-01-23 03:58:19.631413\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0459 Acc: 0.9875\n",
      "2022-01-23 03:58:22.135851\n",
      "validation Loss: 0.1245 Acc: 0.9627\n",
      "2022-01-23 03:58:22.492922\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0435 Acc: 0.9835\n",
      "2022-01-23 03:58:25.099926\n",
      "validation Loss: 0.1048 Acc: 0.9697\n",
      "2022-01-23 03:58:25.445776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0432 Acc: 0.9875\n",
      "2022-01-23 03:58:28.096659\n",
      "validation Loss: 0.0658 Acc: 0.9790\n",
      "2022-01-23 03:58:28.438530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0122 Acc: 0.9965\n",
      "2022-01-23 03:58:30.912188\n",
      "validation Loss: 0.0936 Acc: 0.9814\n",
      "2022-01-23 03:58:31.275828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0376 Acc: 0.9870\n",
      "2022-01-23 03:58:33.727438\n",
      "validation Loss: 0.0934 Acc: 0.9767\n",
      "2022-01-23 03:58:34.204929\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0257 Acc: 0.9910\n",
      "2022-01-23 03:58:36.713404\n",
      "validation Loss: 0.0734 Acc: 0.9697\n",
      "2022-01-23 03:58:37.073221\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9975\n",
      "2022-01-23 03:58:39.526155\n",
      "validation Loss: 0.0939 Acc: 0.9744\n",
      "2022-01-23 03:58:39.870990\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 0.9970\n",
      "2022-01-23 03:58:42.356367\n",
      "validation Loss: 0.0784 Acc: 0.9767\n",
      "2022-01-23 03:58:42.799801\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0199 Acc: 0.9910\n",
      "2022-01-23 03:58:45.295356\n",
      "validation Loss: 0.1081 Acc: 0.9674\n",
      "2022-01-23 03:58:45.719746\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0096 Acc: 0.9970\n",
      "2022-01-23 03:58:48.263662\n",
      "validation Loss: 0.0488 Acc: 0.9744\n",
      "2022-01-23 03:58:48.624659\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0224 Acc: 0.9920\n",
      "2022-01-23 03:58:51.147463\n",
      "validation Loss: 0.1550 Acc: 0.9650\n",
      "2022-01-23 03:58:51.648759\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0219 Acc: 0.9960\n",
      "2022-01-23 03:58:54.164318\n",
      "validation Loss: 0.0654 Acc: 0.9790\n",
      "2022-01-23 03:58:54.504791\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0343 Acc: 0.9915\n",
      "2022-01-23 03:58:57.017477\n",
      "validation Loss: 0.0479 Acc: 0.9837\n",
      "2022-01-23 03:58:57.382746\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 0.9985\n",
      "2022-01-23 03:59:00.050112\n",
      "validation Loss: 0.0603 Acc: 0.9814\n",
      "2022-01-23 03:59:00.488759\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 0.9995\n",
      "2022-01-23 03:59:02.975605\n",
      "validation Loss: 0.0457 Acc: 0.9814\n",
      "2022-01-23 03:59:03.387180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 03:59:06.110280\n",
      "validation Loss: 0.0532 Acc: 0.9814\n",
      "2022-01-23 03:59:06.502490\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 0.9995\n",
      "2022-01-23 03:59:08.989917\n",
      "validation Loss: 0.0467 Acc: 0.9837\n",
      "2022-01-23 03:59:09.353282\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 0.9980\n",
      "2022-01-23 03:59:11.912168\n",
      "validation Loss: 0.0748 Acc: 0.9814\n",
      "2022-01-23 03:59:12.280810\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0135 Acc: 0.9965\n",
      "2022-01-23 03:59:14.778144\n",
      "validation Loss: 0.1077 Acc: 0.9697\n",
      "2022-01-23 03:59:15.150972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0127 Acc: 0.9950\n",
      "2022-01-23 03:59:17.615475\n",
      "validation Loss: 0.1475 Acc: 0.9650\n",
      "2022-01-23 03:59:17.991645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0155 Acc: 0.9975\n",
      "2022-01-23 03:59:20.546556\n",
      "validation Loss: 0.1972 Acc: 0.9347\n",
      "2022-01-23 03:59:20.986985\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1372 Acc: 0.9665\n",
      "2022-01-23 03:59:23.521864\n",
      "validation Loss: 0.0567 Acc: 0.9814\n",
      "2022-01-23 03:59:23.889724\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0544 Acc: 0.9830\n",
      "2022-01-23 03:59:26.421181\n",
      "validation Loss: 0.1480 Acc: 0.9510\n",
      "2022-01-23 03:59:26.829040\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0352 Acc: 0.9915\n",
      "2022-01-23 03:59:29.311879\n",
      "validation Loss: 0.0677 Acc: 0.9767\n",
      "2022-01-23 03:59:29.703853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9955\n",
      "2022-01-23 03:59:32.163339\n",
      "validation Loss: 0.0685 Acc: 0.9790\n",
      "2022-01-23 03:59:32.612640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0334 Acc: 0.9910\n",
      "2022-01-23 03:59:35.038115\n",
      "validation Loss: 0.0770 Acc: 0.9744\n",
      "2022-01-23 03:59:35.390861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9945\n",
      "2022-01-23 03:59:37.832400\n",
      "validation Loss: 0.0885 Acc: 0.9720\n",
      "2022-01-23 03:59:38.181849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0079 Acc: 0.9980\n",
      "2022-01-23 03:59:40.642347\n",
      "validation Loss: 0.0814 Acc: 0.9837\n",
      "2022-01-23 03:59:41.085682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 0.9990\n",
      "2022-01-23 03:59:43.737208\n",
      "validation Loss: 0.0762 Acc: 0.9814\n",
      "2022-01-23 03:59:44.114127\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 0.9985\n",
      "2022-01-23 03:59:46.580568\n",
      "validation Loss: 0.1016 Acc: 0.9697\n",
      "2022-01-23 03:59:46.937784\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0082 Acc: 0.9980\n",
      "2022-01-23 03:59:49.497827\n",
      "validation Loss: 0.0649 Acc: 0.9744\n",
      "2022-01-23 03:59:49.996635\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 03:59:52.626559\n",
      "validation Loss: 0.0666 Acc: 0.9767\n",
      "2022-01-23 03:59:53.030335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 03:59:55.628305\n",
      "validation Loss: 0.0697 Acc: 0.9837\n",
      "2022-01-23 03:59:56.002438\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 03:59:58.482761\n",
      "validation Loss: 0.0812 Acc: 0.9837\n",
      "2022-01-23 03:59:58.875378\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:01.402896\n",
      "validation Loss: 0.0887 Acc: 0.9837\n",
      "2022-01-23 04:00:01.827429\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:04.230642\n",
      "validation Loss: 0.0940 Acc: 0.9837\n",
      "2022-01-23 04:00:04.611764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:07.140439\n",
      "validation Loss: 0.1017 Acc: 0.9837\n",
      "2022-01-23 04:00:07.487064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:09.966993\n",
      "validation Loss: 0.1059 Acc: 0.9837\n",
      "2022-01-23 04:00:10.317980\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:12.936185\n",
      "validation Loss: 0.1104 Acc: 0.9837\n",
      "2022-01-23 04:00:13.349283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:15.874418\n",
      "validation Loss: 0.1147 Acc: 0.9837\n",
      "2022-01-23 04:00:16.255189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:18.847839\n",
      "validation Loss: 0.1183 Acc: 0.9814\n",
      "2022-01-23 04:00:19.186801\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:00:21.826648\n",
      "validation Loss: 0.1217 Acc: 0.9814\n",
      "2022-01-23 04:00:22.181492\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:24.676229\n",
      "validation Loss: 0.1252 Acc: 0.9814\n",
      "2022-01-23 04:00:25.049348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:27.596604\n",
      "validation Loss: 0.1283 Acc: 0.9814\n",
      "2022-01-23 04:00:27.985683\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:30.545130\n",
      "validation Loss: 0.1322 Acc: 0.9814\n",
      "2022-01-23 04:00:31.022948\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:32.938901\n",
      "validation Loss: 0.1352 Acc: 0.9814\n",
      "2022-01-23 04:00:33.410738\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:35.866519\n",
      "validation Loss: 0.1377 Acc: 0.9814\n",
      "2022-01-23 04:00:36.187248\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:38.701126\n",
      "validation Loss: 0.1408 Acc: 0.9814\n",
      "2022-01-23 04:00:39.130055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:41.573015\n",
      "validation Loss: 0.1440 Acc: 0.9814\n",
      "2022-01-23 04:00:41.921732\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:44.404864\n",
      "validation Loss: 0.1468 Acc: 0.9814\n",
      "2022-01-23 04:00:44.759203\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:47.221745\n",
      "validation Loss: 0.1491 Acc: 0.9814\n",
      "2022-01-23 04:00:47.589298\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:50.131036\n",
      "validation Loss: 0.1519 Acc: 0.9814\n",
      "2022-01-23 04:00:50.491511\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:52.974253\n",
      "validation Loss: 0.1542 Acc: 0.9814\n",
      "2022-01-23 04:00:53.411790\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:55.904419\n",
      "validation Loss: 0.1562 Acc: 0.9814\n",
      "2022-01-23 04:00:56.252272\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:00:58.829050\n",
      "validation Loss: 0.1594 Acc: 0.9814\n",
      "2022-01-23 04:00:59.242437\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:01.791154\n",
      "validation Loss: 0.1614 Acc: 0.9814\n",
      "2022-01-23 04:01:02.171580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:04.821692\n",
      "validation Loss: 0.1637 Acc: 0.9814\n",
      "2022-01-23 04:01:05.156582\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:07.769950\n",
      "validation Loss: 0.1658 Acc: 0.9814\n",
      "2022-01-23 04:01:08.140320\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:10.760567\n",
      "validation Loss: 0.1681 Acc: 0.9814\n",
      "2022-01-23 04:01:11.105889\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:13.691012\n",
      "validation Loss: 0.1711 Acc: 0.9814\n",
      "2022-01-23 04:01:14.039878\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:16.618627\n",
      "validation Loss: 0.1723 Acc: 0.9814\n",
      "2022-01-23 04:01:16.987244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:19.533691\n",
      "validation Loss: 0.1742 Acc: 0.9814\n",
      "2022-01-23 04:01:19.867964\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:22.391123\n",
      "validation Loss: 0.1765 Acc: 0.9814\n",
      "2022-01-23 04:01:22.774593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:25.294076\n",
      "validation Loss: 0.1781 Acc: 0.9814\n",
      "2022-01-23 04:01:25.694487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:01:28.220386\n",
      "validation Loss: 0.1801 Acc: 0.9814\n",
      "2022-01-23 04:01:28.606032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1m2ncy3r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27654... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇▇▇█▇█████</td></tr><tr><td>accuracy_train</td><td>▁▇█▇████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▆▇▇▆▇▇█▇█▇██▇█▇▇▇██▇▆█████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▃▂▁▂▂▂▁▂▁▂▁▂▂▂▁▂▂▁▁▂▃▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98368</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98135</td></tr><tr><td>best_test_accuracy</td><td>0.98368</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.06192</td></tr><tr><td>loss_train</td><td>1e-05</td></tr><tr><td>loss_validation</td><td>0.18005</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1m2ncy3r\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1m2ncy3r</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_035624-1m2ncy3r/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1m2ncy3r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1olhfhiv\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 04:01:38.289303\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.6965 Acc: 0.1640\n",
      "2022-01-23 04:01:40.766133\n",
      "validation Loss: 1.9434 Acc: 0.3636\n",
      "2022-01-23 04:01:41.231669\n",
      "Accuracy of the network on the 429 test samples: 34.4988344988345\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.3549 Acc: 0.6015\n",
      "2022-01-23 04:01:43.944890\n",
      "validation Loss: 0.9935 Acc: 0.7529\n",
      "2022-01-23 04:01:44.305765\n",
      "Accuracy of the network on the 429 test samples: 74.5920745920746\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.7216 Acc: 0.8135\n",
      "2022-01-23 04:01:47.128027\n",
      "validation Loss: 0.4552 Acc: 0.9021\n",
      "2022-01-23 04:01:47.582255\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4289 Acc: 0.8975\n",
      "2022-01-23 04:01:50.418160\n",
      "validation Loss: 0.3936 Acc: 0.8904\n",
      "2022-01-23 04:01:50.785803\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4341 Acc: 0.8905\n",
      "2022-01-23 04:01:53.305390\n",
      "validation Loss: 0.4693 Acc: 0.8718\n",
      "2022-01-23 04:01:53.648848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2824 Acc: 0.9280\n",
      "2022-01-23 04:01:56.078390\n",
      "validation Loss: 0.2209 Acc: 0.9254\n",
      "2022-01-23 04:01:56.480510\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1692 Acc: 0.9520\n",
      "2022-01-23 04:01:59.366236\n",
      "validation Loss: 0.2054 Acc: 0.9394\n",
      "2022-01-23 04:01:59.726557\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1358 Acc: 0.9600\n",
      "2022-01-23 04:02:02.467401\n",
      "validation Loss: 0.2599 Acc: 0.9044\n",
      "2022-01-23 04:02:02.862886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1321 Acc: 0.9565\n",
      "2022-01-23 04:02:04.289702\n",
      "validation Loss: 0.1298 Acc: 0.9487\n",
      "2022-01-23 04:02:04.709312\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1252 Acc: 0.9575\n",
      "2022-01-23 04:02:07.561315\n",
      "validation Loss: 0.1833 Acc: 0.9441\n",
      "2022-01-23 04:02:08.068829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0830 Acc: 0.9720\n",
      "2022-01-23 04:02:10.582227\n",
      "validation Loss: 0.1458 Acc: 0.9487\n",
      "2022-01-23 04:02:10.941574\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1351 Acc: 0.9620\n",
      "2022-01-23 04:02:13.499697\n",
      "validation Loss: 0.1452 Acc: 0.9441\n",
      "2022-01-23 04:02:13.858043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0945 Acc: 0.9765\n",
      "2022-01-23 04:02:16.281156\n",
      "validation Loss: 0.2128 Acc: 0.9277\n",
      "2022-01-23 04:02:16.678981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2010 Acc: 0.9520\n",
      "2022-01-23 04:02:19.140417\n",
      "validation Loss: 0.0888 Acc: 0.9697\n",
      "2022-01-23 04:02:19.634391\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0627 Acc: 0.9815\n",
      "2022-01-23 04:02:22.331619\n",
      "validation Loss: 0.0806 Acc: 0.9650\n",
      "2022-01-23 04:02:22.710317\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0593 Acc: 0.9840\n",
      "2022-01-23 04:02:25.350480\n",
      "validation Loss: 0.0785 Acc: 0.9674\n",
      "2022-01-23 04:02:25.690751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0534 Acc: 0.9815\n",
      "2022-01-23 04:02:28.210839\n",
      "validation Loss: 0.0733 Acc: 0.9604\n",
      "2022-01-23 04:02:28.584039\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0357 Acc: 0.9880\n",
      "2022-01-23 04:02:31.230954\n",
      "validation Loss: 0.0842 Acc: 0.9674\n",
      "2022-01-23 04:02:31.595141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0451 Acc: 0.9855\n",
      "2022-01-23 04:02:34.038280\n",
      "validation Loss: 0.0884 Acc: 0.9650\n",
      "2022-01-23 04:02:34.403574\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0774 Acc: 0.9795\n",
      "2022-01-23 04:02:36.951747\n",
      "validation Loss: 0.1058 Acc: 0.9604\n",
      "2022-01-23 04:02:37.465831\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0536 Acc: 0.9820\n",
      "2022-01-23 04:02:40.129771\n",
      "validation Loss: 0.1086 Acc: 0.9580\n",
      "2022-01-23 04:02:40.503009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0571 Acc: 0.9820\n",
      "2022-01-23 04:02:43.056308\n",
      "validation Loss: 0.1435 Acc: 0.9487\n",
      "2022-01-23 04:02:43.436907\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0640 Acc: 0.9840\n",
      "2022-01-23 04:02:45.900306\n",
      "validation Loss: 0.0801 Acc: 0.9674\n",
      "2022-01-23 04:02:46.254182\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0258 Acc: 0.9905\n",
      "2022-01-23 04:02:48.771146\n",
      "validation Loss: 0.0736 Acc: 0.9720\n",
      "2022-01-23 04:02:49.294030\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0204 Acc: 0.9940\n",
      "2022-01-23 04:02:52.155519\n",
      "validation Loss: 0.1289 Acc: 0.9557\n",
      "2022-01-23 04:02:52.560891\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0398 Acc: 0.9835\n",
      "2022-01-23 04:02:54.974165\n",
      "validation Loss: 0.0624 Acc: 0.9767\n",
      "2022-01-23 04:02:55.324911\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0322 Acc: 0.9915\n",
      "2022-01-23 04:02:58.279989\n",
      "validation Loss: 0.0766 Acc: 0.9674\n",
      "2022-01-23 04:02:58.655112\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0267 Acc: 0.9910\n",
      "2022-01-23 04:03:01.059493\n",
      "validation Loss: 0.0815 Acc: 0.9674\n",
      "2022-01-23 04:03:01.430626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0254 Acc: 0.9905\n",
      "2022-01-23 04:03:03.834906\n",
      "validation Loss: 0.0739 Acc: 0.9627\n",
      "2022-01-23 04:03:04.208586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0171 Acc: 0.9950\n",
      "2022-01-23 04:03:06.664725\n",
      "validation Loss: 0.0709 Acc: 0.9627\n",
      "2022-01-23 04:03:07.160417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0224 Acc: 0.9935\n",
      "2022-01-23 04:03:09.645801\n",
      "validation Loss: 0.0806 Acc: 0.9720\n",
      "2022-01-23 04:03:09.993589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0526 Acc: 0.9880\n",
      "2022-01-23 04:03:12.655159\n",
      "validation Loss: 0.0836 Acc: 0.9767\n",
      "2022-01-23 04:03:13.011971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0225 Acc: 0.9950\n",
      "2022-01-23 04:03:15.539831\n",
      "validation Loss: 0.0594 Acc: 0.9744\n",
      "2022-01-23 04:03:15.909886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0191 Acc: 0.9925\n",
      "2022-01-23 04:03:18.539314\n",
      "validation Loss: 0.1150 Acc: 0.9674\n",
      "2022-01-23 04:03:18.964321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0460 Acc: 0.9850\n",
      "2022-01-23 04:03:21.451794\n",
      "validation Loss: 0.1049 Acc: 0.9627\n",
      "2022-01-23 04:03:21.810512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0242 Acc: 0.9920\n",
      "2022-01-23 04:03:24.452236\n",
      "validation Loss: 0.0606 Acc: 0.9744\n",
      "2022-01-23 04:03:24.806079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 0.9965\n",
      "2022-01-23 04:03:27.478738\n",
      "validation Loss: 0.0826 Acc: 0.9720\n",
      "2022-01-23 04:03:27.900898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9950\n",
      "2022-01-23 04:03:30.548281\n",
      "validation Loss: 0.1581 Acc: 0.9650\n",
      "2022-01-23 04:03:30.923858\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9935\n",
      "2022-01-23 04:03:33.327167\n",
      "validation Loss: 0.0903 Acc: 0.9767\n",
      "2022-01-23 04:03:33.714191\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0161 Acc: 0.9955\n",
      "2022-01-23 04:03:36.145724\n",
      "validation Loss: 0.0698 Acc: 0.9744\n",
      "2022-01-23 04:03:36.654829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0096 Acc: 0.9975\n",
      "2022-01-23 04:03:39.178292\n",
      "validation Loss: 0.0758 Acc: 0.9767\n",
      "2022-01-23 04:03:39.526183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0237 Acc: 0.9930\n",
      "2022-01-23 04:03:42.349313\n",
      "validation Loss: 0.0880 Acc: 0.9744\n",
      "2022-01-23 04:03:42.722426\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 0.9970\n",
      "2022-01-23 04:03:45.398390\n",
      "validation Loss: 0.0764 Acc: 0.9790\n",
      "2022-01-23 04:03:45.763917\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 0.9975\n",
      "2022-01-23 04:03:48.735494\n",
      "validation Loss: 0.0803 Acc: 0.9767\n",
      "2022-01-23 04:03:49.080709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9975\n",
      "2022-01-23 04:03:51.564765\n",
      "validation Loss: 0.1333 Acc: 0.9604\n",
      "2022-01-23 04:03:51.953020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0198 Acc: 0.9925\n",
      "2022-01-23 04:03:54.475885\n",
      "validation Loss: 0.0802 Acc: 0.9674\n",
      "2022-01-23 04:03:54.974669\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0141 Acc: 0.9980\n",
      "2022-01-23 04:03:57.704545\n",
      "validation Loss: 0.1512 Acc: 0.9627\n",
      "2022-01-23 04:03:58.075352\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9960\n",
      "2022-01-23 04:04:00.553013\n",
      "validation Loss: 0.0703 Acc: 0.9767\n",
      "2022-01-23 04:04:00.990680\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0068 Acc: 0.9975\n",
      "2022-01-23 04:04:03.443310\n",
      "validation Loss: 0.0876 Acc: 0.9720\n",
      "2022-01-23 04:04:03.811522\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0082 Acc: 0.9965\n",
      "2022-01-23 04:04:06.262726\n",
      "validation Loss: 0.1599 Acc: 0.9627\n",
      "2022-01-23 04:04:06.656382\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9965\n",
      "2022-01-23 04:04:09.131998\n",
      "validation Loss: 0.2360 Acc: 0.9627\n",
      "2022-01-23 04:04:09.493286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0686 Acc: 0.9860\n",
      "2022-01-23 04:04:11.919323\n",
      "validation Loss: 0.2762 Acc: 0.9347\n",
      "2022-01-23 04:04:12.253182\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0505 Acc: 0.9895\n",
      "2022-01-23 04:04:14.682966\n",
      "validation Loss: 0.0610 Acc: 0.9790\n",
      "2022-01-23 04:04:15.036652\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0076 Acc: 0.9980\n",
      "2022-01-23 04:04:18.031280\n",
      "validation Loss: 0.0809 Acc: 0.9767\n",
      "2022-01-23 04:04:18.392304\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 0.9985\n",
      "2022-01-23 04:04:20.871789\n",
      "validation Loss: 0.1094 Acc: 0.9744\n",
      "2022-01-23 04:04:21.220240\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9980\n",
      "2022-01-23 04:04:23.735280\n",
      "validation Loss: 0.0893 Acc: 0.9790\n",
      "2022-01-23 04:04:24.073198\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0157 Acc: 0.9935\n",
      "2022-01-23 04:04:26.474857\n",
      "validation Loss: 0.1746 Acc: 0.9650\n",
      "2022-01-23 04:04:26.973241\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0557 Acc: 0.9810\n",
      "2022-01-23 04:04:29.421762\n",
      "validation Loss: 0.0700 Acc: 0.9720\n",
      "2022-01-23 04:04:29.765463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0098 Acc: 0.9985\n",
      "2022-01-23 04:04:32.223117\n",
      "validation Loss: 0.0524 Acc: 0.9790\n",
      "2022-01-23 04:04:32.560324\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 0.9990\n",
      "2022-01-23 04:04:35.449679\n",
      "validation Loss: 0.0733 Acc: 0.9790\n",
      "2022-01-23 04:04:35.849312\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0159 Acc: 0.9945\n",
      "2022-01-23 04:04:37.392113\n",
      "validation Loss: 0.0662 Acc: 0.9767\n",
      "2022-01-23 04:04:37.746549\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0086 Acc: 0.9990\n",
      "2022-01-23 04:04:40.136180\n",
      "validation Loss: 0.0797 Acc: 0.9767\n",
      "2022-01-23 04:04:40.483056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 0.9980\n",
      "2022-01-23 04:04:43.065365\n",
      "validation Loss: 0.0791 Acc: 0.9697\n",
      "2022-01-23 04:04:43.520824\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 0.9990\n",
      "2022-01-23 04:04:46.175712\n",
      "validation Loss: 0.0977 Acc: 0.9744\n",
      "2022-01-23 04:04:46.519388\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9965\n",
      "2022-01-23 04:04:49.011633\n",
      "validation Loss: 0.0842 Acc: 0.9697\n",
      "2022-01-23 04:04:49.410642\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0046 Acc: 0.9990\n",
      "2022-01-23 04:04:51.942071\n",
      "validation Loss: 0.0987 Acc: 0.9720\n",
      "2022-01-23 04:04:52.292050\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0266 Acc: 0.9900\n",
      "2022-01-23 04:04:54.849196\n",
      "validation Loss: 0.1344 Acc: 0.9580\n",
      "2022-01-23 04:04:55.268650\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0555 Acc: 0.9815\n",
      "2022-01-23 04:04:57.793679\n",
      "validation Loss: 0.0804 Acc: 0.9720\n",
      "2022-01-23 04:04:58.181792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0283 Acc: 0.9920\n",
      "2022-01-23 04:05:00.785853\n",
      "validation Loss: 0.0850 Acc: 0.9604\n",
      "2022-01-23 04:05:01.208960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0250 Acc: 0.9915\n",
      "2022-01-23 04:05:03.965516\n",
      "validation Loss: 0.0568 Acc: 0.9767\n",
      "2022-01-23 04:05:04.546647\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0130 Acc: 0.9950\n",
      "2022-01-23 04:05:07.165954\n",
      "validation Loss: 0.0640 Acc: 0.9767\n",
      "2022-01-23 04:05:07.544111\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0341 Acc: 0.9905\n",
      "2022-01-23 04:05:09.979105\n",
      "validation Loss: 0.0933 Acc: 0.9790\n",
      "2022-01-23 04:05:10.375262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9975\n",
      "2022-01-23 04:05:12.854511\n",
      "validation Loss: 0.0704 Acc: 0.9790\n",
      "2022-01-23 04:05:13.207441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0424 Acc: 0.9925\n",
      "2022-01-23 04:05:15.661146\n",
      "validation Loss: 0.2602 Acc: 0.9510\n",
      "2022-01-23 04:05:16.180175\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1479 Acc: 0.9635\n",
      "2022-01-23 04:05:18.757346\n",
      "validation Loss: 0.0802 Acc: 0.9790\n",
      "2022-01-23 04:05:19.131790\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0679 Acc: 0.9885\n",
      "2022-01-23 04:05:21.718586\n",
      "validation Loss: 0.0614 Acc: 0.9767\n",
      "2022-01-23 04:05:22.068790\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0159 Acc: 0.9950\n",
      "2022-01-23 04:05:24.684122\n",
      "validation Loss: 0.0584 Acc: 0.9837\n",
      "2022-01-23 04:05:25.063938\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0100 Acc: 0.9960\n",
      "2022-01-23 04:05:28.362554\n",
      "validation Loss: 0.0540 Acc: 0.9814\n",
      "2022-01-23 04:05:28.764458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0059 Acc: 0.9985\n",
      "2022-01-23 04:05:31.286511\n",
      "validation Loss: 0.0553 Acc: 0.9767\n",
      "2022-01-23 04:05:31.644653\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0056 Acc: 0.9985\n",
      "2022-01-23 04:05:34.227277\n",
      "validation Loss: 0.0520 Acc: 0.9883\n",
      "2022-01-23 04:05:34.577010\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 0.9985\n",
      "2022-01-23 04:05:37.738180\n",
      "validation Loss: 0.0584 Acc: 0.9837\n",
      "2022-01-23 04:05:38.200853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9980\n",
      "2022-01-23 04:05:40.930080\n",
      "validation Loss: 0.0673 Acc: 0.9790\n",
      "2022-01-23 04:05:41.274640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0023 Acc: 0.9990\n",
      "2022-01-23 04:05:43.874742\n",
      "validation Loss: 0.0800 Acc: 0.9767\n",
      "2022-01-23 04:05:44.363947\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 0.9995\n",
      "2022-01-23 04:05:46.924580\n",
      "validation Loss: 0.0557 Acc: 0.9790\n",
      "2022-01-23 04:05:47.283162\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 0.9990\n",
      "2022-01-23 04:05:49.782640\n",
      "validation Loss: 0.0749 Acc: 0.9790\n",
      "2022-01-23 04:05:50.174022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 0.9985\n",
      "2022-01-23 04:05:52.678954\n",
      "validation Loss: 0.0853 Acc: 0.9767\n",
      "2022-01-23 04:05:53.006067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 04:05:55.523198\n",
      "validation Loss: 0.0627 Acc: 0.9814\n",
      "2022-01-23 04:05:55.876625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:05:58.382881\n",
      "validation Loss: 0.0690 Acc: 0.9790\n",
      "2022-01-23 04:05:58.722416\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:06:01.205216\n",
      "validation Loss: 0.0673 Acc: 0.9814\n",
      "2022-01-23 04:06:01.555678\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:06:04.056537\n",
      "validation Loss: 0.0696 Acc: 0.9814\n",
      "2022-01-23 04:06:04.431773\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:06:06.983182\n",
      "validation Loss: 0.0739 Acc: 0.9790\n",
      "2022-01-23 04:06:07.479463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:06:09.959344\n",
      "validation Loss: 0.0759 Acc: 0.9790\n",
      "2022-01-23 04:06:10.324248\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:06:11.721759\n",
      "validation Loss: 0.0748 Acc: 0.9790\n",
      "2022-01-23 04:06:12.173404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:06:14.705900\n",
      "validation Loss: 0.0785 Acc: 0.9790\n",
      "2022-01-23 04:06:15.068931\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:06:17.655395\n",
      "validation Loss: 0.0790 Acc: 0.9790\n",
      "2022-01-23 04:06:18.057763\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:06:19.532111\n",
      "validation Loss: 0.0811 Acc: 0.9790\n",
      "2022-01-23 04:06:19.886064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:06:22.410188\n",
      "validation Loss: 0.0808 Acc: 0.9790\n",
      "2022-01-23 04:06:22.792053\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:06:25.229370\n",
      "validation Loss: 0.0825 Acc: 0.9790\n",
      "2022-01-23 04:06:25.800854\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:06:28.194068\n",
      "validation Loss: 0.0843 Acc: 0.9790\n",
      "2022-01-23 04:06:28.599784\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:06:31.177245\n",
      "validation Loss: 0.0852 Acc: 0.9790\n",
      "2022-01-23 04:06:31.544231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1olhfhiv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18573... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▇▇██████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇▇█▇██████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.97902</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.05197</td></tr><tr><td>loss_train</td><td>0.00011</td></tr><tr><td>loss_validation</td><td>0.08522</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1olhfhiv\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1olhfhiv</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_040128-1olhfhiv/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1olhfhiv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/8e9ouqsq\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 04:06:41.988003\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.9340 Acc: 0.0840\n",
      "2022-01-23 04:06:44.587432\n",
      "validation Loss: 2.7675 Acc: 0.1235\n",
      "2022-01-23 04:06:44.914828\n",
      "Accuracy of the network on the 429 test samples: 10.722610722610723\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.0366 Acc: 0.3835\n",
      "2022-01-23 04:06:47.631921\n",
      "validation Loss: 1.2637 Acc: 0.6830\n",
      "2022-01-23 04:06:48.133727\n",
      "Accuracy of the network on the 429 test samples: 69.23076923076923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.9635 Acc: 0.7635\n",
      "2022-01-23 04:06:51.242256\n",
      "validation Loss: 0.8867 Acc: 0.8065\n",
      "2022-01-23 04:06:51.705096\n",
      "Accuracy of the network on the 429 test samples: 82.28438228438229\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.6090 Acc: 0.8595\n",
      "2022-01-23 04:06:54.819198\n",
      "validation Loss: 0.6781 Acc: 0.8508\n",
      "2022-01-23 04:06:55.168818\n",
      "Accuracy of the network on the 429 test samples: 86.48018648018649\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4228 Acc: 0.8930\n",
      "2022-01-23 04:06:57.934650\n",
      "validation Loss: 0.4982 Acc: 0.9091\n",
      "2022-01-23 04:06:58.277081\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3362 Acc: 0.9110\n",
      "2022-01-23 04:07:01.223521\n",
      "validation Loss: 0.4034 Acc: 0.9184\n",
      "2022-01-23 04:07:01.632160\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2515 Acc: 0.9230\n",
      "2022-01-23 04:07:04.641780\n",
      "validation Loss: 0.3271 Acc: 0.9254\n",
      "2022-01-23 04:07:05.022862\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1898 Acc: 0.9455\n",
      "2022-01-23 04:07:07.858829\n",
      "validation Loss: 0.3289 Acc: 0.9277\n",
      "2022-01-23 04:07:08.288195\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1745 Acc: 0.9505\n",
      "2022-01-23 04:07:11.303232\n",
      "validation Loss: 0.3320 Acc: 0.9231\n",
      "2022-01-23 04:07:11.676208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2759 Acc: 0.9290\n",
      "2022-01-23 04:07:14.232071\n",
      "validation Loss: 0.3189 Acc: 0.9371\n",
      "2022-01-23 04:07:14.595521\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1646 Acc: 0.9560\n",
      "2022-01-23 04:07:17.497463\n",
      "validation Loss: 0.3270 Acc: 0.9277\n",
      "2022-01-23 04:07:17.979450\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1296 Acc: 0.9625\n",
      "2022-01-23 04:07:20.509508\n",
      "validation Loss: 0.3395 Acc: 0.9417\n",
      "2022-01-23 04:07:20.847219\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1457 Acc: 0.9560\n",
      "2022-01-23 04:07:23.677695\n",
      "validation Loss: 0.2563 Acc: 0.9441\n",
      "2022-01-23 04:07:24.054406\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1109 Acc: 0.9670\n",
      "2022-01-23 04:07:27.243333\n",
      "validation Loss: 0.2313 Acc: 0.9604\n",
      "2022-01-23 04:07:27.696689\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0947 Acc: 0.9725\n",
      "2022-01-23 04:07:30.990351\n",
      "validation Loss: 0.2437 Acc: 0.9580\n",
      "2022-01-23 04:07:31.417228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2972 Acc: 0.9380\n",
      "2022-01-23 04:07:33.941487\n",
      "validation Loss: 0.3005 Acc: 0.9347\n",
      "2022-01-23 04:07:34.316596\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1549 Acc: 0.9650\n",
      "2022-01-23 04:07:37.088003\n",
      "validation Loss: 0.3044 Acc: 0.9464\n",
      "2022-01-23 04:07:37.516676\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1016 Acc: 0.9700\n",
      "2022-01-23 04:07:40.068803\n",
      "validation Loss: 0.2602 Acc: 0.9441\n",
      "2022-01-23 04:07:40.463402\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0884 Acc: 0.9715\n",
      "2022-01-23 04:07:43.039711\n",
      "validation Loss: 0.2638 Acc: 0.9557\n",
      "2022-01-23 04:07:43.394199\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0752 Acc: 0.9780\n",
      "2022-01-23 04:07:45.877339\n",
      "validation Loss: 0.2572 Acc: 0.9557\n",
      "2022-01-23 04:07:46.219020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0779 Acc: 0.9730\n",
      "2022-01-23 04:07:48.759589\n",
      "validation Loss: 0.3254 Acc: 0.9604\n",
      "2022-01-23 04:07:49.123197\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0560 Acc: 0.9815\n",
      "2022-01-23 04:07:51.656594\n",
      "validation Loss: 0.3007 Acc: 0.9510\n",
      "2022-01-23 04:07:52.011115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0727 Acc: 0.9770\n",
      "2022-01-23 04:07:54.549578\n",
      "validation Loss: 0.2836 Acc: 0.9604\n",
      "2022-01-23 04:07:54.900869\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0562 Acc: 0.9825\n",
      "2022-01-23 04:07:57.495177\n",
      "validation Loss: 0.3033 Acc: 0.9650\n",
      "2022-01-23 04:07:57.849920\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0624 Acc: 0.9825\n",
      "2022-01-23 04:08:00.883732\n",
      "validation Loss: 0.3448 Acc: 0.9604\n",
      "2022-01-23 04:08:01.279561\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0523 Acc: 0.9830\n",
      "2022-01-23 04:08:03.718330\n",
      "validation Loss: 0.2196 Acc: 0.9604\n",
      "2022-01-23 04:08:04.088550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0464 Acc: 0.9865\n",
      "2022-01-23 04:08:06.630412\n",
      "validation Loss: 0.2775 Acc: 0.9674\n",
      "2022-01-23 04:08:07.004759\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0369 Acc: 0.9890\n",
      "2022-01-23 04:08:09.906985\n",
      "validation Loss: 0.3091 Acc: 0.9604\n",
      "2022-01-23 04:08:10.352216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0315 Acc: 0.9900\n",
      "2022-01-23 04:08:12.866651\n",
      "validation Loss: 0.3635 Acc: 0.9674\n",
      "2022-01-23 04:08:13.238578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9810\n",
      "2022-01-23 04:08:15.775072\n",
      "validation Loss: 0.3168 Acc: 0.9604\n",
      "2022-01-23 04:08:16.330324\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0848 Acc: 0.9805\n",
      "2022-01-23 04:08:19.040947\n",
      "validation Loss: 1.3372 Acc: 0.8089\n",
      "2022-01-23 04:08:19.423446\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3912 Acc: 0.9020\n",
      "2022-01-23 04:08:21.916658\n",
      "validation Loss: 0.2162 Acc: 0.9580\n",
      "2022-01-23 04:08:22.291233\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1439 Acc: 0.9610\n",
      "2022-01-23 04:08:24.961382\n",
      "validation Loss: 0.1772 Acc: 0.9557\n",
      "2022-01-23 04:08:25.412698\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0929 Acc: 0.9745\n",
      "2022-01-23 04:08:28.201657\n",
      "validation Loss: 0.1950 Acc: 0.9534\n",
      "2022-01-23 04:08:28.658046\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0643 Acc: 0.9775\n",
      "2022-01-23 04:08:31.375326\n",
      "validation Loss: 0.1731 Acc: 0.9557\n",
      "2022-01-23 04:08:31.888485\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0492 Acc: 0.9820\n",
      "2022-01-23 04:08:34.436418\n",
      "validation Loss: 0.1893 Acc: 0.9604\n",
      "2022-01-23 04:08:34.868974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0431 Acc: 0.9840\n",
      "2022-01-23 04:08:37.356003\n",
      "validation Loss: 0.2478 Acc: 0.9650\n",
      "2022-01-23 04:08:37.704252\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0363 Acc: 0.9870\n",
      "2022-01-23 04:08:40.355710\n",
      "validation Loss: 0.3173 Acc: 0.9674\n",
      "2022-01-23 04:08:40.753783\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0348 Acc: 0.9880\n",
      "2022-01-23 04:08:43.162282\n",
      "validation Loss: 0.2921 Acc: 0.9674\n",
      "2022-01-23 04:08:43.593106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0431 Acc: 0.9845\n",
      "2022-01-23 04:08:46.149436\n",
      "validation Loss: 0.2280 Acc: 0.9650\n",
      "2022-01-23 04:08:46.535362\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0328 Acc: 0.9865\n",
      "2022-01-23 04:08:48.906008\n",
      "validation Loss: 0.2543 Acc: 0.9720\n",
      "2022-01-23 04:08:49.353446\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0265 Acc: 0.9900\n",
      "2022-01-23 04:08:52.300035\n",
      "validation Loss: 0.2925 Acc: 0.9674\n",
      "2022-01-23 04:08:52.700292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0432 Acc: 0.9865\n",
      "2022-01-23 04:08:55.132695\n",
      "validation Loss: 0.2828 Acc: 0.9720\n",
      "2022-01-23 04:08:55.491288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 04:08:58.016697\n",
      "validation Loss: 0.2321 Acc: 0.9720\n",
      "2022-01-23 04:08:58.553312\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0271 Acc: 0.9905\n",
      "2022-01-23 04:09:01.377532\n",
      "validation Loss: 0.2511 Acc: 0.9720\n",
      "2022-01-23 04:09:01.745353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0214 Acc: 0.9940\n",
      "2022-01-23 04:09:04.238958\n",
      "validation Loss: 0.2886 Acc: 0.9720\n",
      "2022-01-23 04:09:04.630625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0180 Acc: 0.9930\n",
      "2022-01-23 04:09:06.972547\n",
      "validation Loss: 0.2934 Acc: 0.9744\n",
      "2022-01-23 04:09:07.425830\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0205 Acc: 0.9925\n",
      "2022-01-23 04:09:10.430567\n",
      "validation Loss: 0.3518 Acc: 0.9697\n",
      "2022-01-23 04:09:10.802400\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0191 Acc: 0.9925\n",
      "2022-01-23 04:09:13.240554\n",
      "validation Loss: 0.3978 Acc: 0.9627\n",
      "2022-01-23 04:09:13.589399\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0197 Acc: 0.9935\n",
      "2022-01-23 04:09:16.168684\n",
      "validation Loss: 0.3754 Acc: 0.9674\n",
      "2022-01-23 04:09:16.545274\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0170 Acc: 0.9940\n",
      "2022-01-23 04:09:19.244103\n",
      "validation Loss: 0.5126 Acc: 0.9720\n",
      "2022-01-23 04:09:19.599321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0186 Acc: 0.9935\n",
      "2022-01-23 04:09:22.109434\n",
      "validation Loss: 0.4633 Acc: 0.9744\n",
      "2022-01-23 04:09:22.490338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0185 Acc: 0.9935\n",
      "2022-01-23 04:09:25.255671\n",
      "validation Loss: 0.3492 Acc: 0.9697\n",
      "2022-01-23 04:09:25.743614\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0188 Acc: 0.9940\n",
      "2022-01-23 04:09:28.239340\n",
      "validation Loss: 0.3872 Acc: 0.9697\n",
      "2022-01-23 04:09:28.583011\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0096 Acc: 0.9975\n",
      "2022-01-23 04:09:31.104825\n",
      "validation Loss: 0.4239 Acc: 0.9744\n",
      "2022-01-23 04:09:31.458381\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 0.9940\n",
      "2022-01-23 04:09:34.036127\n",
      "validation Loss: 0.4685 Acc: 0.9650\n",
      "2022-01-23 04:09:34.450101\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0339 Acc: 0.9915\n",
      "2022-01-23 04:09:37.053611\n",
      "validation Loss: 0.3811 Acc: 0.9697\n",
      "2022-01-23 04:09:37.408024\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0667 Acc: 0.9830\n",
      "2022-01-23 04:09:38.861198\n",
      "validation Loss: 0.3493 Acc: 0.9604\n",
      "2022-01-23 04:09:39.204681\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0532 Acc: 0.9875\n",
      "2022-01-23 04:09:41.805008\n",
      "validation Loss: 0.3112 Acc: 0.9744\n",
      "2022-01-23 04:09:42.157476\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0166 Acc: 0.9950\n",
      "2022-01-23 04:09:44.859777\n",
      "validation Loss: 0.3019 Acc: 0.9627\n",
      "2022-01-23 04:09:45.259168\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0167 Acc: 0.9940\n",
      "2022-01-23 04:09:47.891798\n",
      "validation Loss: 0.3512 Acc: 0.9744\n",
      "2022-01-23 04:09:48.318332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0168 Acc: 0.9950\n",
      "2022-01-23 04:09:50.881512\n",
      "validation Loss: 0.3529 Acc: 0.9790\n",
      "2022-01-23 04:09:51.244946\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9970\n",
      "2022-01-23 04:09:54.307739\n",
      "validation Loss: 0.4267 Acc: 0.9790\n",
      "2022-01-23 04:09:54.699641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0138 Acc: 0.9940\n",
      "2022-01-23 04:09:57.540262\n",
      "validation Loss: 0.4534 Acc: 0.9697\n",
      "2022-01-23 04:09:57.985434\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0105 Acc: 0.9965\n",
      "2022-01-23 04:10:00.644594\n",
      "validation Loss: 0.4458 Acc: 0.9790\n",
      "2022-01-23 04:10:01.034825\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0779 Acc: 0.9815\n",
      "2022-01-23 04:10:03.611428\n",
      "validation Loss: 0.1823 Acc: 0.9627\n",
      "2022-01-23 04:10:03.968267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0456 Acc: 0.9870\n",
      "2022-01-23 04:10:06.468866\n",
      "validation Loss: 0.2483 Acc: 0.9604\n",
      "2022-01-23 04:10:06.842420\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0383 Acc: 0.9875\n",
      "2022-01-23 04:10:09.367877\n",
      "validation Loss: 0.1548 Acc: 0.9767\n",
      "2022-01-23 04:10:09.817042\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0288 Acc: 0.9930\n",
      "2022-01-23 04:10:12.396609\n",
      "validation Loss: 0.1464 Acc: 0.9744\n",
      "2022-01-23 04:10:12.746340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0186 Acc: 0.9945\n",
      "2022-01-23 04:10:15.248504\n",
      "validation Loss: 0.1608 Acc: 0.9767\n",
      "2022-01-23 04:10:15.612411\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0179 Acc: 0.9940\n",
      "2022-01-23 04:10:18.081758\n",
      "validation Loss: 0.1772 Acc: 0.9697\n",
      "2022-01-23 04:10:18.563499\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0148 Acc: 0.9920\n",
      "2022-01-23 04:10:21.146420\n",
      "validation Loss: 0.2263 Acc: 0.9720\n",
      "2022-01-23 04:10:21.515947\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0109 Acc: 0.9965\n",
      "2022-01-23 04:10:24.020915\n",
      "validation Loss: 0.2633 Acc: 0.9767\n",
      "2022-01-23 04:10:24.382912\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9980\n",
      "2022-01-23 04:10:26.882144\n",
      "validation Loss: 0.2833 Acc: 0.9720\n",
      "2022-01-23 04:10:27.246333\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9970\n",
      "2022-01-23 04:10:29.871552\n",
      "validation Loss: 0.2976 Acc: 0.9744\n",
      "2022-01-23 04:10:30.276881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 0.9985\n",
      "2022-01-23 04:10:32.793754\n",
      "validation Loss: 0.3242 Acc: 0.9767\n",
      "2022-01-23 04:10:33.190585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9960\n",
      "2022-01-23 04:10:35.923153\n",
      "validation Loss: 0.3823 Acc: 0.9790\n",
      "2022-01-23 04:10:36.337885\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0044 Acc: 0.9995\n",
      "2022-01-23 04:10:38.884840\n",
      "validation Loss: 0.3848 Acc: 0.9790\n",
      "2022-01-23 04:10:39.265216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 0.9980\n",
      "2022-01-23 04:10:41.794549\n",
      "validation Loss: 0.4370 Acc: 0.9790\n",
      "2022-01-23 04:10:42.129962\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 0.9975\n",
      "2022-01-23 04:10:44.615787\n",
      "validation Loss: 0.4496 Acc: 0.9744\n",
      "2022-01-23 04:10:44.961831\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0350 Acc: 0.9925\n",
      "2022-01-23 04:10:47.511820\n",
      "validation Loss: 0.3523 Acc: 0.9650\n",
      "2022-01-23 04:10:47.893849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1577 Acc: 0.9730\n",
      "2022-01-23 04:10:50.500195\n",
      "validation Loss: 0.1728 Acc: 0.9720\n",
      "2022-01-23 04:10:50.846161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0406 Acc: 0.9890\n",
      "2022-01-23 04:10:53.333075\n",
      "validation Loss: 0.2033 Acc: 0.9814\n",
      "2022-01-23 04:10:53.678454\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0179 Acc: 0.9960\n",
      "2022-01-23 04:10:56.639086\n",
      "validation Loss: 0.2549 Acc: 0.9744\n",
      "2022-01-23 04:10:57.096629\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0120 Acc: 0.9975\n",
      "2022-01-23 04:10:59.508194\n",
      "validation Loss: 0.3134 Acc: 0.9767\n",
      "2022-01-23 04:10:59.863563\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0090 Acc: 0.9975\n",
      "2022-01-23 04:11:02.335128\n",
      "validation Loss: 0.3932 Acc: 0.9814\n",
      "2022-01-23 04:11:02.662287\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0090 Acc: 0.9975\n",
      "2022-01-23 04:11:05.207106\n",
      "validation Loss: 0.4442 Acc: 0.9814\n",
      "2022-01-23 04:11:05.560196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9960\n",
      "2022-01-23 04:11:08.049349\n",
      "validation Loss: 0.4379 Acc: 0.9767\n",
      "2022-01-23 04:11:08.440411\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 0.9965\n",
      "2022-01-23 04:11:10.862454\n",
      "validation Loss: 0.4813 Acc: 0.9814\n",
      "2022-01-23 04:11:11.258448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 0.9985\n",
      "2022-01-23 04:11:13.695293\n",
      "validation Loss: 0.5421 Acc: 0.9814\n",
      "2022-01-23 04:11:14.119580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1253 Acc: 0.9770\n",
      "2022-01-23 04:11:16.534670\n",
      "validation Loss: 0.3214 Acc: 0.9464\n",
      "2022-01-23 04:11:16.989562\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0757 Acc: 0.9785\n",
      "2022-01-23 04:11:19.413889\n",
      "validation Loss: 0.1448 Acc: 0.9650\n",
      "2022-01-23 04:11:19.784150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0408 Acc: 0.9855\n",
      "2022-01-23 04:11:22.316693\n",
      "validation Loss: 0.2326 Acc: 0.9604\n",
      "2022-01-23 04:11:22.749851\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0359 Acc: 0.9905\n",
      "2022-01-23 04:11:25.297001\n",
      "validation Loss: 0.1948 Acc: 0.9697\n",
      "2022-01-23 04:11:25.674586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0174 Acc: 0.9960\n",
      "2022-01-23 04:11:28.266644\n",
      "validation Loss: 0.2549 Acc: 0.9720\n",
      "2022-01-23 04:11:28.608568\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9950\n",
      "2022-01-23 04:11:31.173301\n",
      "validation Loss: 0.3005 Acc: 0.9720\n",
      "2022-01-23 04:11:31.509230\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9980\n",
      "2022-01-23 04:11:34.067528\n",
      "validation Loss: 0.3130 Acc: 0.9744\n",
      "2022-01-23 04:11:34.408439\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9985\n",
      "2022-01-23 04:11:37.082215\n",
      "validation Loss: 0.3596 Acc: 0.9744\n",
      "2022-01-23 04:11:37.554209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9990\n",
      "2022-01-23 04:11:40.274343\n",
      "validation Loss: 0.3716 Acc: 0.9744\n",
      "2022-01-23 04:11:40.826621\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0129 Acc: 0.9950\n",
      "2022-01-23 04:11:43.495059\n",
      "validation Loss: 0.3129 Acc: 0.9790\n",
      "2022-01-23 04:11:43.864259\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9814\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8e9ouqsq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10974... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇▇▇██████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇█████████▇███████████████████████████</td></tr><tr><td>loss_train</td><td>█▃▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▂▂▂▂▁▂▂▁▁▁▁▂▂▁▁▂▂▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98135</td></tr><tr><td>accuracy_train</td><td>0.995</td></tr><tr><td>accuracy_validation</td><td>0.97902</td></tr><tr><td>best_test_accuracy</td><td>0.98135</td></tr><tr><td>best_val_accuracy</td><td>0.98135</td></tr><tr><td>best_val_loss</td><td>0.20327</td></tr><tr><td>loss_train</td><td>0.01291</td></tr><tr><td>loss_validation</td><td>0.31293</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/8e9ouqsq\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/8e9ouqsq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_040631-8e9ouqsq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8e9ouqsq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2xyxji94\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 04:11:53.813784\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 3.0042 Acc: 0.0465\n",
      "2022-01-23 04:11:56.392060\n",
      "validation Loss: 2.9958 Acc: 0.0466\n",
      "2022-01-23 04:11:56.831662\n",
      "Accuracy of the network on the 429 test samples: 4.662004662004662\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9865 Acc: 0.0465\n",
      "2022-01-23 04:11:59.885217\n",
      "validation Loss: 2.9765 Acc: 0.0466\n",
      "2022-01-23 04:12:00.225557\n",
      "Accuracy of the network on the 429 test samples: 4.662004662004662\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9586 Acc: 0.1015\n",
      "2022-01-23 04:12:03.168724\n",
      "validation Loss: 2.9366 Acc: 0.1702\n",
      "2022-01-23 04:12:03.512342\n",
      "Accuracy of the network on the 429 test samples: 14.219114219114218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8799 Acc: 0.1870\n",
      "2022-01-23 04:12:06.385998\n",
      "validation Loss: 2.7988 Acc: 0.2121\n",
      "2022-01-23 04:12:06.740695\n",
      "Accuracy of the network on the 429 test samples: 20.04662004662005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6294 Acc: 0.2215\n",
      "2022-01-23 04:12:09.549408\n",
      "validation Loss: 2.4484 Acc: 0.2634\n",
      "2022-01-23 04:12:09.913092\n",
      "Accuracy of the network on the 429 test samples: 23.310023310023308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1713 Acc: 0.3035\n",
      "2022-01-23 04:12:12.948501\n",
      "validation Loss: 1.9016 Acc: 0.3730\n",
      "2022-01-23 04:12:13.304258\n",
      "Accuracy of the network on the 429 test samples: 40.0932400932401\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5998 Acc: 0.5145\n",
      "2022-01-23 04:12:16.243313\n",
      "validation Loss: 1.4639 Acc: 0.6503\n",
      "2022-01-23 04:12:16.649730\n",
      "Accuracy of the network on the 429 test samples: 65.5011655011655\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2771 Acc: 0.6890\n",
      "2022-01-23 04:12:19.779474\n",
      "validation Loss: 1.2392 Acc: 0.7343\n",
      "2022-01-23 04:12:20.134242\n",
      "Accuracy of the network on the 429 test samples: 73.65967365967366\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0766 Acc: 0.7390\n",
      "2022-01-23 04:12:22.955857\n",
      "validation Loss: 1.1411 Acc: 0.7669\n",
      "2022-01-23 04:12:23.471795\n",
      "Accuracy of the network on the 429 test samples: 74.5920745920746\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9290 Acc: 0.7705\n",
      "2022-01-23 04:12:26.482389\n",
      "validation Loss: 0.9923 Acc: 0.8205\n",
      "2022-01-23 04:12:26.858942\n",
      "Accuracy of the network on the 429 test samples: 79.25407925407926\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7930 Acc: 0.8010\n",
      "2022-01-23 04:12:29.823108\n",
      "validation Loss: 0.9488 Acc: 0.8415\n",
      "2022-01-23 04:12:30.228616\n",
      "Accuracy of the network on the 429 test samples: 79.48717948717949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7262 Acc: 0.8155\n",
      "2022-01-23 04:12:33.126175\n",
      "validation Loss: 0.9058 Acc: 0.8392\n",
      "2022-01-23 04:12:33.514192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6543 Acc: 0.8300\n",
      "2022-01-23 04:12:36.057176\n",
      "validation Loss: 0.8095 Acc: 0.8392\n",
      "2022-01-23 04:12:36.414801\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5979 Acc: 0.8445\n",
      "2022-01-23 04:12:39.010702\n",
      "validation Loss: 0.7259 Acc: 0.8578\n",
      "2022-01-23 04:12:39.477256\n",
      "Accuracy of the network on the 429 test samples: 82.98368298368298\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5304 Acc: 0.8570\n",
      "2022-01-23 04:12:42.296733\n",
      "validation Loss: 0.7237 Acc: 0.8625\n",
      "2022-01-23 04:12:42.644846\n",
      "Accuracy of the network on the 429 test samples: 84.84848484848484\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4971 Acc: 0.8665\n",
      "2022-01-23 04:12:45.539887\n",
      "validation Loss: 0.7117 Acc: 0.8625\n",
      "2022-01-23 04:12:46.028922\n",
      "Accuracy of the network on the 429 test samples: 86.94638694638695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5586 Acc: 0.8635\n",
      "2022-01-23 04:12:48.896950\n",
      "validation Loss: 0.7510 Acc: 0.8485\n",
      "2022-01-23 04:12:49.248037\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4968 Acc: 0.8830\n",
      "2022-01-23 04:12:51.734890\n",
      "validation Loss: 0.6629 Acc: 0.8695\n",
      "2022-01-23 04:12:52.100818\n",
      "Accuracy of the network on the 429 test samples: 85.3146853146853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4342 Acc: 0.8885\n",
      "2022-01-23 04:12:55.221848\n",
      "validation Loss: 0.6337 Acc: 0.8951\n",
      "2022-01-23 04:12:55.569764\n",
      "Accuracy of the network on the 429 test samples: 87.17948717948718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4024 Acc: 0.8970\n",
      "2022-01-23 04:12:58.533336\n",
      "validation Loss: 0.6375 Acc: 0.8951\n",
      "2022-01-23 04:12:58.907551\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3853 Acc: 0.9015\n",
      "2022-01-23 04:13:01.355209\n",
      "validation Loss: 0.5996 Acc: 0.8951\n",
      "2022-01-23 04:13:01.724638\n",
      "Accuracy of the network on the 429 test samples: 88.57808857808858\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3549 Acc: 0.9130\n",
      "2022-01-23 04:13:04.686852\n",
      "validation Loss: 0.5929 Acc: 0.8974\n",
      "2022-01-23 04:13:05.068440\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3394 Acc: 0.9140\n",
      "2022-01-23 04:13:07.034892\n",
      "validation Loss: 0.5906 Acc: 0.8998\n",
      "2022-01-23 04:13:07.432825\n",
      "Accuracy of the network on the 429 test samples: 89.5104895104895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3235 Acc: 0.9170\n",
      "2022-01-23 04:13:10.278222\n",
      "validation Loss: 0.5843 Acc: 0.9044\n",
      "2022-01-23 04:13:10.617029\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3019 Acc: 0.9235\n",
      "2022-01-23 04:13:13.429993\n",
      "validation Loss: 0.5260 Acc: 0.9138\n",
      "2022-01-23 04:13:13.896261\n",
      "Accuracy of the network on the 429 test samples: 89.5104895104895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2986 Acc: 0.9260\n",
      "2022-01-23 04:13:16.745428\n",
      "validation Loss: 0.5396 Acc: 0.9138\n",
      "2022-01-23 04:13:17.093967\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2750 Acc: 0.9315\n",
      "2022-01-23 04:13:19.529339\n",
      "validation Loss: 0.5323 Acc: 0.9207\n",
      "2022-01-23 04:13:19.878007\n",
      "Accuracy of the network on the 429 test samples: 91.14219114219114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2671 Acc: 0.9325\n",
      "2022-01-23 04:13:22.748049\n",
      "validation Loss: 0.5362 Acc: 0.9231\n",
      "2022-01-23 04:13:23.182597\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2457 Acc: 0.9335\n",
      "2022-01-23 04:13:25.997062\n",
      "validation Loss: 0.5370 Acc: 0.9184\n",
      "2022-01-23 04:13:26.444598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2383 Acc: 0.9380\n",
      "2022-01-23 04:13:28.920477\n",
      "validation Loss: 0.5531 Acc: 0.9184\n",
      "2022-01-23 04:13:29.272522\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2226 Acc: 0.9365\n",
      "2022-01-23 04:13:31.791086\n",
      "validation Loss: 0.5015 Acc: 0.9207\n",
      "2022-01-23 04:13:32.352607\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2130 Acc: 0.9425\n",
      "2022-01-23 04:13:34.879432\n",
      "validation Loss: 0.5000 Acc: 0.9231\n",
      "2022-01-23 04:13:35.248280\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2019 Acc: 0.9435\n",
      "2022-01-23 04:13:38.237023\n",
      "validation Loss: 0.5495 Acc: 0.9254\n",
      "2022-01-23 04:13:38.633411\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1951 Acc: 0.9445\n",
      "2022-01-23 04:13:41.580774\n",
      "validation Loss: 0.5238 Acc: 0.9254\n",
      "2022-01-23 04:13:42.060543\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1933 Acc: 0.9460\n",
      "2022-01-23 04:13:44.887397\n",
      "validation Loss: 0.5051 Acc: 0.9324\n",
      "2022-01-23 04:13:45.247154\n",
      "Accuracy of the network on the 429 test samples: 92.3076923076923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1830 Acc: 0.9460\n",
      "2022-01-23 04:13:48.187308\n",
      "validation Loss: 0.5576 Acc: 0.9324\n",
      "2022-01-23 04:13:48.546478\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1882 Acc: 0.9480\n",
      "2022-01-23 04:13:51.126949\n",
      "validation Loss: 0.4971 Acc: 0.9347\n",
      "2022-01-23 04:13:51.480089\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1606 Acc: 0.9560\n",
      "2022-01-23 04:13:54.460740\n",
      "validation Loss: 0.4836 Acc: 0.9417\n",
      "2022-01-23 04:13:54.808107\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1507 Acc: 0.9585\n",
      "2022-01-23 04:13:57.764871\n",
      "validation Loss: 0.4856 Acc: 0.9394\n",
      "2022-01-23 04:13:58.358545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2107 Acc: 0.9480\n",
      "2022-01-23 04:14:01.026697\n",
      "validation Loss: 0.8034 Acc: 0.8788\n",
      "2022-01-23 04:14:01.382668\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2985 Acc: 0.9175\n",
      "2022-01-23 04:14:03.926786\n",
      "validation Loss: 0.5217 Acc: 0.9184\n",
      "2022-01-23 04:14:04.334662\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1863 Acc: 0.9525\n",
      "2022-01-23 04:14:06.854625\n",
      "validation Loss: 0.4920 Acc: 0.9394\n",
      "2022-01-23 04:14:07.264669\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1584 Acc: 0.9615\n",
      "2022-01-23 04:14:09.775483\n",
      "validation Loss: 0.4917 Acc: 0.9324\n",
      "2022-01-23 04:14:10.307590\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1506 Acc: 0.9610\n",
      "2022-01-23 04:14:11.642908\n",
      "validation Loss: 0.4504 Acc: 0.9441\n",
      "2022-01-23 04:14:12.034694\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1449 Acc: 0.9630\n",
      "2022-01-23 04:14:15.150359\n",
      "validation Loss: 0.4518 Acc: 0.9464\n",
      "2022-01-23 04:14:15.528936\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1312 Acc: 0.9650\n",
      "2022-01-23 04:14:18.362680\n",
      "validation Loss: 0.4848 Acc: 0.9301\n",
      "2022-01-23 04:14:18.727907\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1265 Acc: 0.9640\n",
      "2022-01-23 04:14:21.255226\n",
      "validation Loss: 0.4648 Acc: 0.9510\n",
      "2022-01-23 04:14:21.835721\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1183 Acc: 0.9635\n",
      "2022-01-23 04:14:24.920211\n",
      "validation Loss: 0.4691 Acc: 0.9441\n",
      "2022-01-23 04:14:25.268971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1209 Acc: 0.9685\n",
      "2022-01-23 04:14:27.845149\n",
      "validation Loss: 0.4564 Acc: 0.9464\n",
      "2022-01-23 04:14:28.188295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1247 Acc: 0.9665\n",
      "2022-01-23 04:14:30.716640\n",
      "validation Loss: 0.5628 Acc: 0.9394\n",
      "2022-01-23 04:14:31.294575\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1288 Acc: 0.9655\n",
      "2022-01-23 04:14:33.903502\n",
      "validation Loss: 0.5347 Acc: 0.9417\n",
      "2022-01-23 04:14:34.279816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1150 Acc: 0.9685\n",
      "2022-01-23 04:14:36.758430\n",
      "validation Loss: 0.4840 Acc: 0.9510\n",
      "2022-01-23 04:14:37.172520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1085 Acc: 0.9695\n",
      "2022-01-23 04:14:39.687989\n",
      "validation Loss: 0.5189 Acc: 0.9371\n",
      "2022-01-23 04:14:40.024177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1076 Acc: 0.9690\n",
      "2022-01-23 04:14:42.622222\n",
      "validation Loss: 0.6996 Acc: 0.9184\n",
      "2022-01-23 04:14:43.185303\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1148 Acc: 0.9630\n",
      "2022-01-23 04:14:45.717653\n",
      "validation Loss: 0.4904 Acc: 0.9487\n",
      "2022-01-23 04:14:46.187588\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0950 Acc: 0.9755\n",
      "2022-01-23 04:14:48.823503\n",
      "validation Loss: 0.4928 Acc: 0.9487\n",
      "2022-01-23 04:14:49.181514\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1007 Acc: 0.9700\n",
      "2022-01-23 04:14:51.691484\n",
      "validation Loss: 0.4544 Acc: 0.9510\n",
      "2022-01-23 04:14:52.071015\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0908 Acc: 0.9760\n",
      "2022-01-23 04:14:55.182587\n",
      "validation Loss: 0.5012 Acc: 0.9510\n",
      "2022-01-23 04:14:55.543006\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0822 Acc: 0.9780\n",
      "2022-01-23 04:14:58.058214\n",
      "validation Loss: 0.5230 Acc: 0.9487\n",
      "2022-01-23 04:14:58.458638\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0909 Acc: 0.9725\n",
      "2022-01-23 04:15:00.988079\n",
      "validation Loss: 0.5071 Acc: 0.9510\n",
      "2022-01-23 04:15:01.367405\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0789 Acc: 0.9760\n",
      "2022-01-23 04:15:03.913697\n",
      "validation Loss: 0.5254 Acc: 0.9487\n",
      "2022-01-23 04:15:04.356715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0812 Acc: 0.9770\n",
      "2022-01-23 04:15:06.862770\n",
      "validation Loss: 0.5177 Acc: 0.9557\n",
      "2022-01-23 04:15:07.275141\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0747 Acc: 0.9810\n",
      "2022-01-23 04:15:10.343823\n",
      "validation Loss: 0.5412 Acc: 0.9510\n",
      "2022-01-23 04:15:10.713001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0733 Acc: 0.9800\n",
      "2022-01-23 04:15:13.688646\n",
      "validation Loss: 0.5453 Acc: 0.9534\n",
      "2022-01-23 04:15:14.141709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0692 Acc: 0.9790\n",
      "2022-01-23 04:15:16.908682\n",
      "validation Loss: 0.5840 Acc: 0.9510\n",
      "2022-01-23 04:15:17.274778\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0752 Acc: 0.9780\n",
      "2022-01-23 04:15:19.017444\n",
      "validation Loss: 0.5769 Acc: 0.9487\n",
      "2022-01-23 04:15:19.428917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0816 Acc: 0.9785\n",
      "2022-01-23 04:15:22.063880\n",
      "validation Loss: 0.5278 Acc: 0.9464\n",
      "2022-01-23 04:15:22.418464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3965 Acc: 0.9380\n",
      "2022-01-23 04:15:24.979536\n",
      "validation Loss: 0.7837 Acc: 0.8904\n",
      "2022-01-23 04:15:25.447441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2164 Acc: 0.9510\n",
      "2022-01-23 04:15:27.972831\n",
      "validation Loss: 0.5360 Acc: 0.9394\n",
      "2022-01-23 04:15:28.300530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1174 Acc: 0.9715\n",
      "2022-01-23 04:15:30.793088\n",
      "validation Loss: 0.4999 Acc: 0.9534\n",
      "2022-01-23 04:15:31.170124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1020 Acc: 0.9760\n",
      "2022-01-23 04:15:33.615166\n",
      "validation Loss: 0.5034 Acc: 0.9487\n",
      "2022-01-23 04:15:33.969976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0967 Acc: 0.9750\n",
      "2022-01-23 04:15:36.447575\n",
      "validation Loss: 0.4617 Acc: 0.9487\n",
      "2022-01-23 04:15:36.942995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0905 Acc: 0.9780\n",
      "2022-01-23 04:15:39.534330\n",
      "validation Loss: 0.4706 Acc: 0.9464\n",
      "2022-01-23 04:15:39.861859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0808 Acc: 0.9810\n",
      "2022-01-23 04:15:42.422681\n",
      "validation Loss: 0.4650 Acc: 0.9510\n",
      "2022-01-23 04:15:42.798791\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0801 Acc: 0.9775\n",
      "2022-01-23 04:15:45.196218\n",
      "validation Loss: 0.5006 Acc: 0.9557\n",
      "2022-01-23 04:15:45.561004\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0875 Acc: 0.9785\n",
      "2022-01-23 04:15:48.577814\n",
      "validation Loss: 0.4629 Acc: 0.9534\n",
      "2022-01-23 04:15:48.933391\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0732 Acc: 0.9805\n",
      "2022-01-23 04:15:51.388777\n",
      "validation Loss: 0.4860 Acc: 0.9487\n",
      "2022-01-23 04:15:51.752267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0683 Acc: 0.9815\n",
      "2022-01-23 04:15:54.290835\n",
      "validation Loss: 0.4715 Acc: 0.9534\n",
      "2022-01-23 04:15:54.641436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0643 Acc: 0.9825\n",
      "2022-01-23 04:15:57.077914\n",
      "validation Loss: 0.4698 Acc: 0.9487\n",
      "2022-01-23 04:15:57.442713\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0645 Acc: 0.9815\n",
      "2022-01-23 04:15:59.899698\n",
      "validation Loss: 0.4977 Acc: 0.9464\n",
      "2022-01-23 04:16:00.357154\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0635 Acc: 0.9810\n",
      "2022-01-23 04:16:02.974847\n",
      "validation Loss: 0.5019 Acc: 0.9417\n",
      "2022-01-23 04:16:03.359277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0676 Acc: 0.9795\n",
      "2022-01-23 04:16:05.791074\n",
      "validation Loss: 0.4992 Acc: 0.9441\n",
      "2022-01-23 04:16:06.135050\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0602 Acc: 0.9850\n",
      "2022-01-23 04:16:08.682916\n",
      "validation Loss: 0.4924 Acc: 0.9464\n",
      "2022-01-23 04:16:09.155403\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0571 Acc: 0.9855\n",
      "2022-01-23 04:16:11.664564\n",
      "validation Loss: 0.4849 Acc: 0.9534\n",
      "2022-01-23 04:16:12.042752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0560 Acc: 0.9855\n",
      "2022-01-23 04:16:14.461720\n",
      "validation Loss: 0.5283 Acc: 0.9510\n",
      "2022-01-23 04:16:14.856282\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0534 Acc: 0.9860\n",
      "2022-01-23 04:16:17.383717\n",
      "validation Loss: 0.4990 Acc: 0.9464\n",
      "2022-01-23 04:16:17.764192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0526 Acc: 0.9860\n",
      "2022-01-23 04:16:20.271435\n",
      "validation Loss: 0.5427 Acc: 0.9464\n",
      "2022-01-23 04:16:20.682886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0632 Acc: 0.9820\n",
      "2022-01-23 04:16:23.092410\n",
      "validation Loss: 0.5134 Acc: 0.9441\n",
      "2022-01-23 04:16:23.434104\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0534 Acc: 0.9860\n",
      "2022-01-23 04:16:25.990811\n",
      "validation Loss: 0.5291 Acc: 0.9464\n",
      "2022-01-23 04:16:26.364639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0501 Acc: 0.9860\n",
      "2022-01-23 04:16:28.919045\n",
      "validation Loss: 0.4894 Acc: 0.9534\n",
      "2022-01-23 04:16:29.291106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0473 Acc: 0.9875\n",
      "2022-01-23 04:16:31.771985\n",
      "validation Loss: 0.4990 Acc: 0.9557\n",
      "2022-01-23 04:16:32.242898\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0746 Acc: 0.9820\n",
      "2022-01-23 04:16:35.084149\n",
      "validation Loss: 0.5020 Acc: 0.9557\n",
      "2022-01-23 04:16:35.433260\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0484 Acc: 0.9875\n",
      "2022-01-23 04:16:38.117469\n",
      "validation Loss: 0.4767 Acc: 0.9534\n",
      "2022-01-23 04:16:38.606437\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0454 Acc: 0.9895\n",
      "2022-01-23 04:16:41.210226\n",
      "validation Loss: 0.4715 Acc: 0.9557\n",
      "2022-01-23 04:16:41.656134\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0439 Acc: 0.9890\n",
      "2022-01-23 04:16:44.825373\n",
      "validation Loss: 0.5049 Acc: 0.9534\n",
      "2022-01-23 04:16:45.304902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0442 Acc: 0.9900\n",
      "2022-01-23 04:16:47.999407\n",
      "validation Loss: 0.4559 Acc: 0.9650\n",
      "2022-01-23 04:16:48.367706\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0432 Acc: 0.9880\n",
      "2022-01-23 04:16:51.294150\n",
      "validation Loss: 0.4383 Acc: 0.9557\n",
      "2022-01-23 04:16:51.731815\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0408 Acc: 0.9910\n",
      "2022-01-23 04:16:54.493520\n",
      "validation Loss: 0.4781 Acc: 0.9604\n",
      "2022-01-23 04:16:54.844836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0398 Acc: 0.9895\n",
      "2022-01-23 04:16:57.270710\n",
      "validation Loss: 0.4791 Acc: 0.9510\n",
      "2022-01-23 04:16:57.611210\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0404 Acc: 0.9890\n",
      "2022-01-23 04:17:00.164480\n",
      "validation Loss: 0.4938 Acc: 0.9510\n",
      "2022-01-23 04:17:00.518902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9650\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2xyxji94) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4766... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▁▂▂▂▄▆▆▆▇▇▇▇▇▇▇▇█▇█▇█████████████████</td></tr><tr><td>accuracy_train</td><td>▁▁▃▆▇▇▇▇▇▇██████▇███████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▂▄▆▇▇▇▇████████████████████████████████</td></tr><tr><td>loss_train</td><td>██▆▄▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.9627</td></tr><tr><td>accuracy_train</td><td>0.989</td></tr><tr><td>accuracy_validation</td><td>0.95105</td></tr><tr><td>best_test_accuracy</td><td>0.9627</td></tr><tr><td>best_val_accuracy</td><td>0.96503</td></tr><tr><td>best_val_loss</td><td>0.45589</td></tr><tr><td>loss_train</td><td>0.04045</td></tr><tr><td>loss_validation</td><td>0.49381</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2xyxji94\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2xyxji94</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_041144-2xyxji94/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2xyxji94). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/23bcz7kf\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 04:17:10.453365\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.8278 Acc: 0.7760\n",
      "2022-01-23 04:17:13.068565\n",
      "validation Loss: 0.2495 Acc: 0.9231\n",
      "2022-01-23 04:17:13.425253\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1838 Acc: 0.9430\n",
      "2022-01-23 04:17:16.337039\n",
      "validation Loss: 0.2921 Acc: 0.9161\n",
      "2022-01-23 04:17:16.701469\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1076 Acc: 0.9675\n",
      "2022-01-23 04:17:19.528912\n",
      "validation Loss: 0.1021 Acc: 0.9604\n",
      "2022-01-23 04:17:19.895401\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0952 Acc: 0.9655\n",
      "2022-01-23 04:17:22.829313\n",
      "validation Loss: 0.0932 Acc: 0.9720\n",
      "2022-01-23 04:17:23.181731\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0577 Acc: 0.9825\n",
      "2022-01-23 04:17:26.326680\n",
      "validation Loss: 0.1330 Acc: 0.9580\n",
      "2022-01-23 04:17:26.826097\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0886 Acc: 0.9730\n",
      "2022-01-23 04:17:29.535085\n",
      "validation Loss: 0.0814 Acc: 0.9697\n",
      "2022-01-23 04:17:30.036901\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0670 Acc: 0.9815\n",
      "2022-01-23 04:17:32.728835\n",
      "validation Loss: 0.1138 Acc: 0.9557\n",
      "2022-01-23 04:17:33.096062\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0431 Acc: 0.9865\n",
      "2022-01-23 04:17:35.774004\n",
      "validation Loss: 0.0698 Acc: 0.9790\n",
      "2022-01-23 04:17:36.175447\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0304 Acc: 0.9920\n",
      "2022-01-23 04:17:39.158716\n",
      "validation Loss: 0.0849 Acc: 0.9744\n",
      "2022-01-23 04:17:39.543702\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0155 Acc: 0.9965\n",
      "2022-01-23 04:17:42.076605\n",
      "validation Loss: 0.0419 Acc: 0.9860\n",
      "2022-01-23 04:17:42.429892\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0172 Acc: 0.9960\n",
      "2022-01-23 04:17:45.336296\n",
      "validation Loss: 0.0693 Acc: 0.9720\n",
      "2022-01-23 04:17:45.711103\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0142 Acc: 0.9975\n",
      "2022-01-23 04:17:48.258303\n",
      "validation Loss: 0.1043 Acc: 0.9720\n",
      "2022-01-23 04:17:48.715499\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0515 Acc: 0.9840\n",
      "2022-01-23 04:17:51.385231\n",
      "validation Loss: 0.0654 Acc: 0.9814\n",
      "2022-01-23 04:17:51.800570\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0231 Acc: 0.9925\n",
      "2022-01-23 04:17:54.243030\n",
      "validation Loss: 0.1000 Acc: 0.9580\n",
      "2022-01-23 04:17:54.661840\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0561 Acc: 0.9825\n",
      "2022-01-23 04:17:57.263510\n",
      "validation Loss: 0.0758 Acc: 0.9790\n",
      "2022-01-23 04:17:57.633831\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9960\n",
      "2022-01-23 04:18:00.044075\n",
      "validation Loss: 0.0438 Acc: 0.9860\n",
      "2022-01-23 04:18:00.398287\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9995\n",
      "2022-01-23 04:18:02.849151\n",
      "validation Loss: 0.0557 Acc: 0.9860\n",
      "2022-01-23 04:18:03.207009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0321 Acc: 0.9900\n",
      "2022-01-23 04:18:05.727430\n",
      "validation Loss: 0.0736 Acc: 0.9744\n",
      "2022-01-23 04:18:06.207839\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0659 Acc: 0.9805\n",
      "2022-01-23 04:18:08.722541\n",
      "validation Loss: 0.1523 Acc: 0.9580\n",
      "2022-01-23 04:18:09.134665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1173 Acc: 0.9685\n",
      "2022-01-23 04:18:11.868197\n",
      "validation Loss: 0.0892 Acc: 0.9720\n",
      "2022-01-23 04:18:12.282114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0309 Acc: 0.9910\n",
      "2022-01-23 04:18:14.802453\n",
      "validation Loss: 0.1611 Acc: 0.9487\n",
      "2022-01-23 04:18:15.296192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0150 Acc: 0.9975\n",
      "2022-01-23 04:18:17.827555\n",
      "validation Loss: 0.0625 Acc: 0.9790\n",
      "2022-01-23 04:18:18.192722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0269 Acc: 0.9900\n",
      "2022-01-23 04:18:20.657119\n",
      "validation Loss: 0.0704 Acc: 0.9814\n",
      "2022-01-23 04:18:21.011062\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9920\n",
      "2022-01-23 04:18:23.624199\n",
      "validation Loss: 0.0620 Acc: 0.9883\n",
      "2022-01-23 04:18:24.122172\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 0.9985\n",
      "2022-01-23 04:18:27.062744\n",
      "validation Loss: 0.0423 Acc: 0.9883\n",
      "2022-01-23 04:18:27.439584\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 0.9975\n",
      "2022-01-23 04:18:30.380878\n",
      "validation Loss: 0.0610 Acc: 0.9814\n",
      "2022-01-23 04:18:30.806998\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "2022-01-23 04:18:33.332898\n",
      "validation Loss: 0.0353 Acc: 0.9930\n",
      "2022-01-23 04:18:33.706532\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 04:18:36.709695\n",
      "validation Loss: 0.0380 Acc: 0.9883\n",
      "2022-01-23 04:18:37.237760\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:18:39.803248\n",
      "validation Loss: 0.0423 Acc: 0.9907\n",
      "2022-01-23 04:18:40.158261\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:18:42.784931\n",
      "validation Loss: 0.0399 Acc: 0.9883\n",
      "2022-01-23 04:18:43.179385\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:18:45.789908\n",
      "validation Loss: 0.0377 Acc: 0.9883\n",
      "2022-01-23 04:18:46.140282\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:18:48.827815\n",
      "validation Loss: 0.0364 Acc: 0.9883\n",
      "2022-01-23 04:18:49.188692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:18:51.777975\n",
      "validation Loss: 0.0385 Acc: 0.9883\n",
      "2022-01-23 04:18:52.152375\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:18:54.768122\n",
      "validation Loss: 0.0385 Acc: 0.9883\n",
      "2022-01-23 04:18:55.133388\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:18:57.804851\n",
      "validation Loss: 0.0366 Acc: 0.9883\n",
      "2022-01-23 04:18:58.166595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:19:00.742796\n",
      "validation Loss: 0.0366 Acc: 0.9883\n",
      "2022-01-23 04:19:01.121106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:19:03.676013\n",
      "validation Loss: 0.0345 Acc: 0.9883\n",
      "2022-01-23 04:19:04.039762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:19:06.637253\n",
      "validation Loss: 0.0351 Acc: 0.9883\n",
      "2022-01-23 04:19:07.203903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:19:09.742680\n",
      "validation Loss: 0.0346 Acc: 0.9883\n",
      "2022-01-23 04:19:10.089549\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:19:12.635189\n",
      "validation Loss: 0.0365 Acc: 0.9883\n",
      "2022-01-23 04:19:13.002334\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:15.589609\n",
      "validation Loss: 0.0356 Acc: 0.9883\n",
      "2022-01-23 04:19:15.997280\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:18.633751\n",
      "validation Loss: 0.0364 Acc: 0.9883\n",
      "2022-01-23 04:19:19.115874\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:21.805495\n",
      "validation Loss: 0.0358 Acc: 0.9883\n",
      "2022-01-23 04:19:22.324911\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:25.023293\n",
      "validation Loss: 0.0364 Acc: 0.9883\n",
      "2022-01-23 04:19:25.433970\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:28.154407\n",
      "validation Loss: 0.0354 Acc: 0.9883\n",
      "2022-01-23 04:19:28.547913\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:31.130060\n",
      "validation Loss: 0.0344 Acc: 0.9907\n",
      "2022-01-23 04:19:31.616110\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:34.337939\n",
      "validation Loss: 0.0340 Acc: 0.9907\n",
      "2022-01-23 04:19:34.702141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:37.289432\n",
      "validation Loss: 0.0359 Acc: 0.9907\n",
      "2022-01-23 04:19:37.691688\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:40.267668\n",
      "validation Loss: 0.0343 Acc: 0.9907\n",
      "2022-01-23 04:19:40.644060\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:42.172490\n",
      "validation Loss: 0.0366 Acc: 0.9883\n",
      "2022-01-23 04:19:42.577743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:45.146585\n",
      "validation Loss: 0.0351 Acc: 0.9907\n",
      "2022-01-23 04:19:45.569704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:48.136072\n",
      "validation Loss: 0.0364 Acc: 0.9907\n",
      "2022-01-23 04:19:48.536568\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:51.252573\n",
      "validation Loss: 0.0356 Acc: 0.9883\n",
      "2022-01-23 04:19:51.830032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:54.499823\n",
      "validation Loss: 0.0363 Acc: 0.9883\n",
      "2022-01-23 04:19:54.904336\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:19:57.468234\n",
      "validation Loss: 0.0369 Acc: 0.9883\n",
      "2022-01-23 04:19:57.849623\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:00.351216\n",
      "validation Loss: 0.0363 Acc: 0.9883\n",
      "2022-01-23 04:20:00.691149\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:03.608682\n",
      "validation Loss: 0.0361 Acc: 0.9907\n",
      "2022-01-23 04:20:04.003431\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:06.502516\n",
      "validation Loss: 0.0345 Acc: 0.9907\n",
      "2022-01-23 04:20:06.877165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:09.363228\n",
      "validation Loss: 0.0363 Acc: 0.9907\n",
      "2022-01-23 04:20:09.719641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:12.217971\n",
      "validation Loss: 0.0360 Acc: 0.9907\n",
      "2022-01-23 04:20:12.699695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:15.207509\n",
      "validation Loss: 0.0381 Acc: 0.9883\n",
      "2022-01-23 04:20:15.589370\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:18.015938\n",
      "validation Loss: 0.0357 Acc: 0.9907\n",
      "2022-01-23 04:20:18.379949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:20.978630\n",
      "validation Loss: 0.0366 Acc: 0.9883\n",
      "2022-01-23 04:20:21.329954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:24.088705\n",
      "validation Loss: 0.0355 Acc: 0.9907\n",
      "2022-01-23 04:20:24.489751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:27.093137\n",
      "validation Loss: 0.0353 Acc: 0.9907\n",
      "2022-01-23 04:20:27.436199\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:29.954524\n",
      "validation Loss: 0.0355 Acc: 0.9907\n",
      "2022-01-23 04:20:30.336904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:32.805435\n",
      "validation Loss: 0.0351 Acc: 0.9907\n",
      "2022-01-23 04:20:33.159369\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:35.656091\n",
      "validation Loss: 0.0338 Acc: 0.9907\n",
      "2022-01-23 04:20:36.025086\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:20:38.534818\n",
      "validation Loss: 0.0362 Acc: 0.9907\n",
      "2022-01-23 04:20:38.912644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:41.437876\n",
      "validation Loss: 0.0375 Acc: 0.9883\n",
      "2022-01-23 04:20:41.778950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:44.506287\n",
      "validation Loss: 0.0340 Acc: 0.9907\n",
      "2022-01-23 04:20:44.893664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:47.446215\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 04:20:47.773619\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:50.231332\n",
      "validation Loss: 0.0352 Acc: 0.9907\n",
      "2022-01-23 04:20:50.573828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:53.124781\n",
      "validation Loss: 0.0367 Acc: 0.9907\n",
      "2022-01-23 04:20:53.542100\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:56.106402\n",
      "validation Loss: 0.0345 Acc: 0.9907\n",
      "2022-01-23 04:20:56.500356\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:20:59.197615\n",
      "validation Loss: 0.0352 Acc: 0.9907\n",
      "2022-01-23 04:20:59.568983\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:02.355900\n",
      "validation Loss: 0.0370 Acc: 0.9907\n",
      "2022-01-23 04:21:02.866822\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:05.411649\n",
      "validation Loss: 0.0371 Acc: 0.9907\n",
      "2022-01-23 04:21:05.766310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:08.289297\n",
      "validation Loss: 0.0344 Acc: 0.9907\n",
      "2022-01-23 04:21:08.645200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:11.256806\n",
      "validation Loss: 0.0353 Acc: 0.9907\n",
      "2022-01-23 04:21:11.779525\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:14.348011\n",
      "validation Loss: 0.0360 Acc: 0.9907\n",
      "2022-01-23 04:21:14.719505\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:17.211252\n",
      "validation Loss: 0.0354 Acc: 0.9907\n",
      "2022-01-23 04:21:17.578962\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:20.210906\n",
      "validation Loss: 0.0343 Acc: 0.9907\n",
      "2022-01-23 04:21:20.692546\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:23.187497\n",
      "validation Loss: 0.0354 Acc: 0.9907\n",
      "2022-01-23 04:21:23.558495\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:26.115430\n",
      "validation Loss: 0.0361 Acc: 0.9907\n",
      "2022-01-23 04:21:26.483460\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:29.122355\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 04:21:29.604252\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:32.118103\n",
      "validation Loss: 0.0364 Acc: 0.9907\n",
      "2022-01-23 04:21:32.473444\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:35.056593\n",
      "validation Loss: 0.0365 Acc: 0.9907\n",
      "2022-01-23 04:21:35.413487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:38.045853\n",
      "validation Loss: 0.0349 Acc: 0.9907\n",
      "2022-01-23 04:21:38.421135\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:41.203446\n",
      "validation Loss: 0.0340 Acc: 0.9907\n",
      "2022-01-23 04:21:41.599281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:44.188284\n",
      "validation Loss: 0.0367 Acc: 0.9907\n",
      "2022-01-23 04:21:44.673438\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:47.175503\n",
      "validation Loss: 0.0368 Acc: 0.9907\n",
      "2022-01-23 04:21:47.667999\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:50.212572\n",
      "validation Loss: 0.0341 Acc: 0.9907\n",
      "2022-01-23 04:21:50.575028\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:53.125325\n",
      "validation Loss: 0.0344 Acc: 0.9907\n",
      "2022-01-23 04:21:53.550479\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:56.105298\n",
      "validation Loss: 0.0354 Acc: 0.9907\n",
      "2022-01-23 04:21:56.568345\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:21:59.092289\n",
      "validation Loss: 0.0359 Acc: 0.9907\n",
      "2022-01-23 04:21:59.466606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:22:02.013081\n",
      "validation Loss: 0.0343 Acc: 0.9907\n",
      "2022-01-23 04:22:02.433687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:22:04.989674\n",
      "validation Loss: 0.0350 Acc: 0.9907\n",
      "2022-01-23 04:22:05.482142\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:22:08.049227\n",
      "validation Loss: 0.0361 Acc: 0.9907\n",
      "2022-01-23 04:22:08.403140\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:22:10.026963\n",
      "validation Loss: 0.0377 Acc: 0.9907\n",
      "2022-01-23 04:22:10.363138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9930\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:23bcz7kf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5209... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▇█▇▇▇</td></tr><tr><td>accuracy_train</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▅▆▇▆▇█▆▄▇▇█████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▃▂▂▂▁▂▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99068</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99301</td></tr><tr><td>best_val_loss</td><td>0.03532</td></tr><tr><td>loss_train</td><td>2e-05</td></tr><tr><td>loss_validation</td><td>0.03771</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/23bcz7kf\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/23bcz7kf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_041701-23bcz7kf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:23bcz7kf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/288ayd57\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 04:22:20.163200\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.0846 Acc: 0.7540\n",
      "2022-01-23 04:22:22.703715\n",
      "validation Loss: 0.3007 Acc: 0.9324\n",
      "2022-01-23 04:22:23.054934\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2109 Acc: 0.9495\n",
      "2022-01-23 04:22:25.858531\n",
      "validation Loss: 0.1725 Acc: 0.9441\n",
      "2022-01-23 04:22:26.221941\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1145 Acc: 0.9715\n",
      "2022-01-23 04:22:29.154759\n",
      "validation Loss: 0.1668 Acc: 0.9464\n",
      "2022-01-23 04:22:29.508324\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0921 Acc: 0.9725\n",
      "2022-01-23 04:22:32.281989\n",
      "validation Loss: 0.1338 Acc: 0.9487\n",
      "2022-01-23 04:22:32.619302\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1039 Acc: 0.9705\n",
      "2022-01-23 04:22:35.541207\n",
      "validation Loss: 0.1287 Acc: 0.9604\n",
      "2022-01-23 04:22:36.053088\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0617 Acc: 0.9840\n",
      "2022-01-23 04:22:39.090046\n",
      "validation Loss: 0.0795 Acc: 0.9697\n",
      "2022-01-23 04:22:39.449919\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0496 Acc: 0.9855\n",
      "2022-01-23 04:22:42.446899\n",
      "validation Loss: 0.1047 Acc: 0.9650\n",
      "2022-01-23 04:22:42.792511\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0401 Acc: 0.9895\n",
      "2022-01-23 04:22:45.404771\n",
      "validation Loss: 0.0668 Acc: 0.9837\n",
      "2022-01-23 04:22:45.747719\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0494 Acc: 0.9865\n",
      "2022-01-23 04:22:48.817241\n",
      "validation Loss: 0.0724 Acc: 0.9814\n",
      "2022-01-23 04:22:49.239740\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0330 Acc: 0.9905\n",
      "2022-01-23 04:22:51.877117\n",
      "validation Loss: 0.0504 Acc: 0.9837\n",
      "2022-01-23 04:22:52.292464\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0243 Acc: 0.9925\n",
      "2022-01-23 04:22:55.115691\n",
      "validation Loss: 0.0578 Acc: 0.9860\n",
      "2022-01-23 04:22:55.647334\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9970\n",
      "2022-01-23 04:22:58.694046\n",
      "validation Loss: 0.0457 Acc: 0.9860\n",
      "2022-01-23 04:22:59.035327\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0124 Acc: 0.9965\n",
      "2022-01-23 04:23:01.873449\n",
      "validation Loss: 0.0848 Acc: 0.9744\n",
      "2022-01-23 04:23:02.309688\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0124 Acc: 0.9975\n",
      "2022-01-23 04:23:04.818755\n",
      "validation Loss: 0.1063 Acc: 0.9720\n",
      "2022-01-23 04:23:05.261838\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0298 Acc: 0.9925\n",
      "2022-01-23 04:23:07.744370\n",
      "validation Loss: 0.0829 Acc: 0.9674\n",
      "2022-01-23 04:23:08.079294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0405 Acc: 0.9905\n",
      "2022-01-23 04:23:10.571147\n",
      "validation Loss: 0.1248 Acc: 0.9580\n",
      "2022-01-23 04:23:11.018358\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9960\n",
      "2022-01-23 04:23:13.545563\n",
      "validation Loss: 0.0520 Acc: 0.9790\n",
      "2022-01-23 04:23:13.953712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0270 Acc: 0.9910\n",
      "2022-01-23 04:23:16.475979\n",
      "validation Loss: 0.1478 Acc: 0.9487\n",
      "2022-01-23 04:23:16.841367\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0290 Acc: 0.9915\n",
      "2022-01-23 04:23:19.542752\n",
      "validation Loss: 0.0630 Acc: 0.9744\n",
      "2022-01-23 04:23:19.953576\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9960\n",
      "2022-01-23 04:23:22.503009\n",
      "validation Loss: 0.0569 Acc: 0.9860\n",
      "2022-01-23 04:23:22.860799\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0140 Acc: 0.9945\n",
      "2022-01-23 04:23:25.482286\n",
      "validation Loss: 0.0600 Acc: 0.9814\n",
      "2022-01-23 04:23:25.913654\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0443 Acc: 0.9900\n",
      "2022-01-23 04:23:28.539812\n",
      "validation Loss: 0.0596 Acc: 0.9790\n",
      "2022-01-23 04:23:29.014544\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9970\n",
      "2022-01-23 04:23:31.541589\n",
      "validation Loss: 0.0719 Acc: 0.9814\n",
      "2022-01-23 04:23:31.886685\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0161 Acc: 0.9935\n",
      "2022-01-23 04:23:34.504225\n",
      "validation Loss: 0.0811 Acc: 0.9697\n",
      "2022-01-23 04:23:34.868733\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0245 Acc: 0.9930\n",
      "2022-01-23 04:23:37.331654\n",
      "validation Loss: 0.0456 Acc: 0.9837\n",
      "2022-01-23 04:23:37.686084\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 0.9970\n",
      "2022-01-23 04:23:40.151848\n",
      "validation Loss: 0.0411 Acc: 0.9907\n",
      "2022-01-23 04:23:40.499002\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0204 Acc: 0.9935\n",
      "2022-01-23 04:23:43.596589\n",
      "validation Loss: 0.0642 Acc: 0.9814\n",
      "2022-01-23 04:23:43.948448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0342 Acc: 0.9890\n",
      "2022-01-23 04:23:46.433236\n",
      "validation Loss: 0.0708 Acc: 0.9767\n",
      "2022-01-23 04:23:46.890250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0235 Acc: 0.9925\n",
      "2022-01-23 04:23:49.376547\n",
      "validation Loss: 0.0440 Acc: 0.9814\n",
      "2022-01-23 04:23:49.726055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 0.9960\n",
      "2022-01-23 04:23:52.285225\n",
      "validation Loss: 0.0352 Acc: 0.9930\n",
      "2022-01-23 04:23:52.656959\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9985\n",
      "2022-01-23 04:23:55.543090\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 04:23:55.934039\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 04:23:58.931470\n",
      "validation Loss: 0.0263 Acc: 0.9953\n",
      "2022-01-23 04:23:59.352143\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 04:24:02.378279\n",
      "validation Loss: 0.0272 Acc: 0.9953\n",
      "2022-01-23 04:24:02.756421\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 04:24:05.288889\n",
      "validation Loss: 0.0281 Acc: 0.9953\n",
      "2022-01-23 04:24:05.652043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:24:08.241317\n",
      "validation Loss: 0.0286 Acc: 0.9953\n",
      "2022-01-23 04:24:08.598155\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:24:11.102029\n",
      "validation Loss: 0.0287 Acc: 0.9953\n",
      "2022-01-23 04:24:11.438674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:24:13.962490\n",
      "validation Loss: 0.0291 Acc: 0.9953\n",
      "2022-01-23 04:24:14.334155\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:24:16.800693\n",
      "validation Loss: 0.0292 Acc: 0.9953\n",
      "2022-01-23 04:24:17.232059\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:24:19.724033\n",
      "validation Loss: 0.0308 Acc: 0.9953\n",
      "2022-01-23 04:24:20.297025\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:24:22.786129\n",
      "validation Loss: 0.0300 Acc: 0.9953\n",
      "2022-01-23 04:24:23.128510\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:24:25.592862\n",
      "validation Loss: 0.0291 Acc: 0.9953\n",
      "2022-01-23 04:24:25.950686\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:27.386937\n",
      "validation Loss: 0.0303 Acc: 0.9953\n",
      "2022-01-23 04:24:27.722595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:30.258224\n",
      "validation Loss: 0.0298 Acc: 0.9953\n",
      "2022-01-23 04:24:30.755321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:33.216674\n",
      "validation Loss: 0.0315 Acc: 0.9953\n",
      "2022-01-23 04:24:33.628280\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:36.124975\n",
      "validation Loss: 0.0309 Acc: 0.9953\n",
      "2022-01-23 04:24:36.461665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:38.956597\n",
      "validation Loss: 0.0314 Acc: 0.9953\n",
      "2022-01-23 04:24:39.403169\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:24:42.012870\n",
      "validation Loss: 0.0309 Acc: 0.9953\n",
      "2022-01-23 04:24:42.503399\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:24:45.272965\n",
      "validation Loss: 0.0309 Acc: 0.9953\n",
      "2022-01-23 04:24:45.626926\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:24:48.349450\n",
      "validation Loss: 0.0322 Acc: 0.9953\n",
      "2022-01-23 04:24:48.802504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:24:51.398329\n",
      "validation Loss: 0.0317 Acc: 0.9953\n",
      "2022-01-23 04:24:51.752203\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:24:54.512228\n",
      "validation Loss: 0.0317 Acc: 0.9953\n",
      "2022-01-23 04:24:54.975192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:24:57.599743\n",
      "validation Loss: 0.0315 Acc: 0.9953\n",
      "2022-01-23 04:24:57.991412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:00.565076\n",
      "validation Loss: 0.0324 Acc: 0.9953\n",
      "2022-01-23 04:25:00.899608\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:03.562663\n",
      "validation Loss: 0.0324 Acc: 0.9953\n",
      "2022-01-23 04:25:03.965098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:06.573668\n",
      "validation Loss: 0.0331 Acc: 0.9953\n",
      "2022-01-23 04:25:07.012053\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:09.398364\n",
      "validation Loss: 0.0326 Acc: 0.9953\n",
      "2022-01-23 04:25:09.750129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:12.146390\n",
      "validation Loss: 0.0336 Acc: 0.9953\n",
      "2022-01-23 04:25:12.490960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:14.955009\n",
      "validation Loss: 0.0327 Acc: 0.9953\n",
      "2022-01-23 04:25:15.311698\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:17.868980\n",
      "validation Loss: 0.0334 Acc: 0.9953\n",
      "2022-01-23 04:25:18.420305\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:25:21.011385\n",
      "validation Loss: 0.0327 Acc: 0.9953\n",
      "2022-01-23 04:25:21.387842\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:24.047394\n",
      "validation Loss: 0.0331 Acc: 0.9953\n",
      "2022-01-23 04:25:24.413752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:27.030472\n",
      "validation Loss: 0.0340 Acc: 0.9953\n",
      "2022-01-23 04:25:27.548338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:30.217101\n",
      "validation Loss: 0.0335 Acc: 0.9953\n",
      "2022-01-23 04:25:30.583484\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:33.147359\n",
      "validation Loss: 0.0341 Acc: 0.9953\n",
      "2022-01-23 04:25:33.544794\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:36.099359\n",
      "validation Loss: 0.0345 Acc: 0.9953\n",
      "2022-01-23 04:25:36.749512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:39.610107\n",
      "validation Loss: 0.0340 Acc: 0.9953\n",
      "2022-01-23 04:25:39.983343\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:42.495893\n",
      "validation Loss: 0.0353 Acc: 0.9953\n",
      "2022-01-23 04:25:42.865401\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:45.400859\n",
      "validation Loss: 0.0349 Acc: 0.9953\n",
      "2022-01-23 04:25:45.761209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:48.369756\n",
      "validation Loss: 0.0344 Acc: 0.9930\n",
      "2022-01-23 04:25:48.734730\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:51.256841\n",
      "validation Loss: 0.0356 Acc: 0.9930\n",
      "2022-01-23 04:25:51.598701\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:54.174663\n",
      "validation Loss: 0.0345 Acc: 0.9953\n",
      "2022-01-23 04:25:54.572765\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:25:57.148150\n",
      "validation Loss: 0.0344 Acc: 0.9953\n",
      "2022-01-23 04:25:57.508010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:00.017704\n",
      "validation Loss: 0.0350 Acc: 0.9953\n",
      "2022-01-23 04:26:00.411414\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:01.774898\n",
      "validation Loss: 0.0349 Acc: 0.9930\n",
      "2022-01-23 04:26:02.125902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:04.700586\n",
      "validation Loss: 0.0358 Acc: 0.9930\n",
      "2022-01-23 04:26:05.196412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:07.815574\n",
      "validation Loss: 0.0344 Acc: 0.9953\n",
      "2022-01-23 04:26:08.170006\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:09.714398\n",
      "validation Loss: 0.0364 Acc: 0.9930\n",
      "2022-01-23 04:26:10.058320\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:12.633230\n",
      "validation Loss: 0.0355 Acc: 0.9930\n",
      "2022-01-23 04:26:12.999823\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:15.515915\n",
      "validation Loss: 0.0371 Acc: 0.9930\n",
      "2022-01-23 04:26:15.894055\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:18.428881\n",
      "validation Loss: 0.0352 Acc: 0.9930\n",
      "2022-01-23 04:26:19.043303\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:21.617059\n",
      "validation Loss: 0.0374 Acc: 0.9930\n",
      "2022-01-23 04:26:22.005543\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:24.684349\n",
      "validation Loss: 0.0355 Acc: 0.9930\n",
      "2022-01-23 04:26:25.032989\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:27.546132\n",
      "validation Loss: 0.0374 Acc: 0.9930\n",
      "2022-01-23 04:26:27.911047\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:30.458874\n",
      "validation Loss: 0.0357 Acc: 0.9907\n",
      "2022-01-23 04:26:30.924480\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:33.463851\n",
      "validation Loss: 0.0371 Acc: 0.9930\n",
      "2022-01-23 04:26:33.835635\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:36.340374\n",
      "validation Loss: 0.0364 Acc: 0.9930\n",
      "2022-01-23 04:26:36.693152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:39.306689\n",
      "validation Loss: 0.0379 Acc: 0.9907\n",
      "2022-01-23 04:26:39.652096\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:42.235877\n",
      "validation Loss: 0.0372 Acc: 0.9907\n",
      "2022-01-23 04:26:42.711550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:45.246925\n",
      "validation Loss: 0.0363 Acc: 0.9930\n",
      "2022-01-23 04:26:45.584603\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:48.210460\n",
      "validation Loss: 0.0372 Acc: 0.9907\n",
      "2022-01-23 04:26:48.580896\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:51.010658\n",
      "validation Loss: 0.0373 Acc: 0.9907\n",
      "2022-01-23 04:26:51.384369\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:53.910296\n",
      "validation Loss: 0.0367 Acc: 0.9907\n",
      "2022-01-23 04:26:54.290441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:56.641662\n",
      "validation Loss: 0.0372 Acc: 0.9907\n",
      "2022-01-23 04:26:56.976585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:26:59.405112\n",
      "validation Loss: 0.0371 Acc: 0.9907\n",
      "2022-01-23 04:26:59.751854\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:27:02.105859\n",
      "validation Loss: 0.0393 Acc: 0.9883\n",
      "2022-01-23 04:27:02.467337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:27:04.944818\n",
      "validation Loss: 0.0372 Acc: 0.9907\n",
      "2022-01-23 04:27:05.414821\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:27:07.872768\n",
      "validation Loss: 0.0360 Acc: 0.9907\n",
      "2022-01-23 04:27:08.225760\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:27:10.718252\n",
      "validation Loss: 0.0393 Acc: 0.9883\n",
      "2022-01-23 04:27:11.148569\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:27:13.655831\n",
      "validation Loss: 0.0381 Acc: 0.9907\n",
      "2022-01-23 04:27:13.993327\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:27:16.460943\n",
      "validation Loss: 0.0379 Acc: 0.9907\n",
      "2022-01-23 04:27:16.946266\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:288ayd57) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 84043... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▃▄▅▆▆▆█▇▇▆▇█</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▃▅▇▇▆▄▃▆▆▇▆█████████████████████▇▇█▇▇▇▇</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▂▂▂▂▃▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98601</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99068</td></tr><tr><td>best_test_accuracy</td><td>0.98601</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.02635</td></tr><tr><td>loss_train</td><td>4e-05</td></tr><tr><td>loss_validation</td><td>0.03792</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/288ayd57\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/288ayd57</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_042210-288ayd57/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:288ayd57). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2yxvp2mn\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 04:27:26.819402\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.5525 Acc: 0.6645\n",
      "2022-01-23 04:27:29.463362\n",
      "validation Loss: 0.5401 Acc: 0.9371\n",
      "2022-01-23 04:27:29.787552\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.3665 Acc: 0.9450\n",
      "2022-01-23 04:27:32.696373\n",
      "validation Loss: 0.2379 Acc: 0.9534\n",
      "2022-01-23 04:27:33.040225\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2022 Acc: 0.9565\n",
      "2022-01-23 04:27:35.964502\n",
      "validation Loss: 0.1730 Acc: 0.9604\n",
      "2022-01-23 04:27:36.347287\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1400 Acc: 0.9725\n",
      "2022-01-23 04:27:39.367712\n",
      "validation Loss: 0.1348 Acc: 0.9650\n",
      "2022-01-23 04:27:39.713231\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0941 Acc: 0.9845\n",
      "2022-01-23 04:27:42.792407\n",
      "validation Loss: 0.1130 Acc: 0.9627\n",
      "2022-01-23 04:27:43.147104\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0790 Acc: 0.9820\n",
      "2022-01-23 04:27:45.749585\n",
      "validation Loss: 0.0993 Acc: 0.9720\n",
      "2022-01-23 04:27:46.101456\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0626 Acc: 0.9850\n",
      "2022-01-23 04:27:49.006940\n",
      "validation Loss: 0.0968 Acc: 0.9697\n",
      "2022-01-23 04:27:49.542912\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0642 Acc: 0.9840\n",
      "2022-01-23 04:27:52.239221\n",
      "validation Loss: 0.0790 Acc: 0.9720\n",
      "2022-01-23 04:27:52.616972\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0422 Acc: 0.9915\n",
      "2022-01-23 04:27:55.521324\n",
      "validation Loss: 0.0976 Acc: 0.9650\n",
      "2022-01-23 04:27:55.873846\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0420 Acc: 0.9910\n",
      "2022-01-23 04:27:58.686176\n",
      "validation Loss: 0.0673 Acc: 0.9814\n",
      "2022-01-23 04:27:59.083294\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0346 Acc: 0.9930\n",
      "2022-01-23 04:28:01.994335\n",
      "validation Loss: 0.0584 Acc: 0.9837\n",
      "2022-01-23 04:28:02.328903\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0314 Acc: 0.9930\n",
      "2022-01-23 04:28:05.504346\n",
      "validation Loss: 0.0833 Acc: 0.9720\n",
      "2022-01-23 04:28:05.896706\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0315 Acc: 0.9930\n",
      "2022-01-23 04:28:08.387363\n",
      "validation Loss: 0.0700 Acc: 0.9790\n",
      "2022-01-23 04:28:08.785098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0337 Acc: 0.9905\n",
      "2022-01-23 04:28:11.308864\n",
      "validation Loss: 0.0571 Acc: 0.9883\n",
      "2022-01-23 04:28:11.697828\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0204 Acc: 0.9965\n",
      "2022-01-23 04:28:14.717257\n",
      "validation Loss: 0.0694 Acc: 0.9627\n",
      "2022-01-23 04:28:15.089189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0215 Acc: 0.9950\n",
      "2022-01-23 04:28:17.656661\n",
      "validation Loss: 0.0467 Acc: 0.9860\n",
      "2022-01-23 04:28:18.016276\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0135 Acc: 0.9985\n",
      "2022-01-23 04:28:20.583927\n",
      "validation Loss: 0.0519 Acc: 0.9790\n",
      "2022-01-23 04:28:21.084219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0129 Acc: 0.9980\n",
      "2022-01-23 04:28:23.658708\n",
      "validation Loss: 0.1002 Acc: 0.9720\n",
      "2022-01-23 04:28:24.007122\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0112 Acc: 0.9990\n",
      "2022-01-23 04:28:26.521873\n",
      "validation Loss: 0.0408 Acc: 0.9907\n",
      "2022-01-23 04:28:26.864673\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 1.0000\n",
      "2022-01-23 04:28:29.878379\n",
      "validation Loss: 0.0353 Acc: 0.9907\n",
      "2022-01-23 04:28:30.385096\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 1.0000\n",
      "2022-01-23 04:28:33.318551\n",
      "validation Loss: 0.0375 Acc: 0.9883\n",
      "2022-01-23 04:28:33.682781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 0.9995\n",
      "2022-01-23 04:28:36.241234\n",
      "validation Loss: 0.0388 Acc: 0.9907\n",
      "2022-01-23 04:28:36.613950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 0.9975\n",
      "2022-01-23 04:28:39.221221\n",
      "validation Loss: 0.0521 Acc: 0.9814\n",
      "2022-01-23 04:28:39.573917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0150 Acc: 0.9970\n",
      "2022-01-23 04:28:42.322767\n",
      "validation Loss: 0.0587 Acc: 0.9767\n",
      "2022-01-23 04:28:42.690374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0206 Acc: 0.9960\n",
      "2022-01-23 04:28:45.265090\n",
      "validation Loss: 0.0360 Acc: 0.9953\n",
      "2022-01-23 04:28:45.638322\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0126 Acc: 0.9980\n",
      "2022-01-23 04:28:48.993312\n",
      "validation Loss: 0.0337 Acc: 0.9930\n",
      "2022-01-23 04:28:49.339226\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "2022-01-23 04:28:51.890933\n",
      "validation Loss: 0.0336 Acc: 0.9907\n",
      "2022-01-23 04:28:52.237209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0033 Acc: 1.0000\n",
      "2022-01-23 04:28:54.837698\n",
      "validation Loss: 0.0356 Acc: 0.9907\n",
      "2022-01-23 04:28:55.220751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 0.9995\n",
      "2022-01-23 04:28:57.827478\n",
      "validation Loss: 0.0430 Acc: 0.9883\n",
      "2022-01-23 04:28:58.218042\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 0.9985\n",
      "2022-01-23 04:29:00.823133\n",
      "validation Loss: 0.0606 Acc: 0.9814\n",
      "2022-01-23 04:29:01.172829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0210 Acc: 0.9950\n",
      "2022-01-23 04:29:03.755749\n",
      "validation Loss: 0.0639 Acc: 0.9790\n",
      "2022-01-23 04:29:04.116941\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0155 Acc: 0.9960\n",
      "2022-01-23 04:29:07.004749\n",
      "validation Loss: 0.0653 Acc: 0.9837\n",
      "2022-01-23 04:29:07.357059\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9960\n",
      "2022-01-23 04:29:10.103297\n",
      "validation Loss: 0.0509 Acc: 0.9860\n",
      "2022-01-23 04:29:10.462286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0193 Acc: 0.9950\n",
      "2022-01-23 04:29:13.097802\n",
      "validation Loss: 0.0693 Acc: 0.9814\n",
      "2022-01-23 04:29:13.463859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 1.0000\n",
      "2022-01-23 04:29:15.993659\n",
      "validation Loss: 0.0338 Acc: 0.9907\n",
      "2022-01-23 04:29:16.412347\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0025 Acc: 1.0000\n",
      "2022-01-23 04:29:18.911738\n",
      "validation Loss: 0.0339 Acc: 0.9930\n",
      "2022-01-23 04:29:19.255549\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 04:29:21.753636\n",
      "validation Loss: 0.0341 Acc: 0.9930\n",
      "2022-01-23 04:29:22.106098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 04:29:24.529801\n",
      "validation Loss: 0.0303 Acc: 0.9930\n",
      "2022-01-23 04:29:24.951011\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 04:29:27.420249\n",
      "validation Loss: 0.0300 Acc: 0.9930\n",
      "2022-01-23 04:29:27.932949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 04:29:30.427007\n",
      "validation Loss: 0.0330 Acc: 0.9930\n",
      "2022-01-23 04:29:30.771682\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 04:29:33.307283\n",
      "validation Loss: 0.0334 Acc: 0.9930\n",
      "2022-01-23 04:29:33.643343\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 04:29:36.157440\n",
      "validation Loss: 0.0337 Acc: 0.9930\n",
      "2022-01-23 04:29:36.601863\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 04:29:39.164693\n",
      "validation Loss: 0.0328 Acc: 0.9930\n",
      "2022-01-23 04:29:39.712679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 04:29:42.176402\n",
      "validation Loss: 0.0322 Acc: 0.9930\n",
      "2022-01-23 04:29:42.529636\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 04:29:44.926336\n",
      "validation Loss: 0.0312 Acc: 0.9930\n",
      "2022-01-23 04:29:45.267200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 04:29:47.730856\n",
      "validation Loss: 0.0351 Acc: 0.9907\n",
      "2022-01-23 04:29:48.088465\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 04:29:50.605627\n",
      "validation Loss: 0.0318 Acc: 0.9930\n",
      "2022-01-23 04:29:51.163496\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 04:29:53.614959\n",
      "validation Loss: 0.0283 Acc: 0.9930\n",
      "2022-01-23 04:29:53.990664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:29:56.494614\n",
      "validation Loss: 0.0300 Acc: 0.9930\n",
      "2022-01-23 04:29:56.832951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:29:59.377674\n",
      "validation Loss: 0.0316 Acc: 0.9930\n",
      "2022-01-23 04:29:59.798634\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:30:02.374240\n",
      "validation Loss: 0.0369 Acc: 0.9883\n",
      "2022-01-23 04:30:02.952792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:30:05.602057\n",
      "validation Loss: 0.0319 Acc: 0.9930\n",
      "2022-01-23 04:30:05.973756\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:08.526485\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 04:30:08.901100\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:11.451435\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 04:30:12.016054\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:14.647444\n",
      "validation Loss: 0.0301 Acc: 0.9930\n",
      "2022-01-23 04:30:15.031402\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:17.569461\n",
      "validation Loss: 0.0293 Acc: 0.9930\n",
      "2022-01-23 04:30:17.919943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:19.568789\n",
      "validation Loss: 0.0305 Acc: 0.9930\n",
      "2022-01-23 04:30:19.903235\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 04:30:22.455265\n",
      "validation Loss: 0.0299 Acc: 0.9930\n",
      "2022-01-23 04:30:22.824040\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:25.379425\n",
      "validation Loss: 0.0318 Acc: 0.9930\n",
      "2022-01-23 04:30:25.844443\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:27.242040\n",
      "validation Loss: 0.0285 Acc: 0.9930\n",
      "2022-01-23 04:30:27.633936\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:30.124346\n",
      "validation Loss: 0.0291 Acc: 0.9930\n",
      "2022-01-23 04:30:30.697902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:33.382594\n",
      "validation Loss: 0.0303 Acc: 0.9930\n",
      "2022-01-23 04:30:33.759284\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:36.332003\n",
      "validation Loss: 0.0299 Acc: 0.9930\n",
      "2022-01-23 04:30:36.682466\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:30:39.305223\n",
      "validation Loss: 0.0289 Acc: 0.9930\n",
      "2022-01-23 04:30:39.687513\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:42.344727\n",
      "validation Loss: 0.0291 Acc: 0.9930\n",
      "2022-01-23 04:30:42.701703\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:45.240982\n",
      "validation Loss: 0.0345 Acc: 0.9883\n",
      "2022-01-23 04:30:45.657479\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:48.402138\n",
      "validation Loss: 0.0288 Acc: 0.9930\n",
      "2022-01-23 04:30:48.847558\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:51.411344\n",
      "validation Loss: 0.0292 Acc: 0.9930\n",
      "2022-01-23 04:30:51.874076\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:54.427854\n",
      "validation Loss: 0.0313 Acc: 0.9930\n",
      "2022-01-23 04:30:54.777727\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:30:57.300068\n",
      "validation Loss: 0.0284 Acc: 0.9930\n",
      "2022-01-23 04:30:57.636928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:31:00.114888\n",
      "validation Loss: 0.0286 Acc: 0.9930\n",
      "2022-01-23 04:31:00.499770\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:31:03.097413\n",
      "validation Loss: 0.0303 Acc: 0.9930\n",
      "2022-01-23 04:31:03.538072\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:31:06.054681\n",
      "validation Loss: 0.0301 Acc: 0.9930\n",
      "2022-01-23 04:31:06.428798\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 04:31:09.013261\n",
      "validation Loss: 0.0298 Acc: 0.9907\n",
      "2022-01-23 04:31:09.424142\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:11.985057\n",
      "validation Loss: 0.0307 Acc: 0.9907\n",
      "2022-01-23 04:31:12.338332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:14.976314\n",
      "validation Loss: 0.0281 Acc: 0.9907\n",
      "2022-01-23 04:31:15.414538\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:18.052337\n",
      "validation Loss: 0.0263 Acc: 0.9930\n",
      "2022-01-23 04:31:18.425981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:21.079117\n",
      "validation Loss: 0.0298 Acc: 0.9930\n",
      "2022-01-23 04:31:21.417634\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:24.060610\n",
      "validation Loss: 0.0309 Acc: 0.9930\n",
      "2022-01-23 04:31:24.681409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:27.318218\n",
      "validation Loss: 0.0321 Acc: 0.9883\n",
      "2022-01-23 04:31:27.676113\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:30.220490\n",
      "validation Loss: 0.0302 Acc: 0.9930\n",
      "2022-01-23 04:31:30.580689\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:33.197100\n",
      "validation Loss: 0.0262 Acc: 0.9930\n",
      "2022-01-23 04:31:33.562518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:36.206549\n",
      "validation Loss: 0.0293 Acc: 0.9930\n",
      "2022-01-23 04:31:36.551243\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:39.251789\n",
      "validation Loss: 0.0306 Acc: 0.9907\n",
      "2022-01-23 04:31:39.591070\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:42.037718\n",
      "validation Loss: 0.0278 Acc: 0.9930\n",
      "2022-01-23 04:31:42.421316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:44.901880\n",
      "validation Loss: 0.0308 Acc: 0.9907\n",
      "2022-01-23 04:31:45.478079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:48.028708\n",
      "validation Loss: 0.0310 Acc: 0.9907\n",
      "2022-01-23 04:31:48.378725\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:50.859333\n",
      "validation Loss: 0.0286 Acc: 0.9930\n",
      "2022-01-23 04:31:51.198911\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:31:53.700396\n",
      "validation Loss: 0.0286 Acc: 0.9930\n",
      "2022-01-23 04:31:54.051723\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:31:56.522894\n",
      "validation Loss: 0.0270 Acc: 0.9930\n",
      "2022-01-23 04:31:57.047231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:31:59.496896\n",
      "validation Loss: 0.0281 Acc: 0.9907\n",
      "2022-01-23 04:31:59.854209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:02.299716\n",
      "validation Loss: 0.0275 Acc: 0.9930\n",
      "2022-01-23 04:32:02.678825\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:05.172776\n",
      "validation Loss: 0.0259 Acc: 0.9930\n",
      "2022-01-23 04:32:05.534168\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:08.184668\n",
      "validation Loss: 0.0312 Acc: 0.9907\n",
      "2022-01-23 04:32:08.590064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:11.083010\n",
      "validation Loss: 0.0289 Acc: 0.9930\n",
      "2022-01-23 04:32:11.472675\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:14.034762\n",
      "validation Loss: 0.0299 Acc: 0.9930\n",
      "2022-01-23 04:32:14.410221\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:16.955272\n",
      "validation Loss: 0.0284 Acc: 0.9930\n",
      "2022-01-23 04:32:17.395080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:19.969152\n",
      "validation Loss: 0.0290 Acc: 0.9930\n",
      "2022-01-23 04:32:20.331081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:23.121609\n",
      "validation Loss: 0.0299 Acc: 0.9907\n",
      "2022-01-23 04:32:23.507737\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:32:26.135452\n",
      "validation Loss: 0.0268 Acc: 0.9930\n",
      "2022-01-23 04:32:26.534135\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2yxvp2mn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 76435... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▆▇▇▇█▇▇██</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▅▅▇▆▇▅▇▇██▆▇██████▇███████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▁▂▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.03601</td></tr><tr><td>loss_train</td><td>0.00011</td></tr><tr><td>loss_validation</td><td>0.02681</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2yxvp2mn\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2yxvp2mn</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_042717-2yxvp2mn/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2yxvp2mn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3108flh4\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 04:32:36.566069\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.5886 Acc: 0.3860\n",
      "2022-01-23 04:32:39.118497\n",
      "validation Loss: 2.0584 Acc: 0.7389\n",
      "2022-01-23 04:32:39.609467\n",
      "Accuracy of the network on the 429 test samples: 75.52447552447552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.5982 Acc: 0.8320\n",
      "2022-01-23 04:32:42.546956\n",
      "validation Loss: 1.1744 Acc: 0.9068\n",
      "2022-01-23 04:32:42.927456\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.9297 Acc: 0.9255\n",
      "2022-01-23 04:32:45.887761\n",
      "validation Loss: 0.7138 Acc: 0.9371\n",
      "2022-01-23 04:32:46.474596\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.5906 Acc: 0.9485\n",
      "2022-01-23 04:32:49.417128\n",
      "validation Loss: 0.4862 Acc: 0.9464\n",
      "2022-01-23 04:32:49.761106\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4146 Acc: 0.9565\n",
      "2022-01-23 04:32:52.796219\n",
      "validation Loss: 0.3598 Acc: 0.9580\n",
      "2022-01-23 04:32:53.227446\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3146 Acc: 0.9635\n",
      "2022-01-23 04:32:56.276125\n",
      "validation Loss: 0.2860 Acc: 0.9627\n",
      "2022-01-23 04:32:56.640510\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2504 Acc: 0.9710\n",
      "2022-01-23 04:32:59.614992\n",
      "validation Loss: 0.2364 Acc: 0.9650\n",
      "2022-01-23 04:32:59.960864\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2054 Acc: 0.9755\n",
      "2022-01-23 04:33:02.982356\n",
      "validation Loss: 0.2082 Acc: 0.9650\n",
      "2022-01-23 04:33:03.348097\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1733 Acc: 0.9800\n",
      "2022-01-23 04:33:06.262324\n",
      "validation Loss: 0.1818 Acc: 0.9650\n",
      "2022-01-23 04:33:06.624832\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1514 Acc: 0.9790\n",
      "2022-01-23 04:33:09.642848\n",
      "validation Loss: 0.1612 Acc: 0.9674\n",
      "2022-01-23 04:33:10.052014\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1320 Acc: 0.9820\n",
      "2022-01-23 04:33:12.898244\n",
      "validation Loss: 0.1413 Acc: 0.9790\n",
      "2022-01-23 04:33:13.243760\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1185 Acc: 0.9825\n",
      "2022-01-23 04:33:16.112084\n",
      "validation Loss: 0.1324 Acc: 0.9697\n",
      "2022-01-23 04:33:16.649281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1059 Acc: 0.9840\n",
      "2022-01-23 04:33:19.150473\n",
      "validation Loss: 0.1219 Acc: 0.9790\n",
      "2022-01-23 04:33:19.488136\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0940 Acc: 0.9855\n",
      "2022-01-23 04:33:22.592401\n",
      "validation Loss: 0.1142 Acc: 0.9767\n",
      "2022-01-23 04:33:22.955053\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0863 Acc: 0.9885\n",
      "2022-01-23 04:33:25.827067\n",
      "validation Loss: 0.1085 Acc: 0.9767\n",
      "2022-01-23 04:33:26.210115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0780 Acc: 0.9865\n",
      "2022-01-23 04:33:29.130003\n",
      "validation Loss: 0.0990 Acc: 0.9744\n",
      "2022-01-23 04:33:29.541793\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0705 Acc: 0.9905\n",
      "2022-01-23 04:33:32.322393\n",
      "validation Loss: 0.0937 Acc: 0.9814\n",
      "2022-01-23 04:33:32.867505\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0645 Acc: 0.9905\n",
      "2022-01-23 04:33:35.981280\n",
      "validation Loss: 0.0879 Acc: 0.9767\n",
      "2022-01-23 04:33:36.378437\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0604 Acc: 0.9900\n",
      "2022-01-23 04:33:39.050486\n",
      "validation Loss: 0.0837 Acc: 0.9744\n",
      "2022-01-23 04:33:39.596829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0552 Acc: 0.9920\n",
      "2022-01-23 04:33:40.940918\n",
      "validation Loss: 0.0826 Acc: 0.9790\n",
      "2022-01-23 04:33:41.303707\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0551 Acc: 0.9910\n",
      "2022-01-23 04:33:43.783750\n",
      "validation Loss: 0.0785 Acc: 0.9837\n",
      "2022-01-23 04:33:44.160049\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0492 Acc: 0.9910\n",
      "2022-01-23 04:33:47.071858\n",
      "validation Loss: 0.0773 Acc: 0.9790\n",
      "2022-01-23 04:33:47.446764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0438 Acc: 0.9940\n",
      "2022-01-23 04:33:50.057257\n",
      "validation Loss: 0.0708 Acc: 0.9790\n",
      "2022-01-23 04:33:50.418016\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0402 Acc: 0.9945\n",
      "2022-01-23 04:33:52.903377\n",
      "validation Loss: 0.0646 Acc: 0.9837\n",
      "2022-01-23 04:33:53.292577\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0383 Acc: 0.9950\n",
      "2022-01-23 04:33:56.177207\n",
      "validation Loss: 0.0605 Acc: 0.9814\n",
      "2022-01-23 04:33:56.526848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0367 Acc: 0.9950\n",
      "2022-01-23 04:33:58.901612\n",
      "validation Loss: 0.0601 Acc: 0.9837\n",
      "2022-01-23 04:33:59.262659\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0334 Acc: 0.9965\n",
      "2022-01-23 04:34:02.030722\n",
      "validation Loss: 0.0723 Acc: 0.9814\n",
      "2022-01-23 04:34:02.380065\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0312 Acc: 0.9975\n",
      "2022-01-23 04:34:04.806961\n",
      "validation Loss: 0.0588 Acc: 0.9883\n",
      "2022-01-23 04:34:05.439722\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0298 Acc: 0.9970\n",
      "2022-01-23 04:34:08.260635\n",
      "validation Loss: 0.0605 Acc: 0.9814\n",
      "2022-01-23 04:34:08.608416\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0290 Acc: 0.9950\n",
      "2022-01-23 04:34:11.024177\n",
      "validation Loss: 0.0536 Acc: 0.9814\n",
      "2022-01-23 04:34:11.360830\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0251 Acc: 0.9985\n",
      "2022-01-23 04:34:13.768688\n",
      "validation Loss: 0.0583 Acc: 0.9814\n",
      "2022-01-23 04:34:14.269215\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0228 Acc: 0.9985\n",
      "2022-01-23 04:34:16.737720\n",
      "validation Loss: 0.0572 Acc: 0.9837\n",
      "2022-01-23 04:34:17.078081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0213 Acc: 0.9970\n",
      "2022-01-23 04:34:19.592386\n",
      "validation Loss: 0.0525 Acc: 0.9860\n",
      "2022-01-23 04:34:20.065200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 1.0000\n",
      "2022-01-23 04:34:22.688274\n",
      "validation Loss: 0.0516 Acc: 0.9837\n",
      "2022-01-23 04:34:23.131912\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0188 Acc: 0.9995\n",
      "2022-01-23 04:34:25.636223\n",
      "validation Loss: 0.0453 Acc: 0.9883\n",
      "2022-01-23 04:34:26.007302\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0180 Acc: 0.9995\n",
      "2022-01-23 04:34:28.730281\n",
      "validation Loss: 0.0517 Acc: 0.9883\n",
      "2022-01-23 04:34:29.066673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0183 Acc: 0.9985\n",
      "2022-01-23 04:34:31.559133\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 04:34:31.913069\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0152 Acc: 0.9995\n",
      "2022-01-23 04:34:34.424558\n",
      "validation Loss: 0.0454 Acc: 0.9860\n",
      "2022-01-23 04:34:34.810153\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9995\n",
      "2022-01-23 04:34:37.304291\n",
      "validation Loss: 0.0443 Acc: 0.9860\n",
      "2022-01-23 04:34:37.678888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0138 Acc: 0.9995\n",
      "2022-01-23 04:34:40.365384\n",
      "validation Loss: 0.0382 Acc: 0.9883\n",
      "2022-01-23 04:34:40.784391\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0136 Acc: 0.9995\n",
      "2022-01-23 04:34:43.809768\n",
      "validation Loss: 0.0428 Acc: 0.9860\n",
      "2022-01-23 04:34:44.168124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0190 Acc: 0.9970\n",
      "2022-01-23 04:34:46.687068\n",
      "validation Loss: 0.0430 Acc: 0.9860\n",
      "2022-01-23 04:34:47.068151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0129 Acc: 0.9995\n",
      "2022-01-23 04:34:49.570399\n",
      "validation Loss: 0.0410 Acc: 0.9883\n",
      "2022-01-23 04:34:49.973324\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 1.0000\n",
      "2022-01-23 04:34:52.651922\n",
      "validation Loss: 0.0402 Acc: 0.9883\n",
      "2022-01-23 04:34:53.104760\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0101 Acc: 1.0000\n",
      "2022-01-23 04:34:55.661453\n",
      "validation Loss: 0.0377 Acc: 0.9907\n",
      "2022-01-23 04:34:56.017072\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 1.0000\n",
      "2022-01-23 04:34:59.007786\n",
      "validation Loss: 0.0349 Acc: 0.9907\n",
      "2022-01-23 04:34:59.378331\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9995\n",
      "2022-01-23 04:35:02.590027\n",
      "validation Loss: 0.0320 Acc: 0.9907\n",
      "2022-01-23 04:35:02.984262\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0090 Acc: 1.0000\n",
      "2022-01-23 04:35:05.887457\n",
      "validation Loss: 0.0393 Acc: 0.9860\n",
      "2022-01-23 04:35:06.241151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0084 Acc: 1.0000\n",
      "2022-01-23 04:35:08.954454\n",
      "validation Loss: 0.0361 Acc: 0.9883\n",
      "2022-01-23 04:35:09.327710\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 1.0000\n",
      "2022-01-23 04:35:11.900855\n",
      "validation Loss: 0.0331 Acc: 0.9907\n",
      "2022-01-23 04:35:12.257180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9995\n",
      "2022-01-23 04:35:14.709491\n",
      "validation Loss: 0.0359 Acc: 0.9907\n",
      "2022-01-23 04:35:15.067814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 1.0000\n",
      "2022-01-23 04:35:17.544359\n",
      "validation Loss: 0.0303 Acc: 0.9907\n",
      "2022-01-23 04:35:17.944151\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 1.0000\n",
      "2022-01-23 04:35:20.891911\n",
      "validation Loss: 0.0439 Acc: 0.9860\n",
      "2022-01-23 04:35:21.267322\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 1.0000\n",
      "2022-01-23 04:35:23.829406\n",
      "validation Loss: 0.0425 Acc: 0.9837\n",
      "2022-01-23 04:35:24.191836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 1.0000\n",
      "2022-01-23 04:35:26.696142\n",
      "validation Loss: 0.0338 Acc: 0.9883\n",
      "2022-01-23 04:35:27.042491\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0059 Acc: 1.0000\n",
      "2022-01-23 04:35:29.717051\n",
      "validation Loss: 0.0324 Acc: 0.9883\n",
      "2022-01-23 04:35:30.355880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0053 Acc: 1.0000\n",
      "2022-01-23 04:35:32.835141\n",
      "validation Loss: 0.0363 Acc: 0.9907\n",
      "2022-01-23 04:35:33.234723\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 1.0000\n",
      "2022-01-23 04:35:35.758965\n",
      "validation Loss: 0.0299 Acc: 0.9883\n",
      "2022-01-23 04:35:36.111040\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0063 Acc: 1.0000\n",
      "2022-01-23 04:35:38.572921\n",
      "validation Loss: 0.0417 Acc: 0.9837\n",
      "2022-01-23 04:35:38.916547\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 1.0000\n",
      "2022-01-23 04:35:40.418954\n",
      "validation Loss: 0.0352 Acc: 0.9883\n",
      "2022-01-23 04:35:40.771529\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 1.0000\n",
      "2022-01-23 04:35:43.248901\n",
      "validation Loss: 0.0414 Acc: 0.9837\n",
      "2022-01-23 04:35:43.628050\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "2022-01-23 04:35:46.191926\n",
      "validation Loss: 0.0276 Acc: 0.9883\n",
      "2022-01-23 04:35:46.621793\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "2022-01-23 04:35:49.194241\n",
      "validation Loss: 0.0305 Acc: 0.9907\n",
      "2022-01-23 04:35:49.569081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "2022-01-23 04:35:50.908260\n",
      "validation Loss: 0.0302 Acc: 0.9883\n",
      "2022-01-23 04:35:51.380081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "2022-01-23 04:35:53.837773\n",
      "validation Loss: 0.0309 Acc: 0.9907\n",
      "2022-01-23 04:35:54.218150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "2022-01-23 04:35:56.713951\n",
      "validation Loss: 0.0304 Acc: 0.9907\n",
      "2022-01-23 04:35:57.106301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 04:35:59.745956\n",
      "validation Loss: 0.0346 Acc: 0.9907\n",
      "2022-01-23 04:36:00.109007\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0032 Acc: 1.0000\n",
      "2022-01-23 04:36:02.724359\n",
      "validation Loss: 0.0275 Acc: 0.9907\n",
      "2022-01-23 04:36:03.076948\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 1.0000\n",
      "2022-01-23 04:36:06.209249\n",
      "validation Loss: 0.0392 Acc: 0.9860\n",
      "2022-01-23 04:36:06.575099\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 04:36:09.086435\n",
      "validation Loss: 0.0371 Acc: 0.9907\n",
      "2022-01-23 04:36:09.445679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 0.9995\n",
      "2022-01-23 04:36:12.080048\n",
      "validation Loss: 0.0343 Acc: 0.9883\n",
      "2022-01-23 04:36:12.457617\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 1.0000\n",
      "2022-01-23 04:36:13.786012\n",
      "validation Loss: 0.0266 Acc: 0.9907\n",
      "2022-01-23 04:36:14.112554\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 1.0000\n",
      "2022-01-23 04:36:17.117012\n",
      "validation Loss: 0.0435 Acc: 0.9860\n",
      "2022-01-23 04:36:17.461108\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "2022-01-23 04:36:19.919025\n",
      "validation Loss: 0.0323 Acc: 0.9883\n",
      "2022-01-23 04:36:20.252321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0028 Acc: 1.0000\n",
      "2022-01-23 04:36:22.738408\n",
      "validation Loss: 0.0374 Acc: 0.9837\n",
      "2022-01-23 04:36:23.084823\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 04:36:25.523305\n",
      "validation Loss: 0.0266 Acc: 0.9907\n",
      "2022-01-23 04:36:25.882689\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0030 Acc: 1.0000\n",
      "2022-01-23 04:36:28.995507\n",
      "validation Loss: 0.0245 Acc: 0.9907\n",
      "2022-01-23 04:36:29.357194\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0046 Acc: 0.9995\n",
      "2022-01-23 04:36:32.419430\n",
      "validation Loss: 0.0286 Acc: 0.9883\n",
      "2022-01-23 04:36:32.784796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0041 Acc: 0.9995\n",
      "2022-01-23 04:36:35.598454\n",
      "validation Loss: 0.0290 Acc: 0.9907\n",
      "2022-01-23 04:36:35.984074\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 04:36:38.645315\n",
      "validation Loss: 0.0341 Acc: 0.9883\n",
      "2022-01-23 04:36:38.989219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 04:36:41.420078\n",
      "validation Loss: 0.0246 Acc: 0.9907\n",
      "2022-01-23 04:36:41.808662\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 04:36:44.260071\n",
      "validation Loss: 0.0329 Acc: 0.9860\n",
      "2022-01-23 04:36:44.694269\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "2022-01-23 04:36:47.062131\n",
      "validation Loss: 0.0280 Acc: 0.9907\n",
      "2022-01-23 04:36:47.429813\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 04:36:49.936048\n",
      "validation Loss: 0.0321 Acc: 0.9883\n",
      "2022-01-23 04:36:50.307924\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 04:36:52.812301\n",
      "validation Loss: 0.0273 Acc: 0.9907\n",
      "2022-01-23 04:36:53.183532\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 04:36:55.744041\n",
      "validation Loss: 0.0282 Acc: 0.9883\n",
      "2022-01-23 04:36:56.130042\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 04:36:58.751134\n",
      "validation Loss: 0.0283 Acc: 0.9883\n",
      "2022-01-23 04:36:59.184094\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 04:37:01.697743\n",
      "validation Loss: 0.0297 Acc: 0.9907\n",
      "2022-01-23 04:37:02.066844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 04:37:04.510522\n",
      "validation Loss: 0.0359 Acc: 0.9883\n",
      "2022-01-23 04:37:04.896359\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 04:37:07.330445\n",
      "validation Loss: 0.0333 Acc: 0.9883\n",
      "2022-01-23 04:37:07.677196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 04:37:10.213188\n",
      "validation Loss: 0.0222 Acc: 0.9907\n",
      "2022-01-23 04:37:10.733911\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0181 Acc: 0.9955\n",
      "2022-01-23 04:37:13.659320\n",
      "validation Loss: 0.0531 Acc: 0.9814\n",
      "2022-01-23 04:37:14.052460\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 0.9995\n",
      "2022-01-23 04:37:16.634100\n",
      "validation Loss: 0.0323 Acc: 0.9883\n",
      "2022-01-23 04:37:17.005300\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0028 Acc: 1.0000\n",
      "2022-01-23 04:37:19.595344\n",
      "validation Loss: 0.0520 Acc: 0.9860\n",
      "2022-01-23 04:37:20.048915\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 0.9995\n",
      "2022-01-23 04:37:21.389625\n",
      "validation Loss: 0.0268 Acc: 0.9930\n",
      "2022-01-23 04:37:21.738182\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 04:37:24.962729\n",
      "validation Loss: 0.0247 Acc: 0.9907\n",
      "2022-01-23 04:37:25.300214\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 04:37:27.733037\n",
      "validation Loss: 0.0273 Acc: 0.9930\n",
      "2022-01-23 04:37:28.070664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 04:37:30.484902\n",
      "validation Loss: 0.0275 Acc: 0.9953\n",
      "2022-01-23 04:37:30.860813\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 04:37:33.964925\n",
      "validation Loss: 0.0269 Acc: 0.9953\n",
      "2022-01-23 04:37:34.368173\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 04:37:37.232038\n",
      "validation Loss: 0.0245 Acc: 0.9930\n",
      "2022-01-23 04:37:37.620096\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3108flh4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 67671... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇▇▇██████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇██▇█████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.0269</td></tr><tr><td>loss_train</td><td>0.00097</td></tr><tr><td>loss_validation</td><td>0.02452</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3108flh4\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3108flh4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_043226-3108flh4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3108flh4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/21nfndav\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 04:37:47.317075\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.8418 Acc: 0.1825\n",
      "2022-01-23 04:37:49.780124\n",
      "validation Loss: 2.6202 Acc: 0.3776\n",
      "2022-01-23 04:37:50.150538\n",
      "Accuracy of the network on the 429 test samples: 38.46153846153847\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.3359 Acc: 0.5760\n",
      "2022-01-23 04:37:52.957488\n",
      "validation Loss: 2.0383 Acc: 0.7296\n",
      "2022-01-23 04:37:53.317946\n",
      "Accuracy of the network on the 429 test samples: 69.23076923076923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.7931 Acc: 0.7760\n",
      "2022-01-23 04:37:56.258091\n",
      "validation Loss: 1.5545 Acc: 0.8508\n",
      "2022-01-23 04:37:56.639346\n",
      "Accuracy of the network on the 429 test samples: 82.28438228438229\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.3723 Acc: 0.8385\n",
      "2022-01-23 04:37:59.514152\n",
      "validation Loss: 1.1914 Acc: 0.8858\n",
      "2022-01-23 04:37:59.878512\n",
      "Accuracy of the network on the 429 test samples: 89.27738927738928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.0614 Acc: 0.8980\n",
      "2022-01-23 04:38:02.825918\n",
      "validation Loss: 0.9283 Acc: 0.9231\n",
      "2022-01-23 04:38:03.333339\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.8383 Acc: 0.9220\n",
      "2022-01-23 04:38:06.323887\n",
      "validation Loss: 0.7365 Acc: 0.9464\n",
      "2022-01-23 04:38:06.683767\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.6770 Acc: 0.9365\n",
      "2022-01-23 04:38:09.741583\n",
      "validation Loss: 0.5980 Acc: 0.9557\n",
      "2022-01-23 04:38:10.299708\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5568 Acc: 0.9440\n",
      "2022-01-23 04:38:13.353489\n",
      "validation Loss: 0.4988 Acc: 0.9557\n",
      "2022-01-23 04:38:13.751626\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4697 Acc: 0.9510\n",
      "2022-01-23 04:38:16.687944\n",
      "validation Loss: 0.4225 Acc: 0.9557\n",
      "2022-01-23 04:38:17.291552\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4003 Acc: 0.9560\n",
      "2022-01-23 04:38:20.187890\n",
      "validation Loss: 0.3672 Acc: 0.9604\n",
      "2022-01-23 04:38:20.531758\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3464 Acc: 0.9585\n",
      "2022-01-23 04:38:23.343432\n",
      "validation Loss: 0.3191 Acc: 0.9580\n",
      "2022-01-23 04:38:23.682602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3045 Acc: 0.9630\n",
      "2022-01-23 04:38:26.181011\n",
      "validation Loss: 0.2874 Acc: 0.9580\n",
      "2022-01-23 04:38:26.738360\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2695 Acc: 0.9655\n",
      "2022-01-23 04:38:29.277660\n",
      "validation Loss: 0.2537 Acc: 0.9604\n",
      "2022-01-23 04:38:29.617650\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2415 Acc: 0.9675\n",
      "2022-01-23 04:38:32.511043\n",
      "validation Loss: 0.2312 Acc: 0.9627\n",
      "2022-01-23 04:38:32.873498\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2177 Acc: 0.9695\n",
      "2022-01-23 04:38:35.727841\n",
      "validation Loss: 0.2114 Acc: 0.9674\n",
      "2022-01-23 04:38:36.220692\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1988 Acc: 0.9695\n",
      "2022-01-23 04:38:39.031390\n",
      "validation Loss: 0.1966 Acc: 0.9604\n",
      "2022-01-23 04:38:39.373097\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1831 Acc: 0.9705\n",
      "2022-01-23 04:38:41.789180\n",
      "validation Loss: 0.1812 Acc: 0.9697\n",
      "2022-01-23 04:38:42.135004\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1678 Acc: 0.9735\n",
      "2022-01-23 04:38:45.119670\n",
      "validation Loss: 0.1685 Acc: 0.9744\n",
      "2022-01-23 04:38:45.623752\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1538 Acc: 0.9745\n",
      "2022-01-23 04:38:48.527371\n",
      "validation Loss: 0.1598 Acc: 0.9674\n",
      "2022-01-23 04:38:48.900624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1442 Acc: 0.9775\n",
      "2022-01-23 04:38:51.441220\n",
      "validation Loss: 0.1490 Acc: 0.9744\n",
      "2022-01-23 04:38:51.791585\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1331 Acc: 0.9795\n",
      "2022-01-23 04:38:54.569329\n",
      "validation Loss: 0.1390 Acc: 0.9720\n",
      "2022-01-23 04:38:55.035294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1254 Acc: 0.9775\n",
      "2022-01-23 04:38:57.499044\n",
      "validation Loss: 0.1330 Acc: 0.9720\n",
      "2022-01-23 04:38:57.854952\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1156 Acc: 0.9795\n",
      "2022-01-23 04:39:00.260579\n",
      "validation Loss: 0.1257 Acc: 0.9720\n",
      "2022-01-23 04:39:00.649939\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1079 Acc: 0.9830\n",
      "2022-01-23 04:39:03.175642\n",
      "validation Loss: 0.1201 Acc: 0.9744\n",
      "2022-01-23 04:39:03.528842\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1015 Acc: 0.9830\n",
      "2022-01-23 04:39:06.308110\n",
      "validation Loss: 0.1132 Acc: 0.9720\n",
      "2022-01-23 04:39:06.720862\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0967 Acc: 0.9855\n",
      "2022-01-23 04:39:09.310109\n",
      "validation Loss: 0.1100 Acc: 0.9767\n",
      "2022-01-23 04:39:09.699893\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0929 Acc: 0.9830\n",
      "2022-01-23 04:39:12.621663\n",
      "validation Loss: 0.1054 Acc: 0.9790\n",
      "2022-01-23 04:39:12.968949\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0867 Acc: 0.9855\n",
      "2022-01-23 04:39:15.940124\n",
      "validation Loss: 0.1006 Acc: 0.9790\n",
      "2022-01-23 04:39:16.334554\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0823 Acc: 0.9895\n",
      "2022-01-23 04:39:19.310903\n",
      "validation Loss: 0.0979 Acc: 0.9767\n",
      "2022-01-23 04:39:19.673207\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0785 Acc: 0.9880\n",
      "2022-01-23 04:39:22.200694\n",
      "validation Loss: 0.0927 Acc: 0.9767\n",
      "2022-01-23 04:39:22.557625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0723 Acc: 0.9895\n",
      "2022-01-23 04:39:25.302575\n",
      "validation Loss: 0.0892 Acc: 0.9790\n",
      "2022-01-23 04:39:25.684458\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0708 Acc: 0.9890\n",
      "2022-01-23 04:39:28.540957\n",
      "validation Loss: 0.0862 Acc: 0.9744\n",
      "2022-01-23 04:39:28.897316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0678 Acc: 0.9895\n",
      "2022-01-23 04:39:31.388539\n",
      "validation Loss: 0.0860 Acc: 0.9767\n",
      "2022-01-23 04:39:31.781896\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0638 Acc: 0.9905\n",
      "2022-01-23 04:39:34.329007\n",
      "validation Loss: 0.0813 Acc: 0.9767\n",
      "2022-01-23 04:39:34.744474\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0609 Acc: 0.9905\n",
      "2022-01-23 04:39:37.383228\n",
      "validation Loss: 0.0789 Acc: 0.9860\n",
      "2022-01-23 04:39:37.726619\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0580 Acc: 0.9920\n",
      "2022-01-23 04:39:40.567329\n",
      "validation Loss: 0.0773 Acc: 0.9744\n",
      "2022-01-23 04:39:40.949527\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0558 Acc: 0.9920\n",
      "2022-01-23 04:39:43.609675\n",
      "validation Loss: 0.0746 Acc: 0.9883\n",
      "2022-01-23 04:39:44.012094\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0549 Acc: 0.9915\n",
      "2022-01-23 04:39:46.813888\n",
      "validation Loss: 0.0698 Acc: 0.9860\n",
      "2022-01-23 04:39:47.160507\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9920\n",
      "2022-01-23 04:39:49.587706\n",
      "validation Loss: 0.0680 Acc: 0.9837\n",
      "2022-01-23 04:39:49.967443\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0489 Acc: 0.9925\n",
      "2022-01-23 04:39:52.391776\n",
      "validation Loss: 0.0667 Acc: 0.9860\n",
      "2022-01-23 04:39:52.948992\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0463 Acc: 0.9925\n",
      "2022-01-23 04:39:55.578327\n",
      "validation Loss: 0.0691 Acc: 0.9814\n",
      "2022-01-23 04:39:55.972404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0447 Acc: 0.9945\n",
      "2022-01-23 04:39:58.462426\n",
      "validation Loss: 0.0624 Acc: 0.9837\n",
      "2022-01-23 04:39:58.857678\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0426 Acc: 0.9945\n",
      "2022-01-23 04:40:01.382652\n",
      "validation Loss: 0.0609 Acc: 0.9883\n",
      "2022-01-23 04:40:01.737533\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0420 Acc: 0.9945\n",
      "2022-01-23 04:40:04.655950\n",
      "validation Loss: 0.0625 Acc: 0.9837\n",
      "2022-01-23 04:40:04.994419\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0390 Acc: 0.9945\n",
      "2022-01-23 04:40:07.421067\n",
      "validation Loss: 0.0603 Acc: 0.9837\n",
      "2022-01-23 04:40:07.782118\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0381 Acc: 0.9940\n",
      "2022-01-23 04:40:10.239117\n",
      "validation Loss: 0.0571 Acc: 0.9883\n",
      "2022-01-23 04:40:10.605286\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0371 Acc: 0.9945\n",
      "2022-01-23 04:40:13.547429\n",
      "validation Loss: 0.0614 Acc: 0.9860\n",
      "2022-01-23 04:40:13.914984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0360 Acc: 0.9940\n",
      "2022-01-23 04:40:16.421657\n",
      "validation Loss: 0.0576 Acc: 0.9883\n",
      "2022-01-23 04:40:16.827639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0340 Acc: 0.9945\n",
      "2022-01-23 04:40:19.333865\n",
      "validation Loss: 0.0543 Acc: 0.9837\n",
      "2022-01-23 04:40:19.777736\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0341 Acc: 0.9945\n",
      "2022-01-23 04:40:22.318270\n",
      "validation Loss: 0.0537 Acc: 0.9860\n",
      "2022-01-23 04:40:22.880798\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0323 Acc: 0.9960\n",
      "2022-01-23 04:40:25.344171\n",
      "validation Loss: 0.0511 Acc: 0.9907\n",
      "2022-01-23 04:40:25.676394\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0294 Acc: 0.9980\n",
      "2022-01-23 04:40:28.539805\n",
      "validation Loss: 0.0519 Acc: 0.9860\n",
      "2022-01-23 04:40:28.923315\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0296 Acc: 0.9950\n",
      "2022-01-23 04:40:31.454069\n",
      "validation Loss: 0.0520 Acc: 0.9883\n",
      "2022-01-23 04:40:31.820211\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0294 Acc: 0.9955\n",
      "2022-01-23 04:40:34.573614\n",
      "validation Loss: 0.0503 Acc: 0.9860\n",
      "2022-01-23 04:40:34.986453\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0268 Acc: 0.9965\n",
      "2022-01-23 04:40:36.326086\n",
      "validation Loss: 0.0523 Acc: 0.9860\n",
      "2022-01-23 04:40:36.867971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0264 Acc: 0.9960\n",
      "2022-01-23 04:40:39.355907\n",
      "validation Loss: 0.0505 Acc: 0.9930\n",
      "2022-01-23 04:40:39.706344\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9960\n",
      "2022-01-23 04:40:42.558952\n",
      "validation Loss: 0.0489 Acc: 0.9907\n",
      "2022-01-23 04:40:42.918822\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0243 Acc: 0.9975\n",
      "2022-01-23 04:40:45.403388\n",
      "validation Loss: 0.0472 Acc: 0.9907\n",
      "2022-01-23 04:40:45.891024\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0231 Acc: 0.9980\n",
      "2022-01-23 04:40:48.357269\n",
      "validation Loss: 0.0436 Acc: 0.9930\n",
      "2022-01-23 04:40:48.756365\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0222 Acc: 0.9980\n",
      "2022-01-23 04:40:51.581633\n",
      "validation Loss: 0.0447 Acc: 0.9930\n",
      "2022-01-23 04:40:51.942150\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9980\n",
      "2022-01-23 04:40:54.573697\n",
      "validation Loss: 0.0474 Acc: 0.9883\n",
      "2022-01-23 04:40:54.941869\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9980\n",
      "2022-01-23 04:40:57.334575\n",
      "validation Loss: 0.0430 Acc: 0.9930\n",
      "2022-01-23 04:40:57.678591\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0217 Acc: 0.9965\n",
      "2022-01-23 04:41:00.428124\n",
      "validation Loss: 0.0424 Acc: 0.9883\n",
      "2022-01-23 04:41:00.782559\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9980\n",
      "2022-01-23 04:41:03.328574\n",
      "validation Loss: 0.0390 Acc: 0.9930\n",
      "2022-01-23 04:41:03.902993\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0194 Acc: 0.9990\n",
      "2022-01-23 04:41:06.703814\n",
      "validation Loss: 0.0397 Acc: 0.9930\n",
      "2022-01-23 04:41:07.081129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0179 Acc: 0.9995\n",
      "2022-01-23 04:41:09.512683\n",
      "validation Loss: 0.0384 Acc: 0.9930\n",
      "2022-01-23 04:41:09.856493\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0169 Acc: 0.9990\n",
      "2022-01-23 04:41:13.089708\n",
      "validation Loss: 0.0393 Acc: 0.9930\n",
      "2022-01-23 04:41:13.505099\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9990\n",
      "2022-01-23 04:41:16.084215\n",
      "validation Loss: 0.0477 Acc: 0.9930\n",
      "2022-01-23 04:41:16.459909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0169 Acc: 0.9980\n",
      "2022-01-23 04:41:19.033441\n",
      "validation Loss: 0.0415 Acc: 0.9930\n",
      "2022-01-23 04:41:19.452866\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0157 Acc: 0.9985\n",
      "2022-01-23 04:41:21.922864\n",
      "validation Loss: 0.0406 Acc: 0.9930\n",
      "2022-01-23 04:41:22.339429\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9995\n",
      "2022-01-23 04:41:24.804876\n",
      "validation Loss: 0.0398 Acc: 0.9907\n",
      "2022-01-23 04:41:25.242826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0138 Acc: 1.0000\n",
      "2022-01-23 04:41:27.737165\n",
      "validation Loss: 0.0387 Acc: 0.9907\n",
      "2022-01-23 04:41:28.090829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0140 Acc: 0.9985\n",
      "2022-01-23 04:41:30.618821\n",
      "validation Loss: 0.0393 Acc: 0.9930\n",
      "2022-01-23 04:41:31.069083\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0126 Acc: 1.0000\n",
      "2022-01-23 04:41:32.405737\n",
      "validation Loss: 0.0344 Acc: 0.9930\n",
      "2022-01-23 04:41:32.819825\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 0.9985\n",
      "2022-01-23 04:41:35.789789\n",
      "validation Loss: 0.0417 Acc: 0.9930\n",
      "2022-01-23 04:41:36.112180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9995\n",
      "2022-01-23 04:41:38.612502\n",
      "validation Loss: 0.0406 Acc: 0.9907\n",
      "2022-01-23 04:41:38.957880\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9995\n",
      "2022-01-23 04:41:41.381603\n",
      "validation Loss: 0.0348 Acc: 0.9930\n",
      "2022-01-23 04:41:41.859388\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0108 Acc: 1.0000\n",
      "2022-01-23 04:41:44.403797\n",
      "validation Loss: 0.0366 Acc: 0.9930\n",
      "2022-01-23 04:41:44.749232\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0105 Acc: 1.0000\n",
      "2022-01-23 04:41:47.353582\n",
      "validation Loss: 0.0458 Acc: 0.9907\n",
      "2022-01-23 04:41:47.731506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0120 Acc: 0.9985\n",
      "2022-01-23 04:41:49.565728\n",
      "validation Loss: 0.0401 Acc: 0.9907\n",
      "2022-01-23 04:41:49.915164\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0107 Acc: 0.9990\n",
      "2022-01-23 04:41:52.387799\n",
      "validation Loss: 0.0359 Acc: 0.9907\n",
      "2022-01-23 04:41:52.930192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0100 Acc: 0.9995\n",
      "2022-01-23 04:41:55.662564\n",
      "validation Loss: 0.0372 Acc: 0.9930\n",
      "2022-01-23 04:41:56.072249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 1.0000\n",
      "2022-01-23 04:41:57.509894\n",
      "validation Loss: 0.0304 Acc: 0.9953\n",
      "2022-01-23 04:41:57.947123\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0087 Acc: 1.0000\n",
      "2022-01-23 04:42:00.817130\n",
      "validation Loss: 0.0391 Acc: 0.9907\n",
      "2022-01-23 04:42:01.174982\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0089 Acc: 1.0000\n",
      "2022-01-23 04:42:03.634752\n",
      "validation Loss: 0.0322 Acc: 0.9930\n",
      "2022-01-23 04:42:04.015464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0086 Acc: 1.0000\n",
      "2022-01-23 04:42:06.536194\n",
      "validation Loss: 0.0383 Acc: 0.9907\n",
      "2022-01-23 04:42:06.924855\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 1.0000\n",
      "2022-01-23 04:42:09.417401\n",
      "validation Loss: 0.0279 Acc: 0.9953\n",
      "2022-01-23 04:42:09.777961\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0077 Acc: 1.0000\n",
      "2022-01-23 04:42:12.845446\n",
      "validation Loss: 0.0266 Acc: 0.9953\n",
      "2022-01-23 04:42:13.191152\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0079 Acc: 1.0000\n",
      "2022-01-23 04:42:16.306711\n",
      "validation Loss: 0.0348 Acc: 0.9930\n",
      "2022-01-23 04:42:16.707865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0076 Acc: 1.0000\n",
      "2022-01-23 04:42:19.237090\n",
      "validation Loss: 0.0404 Acc: 0.9930\n",
      "2022-01-23 04:42:19.664305\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 0.9995\n",
      "2022-01-23 04:42:22.156432\n",
      "validation Loss: 0.0344 Acc: 0.9907\n",
      "2022-01-23 04:42:22.531533\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0068 Acc: 1.0000\n",
      "2022-01-23 04:42:25.024111\n",
      "validation Loss: 0.0261 Acc: 0.9953\n",
      "2022-01-23 04:42:25.362933\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 1.0000\n",
      "2022-01-23 04:42:28.428182\n",
      "validation Loss: 0.0362 Acc: 0.9930\n",
      "2022-01-23 04:42:28.795000\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0061 Acc: 1.0000\n",
      "2022-01-23 04:42:31.296595\n",
      "validation Loss: 0.0381 Acc: 0.9907\n",
      "2022-01-23 04:42:31.695980\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0064 Acc: 1.0000\n",
      "2022-01-23 04:42:34.166831\n",
      "validation Loss: 0.0392 Acc: 0.9907\n",
      "2022-01-23 04:42:34.624044\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9995\n",
      "2022-01-23 04:42:37.377221\n",
      "validation Loss: 0.0345 Acc: 0.9930\n",
      "2022-01-23 04:42:37.741650\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 0.9990\n",
      "2022-01-23 04:42:40.226130\n",
      "validation Loss: 0.0386 Acc: 0.9883\n",
      "2022-01-23 04:42:40.648123\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9995\n",
      "2022-01-23 04:42:43.197984\n",
      "validation Loss: 0.0290 Acc: 0.9953\n",
      "2022-01-23 04:42:43.552552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0058 Acc: 1.0000\n",
      "2022-01-23 04:42:46.228022\n",
      "validation Loss: 0.0371 Acc: 0.9930\n",
      "2022-01-23 04:42:46.559248\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0050 Acc: 1.0000\n",
      "2022-01-23 04:42:48.980250\n",
      "validation Loss: 0.0297 Acc: 0.9930\n",
      "2022-01-23 04:42:49.475441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:21nfndav) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 65539... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▇▇▇▇█████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99534</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.99534</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.0261</td></tr><tr><td>loss_train</td><td>0.00504</td></tr><tr><td>loss_validation</td><td>0.02966</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/21nfndav\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/21nfndav</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_043738-21nfndav/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:21nfndav). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3coi0tk3\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 04:42:59.173753\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9702 Acc: 0.0610\n",
      "2022-01-23 04:43:01.686063\n",
      "validation Loss: 2.9409 Acc: 0.1678\n",
      "2022-01-23 04:43:02.101623\n",
      "Accuracy of the network on the 429 test samples: 15.85081585081585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9043 Acc: 0.2470\n",
      "2022-01-23 04:43:04.907112\n",
      "validation Loss: 2.8698 Acc: 0.3147\n",
      "2022-01-23 04:43:05.333899\n",
      "Accuracy of the network on the 429 test samples: 31.23543123543124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8205 Acc: 0.3700\n",
      "2022-01-23 04:43:08.008144\n",
      "validation Loss: 2.7767 Acc: 0.4336\n",
      "2022-01-23 04:43:08.405685\n",
      "Accuracy of the network on the 429 test samples: 40.79254079254079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.7155 Acc: 0.4535\n",
      "2022-01-23 04:43:11.450166\n",
      "validation Loss: 2.6630 Acc: 0.4802\n",
      "2022-01-23 04:43:11.831958\n",
      "Accuracy of the network on the 429 test samples: 49.65034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5921 Acc: 0.5225\n",
      "2022-01-23 04:43:14.575680\n",
      "validation Loss: 2.5344 Acc: 0.5361\n",
      "2022-01-23 04:43:14.953613\n",
      "Accuracy of the network on the 429 test samples: 53.613053613053616\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.4593 Acc: 0.5720\n",
      "2022-01-23 04:43:17.837227\n",
      "validation Loss: 2.4001 Acc: 0.5851\n",
      "2022-01-23 04:43:18.344401\n",
      "Accuracy of the network on the 429 test samples: 58.04195804195804\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3259 Acc: 0.6225\n",
      "2022-01-23 04:43:21.201592\n",
      "validation Loss: 2.2680 Acc: 0.6434\n",
      "2022-01-23 04:43:21.563638\n",
      "Accuracy of the network on the 429 test samples: 64.56876456876456\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1986 Acc: 0.6700\n",
      "2022-01-23 04:43:24.289059\n",
      "validation Loss: 2.1441 Acc: 0.6993\n",
      "2022-01-23 04:43:24.623870\n",
      "Accuracy of the network on the 429 test samples: 67.36596736596736\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.0790 Acc: 0.7315\n",
      "2022-01-23 04:43:27.686778\n",
      "validation Loss: 2.0281 Acc: 0.7413\n",
      "2022-01-23 04:43:28.010115\n",
      "Accuracy of the network on the 429 test samples: 72.49417249417249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.9677 Acc: 0.7670\n",
      "2022-01-23 04:43:30.733039\n",
      "validation Loss: 1.9199 Acc: 0.7809\n",
      "2022-01-23 04:43:31.086445\n",
      "Accuracy of the network on the 429 test samples: 77.62237762237763\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.8637 Acc: 0.8020\n",
      "2022-01-23 04:43:34.102560\n",
      "validation Loss: 1.8197 Acc: 0.8065\n",
      "2022-01-23 04:43:34.506441\n",
      "Accuracy of the network on the 429 test samples: 81.81818181818183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7667 Acc: 0.8315\n",
      "2022-01-23 04:43:37.421182\n",
      "validation Loss: 1.7260 Acc: 0.8159\n",
      "2022-01-23 04:43:37.754215\n",
      "Accuracy of the network on the 429 test samples: 84.38228438228438\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.6760 Acc: 0.8430\n",
      "2022-01-23 04:43:40.732543\n",
      "validation Loss: 1.6378 Acc: 0.8275\n",
      "2022-01-23 04:43:41.161110\n",
      "Accuracy of the network on the 429 test samples: 86.01398601398601\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5913 Acc: 0.8535\n",
      "2022-01-23 04:43:44.013541\n",
      "validation Loss: 1.5554 Acc: 0.8392\n",
      "2022-01-23 04:43:44.360204\n",
      "Accuracy of the network on the 429 test samples: 88.34498834498834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5116 Acc: 0.8670\n",
      "2022-01-23 04:43:47.337188\n",
      "validation Loss: 1.4781 Acc: 0.8415\n",
      "2022-01-23 04:43:47.828913\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.4367 Acc: 0.8700\n",
      "2022-01-23 04:43:50.764869\n",
      "validation Loss: 1.4054 Acc: 0.8508\n",
      "2022-01-23 04:43:51.138157\n",
      "Accuracy of the network on the 429 test samples: 89.74358974358975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3662 Acc: 0.8815\n",
      "2022-01-23 04:43:54.280379\n",
      "validation Loss: 1.3364 Acc: 0.8625\n",
      "2022-01-23 04:43:54.606528\n",
      "Accuracy of the network on the 429 test samples: 89.97668997668997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2999 Acc: 0.8855\n",
      "2022-01-23 04:43:57.577670\n",
      "validation Loss: 1.2716 Acc: 0.8671\n",
      "2022-01-23 04:43:57.945940\n",
      "Accuracy of the network on the 429 test samples: 91.6083916083916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2377 Acc: 0.8950\n",
      "2022-01-23 04:44:01.050363\n",
      "validation Loss: 1.2107 Acc: 0.8765\n",
      "2022-01-23 04:44:01.432539\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1790 Acc: 0.8990\n",
      "2022-01-23 04:44:04.365107\n",
      "validation Loss: 1.1529 Acc: 0.8834\n",
      "2022-01-23 04:44:04.763701\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1234 Acc: 0.9060\n",
      "2022-01-23 04:44:08.014580\n",
      "validation Loss: 1.0990 Acc: 0.8881\n",
      "2022-01-23 04:44:08.371491\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0714 Acc: 0.9115\n",
      "2022-01-23 04:44:11.212254\n",
      "validation Loss: 1.0483 Acc: 0.8974\n",
      "2022-01-23 04:44:11.627313\n",
      "Accuracy of the network on the 429 test samples: 92.3076923076923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0220 Acc: 0.9185\n",
      "2022-01-23 04:44:14.560863\n",
      "validation Loss: 1.0010 Acc: 0.8951\n",
      "2022-01-23 04:44:14.901788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9762 Acc: 0.9215\n",
      "2022-01-23 04:44:17.410773\n",
      "validation Loss: 0.9547 Acc: 0.9021\n",
      "2022-01-23 04:44:17.761936\n",
      "Accuracy of the network on the 429 test samples: 93.47319347319348\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9321 Acc: 0.9250\n",
      "2022-01-23 04:44:20.614474\n",
      "validation Loss: 0.9121 Acc: 0.9091\n",
      "2022-01-23 04:44:20.959082\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8907 Acc: 0.9250\n",
      "2022-01-23 04:44:22.969158\n",
      "validation Loss: 0.8728 Acc: 0.9044\n",
      "2022-01-23 04:44:23.324672\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8524 Acc: 0.9255\n",
      "2022-01-23 04:44:25.792702\n",
      "validation Loss: 0.8338 Acc: 0.9184\n",
      "2022-01-23 04:44:26.154381\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8152 Acc: 0.9290\n",
      "2022-01-23 04:44:29.025557\n",
      "validation Loss: 0.7988 Acc: 0.9301\n",
      "2022-01-23 04:44:29.389514\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7807 Acc: 0.9320\n",
      "2022-01-23 04:44:32.503106\n",
      "validation Loss: 0.7641 Acc: 0.9347\n",
      "2022-01-23 04:44:32.877271\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7477 Acc: 0.9320\n",
      "2022-01-23 04:44:35.760233\n",
      "validation Loss: 0.7324 Acc: 0.9347\n",
      "2022-01-23 04:44:36.104745\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7169 Acc: 0.9355\n",
      "2022-01-23 04:44:39.101720\n",
      "validation Loss: 0.7017 Acc: 0.9417\n",
      "2022-01-23 04:44:39.539714\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6877 Acc: 0.9380\n",
      "2022-01-23 04:44:42.379459\n",
      "validation Loss: 0.6735 Acc: 0.9464\n",
      "2022-01-23 04:44:42.706208\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6599 Acc: 0.9380\n",
      "2022-01-23 04:44:45.635439\n",
      "validation Loss: 0.6472 Acc: 0.9441\n",
      "2022-01-23 04:44:46.113926\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6339 Acc: 0.9395\n",
      "2022-01-23 04:44:47.567208\n",
      "validation Loss: 0.6211 Acc: 0.9464\n",
      "2022-01-23 04:44:47.931082\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6091 Acc: 0.9430\n",
      "2022-01-23 04:44:50.881819\n",
      "validation Loss: 0.5962 Acc: 0.9464\n",
      "2022-01-23 04:44:51.254379\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5859 Acc: 0.9405\n",
      "2022-01-23 04:44:54.164332\n",
      "validation Loss: 0.5742 Acc: 0.9464\n",
      "2022-01-23 04:44:54.529462\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5635 Acc: 0.9430\n",
      "2022-01-23 04:44:57.512755\n",
      "validation Loss: 0.5519 Acc: 0.9487\n",
      "2022-01-23 04:44:57.887323\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5422 Acc: 0.9475\n",
      "2022-01-23 04:45:00.868299\n",
      "validation Loss: 0.5318 Acc: 0.9510\n",
      "2022-01-23 04:45:01.231024\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5223 Acc: 0.9500\n",
      "2022-01-23 04:45:03.247928\n",
      "validation Loss: 0.5125 Acc: 0.9534\n",
      "2022-01-23 04:45:03.616145\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5031 Acc: 0.9515\n",
      "2022-01-23 04:45:06.641277\n",
      "validation Loss: 0.4946 Acc: 0.9487\n",
      "2022-01-23 04:45:07.013394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4860 Acc: 0.9515\n",
      "2022-01-23 04:45:09.572996\n",
      "validation Loss: 0.4766 Acc: 0.9557\n",
      "2022-01-23 04:45:09.989949\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4683 Acc: 0.9535\n",
      "2022-01-23 04:45:12.858857\n",
      "validation Loss: 0.4602 Acc: 0.9557\n",
      "2022-01-23 04:45:13.227641\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4523 Acc: 0.9565\n",
      "2022-01-23 04:45:16.243881\n",
      "validation Loss: 0.4442 Acc: 0.9580\n",
      "2022-01-23 04:45:16.639653\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4365 Acc: 0.9555\n",
      "2022-01-23 04:45:19.500749\n",
      "validation Loss: 0.4293 Acc: 0.9580\n",
      "2022-01-23 04:45:19.879662\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4223 Acc: 0.9570\n",
      "2022-01-23 04:45:22.698936\n",
      "validation Loss: 0.4155 Acc: 0.9580\n",
      "2022-01-23 04:45:23.171133\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4082 Acc: 0.9580\n",
      "2022-01-23 04:45:26.121904\n",
      "validation Loss: 0.4016 Acc: 0.9580\n",
      "2022-01-23 04:45:26.554553\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3950 Acc: 0.9590\n",
      "2022-01-23 04:45:29.305142\n",
      "validation Loss: 0.3883 Acc: 0.9604\n",
      "2022-01-23 04:45:29.745286\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3820 Acc: 0.9605\n",
      "2022-01-23 04:45:32.612504\n",
      "validation Loss: 0.3762 Acc: 0.9604\n",
      "2022-01-23 04:45:33.018453\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3699 Acc: 0.9620\n",
      "2022-01-23 04:45:35.801244\n",
      "validation Loss: 0.3648 Acc: 0.9580\n",
      "2022-01-23 04:45:36.150098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3584 Acc: 0.9615\n",
      "2022-01-23 04:45:38.653911\n",
      "validation Loss: 0.3542 Acc: 0.9580\n",
      "2022-01-23 04:45:39.005307\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3472 Acc: 0.9630\n",
      "2022-01-23 04:45:41.631026\n",
      "validation Loss: 0.3431 Acc: 0.9580\n",
      "2022-01-23 04:45:42.291206\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3367 Acc: 0.9635\n",
      "2022-01-23 04:45:44.716300\n",
      "validation Loss: 0.3345 Acc: 0.9604\n",
      "2022-01-23 04:45:45.072752\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3267 Acc: 0.9635\n",
      "2022-01-23 04:45:48.127545\n",
      "validation Loss: 0.3233 Acc: 0.9580\n",
      "2022-01-23 04:45:48.486612\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3167 Acc: 0.9650\n",
      "2022-01-23 04:45:50.996688\n",
      "validation Loss: 0.3160 Acc: 0.9604\n",
      "2022-01-23 04:45:51.326909\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3080 Acc: 0.9650\n",
      "2022-01-23 04:45:54.154648\n",
      "validation Loss: 0.3052 Acc: 0.9604\n",
      "2022-01-23 04:45:54.502818\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2991 Acc: 0.9665\n",
      "2022-01-23 04:45:57.284422\n",
      "validation Loss: 0.2969 Acc: 0.9604\n",
      "2022-01-23 04:45:57.646268\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2902 Acc: 0.9660\n",
      "2022-01-23 04:46:00.528295\n",
      "validation Loss: 0.2891 Acc: 0.9604\n",
      "2022-01-23 04:46:00.945189\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2820 Acc: 0.9675\n",
      "2022-01-23 04:46:03.814691\n",
      "validation Loss: 0.2811 Acc: 0.9604\n",
      "2022-01-23 04:46:04.180566\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2740 Acc: 0.9680\n",
      "2022-01-23 04:46:07.230153\n",
      "validation Loss: 0.2740 Acc: 0.9604\n",
      "2022-01-23 04:46:07.704284\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2671 Acc: 0.9660\n",
      "2022-01-23 04:46:10.619030\n",
      "validation Loss: 0.2669 Acc: 0.9627\n",
      "2022-01-23 04:46:10.969567\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2595 Acc: 0.9685\n",
      "2022-01-23 04:46:13.900628\n",
      "validation Loss: 0.2599 Acc: 0.9627\n",
      "2022-01-23 04:46:14.371122\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2523 Acc: 0.9700\n",
      "2022-01-23 04:46:17.328903\n",
      "validation Loss: 0.2534 Acc: 0.9627\n",
      "2022-01-23 04:46:17.677742\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2456 Acc: 0.9715\n",
      "2022-01-23 04:46:20.713953\n",
      "validation Loss: 0.2475 Acc: 0.9627\n",
      "2022-01-23 04:46:21.076116\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2395 Acc: 0.9705\n",
      "2022-01-23 04:46:24.017339\n",
      "validation Loss: 0.2412 Acc: 0.9627\n",
      "2022-01-23 04:46:24.379181\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2327 Acc: 0.9735\n",
      "2022-01-23 04:46:27.451012\n",
      "validation Loss: 0.2353 Acc: 0.9627\n",
      "2022-01-23 04:46:27.815374\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2275 Acc: 0.9720\n",
      "2022-01-23 04:46:30.860275\n",
      "validation Loss: 0.2309 Acc: 0.9650\n",
      "2022-01-23 04:46:31.220626\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2212 Acc: 0.9730\n",
      "2022-01-23 04:46:34.259132\n",
      "validation Loss: 0.2245 Acc: 0.9627\n",
      "2022-01-23 04:46:34.616041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2157 Acc: 0.9740\n",
      "2022-01-23 04:46:37.189416\n",
      "validation Loss: 0.2194 Acc: 0.9627\n",
      "2022-01-23 04:46:37.544023\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2102 Acc: 0.9730\n",
      "2022-01-23 04:46:40.121560\n",
      "validation Loss: 0.2144 Acc: 0.9627\n",
      "2022-01-23 04:46:40.560187\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2051 Acc: 0.9745\n",
      "2022-01-23 04:46:43.203833\n",
      "validation Loss: 0.2101 Acc: 0.9650\n",
      "2022-01-23 04:46:43.566405\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1998 Acc: 0.9760\n",
      "2022-01-23 04:46:46.450693\n",
      "validation Loss: 0.2048 Acc: 0.9650\n",
      "2022-01-23 04:46:46.833410\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1949 Acc: 0.9770\n",
      "2022-01-23 04:46:49.810451\n",
      "validation Loss: 0.2002 Acc: 0.9627\n",
      "2022-01-23 04:46:50.160898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1903 Acc: 0.9760\n",
      "2022-01-23 04:46:52.653596\n",
      "validation Loss: 0.1970 Acc: 0.9650\n",
      "2022-01-23 04:46:53.029162\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1856 Acc: 0.9780\n",
      "2022-01-23 04:46:56.078204\n",
      "validation Loss: 0.1919 Acc: 0.9627\n",
      "2022-01-23 04:46:56.673505\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1815 Acc: 0.9790\n",
      "2022-01-23 04:46:59.308859\n",
      "validation Loss: 0.1883 Acc: 0.9650\n",
      "2022-01-23 04:46:59.740859\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1770 Acc: 0.9770\n",
      "2022-01-23 04:47:02.656270\n",
      "validation Loss: 0.1841 Acc: 0.9627\n",
      "2022-01-23 04:47:02.998796\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1731 Acc: 0.9765\n",
      "2022-01-23 04:47:05.525473\n",
      "validation Loss: 0.1809 Acc: 0.9674\n",
      "2022-01-23 04:47:06.050840\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1693 Acc: 0.9780\n",
      "2022-01-23 04:47:09.013293\n",
      "validation Loss: 0.1767 Acc: 0.9627\n",
      "2022-01-23 04:47:09.361283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1652 Acc: 0.9775\n",
      "2022-01-23 04:47:12.024046\n",
      "validation Loss: 0.1733 Acc: 0.9650\n",
      "2022-01-23 04:47:12.364112\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1614 Acc: 0.9770\n",
      "2022-01-23 04:47:15.037709\n",
      "validation Loss: 0.1700 Acc: 0.9650\n",
      "2022-01-23 04:47:15.527852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1578 Acc: 0.9785\n",
      "2022-01-23 04:47:18.039232\n",
      "validation Loss: 0.1676 Acc: 0.9674\n",
      "2022-01-23 04:47:18.412825\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1541 Acc: 0.9795\n",
      "2022-01-23 04:47:21.214819\n",
      "validation Loss: 0.1639 Acc: 0.9650\n",
      "2022-01-23 04:47:21.578006\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1510 Acc: 0.9795\n",
      "2022-01-23 04:47:24.130017\n",
      "validation Loss: 0.1606 Acc: 0.9674\n",
      "2022-01-23 04:47:24.722018\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1475 Acc: 0.9775\n",
      "2022-01-23 04:47:27.612895\n",
      "validation Loss: 0.1573 Acc: 0.9674\n",
      "2022-01-23 04:47:27.979065\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1442 Acc: 0.9790\n",
      "2022-01-23 04:47:30.827201\n",
      "validation Loss: 0.1548 Acc: 0.9697\n",
      "2022-01-23 04:47:31.172489\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1408 Acc: 0.9795\n",
      "2022-01-23 04:47:34.435858\n",
      "validation Loss: 0.1519 Acc: 0.9650\n",
      "2022-01-23 04:47:34.782275\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1380 Acc: 0.9795\n",
      "2022-01-23 04:47:37.308695\n",
      "validation Loss: 0.1492 Acc: 0.9720\n",
      "2022-01-23 04:47:37.695254\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1347 Acc: 0.9790\n",
      "2022-01-23 04:47:40.825181\n",
      "validation Loss: 0.1468 Acc: 0.9674\n",
      "2022-01-23 04:47:41.170644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1317 Acc: 0.9800\n",
      "2022-01-23 04:47:43.831957\n",
      "validation Loss: 0.1463 Acc: 0.9674\n",
      "2022-01-23 04:47:44.183148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1296 Acc: 0.9810\n",
      "2022-01-23 04:47:46.610150\n",
      "validation Loss: 0.1430 Acc: 0.9674\n",
      "2022-01-23 04:47:46.987886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1265 Acc: 0.9810\n",
      "2022-01-23 04:47:49.393211\n",
      "validation Loss: 0.1399 Acc: 0.9674\n",
      "2022-01-23 04:47:49.793818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1239 Acc: 0.9795\n",
      "2022-01-23 04:47:52.325400\n",
      "validation Loss: 0.1376 Acc: 0.9674\n",
      "2022-01-23 04:47:52.715899\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1213 Acc: 0.9800\n",
      "2022-01-23 04:47:55.151294\n",
      "validation Loss: 0.1356 Acc: 0.9674\n",
      "2022-01-23 04:47:55.494639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1190 Acc: 0.9810\n",
      "2022-01-23 04:47:57.951559\n",
      "validation Loss: 0.1332 Acc: 0.9674\n",
      "2022-01-23 04:47:58.339356\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1162 Acc: 0.9805\n",
      "2022-01-23 04:48:00.934678\n",
      "validation Loss: 0.1333 Acc: 0.9674\n",
      "2022-01-23 04:48:01.352395\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1143 Acc: 0.9810\n",
      "2022-01-23 04:48:03.841435\n",
      "validation Loss: 0.1291 Acc: 0.9674\n",
      "2022-01-23 04:48:04.359809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1116 Acc: 0.9825\n",
      "2022-01-23 04:48:06.765391\n",
      "validation Loss: 0.1271 Acc: 0.9674\n",
      "2022-01-23 04:48:07.133364\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1092 Acc: 0.9820\n",
      "2022-01-23 04:48:09.657474\n",
      "validation Loss: 0.1248 Acc: 0.9697\n",
      "2022-01-23 04:48:10.026823\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1070 Acc: 0.9825\n",
      "2022-01-23 04:48:12.456956\n",
      "validation Loss: 0.1236 Acc: 0.9674\n",
      "2022-01-23 04:48:12.828176\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1056 Acc: 0.9815\n",
      "2022-01-23 04:48:15.462249\n",
      "validation Loss: 0.1208 Acc: 0.9720\n",
      "2022-01-23 04:48:15.839005\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9720\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3coi0tk3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 65231... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▂▄▅▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▃▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▃▅▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.97203</td></tr><tr><td>accuracy_train</td><td>0.9815</td></tr><tr><td>accuracy_validation</td><td>0.97203</td></tr><tr><td>best_test_accuracy</td><td>0.97203</td></tr><tr><td>best_val_accuracy</td><td>0.97203</td></tr><tr><td>best_val_loss</td><td>0.12082</td></tr><tr><td>loss_train</td><td>0.10561</td></tr><tr><td>loss_validation</td><td>0.12082</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3coi0tk3\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3coi0tk3</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_044249-3coi0tk3/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3coi0tk3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2jq8fjnh\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 04:48:25.874946\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 1.1740 Acc: 0.6475\n",
      "2022-01-23 04:48:28.451623\n",
      "validation Loss: 1.1493 Acc: 0.6503\n",
      "2022-01-23 04:48:28.844612\n",
      "Accuracy of the network on the 429 test samples: 65.03496503496503\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.7598 Acc: 0.7795\n",
      "2022-01-23 04:48:31.747046\n",
      "validation Loss: 0.6586 Acc: 0.8065\n",
      "2022-01-23 04:48:32.118039\n",
      "Accuracy of the network on the 429 test samples: 82.05128205128204\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.3376 Acc: 0.8900\n",
      "2022-01-23 04:48:35.005030\n",
      "validation Loss: 0.2507 Acc: 0.9231\n",
      "2022-01-23 04:48:35.354761\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1843 Acc: 0.9420\n",
      "2022-01-23 04:48:38.295935\n",
      "validation Loss: 0.2059 Acc: 0.9441\n",
      "2022-01-23 04:48:38.688838\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1271 Acc: 0.9680\n",
      "2022-01-23 04:48:41.728938\n",
      "validation Loss: 0.2066 Acc: 0.9231\n",
      "2022-01-23 04:48:42.071901\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1466 Acc: 0.9520\n",
      "2022-01-23 04:48:44.658197\n",
      "validation Loss: 0.3010 Acc: 0.9161\n",
      "2022-01-23 04:48:45.021238\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1383 Acc: 0.9505\n",
      "2022-01-23 04:48:47.520563\n",
      "validation Loss: 0.2321 Acc: 0.9394\n",
      "2022-01-23 04:48:47.906870\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1593 Acc: 0.9545\n",
      "2022-01-23 04:48:50.478446\n",
      "validation Loss: 0.1338 Acc: 0.9487\n",
      "2022-01-23 04:48:50.896834\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2322 Acc: 0.9330\n",
      "2022-01-23 04:48:53.899756\n",
      "validation Loss: 0.3180 Acc: 0.9184\n",
      "2022-01-23 04:48:54.270562\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1488 Acc: 0.9480\n",
      "2022-01-23 04:48:56.799521\n",
      "validation Loss: 0.1405 Acc: 0.9464\n",
      "2022-01-23 04:48:57.146382\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1474 Acc: 0.9615\n",
      "2022-01-23 04:48:59.710744\n",
      "validation Loss: 0.1374 Acc: 0.9510\n",
      "2022-01-23 04:49:00.098407\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1534 Acc: 0.9530\n",
      "2022-01-23 04:49:03.058299\n",
      "validation Loss: 0.2975 Acc: 0.9301\n",
      "2022-01-23 04:49:03.400024\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1017 Acc: 0.9695\n",
      "2022-01-23 04:49:05.901555\n",
      "validation Loss: 0.1691 Acc: 0.9371\n",
      "2022-01-23 04:49:06.266797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0610 Acc: 0.9750\n",
      "2022-01-23 04:49:08.875887\n",
      "validation Loss: 0.0991 Acc: 0.9627\n",
      "2022-01-23 04:49:09.262227\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0875 Acc: 0.9700\n",
      "2022-01-23 04:49:12.260189\n",
      "validation Loss: 0.1562 Acc: 0.9604\n",
      "2022-01-23 04:49:12.644412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0860 Acc: 0.9690\n",
      "2022-01-23 04:49:15.122068\n",
      "validation Loss: 0.1069 Acc: 0.9720\n",
      "2022-01-23 04:49:15.721646\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1096 Acc: 0.9655\n",
      "2022-01-23 04:49:18.643006\n",
      "validation Loss: 0.1180 Acc: 0.9534\n",
      "2022-01-23 04:49:18.997219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0987 Acc: 0.9680\n",
      "2022-01-23 04:49:21.502236\n",
      "validation Loss: 0.1061 Acc: 0.9697\n",
      "2022-01-23 04:49:21.880960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0532 Acc: 0.9825\n",
      "2022-01-23 04:49:24.386661\n",
      "validation Loss: 0.2089 Acc: 0.9417\n",
      "2022-01-23 04:49:24.883786\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2709 Acc: 0.9275\n",
      "2022-01-23 04:49:27.655092\n",
      "validation Loss: 0.1597 Acc: 0.9510\n",
      "2022-01-23 04:49:28.036523\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0936 Acc: 0.9700\n",
      "2022-01-23 04:49:30.658864\n",
      "validation Loss: 0.0925 Acc: 0.9580\n",
      "2022-01-23 04:49:31.029598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0470 Acc: 0.9835\n",
      "2022-01-23 04:49:33.622675\n",
      "validation Loss: 0.0538 Acc: 0.9814\n",
      "2022-01-23 04:49:34.066763\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0364 Acc: 0.9880\n",
      "2022-01-23 04:49:37.086090\n",
      "validation Loss: 0.0536 Acc: 0.9767\n",
      "2022-01-23 04:49:37.448739\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0548 Acc: 0.9845\n",
      "2022-01-23 04:49:40.026427\n",
      "validation Loss: 0.0853 Acc: 0.9744\n",
      "2022-01-23 04:49:40.465656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0575 Acc: 0.9805\n",
      "2022-01-23 04:49:43.088507\n",
      "validation Loss: 0.1264 Acc: 0.9580\n",
      "2022-01-23 04:49:43.563792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0402 Acc: 0.9880\n",
      "2022-01-23 04:49:46.108478\n",
      "validation Loss: 0.0547 Acc: 0.9814\n",
      "2022-01-23 04:49:46.544615\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0190 Acc: 0.9945\n",
      "2022-01-23 04:49:49.222590\n",
      "validation Loss: 0.0330 Acc: 0.9883\n",
      "2022-01-23 04:49:49.608368\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0334 Acc: 0.9885\n",
      "2022-01-23 04:49:52.518700\n",
      "validation Loss: 0.0433 Acc: 0.9814\n",
      "2022-01-23 04:49:53.091077\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9865\n",
      "2022-01-23 04:49:55.628723\n",
      "validation Loss: 0.0942 Acc: 0.9650\n",
      "2022-01-23 04:49:56.004200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0644 Acc: 0.9795\n",
      "2022-01-23 04:49:58.556769\n",
      "validation Loss: 0.1804 Acc: 0.9557\n",
      "2022-01-23 04:49:58.896126\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1001 Acc: 0.9725\n",
      "2022-01-23 04:50:01.344740\n",
      "validation Loss: 0.0963 Acc: 0.9580\n",
      "2022-01-23 04:50:01.687445\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0577 Acc: 0.9820\n",
      "2022-01-23 04:50:04.272934\n",
      "validation Loss: 0.0564 Acc: 0.9814\n",
      "2022-01-23 04:50:04.647544\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0543 Acc: 0.9855\n",
      "2022-01-23 04:50:07.273165\n",
      "validation Loss: 0.0547 Acc: 0.9767\n",
      "2022-01-23 04:50:07.655625\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2323 Acc: 0.9305\n",
      "2022-01-23 04:50:10.095810\n",
      "validation Loss: 0.1289 Acc: 0.9650\n",
      "2022-01-23 04:50:10.508227\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0895 Acc: 0.9745\n",
      "2022-01-23 04:50:13.028171\n",
      "validation Loss: 0.1034 Acc: 0.9627\n",
      "2022-01-23 04:50:13.347584\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0925 Acc: 0.9765\n",
      "2022-01-23 04:50:15.865283\n",
      "validation Loss: 0.1656 Acc: 0.9627\n",
      "2022-01-23 04:50:16.229905\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0631 Acc: 0.9805\n",
      "2022-01-23 04:50:18.752075\n",
      "validation Loss: 0.1022 Acc: 0.9650\n",
      "2022-01-23 04:50:19.335729\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0753 Acc: 0.9755\n",
      "2022-01-23 04:50:21.765680\n",
      "validation Loss: 0.1652 Acc: 0.9510\n",
      "2022-01-23 04:50:22.143512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0547 Acc: 0.9825\n",
      "2022-01-23 04:50:24.591556\n",
      "validation Loss: 0.0812 Acc: 0.9767\n",
      "2022-01-23 04:50:24.946429\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9940\n",
      "2022-01-23 04:50:27.412101\n",
      "validation Loss: 0.0884 Acc: 0.9814\n",
      "2022-01-23 04:50:27.758487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9955\n",
      "2022-01-23 04:50:30.359654\n",
      "validation Loss: 0.0601 Acc: 0.9860\n",
      "2022-01-23 04:50:30.949675\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0249 Acc: 0.9940\n",
      "2022-01-23 04:50:33.445477\n",
      "validation Loss: 0.2136 Acc: 0.9580\n",
      "2022-01-23 04:50:33.804352\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0355 Acc: 0.9890\n",
      "2022-01-23 04:50:36.608784\n",
      "validation Loss: 0.0987 Acc: 0.9744\n",
      "2022-01-23 04:50:37.013494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0228 Acc: 0.9945\n",
      "2022-01-23 04:50:39.714827\n",
      "validation Loss: 0.1119 Acc: 0.9697\n",
      "2022-01-23 04:50:40.055019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0234 Acc: 0.9925\n",
      "2022-01-23 04:50:42.957874\n",
      "validation Loss: 0.0559 Acc: 0.9814\n",
      "2022-01-23 04:50:43.331640\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0319 Acc: 0.9890\n",
      "2022-01-23 04:50:45.925539\n",
      "validation Loss: 0.1592 Acc: 0.9627\n",
      "2022-01-23 04:50:46.281229\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0177 Acc: 0.9950\n",
      "2022-01-23 04:50:48.826379\n",
      "validation Loss: 0.0854 Acc: 0.9767\n",
      "2022-01-23 04:50:49.163249\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0217 Acc: 0.9930\n",
      "2022-01-23 04:50:51.700232\n",
      "validation Loss: 0.2052 Acc: 0.9627\n",
      "2022-01-23 04:50:52.113573\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0932 Acc: 0.9835\n",
      "2022-01-23 04:50:54.629962\n",
      "validation Loss: 0.0802 Acc: 0.9790\n",
      "2022-01-23 04:50:54.971883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0346 Acc: 0.9900\n",
      "2022-01-23 04:50:57.569314\n",
      "validation Loss: 0.0668 Acc: 0.9744\n",
      "2022-01-23 04:50:57.917572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0437 Acc: 0.9860\n",
      "2022-01-23 04:51:00.418564\n",
      "validation Loss: 0.1790 Acc: 0.9347\n",
      "2022-01-23 04:51:00.796372\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1287 Acc: 0.9540\n",
      "2022-01-23 04:51:03.385735\n",
      "validation Loss: 0.1155 Acc: 0.9720\n",
      "2022-01-23 04:51:03.749009\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0503 Acc: 0.9820\n",
      "2022-01-23 04:51:06.478606\n",
      "validation Loss: 0.1091 Acc: 0.9767\n",
      "2022-01-23 04:51:06.839288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0583 Acc: 0.9835\n",
      "2022-01-23 04:51:09.371528\n",
      "validation Loss: 0.0992 Acc: 0.9674\n",
      "2022-01-23 04:51:09.731627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0860 Acc: 0.9740\n",
      "2022-01-23 04:51:12.261405\n",
      "validation Loss: 0.1353 Acc: 0.9627\n",
      "2022-01-23 04:51:12.619752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0342 Acc: 0.9885\n",
      "2022-01-23 04:51:15.306186\n",
      "validation Loss: 0.0616 Acc: 0.9860\n",
      "2022-01-23 04:51:15.680410\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0425 Acc: 0.9880\n",
      "2022-01-23 04:51:17.290050\n",
      "validation Loss: 0.0791 Acc: 0.9767\n",
      "2022-01-23 04:51:17.641948\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0187 Acc: 0.9930\n",
      "2022-01-23 04:51:20.271413\n",
      "validation Loss: 0.0874 Acc: 0.9720\n",
      "2022-01-23 04:51:20.638291\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0299 Acc: 0.9915\n",
      "2022-01-23 04:51:22.163635\n",
      "validation Loss: 0.0610 Acc: 0.9860\n",
      "2022-01-23 04:51:22.502506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0436 Acc: 0.9870\n",
      "2022-01-23 04:51:25.041197\n",
      "validation Loss: 0.1550 Acc: 0.9627\n",
      "2022-01-23 04:51:25.442606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0769 Acc: 0.9775\n",
      "2022-01-23 04:51:28.177308\n",
      "validation Loss: 0.0815 Acc: 0.9767\n",
      "2022-01-23 04:51:28.518602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0687 Acc: 0.9820\n",
      "2022-01-23 04:51:31.223227\n",
      "validation Loss: 0.0498 Acc: 0.9837\n",
      "2022-01-23 04:51:31.636490\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0089 Acc: 0.9960\n",
      "2022-01-23 04:51:34.175948\n",
      "validation Loss: 0.0651 Acc: 0.9767\n",
      "2022-01-23 04:51:34.579465\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 0.9995\n",
      "2022-01-23 04:51:37.205580\n",
      "validation Loss: 0.0197 Acc: 0.9907\n",
      "2022-01-23 04:51:37.763789\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 04:51:40.729268\n",
      "validation Loss: 0.0244 Acc: 0.9883\n",
      "2022-01-23 04:51:41.091829\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 04:51:43.662880\n",
      "validation Loss: 0.0423 Acc: 0.9814\n",
      "2022-01-23 04:51:44.020883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0243 Acc: 0.9925\n",
      "2022-01-23 04:51:46.660485\n",
      "validation Loss: 0.0709 Acc: 0.9767\n",
      "2022-01-23 04:51:47.228885\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0337 Acc: 0.9910\n",
      "2022-01-23 04:51:49.958553\n",
      "validation Loss: 0.0875 Acc: 0.9767\n",
      "2022-01-23 04:51:50.300134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0417 Acc: 0.9870\n",
      "2022-01-23 04:51:52.856918\n",
      "validation Loss: 0.0764 Acc: 0.9790\n",
      "2022-01-23 04:51:53.288626\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0740 Acc: 0.9815\n",
      "2022-01-23 04:51:55.892770\n",
      "validation Loss: 0.1058 Acc: 0.9790\n",
      "2022-01-23 04:51:56.286214\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0626 Acc: 0.9850\n",
      "2022-01-23 04:51:59.224182\n",
      "validation Loss: 0.1130 Acc: 0.9604\n",
      "2022-01-23 04:51:59.606234\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1110 Acc: 0.9685\n",
      "2022-01-23 04:52:02.167859\n",
      "validation Loss: 0.1163 Acc: 0.9744\n",
      "2022-01-23 04:52:02.533019\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1354 Acc: 0.9635\n",
      "2022-01-23 04:52:05.207281\n",
      "validation Loss: 0.1122 Acc: 0.9720\n",
      "2022-01-23 04:52:05.568623\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0760 Acc: 0.9755\n",
      "2022-01-23 04:52:08.438491\n",
      "validation Loss: 0.2001 Acc: 0.9510\n",
      "2022-01-23 04:52:08.926180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0561 Acc: 0.9865\n",
      "2022-01-23 04:52:11.553466\n",
      "validation Loss: 0.0826 Acc: 0.9744\n",
      "2022-01-23 04:52:11.899280\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0300 Acc: 0.9930\n",
      "2022-01-23 04:52:14.559859\n",
      "validation Loss: 0.1055 Acc: 0.9674\n",
      "2022-01-23 04:52:14.955999\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0273 Acc: 0.9900\n",
      "2022-01-23 04:52:17.562126\n",
      "validation Loss: 0.0417 Acc: 0.9907\n",
      "2022-01-23 04:52:17.916202\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9960\n",
      "2022-01-23 04:52:20.452111\n",
      "validation Loss: 0.0968 Acc: 0.9790\n",
      "2022-01-23 04:52:20.846409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.3152 Acc: 0.9225\n",
      "2022-01-23 04:52:23.344097\n",
      "validation Loss: 0.3911 Acc: 0.9138\n",
      "2022-01-23 04:52:23.686661\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0951 Acc: 0.9705\n",
      "2022-01-23 04:52:26.268010\n",
      "validation Loss: 0.1157 Acc: 0.9744\n",
      "2022-01-23 04:52:26.629718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1770 Acc: 0.9525\n",
      "2022-01-23 04:52:28.431445\n",
      "validation Loss: 0.0840 Acc: 0.9674\n",
      "2022-01-23 04:52:28.819194\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0421 Acc: 0.9835\n",
      "2022-01-23 04:52:31.405925\n",
      "validation Loss: 0.0866 Acc: 0.9744\n",
      "2022-01-23 04:52:31.760413\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0620 Acc: 0.9835\n",
      "2022-01-23 04:52:34.184825\n",
      "validation Loss: 0.0632 Acc: 0.9767\n",
      "2022-01-23 04:52:34.573667\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0256 Acc: 0.9910\n",
      "2022-01-23 04:52:37.283687\n",
      "validation Loss: 0.0456 Acc: 0.9814\n",
      "2022-01-23 04:52:37.716674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0272 Acc: 0.9930\n",
      "2022-01-23 04:52:40.206352\n",
      "validation Loss: 0.0718 Acc: 0.9744\n",
      "2022-01-23 04:52:40.598724\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0321 Acc: 0.9900\n",
      "2022-01-23 04:52:43.066209\n",
      "validation Loss: 0.0940 Acc: 0.9627\n",
      "2022-01-23 04:52:43.413118\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9910\n",
      "2022-01-23 04:52:45.880754\n",
      "validation Loss: 0.0277 Acc: 0.9907\n",
      "2022-01-23 04:52:46.327073\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0314 Acc: 0.9915\n",
      "2022-01-23 04:52:48.820258\n",
      "validation Loss: 0.0397 Acc: 0.9860\n",
      "2022-01-23 04:52:49.363954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9980\n",
      "2022-01-23 04:52:51.954574\n",
      "validation Loss: 0.0241 Acc: 0.9883\n",
      "2022-01-23 04:52:52.291930\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 0.9985\n",
      "2022-01-23 04:52:54.864953\n",
      "validation Loss: 0.0672 Acc: 0.9814\n",
      "2022-01-23 04:52:55.286546\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0276 Acc: 0.9935\n",
      "2022-01-23 04:52:57.867444\n",
      "validation Loss: 0.0613 Acc: 0.9814\n",
      "2022-01-23 04:52:58.222888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0112 Acc: 0.9950\n",
      "2022-01-23 04:53:00.802267\n",
      "validation Loss: 0.0450 Acc: 0.9883\n",
      "2022-01-23 04:53:01.376848\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0145 Acc: 0.9945\n",
      "2022-01-23 04:53:04.017230\n",
      "validation Loss: 0.0528 Acc: 0.9837\n",
      "2022-01-23 04:53:04.396589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0052 Acc: 0.9985\n",
      "2022-01-23 04:53:06.929482\n",
      "validation Loss: 0.0273 Acc: 0.9930\n",
      "2022-01-23 04:53:07.275235\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0349 Acc: 0.9900\n",
      "2022-01-23 04:53:10.457389\n",
      "validation Loss: 0.1175 Acc: 0.9720\n",
      "2022-01-23 04:53:10.813499\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0236 Acc: 0.9915\n",
      "2022-01-23 04:53:13.484219\n",
      "validation Loss: 0.2204 Acc: 0.9604\n",
      "2022-01-23 04:53:13.823788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1815 Acc: 0.9525\n",
      "2022-01-23 04:53:16.473472\n",
      "validation Loss: 0.1856 Acc: 0.9510\n",
      "2022-01-23 04:53:16.848132\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0600 Acc: 0.9835\n",
      "2022-01-23 04:53:19.415848\n",
      "validation Loss: 0.0366 Acc: 0.9883\n",
      "2022-01-23 04:53:19.768611\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9945\n",
      "2022-01-23 04:53:22.348002\n",
      "validation Loss: 0.0421 Acc: 0.9814\n",
      "2022-01-23 04:53:22.795363\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0129 Acc: 0.9960\n",
      "2022-01-23 04:53:25.401781\n",
      "validation Loss: 0.0185 Acc: 0.9930\n",
      "2022-01-23 04:53:25.765300\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9930\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2jq8fjnh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 78139... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▇▇▇▇███████</td></tr><tr><td>accuracy_train</td><td>▁▆▇▇▇▇▇▇▇███▇▇██████████████▇██▆██████▇█</td></tr><tr><td>accuracy_validation</td><td>▁▇▆▇▇▇██▇███▇▇▇███▇█▇▇███████▇█▆██████▇█</td></tr><tr><td>loss_train</td><td>█▃▂▂▂▂▁▂▂▁▁▁▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▃▁▁▁▁▁▁▂▁</td></tr><tr><td>loss_validation</td><td>█▂▃▂▂▂▂▂▁▁▁▁▁▂▂▁▁▂▂▁▂▂▁▁▁▁▁▁▂▂▁▃▁▁▁▁▁▁▂▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98368</td></tr><tr><td>accuracy_train</td><td>0.996</td></tr><tr><td>accuracy_validation</td><td>0.99301</td></tr><tr><td>best_test_accuracy</td><td>0.98368</td></tr><tr><td>best_val_accuracy</td><td>0.99301</td></tr><tr><td>best_val_loss</td><td>0.01846</td></tr><tr><td>loss_train</td><td>0.01287</td></tr><tr><td>loss_validation</td><td>0.01846</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2jq8fjnh\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2jq8fjnh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_044816-2jq8fjnh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2jq8fjnh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/xk3ttwve\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 04:53:35.550043\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.3766 Acc: 0.5900\n",
      "2022-01-23 04:53:38.171820\n",
      "validation Loss: 0.5669 Acc: 0.8485\n",
      "2022-01-23 04:53:38.526716\n",
      "Accuracy of the network on the 429 test samples: 85.54778554778555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.4044 Acc: 0.8905\n",
      "2022-01-23 04:53:41.368508\n",
      "validation Loss: 0.3412 Acc: 0.8881\n",
      "2022-01-23 04:53:41.743204\n",
      "Accuracy of the network on the 429 test samples: 88.34498834498834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2873 Acc: 0.9200\n",
      "2022-01-23 04:53:43.687808\n",
      "validation Loss: 0.1764 Acc: 0.9441\n",
      "2022-01-23 04:53:44.032413\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1243 Acc: 0.9595\n",
      "2022-01-23 04:53:46.959760\n",
      "validation Loss: 0.1303 Acc: 0.9441\n",
      "2022-01-23 04:53:47.338438\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2713 Acc: 0.9305\n",
      "2022-01-23 04:53:50.309379\n",
      "validation Loss: 0.2137 Acc: 0.9441\n",
      "2022-01-23 04:53:50.650049\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2105 Acc: 0.9410\n",
      "2022-01-23 04:53:53.240085\n",
      "validation Loss: 0.1625 Acc: 0.9417\n",
      "2022-01-23 04:53:53.685827\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1382 Acc: 0.9580\n",
      "2022-01-23 04:53:56.190432\n",
      "validation Loss: 0.1169 Acc: 0.9627\n",
      "2022-01-23 04:53:56.601088\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0896 Acc: 0.9715\n",
      "2022-01-23 04:53:59.507716\n",
      "validation Loss: 0.1300 Acc: 0.9650\n",
      "2022-01-23 04:53:59.861410\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0994 Acc: 0.9715\n",
      "2022-01-23 04:54:02.883340\n",
      "validation Loss: 0.1127 Acc: 0.9650\n",
      "2022-01-23 04:54:03.243395\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0711 Acc: 0.9740\n",
      "2022-01-23 04:54:06.078364\n",
      "validation Loss: 0.1452 Acc: 0.9464\n",
      "2022-01-23 04:54:06.423071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0699 Acc: 0.9760\n",
      "2022-01-23 04:54:08.909414\n",
      "validation Loss: 0.0873 Acc: 0.9744\n",
      "2022-01-23 04:54:09.418969\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0349 Acc: 0.9865\n",
      "2022-01-23 04:54:12.502754\n",
      "validation Loss: 0.1458 Acc: 0.9487\n",
      "2022-01-23 04:54:12.854816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0826 Acc: 0.9740\n",
      "2022-01-23 04:54:15.548228\n",
      "validation Loss: 0.1571 Acc: 0.9510\n",
      "2022-01-23 04:54:15.957950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0479 Acc: 0.9850\n",
      "2022-01-23 04:54:18.682365\n",
      "validation Loss: 0.1245 Acc: 0.9604\n",
      "2022-01-23 04:54:19.020385\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0512 Acc: 0.9865\n",
      "2022-01-23 04:54:21.802061\n",
      "validation Loss: 0.1037 Acc: 0.9767\n",
      "2022-01-23 04:54:22.196634\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.3823 Acc: 0.9020\n",
      "2022-01-23 04:54:25.470091\n",
      "validation Loss: 1.4393 Acc: 0.5734\n",
      "2022-01-23 04:54:25.913308\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.3140 Acc: 0.9120\n",
      "2022-01-23 04:54:28.529720\n",
      "validation Loss: 0.1915 Acc: 0.9441\n",
      "2022-01-23 04:54:28.888454\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1002 Acc: 0.9665\n",
      "2022-01-23 04:54:31.509608\n",
      "validation Loss: 0.1218 Acc: 0.9580\n",
      "2022-01-23 04:54:31.871679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0667 Acc: 0.9765\n",
      "2022-01-23 04:54:34.360198\n",
      "validation Loss: 0.1616 Acc: 0.9580\n",
      "2022-01-23 04:54:34.720943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0637 Acc: 0.9750\n",
      "2022-01-23 04:54:37.424231\n",
      "validation Loss: 0.0733 Acc: 0.9720\n",
      "2022-01-23 04:54:37.789398\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0395 Acc: 0.9875\n",
      "2022-01-23 04:54:40.266294\n",
      "validation Loss: 0.0772 Acc: 0.9720\n",
      "2022-01-23 04:54:40.678073\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0240 Acc: 0.9925\n",
      "2022-01-23 04:54:43.417473\n",
      "validation Loss: 0.0570 Acc: 0.9767\n",
      "2022-01-23 04:54:43.820191\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0327 Acc: 0.9870\n",
      "2022-01-23 04:54:45.748642\n",
      "validation Loss: 0.0776 Acc: 0.9767\n",
      "2022-01-23 04:54:46.133537\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0803 Acc: 0.9810\n",
      "2022-01-23 04:54:48.547926\n",
      "validation Loss: 0.1976 Acc: 0.9347\n",
      "2022-01-23 04:54:48.889082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0674 Acc: 0.9775\n",
      "2022-01-23 04:54:51.372205\n",
      "validation Loss: 0.0779 Acc: 0.9767\n",
      "2022-01-23 04:54:51.735816\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0267 Acc: 0.9920\n",
      "2022-01-23 04:54:54.230636\n",
      "validation Loss: 0.0414 Acc: 0.9860\n",
      "2022-01-23 04:54:54.647211\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 0.9955\n",
      "2022-01-23 04:54:57.459233\n",
      "validation Loss: 0.0436 Acc: 0.9860\n",
      "2022-01-23 04:54:57.792695\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9955\n",
      "2022-01-23 04:55:00.289019\n",
      "validation Loss: 0.0901 Acc: 0.9697\n",
      "2022-01-23 04:55:00.636322\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1107 Acc: 0.9740\n",
      "2022-01-23 04:55:03.132652\n",
      "validation Loss: 0.0967 Acc: 0.9697\n",
      "2022-01-23 04:55:03.506973\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0365 Acc: 0.9885\n",
      "2022-01-23 04:55:06.140166\n",
      "validation Loss: 0.0625 Acc: 0.9767\n",
      "2022-01-23 04:55:06.515919\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0194 Acc: 0.9955\n",
      "2022-01-23 04:55:09.100429\n",
      "validation Loss: 0.0507 Acc: 0.9860\n",
      "2022-01-23 04:55:09.487672\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9985\n",
      "2022-01-23 04:55:12.223227\n",
      "validation Loss: 0.0802 Acc: 0.9744\n",
      "2022-01-23 04:55:12.591278\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0167 Acc: 0.9980\n",
      "2022-01-23 04:55:15.309923\n",
      "validation Loss: 0.0279 Acc: 0.9860\n",
      "2022-01-23 04:55:15.673945\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9965\n",
      "2022-01-23 04:55:18.701985\n",
      "validation Loss: 0.0479 Acc: 0.9837\n",
      "2022-01-23 04:55:19.098433\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9945\n",
      "2022-01-23 04:55:21.611416\n",
      "validation Loss: 0.0594 Acc: 0.9814\n",
      "2022-01-23 04:55:21.967285\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 0.9995\n",
      "2022-01-23 04:55:24.483243\n",
      "validation Loss: 0.0691 Acc: 0.9837\n",
      "2022-01-23 04:55:24.918589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0032 Acc: 0.9990\n",
      "2022-01-23 04:55:27.391990\n",
      "validation Loss: 0.0645 Acc: 0.9883\n",
      "2022-01-23 04:55:27.801784\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 04:55:30.936089\n",
      "validation Loss: 0.0789 Acc: 0.9907\n",
      "2022-01-23 04:55:31.301267\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 04:55:34.296757\n",
      "validation Loss: 0.0992 Acc: 0.9860\n",
      "2022-01-23 04:55:34.685717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 04:55:37.210258\n",
      "validation Loss: 0.1017 Acc: 0.9860\n",
      "2022-01-23 04:55:37.563014\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:55:40.072606\n",
      "validation Loss: 0.1135 Acc: 0.9860\n",
      "2022-01-23 04:55:40.467232\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 04:55:43.286917\n",
      "validation Loss: 0.1250 Acc: 0.9837\n",
      "2022-01-23 04:55:43.641159\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:55:46.143667\n",
      "validation Loss: 0.1344 Acc: 0.9837\n",
      "2022-01-23 04:55:46.499218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:55:49.157720\n",
      "validation Loss: 0.1407 Acc: 0.9837\n",
      "2022-01-23 04:55:49.530071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:55:52.080893\n",
      "validation Loss: 0.1475 Acc: 0.9837\n",
      "2022-01-23 04:55:52.463451\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:55:54.996723\n",
      "validation Loss: 0.1540 Acc: 0.9837\n",
      "2022-01-23 04:55:55.360542\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:55:57.876203\n",
      "validation Loss: 0.1607 Acc: 0.9837\n",
      "2022-01-23 04:55:58.303383\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:56:00.838172\n",
      "validation Loss: 0.1677 Acc: 0.9837\n",
      "2022-01-23 04:56:01.226403\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:56:03.833608\n",
      "validation Loss: 0.1744 Acc: 0.9837\n",
      "2022-01-23 04:56:04.193807\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:56:06.661545\n",
      "validation Loss: 0.1799 Acc: 0.9837\n",
      "2022-01-23 04:56:07.103231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 04:56:09.647140\n",
      "validation Loss: 0.1880 Acc: 0.9837\n",
      "2022-01-23 04:56:09.991095\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:12.466968\n",
      "validation Loss: 0.1923 Acc: 0.9837\n",
      "2022-01-23 04:56:12.830772\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:15.354924\n",
      "validation Loss: 0.1968 Acc: 0.9837\n",
      "2022-01-23 04:56:15.689218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:18.222475\n",
      "validation Loss: 0.2017 Acc: 0.9814\n",
      "2022-01-23 04:56:18.662885\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:21.183056\n",
      "validation Loss: 0.2076 Acc: 0.9814\n",
      "2022-01-23 04:56:21.590730\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:23.288398\n",
      "validation Loss: 0.2114 Acc: 0.9814\n",
      "2022-01-23 04:56:23.620357\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:26.324162\n",
      "validation Loss: 0.2156 Acc: 0.9814\n",
      "2022-01-23 04:56:26.671062\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:29.495106\n",
      "validation Loss: 0.2209 Acc: 0.9814\n",
      "2022-01-23 04:56:29.885041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:32.555386\n",
      "validation Loss: 0.2262 Acc: 0.9814\n",
      "2022-01-23 04:56:32.922342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:34.501348\n",
      "validation Loss: 0.2298 Acc: 0.9814\n",
      "2022-01-23 04:56:34.888156\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:37.633479\n",
      "validation Loss: 0.2367 Acc: 0.9790\n",
      "2022-01-23 04:56:38.077605\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:40.714569\n",
      "validation Loss: 0.2385 Acc: 0.9790\n",
      "2022-01-23 04:56:41.099153\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:43.691519\n",
      "validation Loss: 0.2432 Acc: 0.9814\n",
      "2022-01-23 04:56:44.073577\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:46.528328\n",
      "validation Loss: 0.2493 Acc: 0.9790\n",
      "2022-01-23 04:56:46.990952\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:49.390273\n",
      "validation Loss: 0.2540 Acc: 0.9790\n",
      "2022-01-23 04:56:49.791697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:52.177524\n",
      "validation Loss: 0.2562 Acc: 0.9790\n",
      "2022-01-23 04:56:52.534500\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:54.945156\n",
      "validation Loss: 0.2620 Acc: 0.9790\n",
      "2022-01-23 04:56:55.295191\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:56:57.772732\n",
      "validation Loss: 0.2645 Acc: 0.9790\n",
      "2022-01-23 04:56:58.217524\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:00.717047\n",
      "validation Loss: 0.2680 Acc: 0.9790\n",
      "2022-01-23 04:57:01.066511\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:03.460310\n",
      "validation Loss: 0.2744 Acc: 0.9790\n",
      "2022-01-23 04:57:03.814752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:06.214928\n",
      "validation Loss: 0.2773 Acc: 0.9790\n",
      "2022-01-23 04:57:06.593354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:09.106540\n",
      "validation Loss: 0.2824 Acc: 0.9790\n",
      "2022-01-23 04:57:09.604244\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:12.048479\n",
      "validation Loss: 0.2851 Acc: 0.9790\n",
      "2022-01-23 04:57:12.413725\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:14.869906\n",
      "validation Loss: 0.2893 Acc: 0.9790\n",
      "2022-01-23 04:57:15.221894\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:17.678502\n",
      "validation Loss: 0.2915 Acc: 0.9790\n",
      "2022-01-23 04:57:18.077624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:20.527523\n",
      "validation Loss: 0.2965 Acc: 0.9790\n",
      "2022-01-23 04:57:20.869712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:23.334604\n",
      "validation Loss: 0.2995 Acc: 0.9790\n",
      "2022-01-23 04:57:23.666669\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:26.230802\n",
      "validation Loss: 0.3038 Acc: 0.9790\n",
      "2022-01-23 04:57:26.578969\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:29.151043\n",
      "validation Loss: 0.3059 Acc: 0.9790\n",
      "2022-01-23 04:57:29.642886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:32.184619\n",
      "validation Loss: 0.3112 Acc: 0.9790\n",
      "2022-01-23 04:57:32.544189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:35.097701\n",
      "validation Loss: 0.3142 Acc: 0.9790\n",
      "2022-01-23 04:57:35.440294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:36.952214\n",
      "validation Loss: 0.3161 Acc: 0.9790\n",
      "2022-01-23 04:57:37.320551\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:39.758649\n",
      "validation Loss: 0.3215 Acc: 0.9790\n",
      "2022-01-23 04:57:40.146936\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:42.750242\n",
      "validation Loss: 0.3247 Acc: 0.9790\n",
      "2022-01-23 04:57:43.093183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:45.550712\n",
      "validation Loss: 0.3289 Acc: 0.9790\n",
      "2022-01-23 04:57:45.896519\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:48.405472\n",
      "validation Loss: 0.3314 Acc: 0.9790\n",
      "2022-01-23 04:57:48.785901\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:51.379291\n",
      "validation Loss: 0.3355 Acc: 0.9790\n",
      "2022-01-23 04:57:51.806939\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:54.370900\n",
      "validation Loss: 0.3382 Acc: 0.9790\n",
      "2022-01-23 04:57:54.726292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:57:57.445581\n",
      "validation Loss: 0.3422 Acc: 0.9790\n",
      "2022-01-23 04:57:57.785566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:00.347106\n",
      "validation Loss: 0.3449 Acc: 0.9790\n",
      "2022-01-23 04:58:00.729512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:03.276923\n",
      "validation Loss: 0.3500 Acc: 0.9790\n",
      "2022-01-23 04:58:03.651512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:06.128288\n",
      "validation Loss: 0.3517 Acc: 0.9790\n",
      "2022-01-23 04:58:06.516222\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:08.989221\n",
      "validation Loss: 0.3557 Acc: 0.9790\n",
      "2022-01-23 04:58:09.363344\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:12.083685\n",
      "validation Loss: 0.3589 Acc: 0.9790\n",
      "2022-01-23 04:58:12.447756\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:14.897257\n",
      "validation Loss: 0.3613 Acc: 0.9790\n",
      "2022-01-23 04:58:15.257241\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:17.683162\n",
      "validation Loss: 0.3651 Acc: 0.9790\n",
      "2022-01-23 04:58:18.152708\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:20.746135\n",
      "validation Loss: 0.3692 Acc: 0.9790\n",
      "2022-01-23 04:58:21.079256\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:23.577197\n",
      "validation Loss: 0.3730 Acc: 0.9790\n",
      "2022-01-23 04:58:23.948647\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:26.461135\n",
      "validation Loss: 0.3774 Acc: 0.9790\n",
      "2022-01-23 04:58:26.902548\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 04:58:29.525289\n",
      "validation Loss: 0.3781 Acc: 0.9790\n",
      "2022-01-23 04:58:29.880555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9907\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xk3ttwve) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 69369... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▂▆▆▇▇▆▇▇█████</td></tr><tr><td>accuracy_train</td><td>▁▇▇███▆▇████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▆▇▇██▇▁█████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>▄▂▂▁▁▂█▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.97902</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99068</td></tr><tr><td>best_val_loss</td><td>0.07892</td></tr><tr><td>loss_train</td><td>0.0</td></tr><tr><td>loss_validation</td><td>0.37806</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/xk3ttwve\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/xk3ttwve</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_045326-xk3ttwve/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xk3ttwve). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ckxwhmf\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 04:58:40.263583\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.7804 Acc: 0.4660\n",
      "2022-01-23 04:58:42.838536\n",
      "validation Loss: 0.5896 Acc: 0.8065\n",
      "2022-01-23 04:58:43.324026\n",
      "Accuracy of the network on the 429 test samples: 82.51748251748252\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.4551 Acc: 0.8735\n",
      "2022-01-23 04:58:46.386776\n",
      "validation Loss: 0.3042 Acc: 0.8974\n",
      "2022-01-23 04:58:46.751859\n",
      "Accuracy of the network on the 429 test samples: 87.64568764568764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2365 Acc: 0.9240\n",
      "2022-01-23 04:58:49.777800\n",
      "validation Loss: 0.2195 Acc: 0.9417\n",
      "2022-01-23 04:58:50.224758\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2485 Acc: 0.9265\n",
      "2022-01-23 04:58:53.276174\n",
      "validation Loss: 0.1633 Acc: 0.9487\n",
      "2022-01-23 04:58:53.649353\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1518 Acc: 0.9520\n",
      "2022-01-23 04:58:56.831200\n",
      "validation Loss: 0.1328 Acc: 0.9604\n",
      "2022-01-23 04:58:57.310983\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1203 Acc: 0.9595\n",
      "2022-01-23 04:59:00.500726\n",
      "validation Loss: 0.1280 Acc: 0.9510\n",
      "2022-01-23 04:59:00.885589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2056 Acc: 0.9540\n",
      "2022-01-23 04:59:03.583465\n",
      "validation Loss: 0.3138 Acc: 0.9161\n",
      "2022-01-23 04:59:04.134457\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.2189 Acc: 0.9465\n",
      "2022-01-23 04:59:06.708672\n",
      "validation Loss: 0.1595 Acc: 0.9580\n",
      "2022-01-23 04:59:07.043281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1240 Acc: 0.9685\n",
      "2022-01-23 04:59:09.535709\n",
      "validation Loss: 0.1707 Acc: 0.9580\n",
      "2022-01-23 04:59:09.939417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1027 Acc: 0.9705\n",
      "2022-01-23 04:59:12.435556\n",
      "validation Loss: 0.0974 Acc: 0.9814\n",
      "2022-01-23 04:59:12.820152\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0796 Acc: 0.9715\n",
      "2022-01-23 04:59:15.708888\n",
      "validation Loss: 0.1275 Acc: 0.9534\n",
      "2022-01-23 04:59:16.176642\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1155 Acc: 0.9675\n",
      "2022-01-23 04:59:18.471310\n",
      "validation Loss: 0.2521 Acc: 0.9207\n",
      "2022-01-23 04:59:18.830239\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0713 Acc: 0.9810\n",
      "2022-01-23 04:59:21.366821\n",
      "validation Loss: 0.0898 Acc: 0.9720\n",
      "2022-01-23 04:59:21.724623\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0433 Acc: 0.9900\n",
      "2022-01-23 04:59:24.189683\n",
      "validation Loss: 0.2710 Acc: 0.9114\n",
      "2022-01-23 04:59:24.540716\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1048 Acc: 0.9705\n",
      "2022-01-23 04:59:26.983958\n",
      "validation Loss: 0.1219 Acc: 0.9650\n",
      "2022-01-23 04:59:27.353126\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0520 Acc: 0.9845\n",
      "2022-01-23 04:59:29.896763\n",
      "validation Loss: 0.1281 Acc: 0.9580\n",
      "2022-01-23 04:59:30.280566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0464 Acc: 0.9870\n",
      "2022-01-23 04:59:32.747313\n",
      "validation Loss: 0.1001 Acc: 0.9697\n",
      "2022-01-23 04:59:33.078968\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0303 Acc: 0.9910\n",
      "2022-01-23 04:59:35.477396\n",
      "validation Loss: 0.1340 Acc: 0.9464\n",
      "2022-01-23 04:59:35.847493\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0188 Acc: 0.9945\n",
      "2022-01-23 04:59:38.288482\n",
      "validation Loss: 0.1010 Acc: 0.9697\n",
      "2022-01-23 04:59:38.710366\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0289 Acc: 0.9895\n",
      "2022-01-23 04:59:41.160369\n",
      "validation Loss: 0.1108 Acc: 0.9697\n",
      "2022-01-23 04:59:41.788194\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0381 Acc: 0.9865\n",
      "2022-01-23 04:59:44.366468\n",
      "validation Loss: 0.1088 Acc: 0.9650\n",
      "2022-01-23 04:59:44.748028\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0560 Acc: 0.9830\n",
      "2022-01-23 04:59:47.350925\n",
      "validation Loss: 0.1084 Acc: 0.9720\n",
      "2022-01-23 04:59:47.694654\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0419 Acc: 0.9875\n",
      "2022-01-23 04:59:50.206462\n",
      "validation Loss: 0.0736 Acc: 0.9790\n",
      "2022-01-23 04:59:50.566959\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1279 Acc: 0.9610\n",
      "2022-01-23 04:59:53.096021\n",
      "validation Loss: 0.3371 Acc: 0.9044\n",
      "2022-01-23 04:59:53.612594\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1491 Acc: 0.9625\n",
      "2022-01-23 04:59:56.131182\n",
      "validation Loss: 0.0801 Acc: 0.9767\n",
      "2022-01-23 04:59:56.486096\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0432 Acc: 0.9885\n",
      "2022-01-23 04:59:58.962327\n",
      "validation Loss: 0.0721 Acc: 0.9744\n",
      "2022-01-23 04:59:59.335474\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0625 Acc: 0.9850\n",
      "2022-01-23 05:00:01.851233\n",
      "validation Loss: 0.0903 Acc: 0.9744\n",
      "2022-01-23 05:00:02.199751\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0250 Acc: 0.9910\n",
      "2022-01-23 05:00:04.752447\n",
      "validation Loss: 0.0588 Acc: 0.9814\n",
      "2022-01-23 05:00:05.217502\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0224 Acc: 0.9930\n",
      "2022-01-23 05:00:08.180054\n",
      "validation Loss: 0.1400 Acc: 0.9627\n",
      "2022-01-23 05:00:08.530000\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0116 Acc: 0.9975\n",
      "2022-01-23 05:00:11.073157\n",
      "validation Loss: 0.0989 Acc: 0.9767\n",
      "2022-01-23 05:00:11.509323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9975\n",
      "2022-01-23 05:00:14.233533\n",
      "validation Loss: 0.0966 Acc: 0.9790\n",
      "2022-01-23 05:00:14.626694\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0369 Acc: 0.9905\n",
      "2022-01-23 05:00:17.144085\n",
      "validation Loss: 0.0662 Acc: 0.9814\n",
      "2022-01-23 05:00:17.481997\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9955\n",
      "2022-01-23 05:00:19.994540\n",
      "validation Loss: 0.0722 Acc: 0.9814\n",
      "2022-01-23 05:00:20.381549\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0054 Acc: 0.9990\n",
      "2022-01-23 05:00:22.918208\n",
      "validation Loss: 0.0619 Acc: 0.9860\n",
      "2022-01-23 05:00:23.288004\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:00:26.161169\n",
      "validation Loss: 0.0600 Acc: 0.9907\n",
      "2022-01-23 05:00:26.560562\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:00:29.435037\n",
      "validation Loss: 0.0663 Acc: 0.9860\n",
      "2022-01-23 05:00:29.819806\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:00:32.400007\n",
      "validation Loss: 0.0706 Acc: 0.9883\n",
      "2022-01-23 05:00:32.764189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:00:35.326884\n",
      "validation Loss: 0.0750 Acc: 0.9883\n",
      "2022-01-23 05:00:35.901749\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:00:38.464120\n",
      "validation Loss: 0.0811 Acc: 0.9883\n",
      "2022-01-23 05:00:38.847209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:00:41.514773\n",
      "validation Loss: 0.0847 Acc: 0.9883\n",
      "2022-01-23 05:00:41.886809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:44.446036\n",
      "validation Loss: 0.0895 Acc: 0.9883\n",
      "2022-01-23 05:00:44.794469\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:47.404700\n",
      "validation Loss: 0.0953 Acc: 0.9883\n",
      "2022-01-23 05:00:47.820255\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:49.215954\n",
      "validation Loss: 0.0992 Acc: 0.9883\n",
      "2022-01-23 05:00:49.565956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:52.087461\n",
      "validation Loss: 0.1035 Acc: 0.9883\n",
      "2022-01-23 05:00:52.512679\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:55.096471\n",
      "validation Loss: 0.1068 Acc: 0.9883\n",
      "2022-01-23 05:00:55.437593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:00:58.003883\n",
      "validation Loss: 0.1111 Acc: 0.9883\n",
      "2022-01-23 05:00:58.372578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:01:00.947161\n",
      "validation Loss: 0.1146 Acc: 0.9883\n",
      "2022-01-23 05:01:01.341913\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:01:03.894325\n",
      "validation Loss: 0.1178 Acc: 0.9883\n",
      "2022-01-23 05:01:04.398494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:01:06.916027\n",
      "validation Loss: 0.1222 Acc: 0.9883\n",
      "2022-01-23 05:01:07.264153\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:09.792451\n",
      "validation Loss: 0.1251 Acc: 0.9883\n",
      "2022-01-23 05:01:10.192558\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:12.689649\n",
      "validation Loss: 0.1284 Acc: 0.9883\n",
      "2022-01-23 05:01:13.045169\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:15.588627\n",
      "validation Loss: 0.1323 Acc: 0.9883\n",
      "2022-01-23 05:01:16.097497\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:18.643744\n",
      "validation Loss: 0.1357 Acc: 0.9883\n",
      "2022-01-23 05:01:19.038728\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:21.571101\n",
      "validation Loss: 0.1389 Acc: 0.9883\n",
      "2022-01-23 05:01:21.920495\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:24.408250\n",
      "validation Loss: 0.1423 Acc: 0.9883\n",
      "2022-01-23 05:01:24.804812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:27.295744\n",
      "validation Loss: 0.1451 Acc: 0.9883\n",
      "2022-01-23 05:01:27.751518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:30.417894\n",
      "validation Loss: 0.1485 Acc: 0.9883\n",
      "2022-01-23 05:01:30.796512\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:33.300884\n",
      "validation Loss: 0.1510 Acc: 0.9883\n",
      "2022-01-23 05:01:33.637346\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:36.062226\n",
      "validation Loss: 0.1550 Acc: 0.9883\n",
      "2022-01-23 05:01:36.436652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:38.949070\n",
      "validation Loss: 0.1581 Acc: 0.9883\n",
      "2022-01-23 05:01:39.437644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:41.876085\n",
      "validation Loss: 0.1614 Acc: 0.9883\n",
      "2022-01-23 05:01:42.230889\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:44.709517\n",
      "validation Loss: 0.1641 Acc: 0.9883\n",
      "2022-01-23 05:01:45.053845\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:47.488465\n",
      "validation Loss: 0.1679 Acc: 0.9883\n",
      "2022-01-23 05:01:47.868928\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:50.325763\n",
      "validation Loss: 0.1705 Acc: 0.9883\n",
      "2022-01-23 05:01:50.801691\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:53.257240\n",
      "validation Loss: 0.1733 Acc: 0.9883\n",
      "2022-01-23 05:01:53.632910\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:56.061867\n",
      "validation Loss: 0.1767 Acc: 0.9883\n",
      "2022-01-23 05:01:56.433241\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:01:58.791123\n",
      "validation Loss: 0.1792 Acc: 0.9883\n",
      "2022-01-23 05:01:59.152314\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:01.731990\n",
      "validation Loss: 0.1824 Acc: 0.9883\n",
      "2022-01-23 05:02:02.100295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:04.593152\n",
      "validation Loss: 0.1855 Acc: 0.9883\n",
      "2022-01-23 05:02:04.956826\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:07.515714\n",
      "validation Loss: 0.1883 Acc: 0.9883\n",
      "2022-01-23 05:02:07.934289\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:10.325391\n",
      "validation Loss: 0.1914 Acc: 0.9883\n",
      "2022-01-23 05:02:10.777231\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:13.315906\n",
      "validation Loss: 0.1938 Acc: 0.9883\n",
      "2022-01-23 05:02:13.725653\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:16.183331\n",
      "validation Loss: 0.1969 Acc: 0.9883\n",
      "2022-01-23 05:02:16.523202\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:18.939114\n",
      "validation Loss: 0.1998 Acc: 0.9883\n",
      "2022-01-23 05:02:19.292354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:21.778005\n",
      "validation Loss: 0.2026 Acc: 0.9883\n",
      "2022-01-23 05:02:22.265858\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:24.911776\n",
      "validation Loss: 0.2059 Acc: 0.9883\n",
      "2022-01-23 05:02:25.321996\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:27.948793\n",
      "validation Loss: 0.2089 Acc: 0.9883\n",
      "2022-01-23 05:02:28.438075\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:30.998003\n",
      "validation Loss: 0.2115 Acc: 0.9883\n",
      "2022-01-23 05:02:31.368975\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:33.884538\n",
      "validation Loss: 0.2144 Acc: 0.9883\n",
      "2022-01-23 05:02:34.224060\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:36.765808\n",
      "validation Loss: 0.2173 Acc: 0.9883\n",
      "2022-01-23 05:02:37.141011\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:39.704284\n",
      "validation Loss: 0.2202 Acc: 0.9883\n",
      "2022-01-23 05:02:40.168300\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:41.539553\n",
      "validation Loss: 0.2229 Acc: 0.9883\n",
      "2022-01-23 05:02:41.966984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:44.477047\n",
      "validation Loss: 0.2255 Acc: 0.9883\n",
      "2022-01-23 05:02:44.826925\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:47.332656\n",
      "validation Loss: 0.2288 Acc: 0.9883\n",
      "2022-01-23 05:02:47.735804\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:50.195487\n",
      "validation Loss: 0.2315 Acc: 0.9883\n",
      "2022-01-23 05:02:50.631687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:53.158394\n",
      "validation Loss: 0.2344 Acc: 0.9883\n",
      "2022-01-23 05:02:53.632377\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:56.134312\n",
      "validation Loss: 0.2374 Acc: 0.9883\n",
      "2022-01-23 05:02:56.488688\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:02:59.036714\n",
      "validation Loss: 0.2398 Acc: 0.9883\n",
      "2022-01-23 05:02:59.412029\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:01.893770\n",
      "validation Loss: 0.2429 Acc: 0.9883\n",
      "2022-01-23 05:03:02.250034\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:04.831989\n",
      "validation Loss: 0.2459 Acc: 0.9883\n",
      "2022-01-23 05:03:05.224422\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:07.720916\n",
      "validation Loss: 0.2489 Acc: 0.9883\n",
      "2022-01-23 05:03:08.085394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:10.702496\n",
      "validation Loss: 0.2513 Acc: 0.9883\n",
      "2022-01-23 05:03:11.066995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:13.808460\n",
      "validation Loss: 0.2546 Acc: 0.9883\n",
      "2022-01-23 05:03:14.149836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:16.645758\n",
      "validation Loss: 0.2572 Acc: 0.9883\n",
      "2022-01-23 05:03:16.992517\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:19.508896\n",
      "validation Loss: 0.2601 Acc: 0.9883\n",
      "2022-01-23 05:03:19.853104\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:22.522404\n",
      "validation Loss: 0.2634 Acc: 0.9883\n",
      "2022-01-23 05:03:22.972404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:25.627201\n",
      "validation Loss: 0.2663 Acc: 0.9883\n",
      "2022-01-23 05:03:25.981200\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:28.748489\n",
      "validation Loss: 0.2690 Acc: 0.9883\n",
      "2022-01-23 05:03:29.103464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:31.905985\n",
      "validation Loss: 0.2715 Acc: 0.9883\n",
      "2022-01-23 05:03:32.285763\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:03:34.997109\n",
      "validation Loss: 0.2748 Acc: 0.9883\n",
      "2022-01-23 05:03:35.402044\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9907\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1ckxwhmf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 61037... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▃▆▇▇▇███</td></tr><tr><td>accuracy_train</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇▇▇▇▆▇█▇█████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.98834</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98834</td></tr><tr><td>best_test_accuracy</td><td>0.98834</td></tr><tr><td>best_val_accuracy</td><td>0.99068</td></tr><tr><td>best_val_loss</td><td>0.06002</td></tr><tr><td>loss_train</td><td>0.0</td></tr><tr><td>loss_validation</td><td>0.27479</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1ckxwhmf\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1ckxwhmf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_045830-1ckxwhmf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1ckxwhmf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2ai43mrq\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 05:03:45.299496\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.6724 Acc: 0.1840\n",
      "2022-01-23 05:03:47.953640\n",
      "validation Loss: 1.5305 Acc: 0.5455\n",
      "2022-01-23 05:03:48.322838\n",
      "Accuracy of the network on the 429 test samples: 52.21445221445221\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.9266 Acc: 0.7545\n",
      "2022-01-23 05:03:51.396323\n",
      "validation Loss: 0.5556 Acc: 0.8695\n",
      "2022-01-23 05:03:51.870126\n",
      "Accuracy of the network on the 429 test samples: 87.87878787878788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4111 Acc: 0.8910\n",
      "2022-01-23 05:03:54.923727\n",
      "validation Loss: 0.3468 Acc: 0.9277\n",
      "2022-01-23 05:03:55.401638\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2594 Acc: 0.9250\n",
      "2022-01-23 05:03:58.366628\n",
      "validation Loss: 0.2703 Acc: 0.9254\n",
      "2022-01-23 05:03:58.837334\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2302 Acc: 0.9310\n",
      "2022-01-23 05:04:01.310333\n",
      "validation Loss: 0.3271 Acc: 0.8974\n",
      "2022-01-23 05:04:01.954554\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1973 Acc: 0.9425\n",
      "2022-01-23 05:04:04.510908\n",
      "validation Loss: 0.2693 Acc: 0.9231\n",
      "2022-01-23 05:04:04.903409\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1361 Acc: 0.9625\n",
      "2022-01-23 05:04:07.407691\n",
      "validation Loss: 0.3067 Acc: 0.9114\n",
      "2022-01-23 05:04:07.762597\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1251 Acc: 0.9545\n",
      "2022-01-23 05:04:10.160009\n",
      "validation Loss: 0.2272 Acc: 0.9464\n",
      "2022-01-23 05:04:10.697903\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0985 Acc: 0.9695\n",
      "2022-01-23 05:04:13.665748\n",
      "validation Loss: 0.2327 Acc: 0.9464\n",
      "2022-01-23 05:04:14.026605\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0952 Acc: 0.9730\n",
      "2022-01-23 05:04:16.817456\n",
      "validation Loss: 0.3332 Acc: 0.9417\n",
      "2022-01-23 05:04:17.267794\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0984 Acc: 0.9735\n",
      "2022-01-23 05:04:20.073899\n",
      "validation Loss: 0.1675 Acc: 0.9674\n",
      "2022-01-23 05:04:20.551363\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0758 Acc: 0.9760\n",
      "2022-01-23 05:04:22.881248\n",
      "validation Loss: 0.2841 Acc: 0.9371\n",
      "2022-01-23 05:04:23.284116\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0954 Acc: 0.9730\n",
      "2022-01-23 05:04:25.736856\n",
      "validation Loss: 0.2302 Acc: 0.9487\n",
      "2022-01-23 05:04:26.249991\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0865 Acc: 0.9825\n",
      "2022-01-23 05:04:28.733440\n",
      "validation Loss: 0.1671 Acc: 0.9604\n",
      "2022-01-23 05:04:29.095788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0443 Acc: 0.9850\n",
      "2022-01-23 05:04:31.653920\n",
      "validation Loss: 0.2094 Acc: 0.9604\n",
      "2022-01-23 05:04:32.115397\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0525 Acc: 0.9835\n",
      "2022-01-23 05:04:34.587573\n",
      "validation Loss: 0.3904 Acc: 0.9417\n",
      "2022-01-23 05:04:35.030349\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9790\n",
      "2022-01-23 05:04:37.516250\n",
      "validation Loss: 0.2262 Acc: 0.9604\n",
      "2022-01-23 05:04:37.886101\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0539 Acc: 0.9815\n",
      "2022-01-23 05:04:40.391896\n",
      "validation Loss: 0.1670 Acc: 0.9604\n",
      "2022-01-23 05:04:40.887665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0453 Acc: 0.9840\n",
      "2022-01-23 05:04:43.398731\n",
      "validation Loss: 0.1970 Acc: 0.9650\n",
      "2022-01-23 05:04:43.869324\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0381 Acc: 0.9855\n",
      "2022-01-23 05:04:46.416592\n",
      "validation Loss: 0.1596 Acc: 0.9650\n",
      "2022-01-23 05:04:46.826082\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1327 Acc: 0.9830\n",
      "2022-01-23 05:04:49.480152\n",
      "validation Loss: 0.4482 Acc: 0.8718\n",
      "2022-01-23 05:04:49.903674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1555 Acc: 0.9625\n",
      "2022-01-23 05:04:52.349393\n",
      "validation Loss: 0.1824 Acc: 0.9744\n",
      "2022-01-23 05:04:52.878000\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0729 Acc: 0.9770\n",
      "2022-01-23 05:04:55.696643\n",
      "validation Loss: 0.1964 Acc: 0.9650\n",
      "2022-01-23 05:04:56.053376\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0318 Acc: 0.9915\n",
      "2022-01-23 05:04:58.608471\n",
      "validation Loss: 0.2348 Acc: 0.9697\n",
      "2022-01-23 05:04:58.993589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0237 Acc: 0.9935\n",
      "2022-01-23 05:05:01.572831\n",
      "validation Loss: 0.2333 Acc: 0.9720\n",
      "2022-01-23 05:05:01.939458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0192 Acc: 0.9950\n",
      "2022-01-23 05:05:04.424412\n",
      "validation Loss: 0.2530 Acc: 0.9697\n",
      "2022-01-23 05:05:04.804528\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0137 Acc: 0.9960\n",
      "2022-01-23 05:05:07.413069\n",
      "validation Loss: 0.3342 Acc: 0.9627\n",
      "2022-01-23 05:05:07.786853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0324 Acc: 0.9890\n",
      "2022-01-23 05:05:10.439194\n",
      "validation Loss: 0.2317 Acc: 0.9650\n",
      "2022-01-23 05:05:10.811217\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0312 Acc: 0.9900\n",
      "2022-01-23 05:05:13.327247\n",
      "validation Loss: 0.2195 Acc: 0.9720\n",
      "2022-01-23 05:05:13.682989\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0211 Acc: 0.9945\n",
      "2022-01-23 05:05:16.257456\n",
      "validation Loss: 0.2483 Acc: 0.9697\n",
      "2022-01-23 05:05:16.613135\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9955\n",
      "2022-01-23 05:05:19.119185\n",
      "validation Loss: 0.2995 Acc: 0.9697\n",
      "2022-01-23 05:05:19.525307\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0145 Acc: 0.9970\n",
      "2022-01-23 05:05:21.039307\n",
      "validation Loss: 0.3192 Acc: 0.9697\n",
      "2022-01-23 05:05:21.520818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 0.9955\n",
      "2022-01-23 05:05:24.026173\n",
      "validation Loss: 0.3133 Acc: 0.9627\n",
      "2022-01-23 05:05:24.442974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9945\n",
      "2022-01-23 05:05:27.028895\n",
      "validation Loss: 0.3878 Acc: 0.9674\n",
      "2022-01-23 05:05:27.389079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0054 Acc: 0.9995\n",
      "2022-01-23 05:05:30.003658\n",
      "validation Loss: 0.4717 Acc: 0.9650\n",
      "2022-01-23 05:05:30.455311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9950\n",
      "2022-01-23 05:05:33.181815\n",
      "validation Loss: 0.2267 Acc: 0.9650\n",
      "2022-01-23 05:05:33.598270\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9950\n",
      "2022-01-23 05:05:36.103495\n",
      "validation Loss: 0.3310 Acc: 0.9650\n",
      "2022-01-23 05:05:36.469433\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0510 Acc: 0.9860\n",
      "2022-01-23 05:05:39.014267\n",
      "validation Loss: 0.2141 Acc: 0.9650\n",
      "2022-01-23 05:05:39.379467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0269 Acc: 0.9930\n",
      "2022-01-23 05:05:41.864227\n",
      "validation Loss: 0.2469 Acc: 0.9697\n",
      "2022-01-23 05:05:42.214977\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0316 Acc: 0.9910\n",
      "2022-01-23 05:05:44.679836\n",
      "validation Loss: 0.2457 Acc: 0.9627\n",
      "2022-01-23 05:05:45.093325\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0365 Acc: 0.9910\n",
      "2022-01-23 05:05:47.506583\n",
      "validation Loss: 0.2430 Acc: 0.9627\n",
      "2022-01-23 05:05:47.898564\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0310 Acc: 0.9960\n",
      "2022-01-23 05:05:50.395902\n",
      "validation Loss: 0.2754 Acc: 0.9744\n",
      "2022-01-23 05:05:50.752536\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0116 Acc: 0.9970\n",
      "2022-01-23 05:05:53.292197\n",
      "validation Loss: 0.2879 Acc: 0.9744\n",
      "2022-01-23 05:05:53.692892\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0109 Acc: 0.9955\n",
      "2022-01-23 05:05:56.149977\n",
      "validation Loss: 0.4535 Acc: 0.9720\n",
      "2022-01-23 05:05:56.514106\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0356 Acc: 0.9910\n",
      "2022-01-23 05:05:58.957089\n",
      "validation Loss: 0.1307 Acc: 0.9650\n",
      "2022-01-23 05:05:59.374486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0271 Acc: 0.9915\n",
      "2022-01-23 05:06:01.818359\n",
      "validation Loss: 0.1389 Acc: 0.9697\n",
      "2022-01-23 05:06:02.213562\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0082 Acc: 0.9985\n",
      "2022-01-23 05:06:04.685143\n",
      "validation Loss: 0.2405 Acc: 0.9744\n",
      "2022-01-23 05:06:05.084291\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9970\n",
      "2022-01-23 05:06:07.466651\n",
      "validation Loss: 0.3048 Acc: 0.9697\n",
      "2022-01-23 05:06:07.802770\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0103 Acc: 0.9970\n",
      "2022-01-23 05:06:10.296985\n",
      "validation Loss: 0.2538 Acc: 0.9697\n",
      "2022-01-23 05:06:10.652510\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0132 Acc: 0.9960\n",
      "2022-01-23 05:06:13.225605\n",
      "validation Loss: 0.2674 Acc: 0.9744\n",
      "2022-01-23 05:06:13.602335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0241 Acc: 0.9925\n",
      "2022-01-23 05:06:16.101877\n",
      "validation Loss: 0.1980 Acc: 0.9720\n",
      "2022-01-23 05:06:16.557960\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0082 Acc: 0.9985\n",
      "2022-01-23 05:06:19.040909\n",
      "validation Loss: 0.3615 Acc: 0.9767\n",
      "2022-01-23 05:06:19.393707\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0122 Acc: 0.9960\n",
      "2022-01-23 05:06:22.142794\n",
      "validation Loss: 0.3642 Acc: 0.9697\n",
      "2022-01-23 05:06:22.505690\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0836 Acc: 0.9775\n",
      "2022-01-23 05:06:24.972612\n",
      "validation Loss: 0.1691 Acc: 0.9744\n",
      "2022-01-23 05:06:25.321961\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0414 Acc: 0.9915\n",
      "2022-01-23 05:06:27.997834\n",
      "validation Loss: 0.1719 Acc: 0.9767\n",
      "2022-01-23 05:06:28.364172\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0156 Acc: 0.9975\n",
      "2022-01-23 05:06:31.317649\n",
      "validation Loss: 0.1935 Acc: 0.9720\n",
      "2022-01-23 05:06:31.763279\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0142 Acc: 0.9970\n",
      "2022-01-23 05:06:34.444072\n",
      "validation Loss: 0.2265 Acc: 0.9744\n",
      "2022-01-23 05:06:34.824428\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0245 Acc: 0.9920\n",
      "2022-01-23 05:06:37.556644\n",
      "validation Loss: 0.2870 Acc: 0.9487\n",
      "2022-01-23 05:06:37.990828\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0406 Acc: 0.9910\n",
      "2022-01-23 05:06:39.505583\n",
      "validation Loss: 0.1339 Acc: 0.9790\n",
      "2022-01-23 05:06:39.836865\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0127 Acc: 0.9955\n",
      "2022-01-23 05:06:42.781098\n",
      "validation Loss: 0.2100 Acc: 0.9720\n",
      "2022-01-23 05:06:43.132660\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0138 Acc: 0.9955\n",
      "2022-01-23 05:06:45.667992\n",
      "validation Loss: 0.1813 Acc: 0.9720\n",
      "2022-01-23 05:06:46.096506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9960\n",
      "2022-01-23 05:06:48.833152\n",
      "validation Loss: 0.1131 Acc: 0.9744\n",
      "2022-01-23 05:06:49.192483\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 0.9995\n",
      "2022-01-23 05:06:51.741597\n",
      "validation Loss: 0.1616 Acc: 0.9720\n",
      "2022-01-23 05:06:52.093600\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 05:06:54.849027\n",
      "validation Loss: 0.2077 Acc: 0.9744\n",
      "2022-01-23 05:06:55.204233\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 05:06:56.847173\n",
      "validation Loss: 0.2268 Acc: 0.9674\n",
      "2022-01-23 05:06:57.189300\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:06:59.693960\n",
      "validation Loss: 0.2383 Acc: 0.9697\n",
      "2022-01-23 05:07:00.072939\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:07:02.624996\n",
      "validation Loss: 0.2645 Acc: 0.9674\n",
      "2022-01-23 05:07:03.009656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:07:05.579320\n",
      "validation Loss: 0.2765 Acc: 0.9697\n",
      "2022-01-23 05:07:05.961673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:07:08.500396\n",
      "validation Loss: 0.3013 Acc: 0.9674\n",
      "2022-01-23 05:07:08.834488\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:07:11.375760\n",
      "validation Loss: 0.3162 Acc: 0.9674\n",
      "2022-01-23 05:07:11.789442\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:07:14.364536\n",
      "validation Loss: 0.3305 Acc: 0.9697\n",
      "2022-01-23 05:07:14.773076\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:07:17.264465\n",
      "validation Loss: 0.3448 Acc: 0.9674\n",
      "2022-01-23 05:07:17.620955\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:07:20.067626\n",
      "validation Loss: 0.3628 Acc: 0.9650\n",
      "2022-01-23 05:07:20.481057\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:07:23.002865\n",
      "validation Loss: 0.3729 Acc: 0.9650\n",
      "2022-01-23 05:07:23.527580\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:07:26.068177\n",
      "validation Loss: 0.3828 Acc: 0.9627\n",
      "2022-01-23 05:07:26.412264\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:07:28.910645\n",
      "validation Loss: 0.3971 Acc: 0.9627\n",
      "2022-01-23 05:07:29.346159\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:07:31.918503\n",
      "validation Loss: 0.4087 Acc: 0.9627\n",
      "2022-01-23 05:07:32.392032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:35.047067\n",
      "validation Loss: 0.4229 Acc: 0.9627\n",
      "2022-01-23 05:07:35.418513\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:37.913902\n",
      "validation Loss: 0.4322 Acc: 0.9627\n",
      "2022-01-23 05:07:38.360914\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:40.930754\n",
      "validation Loss: 0.4451 Acc: 0.9627\n",
      "2022-01-23 05:07:41.371043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:43.823663\n",
      "validation Loss: 0.4517 Acc: 0.9627\n",
      "2022-01-23 05:07:44.160267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:46.602540\n",
      "validation Loss: 0.4622 Acc: 0.9627\n",
      "2022-01-23 05:07:46.962168\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:49.456775\n",
      "validation Loss: 0.4710 Acc: 0.9627\n",
      "2022-01-23 05:07:49.968245\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:51.439331\n",
      "validation Loss: 0.4801 Acc: 0.9627\n",
      "2022-01-23 05:07:51.785099\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:54.226333\n",
      "validation Loss: 0.4909 Acc: 0.9627\n",
      "2022-01-23 05:07:54.617858\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:57.106767\n",
      "validation Loss: 0.4994 Acc: 0.9627\n",
      "2022-01-23 05:07:57.464797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:07:59.928795\n",
      "validation Loss: 0.5054 Acc: 0.9627\n",
      "2022-01-23 05:08:00.281876\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:08:02.807949\n",
      "validation Loss: 0.5145 Acc: 0.9627\n",
      "2022-01-23 05:08:03.163281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:08:05.716440\n",
      "validation Loss: 0.5210 Acc: 0.9650\n",
      "2022-01-23 05:08:06.048832\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:08:08.561087\n",
      "validation Loss: 0.5291 Acc: 0.9650\n",
      "2022-01-23 05:08:08.906856\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:08:11.285160\n",
      "validation Loss: 0.5374 Acc: 0.9650\n",
      "2022-01-23 05:08:11.762859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:08:14.191281\n",
      "validation Loss: 0.5419 Acc: 0.9650\n",
      "2022-01-23 05:08:14.652193\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:17.050222\n",
      "validation Loss: 0.5527 Acc: 0.9650\n",
      "2022-01-23 05:08:17.412400\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:19.829148\n",
      "validation Loss: 0.5603 Acc: 0.9650\n",
      "2022-01-23 05:08:20.168540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:22.762645\n",
      "validation Loss: 0.5666 Acc: 0.9650\n",
      "2022-01-23 05:08:23.104076\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:25.852884\n",
      "validation Loss: 0.5750 Acc: 0.9650\n",
      "2022-01-23 05:08:26.249373\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:28.678872\n",
      "validation Loss: 0.5837 Acc: 0.9650\n",
      "2022-01-23 05:08:29.026868\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:31.715572\n",
      "validation Loss: 0.5901 Acc: 0.9650\n",
      "2022-01-23 05:08:32.110524\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:34.585674\n",
      "validation Loss: 0.5978 Acc: 0.9650\n",
      "2022-01-23 05:08:34.974850\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:08:37.612670\n",
      "validation Loss: 0.6028 Acc: 0.9650\n",
      "2022-01-23 05:08:38.005849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9790\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ai43mrq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 51226... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▆▇██████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▇▇▇██▇█▆███████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▂▂▁▁▁▂▁▃▁▂▁▂▂▁▂▂▃▁▂▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.97203</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.96503</td></tr><tr><td>best_test_accuracy</td><td>0.97203</td></tr><tr><td>best_val_accuracy</td><td>0.97902</td></tr><tr><td>best_val_loss</td><td>0.13393</td></tr><tr><td>loss_train</td><td>3e-05</td></tr><tr><td>loss_validation</td><td>0.60282</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2ai43mrq\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2ai43mrq</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_050335-2ai43mrq/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ai43mrq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2epplsje\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 05:08:47.783400\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.9455 Acc: 0.1120\n",
      "2022-01-23 05:08:50.325848\n",
      "validation Loss: 2.7800 Acc: 0.1096\n",
      "2022-01-23 05:08:50.684936\n",
      "Accuracy of the network on the 429 test samples: 9.79020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.2146 Acc: 0.3055\n",
      "2022-01-23 05:08:53.549206\n",
      "validation Loss: 1.6088 Acc: 0.6387\n",
      "2022-01-23 05:08:53.942449\n",
      "Accuracy of the network on the 429 test samples: 60.60606060606061\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.3712 Acc: 0.6785\n",
      "2022-01-23 05:08:57.008879\n",
      "validation Loss: 1.0979 Acc: 0.7156\n",
      "2022-01-23 05:08:57.408387\n",
      "Accuracy of the network on the 429 test samples: 72.26107226107226\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.9478 Acc: 0.7880\n",
      "2022-01-23 05:09:00.338971\n",
      "validation Loss: 0.7111 Acc: 0.8695\n",
      "2022-01-23 05:09:00.737585\n",
      "Accuracy of the network on the 429 test samples: 85.78088578088578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5888 Acc: 0.8540\n",
      "2022-01-23 05:09:03.769246\n",
      "validation Loss: 0.5189 Acc: 0.8811\n",
      "2022-01-23 05:09:04.101575\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4774 Acc: 0.8800\n",
      "2022-01-23 05:09:06.953014\n",
      "validation Loss: 0.4818 Acc: 0.8881\n",
      "2022-01-23 05:09:07.323193\n",
      "Accuracy of the network on the 429 test samples: 89.5104895104895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4412 Acc: 0.8945\n",
      "2022-01-23 05:09:10.450009\n",
      "validation Loss: 0.3938 Acc: 0.9184\n",
      "2022-01-23 05:09:10.808658\n",
      "Accuracy of the network on the 429 test samples: 90.9090909090909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3131 Acc: 0.9230\n",
      "2022-01-23 05:09:13.672707\n",
      "validation Loss: 0.3680 Acc: 0.9044\n",
      "2022-01-23 05:09:14.061384\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2716 Acc: 0.9230\n",
      "2022-01-23 05:09:16.687732\n",
      "validation Loss: 0.2963 Acc: 0.9138\n",
      "2022-01-23 05:09:17.084444\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2183 Acc: 0.9395\n",
      "2022-01-23 05:09:19.730525\n",
      "validation Loss: 0.2804 Acc: 0.9138\n",
      "2022-01-23 05:09:20.133606\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2175 Acc: 0.9370\n",
      "2022-01-23 05:09:22.627623\n",
      "validation Loss: 0.2686 Acc: 0.9371\n",
      "2022-01-23 05:09:23.021365\n",
      "Accuracy of the network on the 429 test samples: 92.77389277389277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1715 Acc: 0.9515\n",
      "2022-01-23 05:09:26.270546\n",
      "validation Loss: 0.2219 Acc: 0.9371\n",
      "2022-01-23 05:09:26.610640\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1486 Acc: 0.9535\n",
      "2022-01-23 05:09:29.636550\n",
      "validation Loss: 0.2411 Acc: 0.9464\n",
      "2022-01-23 05:09:29.983054\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1426 Acc: 0.9550\n",
      "2022-01-23 05:09:32.852569\n",
      "validation Loss: 0.2126 Acc: 0.9371\n",
      "2022-01-23 05:09:33.191650\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1304 Acc: 0.9620\n",
      "2022-01-23 05:09:35.874188\n",
      "validation Loss: 0.2435 Acc: 0.9441\n",
      "2022-01-23 05:09:36.285218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1654 Acc: 0.9480\n",
      "2022-01-23 05:09:38.792496\n",
      "validation Loss: 0.1490 Acc: 0.9510\n",
      "2022-01-23 05:09:39.180291\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1704 Acc: 0.9535\n",
      "2022-01-23 05:09:42.212054\n",
      "validation Loss: 0.2008 Acc: 0.9347\n",
      "2022-01-23 05:09:42.555797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1405 Acc: 0.9570\n",
      "2022-01-23 05:09:45.043159\n",
      "validation Loss: 0.1339 Acc: 0.9557\n",
      "2022-01-23 05:09:45.417439\n",
      "Accuracy of the network on the 429 test samples: 94.87179487179486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1028 Acc: 0.9660\n",
      "2022-01-23 05:09:48.413831\n",
      "validation Loss: 0.1207 Acc: 0.9534\n",
      "2022-01-23 05:09:48.892133\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0913 Acc: 0.9690\n",
      "2022-01-23 05:09:51.483165\n",
      "validation Loss: 0.1203 Acc: 0.9534\n",
      "2022-01-23 05:09:51.850984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0818 Acc: 0.9705\n",
      "2022-01-23 05:09:54.433169\n",
      "validation Loss: 0.1163 Acc: 0.9510\n",
      "2022-01-23 05:09:54.863385\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0878 Acc: 0.9720\n",
      "2022-01-23 05:09:57.536091\n",
      "validation Loss: 0.1551 Acc: 0.9464\n",
      "2022-01-23 05:09:57.935831\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0851 Acc: 0.9745\n",
      "2022-01-23 05:10:00.456763\n",
      "validation Loss: 0.0998 Acc: 0.9580\n",
      "2022-01-23 05:10:00.823886\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0897 Acc: 0.9700\n",
      "2022-01-23 05:10:03.725120\n",
      "validation Loss: 0.1108 Acc: 0.9604\n",
      "2022-01-23 05:10:04.072937\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0654 Acc: 0.9775\n",
      "2022-01-23 05:10:07.043075\n",
      "validation Loss: 0.1047 Acc: 0.9604\n",
      "2022-01-23 05:10:07.368244\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0659 Acc: 0.9765\n",
      "2022-01-23 05:10:10.336100\n",
      "validation Loss: 0.0960 Acc: 0.9627\n",
      "2022-01-23 05:10:10.719695\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0620 Acc: 0.9795\n",
      "2022-01-23 05:10:13.922964\n",
      "validation Loss: 0.1009 Acc: 0.9627\n",
      "2022-01-23 05:10:14.329530\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0489 Acc: 0.9835\n",
      "2022-01-23 05:10:16.916835\n",
      "validation Loss: 0.1074 Acc: 0.9627\n",
      "2022-01-23 05:10:17.257506\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0797 Acc: 0.9770\n",
      "2022-01-23 05:10:19.900742\n",
      "validation Loss: 0.1332 Acc: 0.9534\n",
      "2022-01-23 05:10:20.236296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0670 Acc: 0.9795\n",
      "2022-01-23 05:10:22.737701\n",
      "validation Loss: 0.0865 Acc: 0.9627\n",
      "2022-01-23 05:10:23.084825\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0631 Acc: 0.9780\n",
      "2022-01-23 05:10:26.154206\n",
      "validation Loss: 0.1018 Acc: 0.9720\n",
      "2022-01-23 05:10:26.502349\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0610 Acc: 0.9785\n",
      "2022-01-23 05:10:29.451662\n",
      "validation Loss: 0.1273 Acc: 0.9557\n",
      "2022-01-23 05:10:29.805778\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0481 Acc: 0.9840\n",
      "2022-01-23 05:10:32.214713\n",
      "validation Loss: 0.0960 Acc: 0.9720\n",
      "2022-01-23 05:10:32.658323\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0803 Acc: 0.9750\n",
      "2022-01-23 05:10:35.575932\n",
      "validation Loss: 0.1133 Acc: 0.9580\n",
      "2022-01-23 05:10:36.021691\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1062 Acc: 0.9755\n",
      "2022-01-23 05:10:38.514595\n",
      "validation Loss: 0.1646 Acc: 0.9464\n",
      "2022-01-23 05:10:38.908261\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0957 Acc: 0.9700\n",
      "2022-01-23 05:10:41.396600\n",
      "validation Loss: 0.1062 Acc: 0.9627\n",
      "2022-01-23 05:10:41.751062\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0513 Acc: 0.9860\n",
      "2022-01-23 05:10:44.136346\n",
      "validation Loss: 0.1320 Acc: 0.9604\n",
      "2022-01-23 05:10:44.521660\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0522 Acc: 0.9850\n",
      "2022-01-23 05:10:47.027997\n",
      "validation Loss: 0.0898 Acc: 0.9627\n",
      "2022-01-23 05:10:47.373147\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0452 Acc: 0.9880\n",
      "2022-01-23 05:10:49.834413\n",
      "validation Loss: 0.0861 Acc: 0.9650\n",
      "2022-01-23 05:10:50.282494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0452 Acc: 0.9850\n",
      "2022-01-23 05:10:52.722091\n",
      "validation Loss: 0.0863 Acc: 0.9744\n",
      "2022-01-23 05:10:53.123537\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0396 Acc: 0.9875\n",
      "2022-01-23 05:10:56.156334\n",
      "validation Loss: 0.0940 Acc: 0.9674\n",
      "2022-01-23 05:10:56.502603\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0320 Acc: 0.9880\n",
      "2022-01-23 05:10:59.005909\n",
      "validation Loss: 0.0830 Acc: 0.9744\n",
      "2022-01-23 05:10:59.398775\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0290 Acc: 0.9900\n",
      "2022-01-23 05:11:02.227981\n",
      "validation Loss: 0.0828 Acc: 0.9720\n",
      "2022-01-23 05:11:02.681029\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0309 Acc: 0.9900\n",
      "2022-01-23 05:11:05.060858\n",
      "validation Loss: 0.0891 Acc: 0.9697\n",
      "2022-01-23 05:11:05.443868\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1519 Acc: 0.9675\n",
      "2022-01-23 05:11:08.013011\n",
      "validation Loss: 0.0973 Acc: 0.9674\n",
      "2022-01-23 05:11:08.423371\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0486 Acc: 0.9865\n",
      "2022-01-23 05:11:10.900529\n",
      "validation Loss: 0.0692 Acc: 0.9767\n",
      "2022-01-23 05:11:11.251310\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0379 Acc: 0.9885\n",
      "2022-01-23 05:11:13.190735\n",
      "validation Loss: 0.0816 Acc: 0.9790\n",
      "2022-01-23 05:11:13.550395\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0268 Acc: 0.9910\n",
      "2022-01-23 05:11:16.561258\n",
      "validation Loss: 0.0723 Acc: 0.9767\n",
      "2022-01-23 05:11:17.069819\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0218 Acc: 0.9935\n",
      "2022-01-23 05:11:19.595080\n",
      "validation Loss: 0.1123 Acc: 0.9697\n",
      "2022-01-23 05:11:20.028171\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0310 Acc: 0.9895\n",
      "2022-01-23 05:11:22.701073\n",
      "validation Loss: 0.0898 Acc: 0.9720\n",
      "2022-01-23 05:11:23.184095\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0327 Acc: 0.9885\n",
      "2022-01-23 05:11:25.800597\n",
      "validation Loss: 0.0751 Acc: 0.9697\n",
      "2022-01-23 05:11:26.189237\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0234 Acc: 0.9930\n",
      "2022-01-23 05:11:28.635015\n",
      "validation Loss: 0.0882 Acc: 0.9650\n",
      "2022-01-23 05:11:28.995324\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0299 Acc: 0.9890\n",
      "2022-01-23 05:11:31.532631\n",
      "validation Loss: 0.0920 Acc: 0.9674\n",
      "2022-01-23 05:11:32.047423\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0230 Acc: 0.9920\n",
      "2022-01-23 05:11:34.617553\n",
      "validation Loss: 0.1072 Acc: 0.9697\n",
      "2022-01-23 05:11:35.017089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0201 Acc: 0.9925\n",
      "2022-01-23 05:11:37.486494\n",
      "validation Loss: 0.0908 Acc: 0.9697\n",
      "2022-01-23 05:11:37.833273\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0166 Acc: 0.9955\n",
      "2022-01-23 05:11:40.353702\n",
      "validation Loss: 0.1034 Acc: 0.9720\n",
      "2022-01-23 05:11:40.733936\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0342 Acc: 0.9890\n",
      "2022-01-23 05:11:43.252558\n",
      "validation Loss: 0.0967 Acc: 0.9697\n",
      "2022-01-23 05:11:43.612295\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0484 Acc: 0.9840\n",
      "2022-01-23 05:11:46.260353\n",
      "validation Loss: 0.1528 Acc: 0.9744\n",
      "2022-01-23 05:11:46.618870\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0512 Acc: 0.9855\n",
      "2022-01-23 05:11:49.111216\n",
      "validation Loss: 0.0893 Acc: 0.9767\n",
      "2022-01-23 05:11:49.477787\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0235 Acc: 0.9935\n",
      "2022-01-23 05:11:52.053276\n",
      "validation Loss: 0.0820 Acc: 0.9697\n",
      "2022-01-23 05:11:52.391417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0149 Acc: 0.9960\n",
      "2022-01-23 05:11:55.043056\n",
      "validation Loss: 0.1216 Acc: 0.9697\n",
      "2022-01-23 05:11:55.409583\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0472 Acc: 0.9890\n",
      "2022-01-23 05:11:57.929322\n",
      "validation Loss: 0.0742 Acc: 0.9744\n",
      "2022-01-23 05:11:58.327971\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0216 Acc: 0.9935\n",
      "2022-01-23 05:12:00.960401\n",
      "validation Loss: 0.0885 Acc: 0.9767\n",
      "2022-01-23 05:12:01.295793\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0168 Acc: 0.9945\n",
      "2022-01-23 05:12:03.886354\n",
      "validation Loss: 0.1140 Acc: 0.9767\n",
      "2022-01-23 05:12:04.230072\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0188 Acc: 0.9950\n",
      "2022-01-23 05:12:06.821139\n",
      "validation Loss: 0.0904 Acc: 0.9744\n",
      "2022-01-23 05:12:07.158123\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0183 Acc: 0.9950\n",
      "2022-01-23 05:12:09.655066\n",
      "validation Loss: 0.0890 Acc: 0.9720\n",
      "2022-01-23 05:12:10.195218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0251 Acc: 0.9950\n",
      "2022-01-23 05:12:12.736548\n",
      "validation Loss: 0.1078 Acc: 0.9790\n",
      "2022-01-23 05:12:13.123823\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0358 Acc: 0.9935\n",
      "2022-01-23 05:12:15.603231\n",
      "validation Loss: 0.1568 Acc: 0.9441\n",
      "2022-01-23 05:12:15.960057\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2330 Acc: 0.9445\n",
      "2022-01-23 05:12:18.472684\n",
      "validation Loss: 0.0842 Acc: 0.9814\n",
      "2022-01-23 05:12:18.844938\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0461 Acc: 0.9855\n",
      "2022-01-23 05:12:21.856805\n",
      "validation Loss: 0.0606 Acc: 0.9814\n",
      "2022-01-23 05:12:22.214056\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0274 Acc: 0.9935\n",
      "2022-01-23 05:12:25.085506\n",
      "validation Loss: 0.0435 Acc: 0.9790\n",
      "2022-01-23 05:12:25.429323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 0.9975\n",
      "2022-01-23 05:12:28.000233\n",
      "validation Loss: 0.0584 Acc: 0.9860\n",
      "2022-01-23 05:12:28.422284\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0132 Acc: 0.9950\n",
      "2022-01-23 05:12:31.516495\n",
      "validation Loss: 0.0626 Acc: 0.9790\n",
      "2022-01-23 05:12:31.888703\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0330 Acc: 0.9915\n",
      "2022-01-23 05:12:34.494791\n",
      "validation Loss: 0.0685 Acc: 0.9814\n",
      "2022-01-23 05:12:34.971870\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0132 Acc: 0.9955\n",
      "2022-01-23 05:12:37.541764\n",
      "validation Loss: 0.0836 Acc: 0.9837\n",
      "2022-01-23 05:12:37.901151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1188 Acc: 0.9730\n",
      "2022-01-23 05:12:40.661788\n",
      "validation Loss: 0.0968 Acc: 0.9767\n",
      "2022-01-23 05:12:41.038441\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0417 Acc: 0.9905\n",
      "2022-01-23 05:12:43.758665\n",
      "validation Loss: 0.0688 Acc: 0.9744\n",
      "2022-01-23 05:12:44.372996\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0231 Acc: 0.9960\n",
      "2022-01-23 05:12:46.999532\n",
      "validation Loss: 0.0685 Acc: 0.9814\n",
      "2022-01-23 05:12:47.341924\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0169 Acc: 0.9975\n",
      "2022-01-23 05:12:49.784629\n",
      "validation Loss: 0.0730 Acc: 0.9814\n",
      "2022-01-23 05:12:50.195522\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0122 Acc: 0.9975\n",
      "2022-01-23 05:12:52.707840\n",
      "validation Loss: 0.0752 Acc: 0.9814\n",
      "2022-01-23 05:12:53.056332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0221 Acc: 0.9945\n",
      "2022-01-23 05:12:55.528661\n",
      "validation Loss: 0.1210 Acc: 0.9720\n",
      "2022-01-23 05:12:56.184574\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0586 Acc: 0.9860\n",
      "2022-01-23 05:12:58.728775\n",
      "validation Loss: 0.0775 Acc: 0.9744\n",
      "2022-01-23 05:12:59.121266\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0189 Acc: 0.9965\n",
      "2022-01-23 05:13:01.726928\n",
      "validation Loss: 0.0727 Acc: 0.9790\n",
      "2022-01-23 05:13:02.083286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0143 Acc: 0.9975\n",
      "2022-01-23 05:13:04.534208\n",
      "validation Loss: 0.0897 Acc: 0.9790\n",
      "2022-01-23 05:13:04.914844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0105 Acc: 0.9985\n",
      "2022-01-23 05:13:07.407776\n",
      "validation Loss: 0.0734 Acc: 0.9814\n",
      "2022-01-23 05:13:07.901748\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0088 Acc: 0.9980\n",
      "2022-01-23 05:13:10.370660\n",
      "validation Loss: 0.0935 Acc: 0.9767\n",
      "2022-01-23 05:13:10.721187\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9960\n",
      "2022-01-23 05:13:13.417569\n",
      "validation Loss: 0.1227 Acc: 0.9720\n",
      "2022-01-23 05:13:13.837148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 0.9980\n",
      "2022-01-23 05:13:16.320367\n",
      "validation Loss: 0.1064 Acc: 0.9790\n",
      "2022-01-23 05:13:16.648218\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9960\n",
      "2022-01-23 05:13:19.136615\n",
      "validation Loss: 0.1247 Acc: 0.9720\n",
      "2022-01-23 05:13:19.745148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9975\n",
      "2022-01-23 05:13:22.168380\n",
      "validation Loss: 0.1617 Acc: 0.9744\n",
      "2022-01-23 05:13:22.538262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0319 Acc: 0.9925\n",
      "2022-01-23 05:13:25.086102\n",
      "validation Loss: 0.0939 Acc: 0.9744\n",
      "2022-01-23 05:13:25.527387\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0124 Acc: 0.9970\n",
      "2022-01-23 05:13:28.018382\n",
      "validation Loss: 0.0858 Acc: 0.9790\n",
      "2022-01-23 05:13:28.380912\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9990\n",
      "2022-01-23 05:13:29.920757\n",
      "validation Loss: 0.0937 Acc: 0.9767\n",
      "2022-01-23 05:13:30.264288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0054 Acc: 0.9995\n",
      "2022-01-23 05:13:32.779280\n",
      "validation Loss: 0.1143 Acc: 0.9790\n",
      "2022-01-23 05:13:33.125545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9970\n",
      "2022-01-23 05:13:35.725024\n",
      "validation Loss: 0.0989 Acc: 0.9790\n",
      "2022-01-23 05:13:36.161642\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1319 Acc: 0.9655\n",
      "2022-01-23 05:13:38.717214\n",
      "validation Loss: 0.1075 Acc: 0.9697\n",
      "2022-01-23 05:13:39.077056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0502 Acc: 0.9865\n",
      "2022-01-23 05:13:41.577862\n",
      "validation Loss: 0.1165 Acc: 0.9674\n",
      "2022-01-23 05:13:41.917368\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0341 Acc: 0.9915\n",
      "2022-01-23 05:13:44.387063\n",
      "validation Loss: 0.1001 Acc: 0.9720\n",
      "2022-01-23 05:13:44.757836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0270 Acc: 0.9930\n",
      "2022-01-23 05:13:47.291356\n",
      "validation Loss: 0.1237 Acc: 0.9697\n",
      "2022-01-23 05:13:47.856896\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0234 Acc: 0.9925\n",
      "2022-01-23 05:13:50.364356\n",
      "validation Loss: 0.1110 Acc: 0.9744\n",
      "2022-01-23 05:13:50.734597\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9860\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2epplsje) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41375... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▇▇▇▇███████████████████</td></tr><tr><td>accuracy_train</td><td>▁▅▇▇████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.96737</td></tr><tr><td>accuracy_train</td><td>0.9925</td></tr><tr><td>accuracy_validation</td><td>0.97436</td></tr><tr><td>best_test_accuracy</td><td>0.96737</td></tr><tr><td>best_val_accuracy</td><td>0.98601</td></tr><tr><td>best_val_loss</td><td>0.05844</td></tr><tr><td>loss_train</td><td>0.02336</td></tr><tr><td>loss_validation</td><td>0.11104</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2epplsje\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2epplsje</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_050838-2epplsje/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2epplsje). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3a1i4tbg\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 05:14:00.543403\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9945 Acc: 0.0600\n",
      "2022-01-23 05:14:03.014944\n",
      "validation Loss: 2.9873 Acc: 0.0606\n",
      "2022-01-23 05:14:03.392577\n",
      "Accuracy of the network on the 429 test samples: 5.827505827505827\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9803 Acc: 0.0600\n",
      "2022-01-23 05:14:06.611517\n",
      "validation Loss: 2.9713 Acc: 0.0606\n",
      "2022-01-23 05:14:06.982888\n",
      "Accuracy of the network on the 429 test samples: 5.827505827505827\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9588 Acc: 0.0905\n",
      "2022-01-23 05:14:10.318183\n",
      "validation Loss: 2.9432 Acc: 0.1259\n",
      "2022-01-23 05:14:10.659128\n",
      "Accuracy of the network on the 429 test samples: 12.354312354312354\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9122 Acc: 0.1070\n",
      "2022-01-23 05:14:13.883243\n",
      "validation Loss: 2.8718 Acc: 0.0769\n",
      "2022-01-23 05:14:14.280461\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.7905 Acc: 0.0960\n",
      "2022-01-23 05:14:16.865428\n",
      "validation Loss: 2.6781 Acc: 0.1562\n",
      "2022-01-23 05:14:17.242045\n",
      "Accuracy of the network on the 429 test samples: 13.286713286713287\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5271 Acc: 0.2165\n",
      "2022-01-23 05:14:20.076720\n",
      "validation Loss: 2.3597 Acc: 0.3030\n",
      "2022-01-23 05:14:20.422293\n",
      "Accuracy of the network on the 429 test samples: 27.03962703962704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1098 Acc: 0.3435\n",
      "2022-01-23 05:14:23.356015\n",
      "validation Loss: 1.9235 Acc: 0.4009\n",
      "2022-01-23 05:14:23.739772\n",
      "Accuracy of the network on the 429 test samples: 38.92773892773892\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7385 Acc: 0.4980\n",
      "2022-01-23 05:14:26.679230\n",
      "validation Loss: 1.6629 Acc: 0.5548\n",
      "2022-01-23 05:14:27.042693\n",
      "Accuracy of the network on the 429 test samples: 55.71095571095571\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.4838 Acc: 0.6060\n",
      "2022-01-23 05:14:29.961337\n",
      "validation Loss: 1.4660 Acc: 0.6480\n",
      "2022-01-23 05:14:30.384043\n",
      "Accuracy of the network on the 429 test samples: 64.56876456876456\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2648 Acc: 0.6810\n",
      "2022-01-23 05:14:33.233727\n",
      "validation Loss: 1.2973 Acc: 0.7249\n",
      "2022-01-23 05:14:33.609302\n",
      "Accuracy of the network on the 429 test samples: 70.3962703962704\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1219 Acc: 0.7185\n",
      "2022-01-23 05:14:36.575627\n",
      "validation Loss: 1.1827 Acc: 0.7483\n",
      "2022-01-23 05:14:36.984842\n",
      "Accuracy of the network on the 429 test samples: 74.35897435897436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9812 Acc: 0.7575\n",
      "2022-01-23 05:14:40.041947\n",
      "validation Loss: 1.1075 Acc: 0.7786\n",
      "2022-01-23 05:14:40.417310\n",
      "Accuracy of the network on the 429 test samples: 76.22377622377621\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8706 Acc: 0.7810\n",
      "2022-01-23 05:14:43.427119\n",
      "validation Loss: 1.0156 Acc: 0.8112\n",
      "2022-01-23 05:14:43.771039\n",
      "Accuracy of the network on the 429 test samples: 79.48717948717949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7784 Acc: 0.8075\n",
      "2022-01-23 05:14:46.597245\n",
      "validation Loss: 1.0124 Acc: 0.8182\n",
      "2022-01-23 05:14:46.940622\n",
      "Accuracy of the network on the 429 test samples: 81.58508158508158\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6978 Acc: 0.8300\n",
      "2022-01-23 05:14:49.813203\n",
      "validation Loss: 0.9303 Acc: 0.8298\n",
      "2022-01-23 05:14:50.236265\n",
      "Accuracy of the network on the 429 test samples: 83.68298368298368\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6176 Acc: 0.8415\n",
      "2022-01-23 05:14:53.176770\n",
      "validation Loss: 0.9292 Acc: 0.8625\n",
      "2022-01-23 05:14:53.598344\n",
      "Accuracy of the network on the 429 test samples: 85.54778554778555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5530 Acc: 0.8640\n",
      "2022-01-23 05:14:56.564627\n",
      "validation Loss: 0.9189 Acc: 0.8741\n",
      "2022-01-23 05:14:57.055837\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4953 Acc: 0.8780\n",
      "2022-01-23 05:14:59.979068\n",
      "validation Loss: 0.8735 Acc: 0.8881\n",
      "2022-01-23 05:15:00.356910\n",
      "Accuracy of the network on the 429 test samples: 87.17948717948718\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4584 Acc: 0.8855\n",
      "2022-01-23 05:15:03.699892\n",
      "validation Loss: 0.8018 Acc: 0.8718\n",
      "2022-01-23 05:15:04.125890\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4252 Acc: 0.8935\n",
      "2022-01-23 05:15:06.624186\n",
      "validation Loss: 0.8933 Acc: 0.8881\n",
      "2022-01-23 05:15:06.960161\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3785 Acc: 0.9035\n",
      "2022-01-23 05:15:09.368436\n",
      "validation Loss: 0.8503 Acc: 0.9068\n",
      "2022-01-23 05:15:09.784881\n",
      "Accuracy of the network on the 429 test samples: 87.87878787878788\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3514 Acc: 0.9120\n",
      "2022-01-23 05:15:12.881401\n",
      "validation Loss: 0.7838 Acc: 0.9068\n",
      "2022-01-23 05:15:13.260140\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3367 Acc: 0.9225\n",
      "2022-01-23 05:15:16.381565\n",
      "validation Loss: 0.8425 Acc: 0.9161\n",
      "2022-01-23 05:15:16.853635\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3271 Acc: 0.9160\n",
      "2022-01-23 05:15:19.727690\n",
      "validation Loss: 0.7571 Acc: 0.9138\n",
      "2022-01-23 05:15:20.086487\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2889 Acc: 0.9255\n",
      "2022-01-23 05:15:22.560492\n",
      "validation Loss: 0.7244 Acc: 0.9254\n",
      "2022-01-23 05:15:22.979157\n",
      "Accuracy of the network on the 429 test samples: 91.14219114219114\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2676 Acc: 0.9345\n",
      "2022-01-23 05:15:25.928548\n",
      "validation Loss: 0.6866 Acc: 0.9231\n",
      "2022-01-23 05:15:26.273387\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2564 Acc: 0.9325\n",
      "2022-01-23 05:15:28.815011\n",
      "validation Loss: 0.6593 Acc: 0.9254\n",
      "2022-01-23 05:15:29.157186\n",
      "Accuracy of the network on the 429 test samples: 90.9090909090909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2363 Acc: 0.9370\n",
      "2022-01-23 05:15:32.197669\n",
      "validation Loss: 0.5947 Acc: 0.9371\n",
      "2022-01-23 05:15:32.544526\n",
      "Accuracy of the network on the 429 test samples: 92.07459207459208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2218 Acc: 0.9385\n",
      "2022-01-23 05:15:35.385535\n",
      "validation Loss: 0.5799 Acc: 0.9394\n",
      "2022-01-23 05:15:35.738038\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2057 Acc: 0.9460\n",
      "2022-01-23 05:15:38.573202\n",
      "validation Loss: 0.6317 Acc: 0.9324\n",
      "2022-01-23 05:15:39.045598\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1991 Acc: 0.9445\n",
      "2022-01-23 05:15:41.491161\n",
      "validation Loss: 0.5357 Acc: 0.9371\n",
      "2022-01-23 05:15:41.853260\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1894 Acc: 0.9460\n",
      "2022-01-23 05:15:44.383926\n",
      "validation Loss: 0.7126 Acc: 0.9487\n",
      "2022-01-23 05:15:44.737500\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2025 Acc: 0.9440\n",
      "2022-01-23 05:15:47.824754\n",
      "validation Loss: 0.6573 Acc: 0.9441\n",
      "2022-01-23 05:15:48.225084\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1974 Acc: 0.9425\n",
      "2022-01-23 05:15:50.712328\n",
      "validation Loss: 0.4070 Acc: 0.9371\n",
      "2022-01-23 05:15:51.147043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1835 Acc: 0.9480\n",
      "2022-01-23 05:15:53.645092\n",
      "validation Loss: 0.3957 Acc: 0.9371\n",
      "2022-01-23 05:15:54.088080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1600 Acc: 0.9535\n",
      "2022-01-23 05:15:56.753082\n",
      "validation Loss: 0.4357 Acc: 0.9371\n",
      "2022-01-23 05:15:57.155914\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1564 Acc: 0.9555\n",
      "2022-01-23 05:15:59.702816\n",
      "validation Loss: 0.3789 Acc: 0.9324\n",
      "2022-01-23 05:16:00.108665\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1989 Acc: 0.9490\n",
      "2022-01-23 05:16:02.608521\n",
      "validation Loss: 0.3537 Acc: 0.9301\n",
      "2022-01-23 05:16:03.022872\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1492 Acc: 0.9585\n",
      "2022-01-23 05:16:05.637437\n",
      "validation Loss: 0.3513 Acc: 0.9441\n",
      "2022-01-23 05:16:06.012780\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1386 Acc: 0.9610\n",
      "2022-01-23 05:16:08.726879\n",
      "validation Loss: 0.3715 Acc: 0.9301\n",
      "2022-01-23 05:16:09.113802\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1348 Acc: 0.9615\n",
      "2022-01-23 05:16:11.673300\n",
      "validation Loss: 0.3961 Acc: 0.9510\n",
      "2022-01-23 05:16:12.120925\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1299 Acc: 0.9625\n",
      "2022-01-23 05:16:15.037209\n",
      "validation Loss: 0.4197 Acc: 0.9534\n",
      "2022-01-23 05:16:15.383079\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1218 Acc: 0.9650\n",
      "2022-01-23 05:16:18.298484\n",
      "validation Loss: 0.3690 Acc: 0.9464\n",
      "2022-01-23 05:16:18.766087\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1293 Acc: 0.9645\n",
      "2022-01-23 05:16:21.245015\n",
      "validation Loss: 0.6381 Acc: 0.9557\n",
      "2022-01-23 05:16:21.586605\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1358 Acc: 0.9615\n",
      "2022-01-23 05:16:24.696248\n",
      "validation Loss: 0.3632 Acc: 0.9580\n",
      "2022-01-23 05:16:25.048479\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1171 Acc: 0.9665\n",
      "2022-01-23 05:16:28.134440\n",
      "validation Loss: 0.3471 Acc: 0.9557\n",
      "2022-01-23 05:16:28.509652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1089 Acc: 0.9695\n",
      "2022-01-23 05:16:31.016518\n",
      "validation Loss: 0.4282 Acc: 0.9534\n",
      "2022-01-23 05:16:31.381296\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1167 Acc: 0.9665\n",
      "2022-01-23 05:16:34.032466\n",
      "validation Loss: 0.3535 Acc: 0.9441\n",
      "2022-01-23 05:16:34.546525\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1087 Acc: 0.9675\n",
      "2022-01-23 05:16:37.136118\n",
      "validation Loss: 0.3918 Acc: 0.9557\n",
      "2022-01-23 05:16:37.517465\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1106 Acc: 0.9670\n",
      "2022-01-23 05:16:40.044923\n",
      "validation Loss: 0.4316 Acc: 0.9510\n",
      "2022-01-23 05:16:40.389555\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0978 Acc: 0.9715\n",
      "2022-01-23 05:16:42.943514\n",
      "validation Loss: 0.4470 Acc: 0.9510\n",
      "2022-01-23 05:16:43.345957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0916 Acc: 0.9710\n",
      "2022-01-23 05:16:45.957137\n",
      "validation Loss: 0.3768 Acc: 0.9557\n",
      "2022-01-23 05:16:46.327540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0880 Acc: 0.9725\n",
      "2022-01-23 05:16:48.820913\n",
      "validation Loss: 0.4842 Acc: 0.9487\n",
      "2022-01-23 05:16:49.157064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0956 Acc: 0.9695\n",
      "2022-01-23 05:16:51.735878\n",
      "validation Loss: 0.4171 Acc: 0.9441\n",
      "2022-01-23 05:16:52.082075\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0856 Acc: 0.9740\n",
      "2022-01-23 05:16:54.607406\n",
      "validation Loss: 0.5526 Acc: 0.9510\n",
      "2022-01-23 05:16:55.005762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0915 Acc: 0.9700\n",
      "2022-01-23 05:16:57.596928\n",
      "validation Loss: 0.4677 Acc: 0.9464\n",
      "2022-01-23 05:16:58.003976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0848 Acc: 0.9725\n",
      "2022-01-23 05:17:00.640768\n",
      "validation Loss: 0.4398 Acc: 0.9464\n",
      "2022-01-23 05:17:01.042350\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1005 Acc: 0.9690\n",
      "2022-01-23 05:17:03.562317\n",
      "validation Loss: 0.4770 Acc: 0.9441\n",
      "2022-01-23 05:17:03.905453\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0993 Acc: 0.9695\n",
      "2022-01-23 05:17:06.520624\n",
      "validation Loss: 0.3092 Acc: 0.9510\n",
      "2022-01-23 05:17:07.059196\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0814 Acc: 0.9740\n",
      "2022-01-23 05:17:09.582140\n",
      "validation Loss: 0.3753 Acc: 0.9557\n",
      "2022-01-23 05:17:09.928293\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0765 Acc: 0.9745\n",
      "2022-01-23 05:17:12.515268\n",
      "validation Loss: 0.2962 Acc: 0.9580\n",
      "2022-01-23 05:17:12.857073\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0762 Acc: 0.9765\n",
      "2022-01-23 05:17:15.860429\n",
      "validation Loss: 0.3014 Acc: 0.9557\n",
      "2022-01-23 05:17:16.381627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0717 Acc: 0.9750\n",
      "2022-01-23 05:17:19.169302\n",
      "validation Loss: 0.3864 Acc: 0.9557\n",
      "2022-01-23 05:17:19.521332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0725 Acc: 0.9775\n",
      "2022-01-23 05:17:21.992595\n",
      "validation Loss: 0.4799 Acc: 0.9464\n",
      "2022-01-23 05:17:22.332117\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0683 Acc: 0.9780\n",
      "2022-01-23 05:17:24.758617\n",
      "validation Loss: 0.4104 Acc: 0.9534\n",
      "2022-01-23 05:17:25.121709\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0827 Acc: 0.9760\n",
      "2022-01-23 05:17:27.623715\n",
      "validation Loss: 0.2948 Acc: 0.9441\n",
      "2022-01-23 05:17:28.094240\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0917 Acc: 0.9725\n",
      "2022-01-23 05:17:30.526510\n",
      "validation Loss: 0.3112 Acc: 0.9441\n",
      "2022-01-23 05:17:30.897748\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0649 Acc: 0.9790\n",
      "2022-01-23 05:17:33.343221\n",
      "validation Loss: 0.3007 Acc: 0.9534\n",
      "2022-01-23 05:17:33.698378\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0606 Acc: 0.9810\n",
      "2022-01-23 05:17:36.205784\n",
      "validation Loss: 0.3012 Acc: 0.9441\n",
      "2022-01-23 05:17:36.537659\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0717 Acc: 0.9765\n",
      "2022-01-23 05:17:38.982803\n",
      "validation Loss: 0.3578 Acc: 0.9557\n",
      "2022-01-23 05:17:39.326276\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0634 Acc: 0.9770\n",
      "2022-01-23 05:17:41.765486\n",
      "validation Loss: 0.4229 Acc: 0.9604\n",
      "2022-01-23 05:17:42.229279\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0599 Acc: 0.9845\n",
      "2022-01-23 05:17:45.162053\n",
      "validation Loss: 0.4307 Acc: 0.9557\n",
      "2022-01-23 05:17:45.504216\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0559 Acc: 0.9830\n",
      "2022-01-23 05:17:48.002310\n",
      "validation Loss: 0.4371 Acc: 0.9604\n",
      "2022-01-23 05:17:48.337637\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0576 Acc: 0.9805\n",
      "2022-01-23 05:17:50.773196\n",
      "validation Loss: 0.4871 Acc: 0.9534\n",
      "2022-01-23 05:17:51.188459\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0512 Acc: 0.9825\n",
      "2022-01-23 05:17:53.644006\n",
      "validation Loss: 0.4941 Acc: 0.9534\n",
      "2022-01-23 05:17:54.104474\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9820\n",
      "2022-01-23 05:17:56.602471\n",
      "validation Loss: 0.5454 Acc: 0.9557\n",
      "2022-01-23 05:17:56.979797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0499 Acc: 0.9845\n",
      "2022-01-23 05:17:59.532046\n",
      "validation Loss: 0.5604 Acc: 0.9580\n",
      "2022-01-23 05:17:59.894957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0469 Acc: 0.9845\n",
      "2022-01-23 05:18:02.430487\n",
      "validation Loss: 0.4195 Acc: 0.9557\n",
      "2022-01-23 05:18:02.786585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0489 Acc: 0.9840\n",
      "2022-01-23 05:18:05.356769\n",
      "validation Loss: 0.6645 Acc: 0.9580\n",
      "2022-01-23 05:18:05.749281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0455 Acc: 0.9865\n",
      "2022-01-23 05:18:08.265412\n",
      "validation Loss: 0.7002 Acc: 0.9604\n",
      "2022-01-23 05:18:08.642032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0473 Acc: 0.9850\n",
      "2022-01-23 05:18:11.375401\n",
      "validation Loss: 0.6592 Acc: 0.9580\n",
      "2022-01-23 05:18:11.784995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0467 Acc: 0.9850\n",
      "2022-01-23 05:18:14.391817\n",
      "validation Loss: 0.6282 Acc: 0.9604\n",
      "2022-01-23 05:18:14.926976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0445 Acc: 0.9860\n",
      "2022-01-23 05:18:17.444578\n",
      "validation Loss: 0.6099 Acc: 0.9604\n",
      "2022-01-23 05:18:17.825135\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0464 Acc: 0.9860\n",
      "2022-01-23 05:18:20.441276\n",
      "validation Loss: 0.6842 Acc: 0.9580\n",
      "2022-01-23 05:18:20.804811\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0412 Acc: 0.9870\n",
      "2022-01-23 05:18:23.529893\n",
      "validation Loss: 0.6580 Acc: 0.9580\n",
      "2022-01-23 05:18:23.943868\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0403 Acc: 0.9850\n",
      "2022-01-23 05:18:26.582446\n",
      "validation Loss: 0.8724 Acc: 0.9557\n",
      "2022-01-23 05:18:26.928246\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0397 Acc: 0.9885\n",
      "2022-01-23 05:18:29.425445\n",
      "validation Loss: 0.6833 Acc: 0.9534\n",
      "2022-01-23 05:18:29.775386\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0359 Acc: 0.9885\n",
      "2022-01-23 05:18:32.335369\n",
      "validation Loss: 0.7475 Acc: 0.9557\n",
      "2022-01-23 05:18:32.682353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0372 Acc: 0.9865\n",
      "2022-01-23 05:18:35.248286\n",
      "validation Loss: 0.7810 Acc: 0.9580\n",
      "2022-01-23 05:18:35.709126\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0396 Acc: 0.9860\n",
      "2022-01-23 05:18:38.200879\n",
      "validation Loss: 0.8358 Acc: 0.9580\n",
      "2022-01-23 05:18:38.569278\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0337 Acc: 0.9885\n",
      "2022-01-23 05:18:41.160906\n",
      "validation Loss: 0.8210 Acc: 0.9580\n",
      "2022-01-23 05:18:41.523673\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0348 Acc: 0.9885\n",
      "2022-01-23 05:18:44.083074\n",
      "validation Loss: 0.7649 Acc: 0.9627\n",
      "2022-01-23 05:18:44.448161\n",
      "Accuracy of the network on the 429 test samples: 95.1048951048951\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0336 Acc: 0.9870\n",
      "2022-01-23 05:18:47.459210\n",
      "validation Loss: 0.8685 Acc: 0.9604\n",
      "2022-01-23 05:18:47.832294\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0332 Acc: 0.9890\n",
      "2022-01-23 05:18:50.418934\n",
      "validation Loss: 0.7493 Acc: 0.9534\n",
      "2022-01-23 05:18:50.762286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0523 Acc: 0.9815\n",
      "2022-01-23 05:18:53.281835\n",
      "validation Loss: 1.0587 Acc: 0.9604\n",
      "2022-01-23 05:18:53.645267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0881 Acc: 0.9790\n",
      "2022-01-23 05:18:56.153977\n",
      "validation Loss: 0.5830 Acc: 0.9604\n",
      "2022-01-23 05:18:56.527185\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0468 Acc: 0.9845\n",
      "2022-01-23 05:18:58.176080\n",
      "validation Loss: 0.6384 Acc: 0.9674\n",
      "2022-01-23 05:18:58.574344\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0319 Acc: 0.9905\n",
      "2022-01-23 05:19:01.437139\n",
      "validation Loss: 0.7056 Acc: 0.9650\n",
      "2022-01-23 05:19:02.007463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0329 Acc: 0.9890\n",
      "2022-01-23 05:19:04.603031\n",
      "validation Loss: 0.7558 Acc: 0.9627\n",
      "2022-01-23 05:19:04.940355\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0568 Acc: 0.9840\n",
      "2022-01-23 05:19:07.563177\n",
      "validation Loss: 0.6827 Acc: 0.9627\n",
      "2022-01-23 05:19:07.934600\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9674\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3a1i4tbg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 37755... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▁▂▂▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>accuracy_train</td><td>▁▁▂▄▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▂▃▅▆▇▇▇████████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▆▅▃▃▃▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.95338</td></tr><tr><td>accuracy_train</td><td>0.984</td></tr><tr><td>accuracy_validation</td><td>0.9627</td></tr><tr><td>best_test_accuracy</td><td>0.95338</td></tr><tr><td>best_val_accuracy</td><td>0.96737</td></tr><tr><td>best_val_loss</td><td>0.63842</td></tr><tr><td>loss_train</td><td>0.05683</td></tr><tr><td>loss_validation</td><td>0.68271</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3a1i4tbg\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3a1i4tbg</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_051351-3a1i4tbg/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3a1i4tbg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kqq96au\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 05:19:18.403161\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.7498 Acc: 0.8020\n",
      "2022-01-23 05:19:20.966573\n",
      "validation Loss: 0.2158 Acc: 0.9347\n",
      "2022-01-23 05:19:21.326570\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1782 Acc: 0.9475\n",
      "2022-01-23 05:19:24.221466\n",
      "validation Loss: 0.1383 Acc: 0.9650\n",
      "2022-01-23 05:19:24.580198\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1043 Acc: 0.9680\n",
      "2022-01-23 05:19:27.655291\n",
      "validation Loss: 0.1016 Acc: 0.9627\n",
      "2022-01-23 05:19:28.021507\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0561 Acc: 0.9810\n",
      "2022-01-23 05:19:29.436759\n",
      "validation Loss: 0.1227 Acc: 0.9580\n",
      "2022-01-23 05:19:29.930773\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0908 Acc: 0.9685\n",
      "2022-01-23 05:19:32.542943\n",
      "validation Loss: 0.0941 Acc: 0.9674\n",
      "2022-01-23 05:19:32.890483\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0551 Acc: 0.9840\n",
      "2022-01-23 05:19:36.135430\n",
      "validation Loss: 0.0768 Acc: 0.9720\n",
      "2022-01-23 05:19:36.637482\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0556 Acc: 0.9845\n",
      "2022-01-23 05:19:39.424953\n",
      "validation Loss: 0.1187 Acc: 0.9650\n",
      "2022-01-23 05:19:39.763061\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0476 Acc: 0.9860\n",
      "2022-01-23 05:19:42.231269\n",
      "validation Loss: 0.0998 Acc: 0.9650\n",
      "2022-01-23 05:19:42.591871\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0726 Acc: 0.9730\n",
      "2022-01-23 05:19:45.165343\n",
      "validation Loss: 0.1144 Acc: 0.9627\n",
      "2022-01-23 05:19:45.713956\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0537 Acc: 0.9825\n",
      "2022-01-23 05:19:48.184728\n",
      "validation Loss: 0.0697 Acc: 0.9720\n",
      "2022-01-23 05:19:48.540507\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0344 Acc: 0.9870\n",
      "2022-01-23 05:19:50.660315\n",
      "validation Loss: 0.0924 Acc: 0.9650\n",
      "2022-01-23 05:19:51.099894\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0282 Acc: 0.9920\n",
      "2022-01-23 05:19:53.497642\n",
      "validation Loss: 0.0648 Acc: 0.9697\n",
      "2022-01-23 05:19:53.896079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0256 Acc: 0.9940\n",
      "2022-01-23 05:19:56.335229\n",
      "validation Loss: 0.0966 Acc: 0.9767\n",
      "2022-01-23 05:19:56.816929\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0271 Acc: 0.9920\n",
      "2022-01-23 05:19:59.581733\n",
      "validation Loss: 0.1315 Acc: 0.9580\n",
      "2022-01-23 05:20:00.024291\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0738 Acc: 0.9730\n",
      "2022-01-23 05:20:02.494188\n",
      "validation Loss: 0.2282 Acc: 0.9441\n",
      "2022-01-23 05:20:02.821779\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0627 Acc: 0.9800\n",
      "2022-01-23 05:20:05.310877\n",
      "validation Loss: 0.0725 Acc: 0.9837\n",
      "2022-01-23 05:20:05.732848\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0366 Acc: 0.9875\n",
      "2022-01-23 05:20:08.608666\n",
      "validation Loss: 0.1090 Acc: 0.9627\n",
      "2022-01-23 05:20:09.026834\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0513 Acc: 0.9855\n",
      "2022-01-23 05:20:11.605650\n",
      "validation Loss: 0.1178 Acc: 0.9650\n",
      "2022-01-23 05:20:11.975049\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0161 Acc: 0.9925\n",
      "2022-01-23 05:20:14.493152\n",
      "validation Loss: 0.0597 Acc: 0.9744\n",
      "2022-01-23 05:20:14.860357\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0199 Acc: 0.9940\n",
      "2022-01-23 05:20:17.467173\n",
      "validation Loss: 0.0623 Acc: 0.9837\n",
      "2022-01-23 05:20:17.871718\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0215 Acc: 0.9945\n",
      "2022-01-23 05:20:20.888419\n",
      "validation Loss: 0.0991 Acc: 0.9720\n",
      "2022-01-23 05:20:21.279381\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0293 Acc: 0.9905\n",
      "2022-01-23 05:20:23.809991\n",
      "validation Loss: 0.0605 Acc: 0.9744\n",
      "2022-01-23 05:20:24.148902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 0.9990\n",
      "2022-01-23 05:20:26.753656\n",
      "validation Loss: 0.0631 Acc: 0.9790\n",
      "2022-01-23 05:20:27.155157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0103 Acc: 0.9965\n",
      "2022-01-23 05:20:29.731746\n",
      "validation Loss: 0.0538 Acc: 0.9814\n",
      "2022-01-23 05:20:30.098557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0255 Acc: 0.9920\n",
      "2022-01-23 05:20:32.978556\n",
      "validation Loss: 0.1167 Acc: 0.9627\n",
      "2022-01-23 05:20:33.400283\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0193 Acc: 0.9950\n",
      "2022-01-23 05:20:35.926145\n",
      "validation Loss: 0.0886 Acc: 0.9744\n",
      "2022-01-23 05:20:36.315211\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0381 Acc: 0.9885\n",
      "2022-01-23 05:20:38.919129\n",
      "validation Loss: 0.1139 Acc: 0.9697\n",
      "2022-01-23 05:20:39.462654\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0210 Acc: 0.9930\n",
      "2022-01-23 05:20:41.999645\n",
      "validation Loss: 0.1735 Acc: 0.9510\n",
      "2022-01-23 05:20:42.433044\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0363 Acc: 0.9890\n",
      "2022-01-23 05:20:45.061336\n",
      "validation Loss: 0.0663 Acc: 0.9744\n",
      "2022-01-23 05:20:45.414526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0196 Acc: 0.9930\n",
      "2022-01-23 05:20:47.972845\n",
      "validation Loss: 0.1433 Acc: 0.9650\n",
      "2022-01-23 05:20:48.487001\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0821 Acc: 0.9745\n",
      "2022-01-23 05:20:51.068823\n",
      "validation Loss: 0.1105 Acc: 0.9627\n",
      "2022-01-23 05:20:51.481404\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0438 Acc: 0.9870\n",
      "2022-01-23 05:20:53.980430\n",
      "validation Loss: 0.1453 Acc: 0.9674\n",
      "2022-01-23 05:20:54.397550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0228 Acc: 0.9925\n",
      "2022-01-23 05:20:56.923075\n",
      "validation Loss: 0.0970 Acc: 0.9744\n",
      "2022-01-23 05:20:57.345715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0090 Acc: 0.9960\n",
      "2022-01-23 05:20:59.978554\n",
      "validation Loss: 0.0664 Acc: 0.9837\n",
      "2022-01-23 05:21:00.329810\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9970\n",
      "2022-01-23 05:21:02.905571\n",
      "validation Loss: 0.0699 Acc: 0.9814\n",
      "2022-01-23 05:21:03.272330\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0024 Acc: 0.9990\n",
      "2022-01-23 05:21:05.801479\n",
      "validation Loss: 0.0496 Acc: 0.9883\n",
      "2022-01-23 05:21:06.211399\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 05:21:09.287811\n",
      "validation Loss: 0.0533 Acc: 0.9790\n",
      "2022-01-23 05:21:09.645452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:21:12.298324\n",
      "validation Loss: 0.0456 Acc: 0.9837\n",
      "2022-01-23 05:21:12.648591\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:21:15.207875\n",
      "validation Loss: 0.0479 Acc: 0.9814\n",
      "2022-01-23 05:21:15.678030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:21:18.296950\n",
      "validation Loss: 0.0465 Acc: 0.9837\n",
      "2022-01-23 05:21:18.639755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:21:21.324551\n",
      "validation Loss: 0.0457 Acc: 0.9837\n",
      "2022-01-23 05:21:21.701941\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:24.323509\n",
      "validation Loss: 0.0459 Acc: 0.9837\n",
      "2022-01-23 05:21:24.873578\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:27.650282\n",
      "validation Loss: 0.0464 Acc: 0.9814\n",
      "2022-01-23 05:21:28.038332\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:30.796662\n",
      "validation Loss: 0.0453 Acc: 0.9837\n",
      "2022-01-23 05:21:31.162568\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:34.149209\n",
      "validation Loss: 0.0450 Acc: 0.9814\n",
      "2022-01-23 05:21:34.500516\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:37.033170\n",
      "validation Loss: 0.0451 Acc: 0.9837\n",
      "2022-01-23 05:21:37.392142\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:39.899014\n",
      "validation Loss: 0.0439 Acc: 0.9837\n",
      "2022-01-23 05:21:40.275542\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:43.209362\n",
      "validation Loss: 0.0444 Acc: 0.9814\n",
      "2022-01-23 05:21:43.589752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:46.192413\n",
      "validation Loss: 0.0440 Acc: 0.9814\n",
      "2022-01-23 05:21:46.623311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:49.208590\n",
      "validation Loss: 0.0437 Acc: 0.9837\n",
      "2022-01-23 05:21:49.816079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:52.215305\n",
      "validation Loss: 0.0440 Acc: 0.9860\n",
      "2022-01-23 05:21:52.571067\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:55.116480\n",
      "validation Loss: 0.0438 Acc: 0.9860\n",
      "2022-01-23 05:21:55.509921\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:21:58.006209\n",
      "validation Loss: 0.0439 Acc: 0.9860\n",
      "2022-01-23 05:21:58.353285\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:00.885402\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 05:22:01.451064\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:03.877686\n",
      "validation Loss: 0.0438 Acc: 0.9860\n",
      "2022-01-23 05:22:04.262861\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:06.812837\n",
      "validation Loss: 0.0446 Acc: 0.9860\n",
      "2022-01-23 05:22:07.265968\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:09.619230\n",
      "validation Loss: 0.0431 Acc: 0.9860\n",
      "2022-01-23 05:22:10.050942\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:12.635645\n",
      "validation Loss: 0.0433 Acc: 0.9860\n",
      "2022-01-23 05:22:13.081076\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:15.619846\n",
      "validation Loss: 0.0435 Acc: 0.9860\n",
      "2022-01-23 05:22:16.018664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:18.466944\n",
      "validation Loss: 0.0430 Acc: 0.9860\n",
      "2022-01-23 05:22:18.972310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:21.552158\n",
      "validation Loss: 0.0425 Acc: 0.9860\n",
      "2022-01-23 05:22:21.938774\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:24.413483\n",
      "validation Loss: 0.0431 Acc: 0.9860\n",
      "2022-01-23 05:22:24.764585\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:27.210328\n",
      "validation Loss: 0.0429 Acc: 0.9860\n",
      "2022-01-23 05:22:27.613976\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:30.110231\n",
      "validation Loss: 0.0415 Acc: 0.9883\n",
      "2022-01-23 05:22:30.593108\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:33.396025\n",
      "validation Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 05:22:33.798493\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:36.340405\n",
      "validation Loss: 0.0420 Acc: 0.9860\n",
      "2022-01-23 05:22:36.727518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:39.265621\n",
      "validation Loss: 0.0429 Acc: 0.9860\n",
      "2022-01-23 05:22:39.698058\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:22:42.182039\n",
      "validation Loss: 0.0425 Acc: 0.9860\n",
      "2022-01-23 05:22:42.566770\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:22:45.162614\n",
      "validation Loss: 0.0422 Acc: 0.9860\n",
      "2022-01-23 05:22:45.632355\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:22:48.210272\n",
      "validation Loss: 0.0419 Acc: 0.9860\n",
      "2022-01-23 05:22:48.667201\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:22:51.466773\n",
      "validation Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 05:22:51.832258\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:22:54.467020\n",
      "validation Loss: 0.0429 Acc: 0.9860\n",
      "2022-01-23 05:22:54.830369\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:22:57.439011\n",
      "validation Loss: 0.0428 Acc: 0.9860\n",
      "2022-01-23 05:22:57.774403\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:00.271839\n",
      "validation Loss: 0.0429 Acc: 0.9860\n",
      "2022-01-23 05:23:00.636698\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:03.265101\n",
      "validation Loss: 0.0431 Acc: 0.9860\n",
      "2022-01-23 05:23:03.637137\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:06.194669\n",
      "validation Loss: 0.0420 Acc: 0.9860\n",
      "2022-01-23 05:23:06.561572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:09.157843\n",
      "validation Loss: 0.0425 Acc: 0.9860\n",
      "2022-01-23 05:23:09.527480\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:12.375129\n",
      "validation Loss: 0.0426 Acc: 0.9860\n",
      "2022-01-23 05:23:12.792048\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:15.409552\n",
      "validation Loss: 0.0419 Acc: 0.9860\n",
      "2022-01-23 05:23:15.814179\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:18.420461\n",
      "validation Loss: 0.0418 Acc: 0.9860\n",
      "2022-01-23 05:23:18.916134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:21.453021\n",
      "validation Loss: 0.0423 Acc: 0.9860\n",
      "2022-01-23 05:23:21.808830\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:24.460294\n",
      "validation Loss: 0.0422 Acc: 0.9860\n",
      "2022-01-23 05:23:24.799435\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:27.369556\n",
      "validation Loss: 0.0418 Acc: 0.9860\n",
      "2022-01-23 05:23:27.758321\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:30.264639\n",
      "validation Loss: 0.0425 Acc: 0.9860\n",
      "2022-01-23 05:23:30.611129\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:33.226184\n",
      "validation Loss: 0.0436 Acc: 0.9860\n",
      "2022-01-23 05:23:33.575752\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:36.099642\n",
      "validation Loss: 0.0405 Acc: 0.9883\n",
      "2022-01-23 05:23:36.457049\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:39.435972\n",
      "validation Loss: 0.0423 Acc: 0.9860\n",
      "2022-01-23 05:23:39.837792\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:42.363563\n",
      "validation Loss: 0.0417 Acc: 0.9860\n",
      "2022-01-23 05:23:42.757056\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:45.248792\n",
      "validation Loss: 0.0428 Acc: 0.9860\n",
      "2022-01-23 05:23:45.721940\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:48.238301\n",
      "validation Loss: 0.0422 Acc: 0.9860\n",
      "2022-01-23 05:23:48.618717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:51.167091\n",
      "validation Loss: 0.0419 Acc: 0.9860\n",
      "2022-01-23 05:23:51.593492\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:54.150330\n",
      "validation Loss: 0.0418 Acc: 0.9860\n",
      "2022-01-23 05:23:54.637440\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:23:57.230177\n",
      "validation Loss: 0.0418 Acc: 0.9860\n",
      "2022-01-23 05:23:57.607153\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:00.503391\n",
      "validation Loss: 0.0432 Acc: 0.9860\n",
      "2022-01-23 05:24:00.834534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:03.707676\n",
      "validation Loss: 0.0420 Acc: 0.9860\n",
      "2022-01-23 05:24:04.074610\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:06.841219\n",
      "validation Loss: 0.0420 Acc: 0.9860\n",
      "2022-01-23 05:24:07.212715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:09.777854\n",
      "validation Loss: 0.0422 Acc: 0.9860\n",
      "2022-01-23 05:24:10.229797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:12.774669\n",
      "validation Loss: 0.0417 Acc: 0.9860\n",
      "2022-01-23 05:24:13.163095\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:15.889183\n",
      "validation Loss: 0.0420 Acc: 0.9860\n",
      "2022-01-23 05:24:16.253629\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:24:19.018274\n",
      "validation Loss: 0.0424 Acc: 0.9860\n",
      "2022-01-23 05:24:19.372448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 99.53379953379954\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3kqq96au) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36303... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▅▇▅▆▅▆▇██</td></tr><tr><td>accuracy_train</td><td>▁▇▇███▇▇████▇███████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▅▆▅▅▆▇▅▆▇▆▃▅▇█▇▇▇▇▇████████████████████</td></tr><tr><td>loss_train</td><td>█▂▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▂▃▃▃▂▄▃▂▃▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99534</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98601</td></tr><tr><td>best_test_accuracy</td><td>0.99534</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.04048</td></tr><tr><td>loss_train</td><td>2e-05</td></tr><tr><td>loss_validation</td><td>0.04242</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3kqq96au\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3kqq96au</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_051908-3kqq96au/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3kqq96au). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2mu1ncn7\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 05:24:29.244446\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.1063 Acc: 0.7370\n",
      "2022-01-23 05:24:31.863236\n",
      "validation Loss: 0.3226 Acc: 0.9277\n",
      "2022-01-23 05:24:32.454226\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.2022 Acc: 0.9480\n",
      "2022-01-23 05:24:35.319656\n",
      "validation Loss: 0.1871 Acc: 0.9441\n",
      "2022-01-23 05:24:35.709949\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1180 Acc: 0.9685\n",
      "2022-01-23 05:24:38.625583\n",
      "validation Loss: 0.1447 Acc: 0.9534\n",
      "2022-01-23 05:24:39.131376\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0840 Acc: 0.9770\n",
      "2022-01-23 05:24:42.225601\n",
      "validation Loss: 0.1005 Acc: 0.9557\n",
      "2022-01-23 05:24:42.703776\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0658 Acc: 0.9845\n",
      "2022-01-23 05:24:45.538034\n",
      "validation Loss: 0.0946 Acc: 0.9674\n",
      "2022-01-23 05:24:45.896581\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0581 Acc: 0.9870\n",
      "2022-01-23 05:24:48.811137\n",
      "validation Loss: 0.0953 Acc: 0.9557\n",
      "2022-01-23 05:24:49.394593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0457 Acc: 0.9870\n",
      "2022-01-23 05:24:51.923933\n",
      "validation Loss: 0.0879 Acc: 0.9674\n",
      "2022-01-23 05:24:52.315662\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0327 Acc: 0.9905\n",
      "2022-01-23 05:24:55.214192\n",
      "validation Loss: 0.0853 Acc: 0.9744\n",
      "2022-01-23 05:24:55.570335\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0531 Acc: 0.9865\n",
      "2022-01-23 05:24:58.778704\n",
      "validation Loss: 0.1018 Acc: 0.9697\n",
      "2022-01-23 05:24:59.117657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0295 Acc: 0.9915\n",
      "2022-01-23 05:25:01.642383\n",
      "validation Loss: 0.1468 Acc: 0.9510\n",
      "2022-01-23 05:25:01.987115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0274 Acc: 0.9920\n",
      "2022-01-23 05:25:04.503989\n",
      "validation Loss: 0.0669 Acc: 0.9790\n",
      "2022-01-23 05:25:04.863217\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0392 Acc: 0.9885\n",
      "2022-01-23 05:25:07.852415\n",
      "validation Loss: 0.0913 Acc: 0.9674\n",
      "2022-01-23 05:25:08.233143\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0221 Acc: 0.9940\n",
      "2022-01-23 05:25:10.869183\n",
      "validation Loss: 0.0740 Acc: 0.9767\n",
      "2022-01-23 05:25:11.229278\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0182 Acc: 0.9945\n",
      "2022-01-23 05:25:13.756291\n",
      "validation Loss: 0.1087 Acc: 0.9650\n",
      "2022-01-23 05:25:14.190762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0147 Acc: 0.9975\n",
      "2022-01-23 05:25:16.773668\n",
      "validation Loss: 0.0726 Acc: 0.9767\n",
      "2022-01-23 05:25:17.122395\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9980\n",
      "2022-01-23 05:25:19.615908\n",
      "validation Loss: 0.0599 Acc: 0.9837\n",
      "2022-01-23 05:25:20.017701\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0195 Acc: 0.9945\n",
      "2022-01-23 05:25:22.956032\n",
      "validation Loss: 0.0615 Acc: 0.9837\n",
      "2022-01-23 05:25:23.383341\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 0.9980\n",
      "2022-01-23 05:25:25.887514\n",
      "validation Loss: 0.0753 Acc: 0.9814\n",
      "2022-01-23 05:25:26.225618\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0190 Acc: 0.9940\n",
      "2022-01-23 05:25:28.808078\n",
      "validation Loss: 0.0789 Acc: 0.9744\n",
      "2022-01-23 05:25:29.144046\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 0.9985\n",
      "2022-01-23 05:25:31.659647\n",
      "validation Loss: 0.0538 Acc: 0.9837\n",
      "2022-01-23 05:25:32.023163\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0037 Acc: 1.0000\n",
      "2022-01-23 05:25:35.086411\n",
      "validation Loss: 0.0916 Acc: 0.9744\n",
      "2022-01-23 05:25:35.531061\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0228 Acc: 0.9920\n",
      "2022-01-23 05:25:38.085755\n",
      "validation Loss: 0.0498 Acc: 0.9860\n",
      "2022-01-23 05:25:38.484410\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0178 Acc: 0.9935\n",
      "2022-01-23 05:25:41.620151\n",
      "validation Loss: 0.0898 Acc: 0.9720\n",
      "2022-01-23 05:25:42.014747\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0207 Acc: 0.9970\n",
      "2022-01-23 05:25:44.615739\n",
      "validation Loss: 0.0717 Acc: 0.9767\n",
      "2022-01-23 05:25:44.996184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0262 Acc: 0.9940\n",
      "2022-01-23 05:25:47.655212\n",
      "validation Loss: 0.0498 Acc: 0.9814\n",
      "2022-01-23 05:25:48.061208\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0150 Acc: 0.9945\n",
      "2022-01-23 05:25:50.579754\n",
      "validation Loss: 0.0893 Acc: 0.9697\n",
      "2022-01-23 05:25:50.944615\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0276 Acc: 0.9920\n",
      "2022-01-23 05:25:53.420065\n",
      "validation Loss: 0.0677 Acc: 0.9767\n",
      "2022-01-23 05:25:53.804916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 0.9985\n",
      "2022-01-23 05:25:56.297781\n",
      "validation Loss: 0.0875 Acc: 0.9720\n",
      "2022-01-23 05:25:56.686877\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0054 Acc: 0.9980\n",
      "2022-01-23 05:25:59.389461\n",
      "validation Loss: 0.0922 Acc: 0.9767\n",
      "2022-01-23 05:25:59.816311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0026 Acc: 1.0000\n",
      "2022-01-23 05:26:02.486420\n",
      "validation Loss: 0.0521 Acc: 0.9860\n",
      "2022-01-23 05:26:02.854876\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 05:26:05.533205\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 05:26:05.921557\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:26:09.141387\n",
      "validation Loss: 0.0590 Acc: 0.9860\n",
      "2022-01-23 05:26:09.503247\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:26:12.092665\n",
      "validation Loss: 0.0442 Acc: 0.9883\n",
      "2022-01-23 05:26:12.487567\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:26:15.316680\n",
      "validation Loss: 0.0514 Acc: 0.9860\n",
      "2022-01-23 05:26:15.883777\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:26:18.485089\n",
      "validation Loss: 0.0523 Acc: 0.9837\n",
      "2022-01-23 05:26:18.880467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:26:21.423579\n",
      "validation Loss: 0.0508 Acc: 0.9860\n",
      "2022-01-23 05:26:21.812303\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:26:24.317785\n",
      "validation Loss: 0.0456 Acc: 0.9883\n",
      "2022-01-23 05:26:24.801614\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:26:27.412855\n",
      "validation Loss: 0.0546 Acc: 0.9860\n",
      "2022-01-23 05:26:27.764984\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:26:30.320135\n",
      "validation Loss: 0.0519 Acc: 0.9860\n",
      "2022-01-23 05:26:30.744630\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:26:33.349371\n",
      "validation Loss: 0.0493 Acc: 0.9883\n",
      "2022-01-23 05:26:33.693467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:36.200275\n",
      "validation Loss: 0.0475 Acc: 0.9883\n",
      "2022-01-23 05:26:36.677475\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:39.190397\n",
      "validation Loss: 0.0502 Acc: 0.9883\n",
      "2022-01-23 05:26:39.615610\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:42.042490\n",
      "validation Loss: 0.0509 Acc: 0.9860\n",
      "2022-01-23 05:26:42.402277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:44.877167\n",
      "validation Loss: 0.0486 Acc: 0.9883\n",
      "2022-01-23 05:26:45.285656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:47.826307\n",
      "validation Loss: 0.0498 Acc: 0.9883\n",
      "2022-01-23 05:26:48.418151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:51.037853\n",
      "validation Loss: 0.0519 Acc: 0.9883\n",
      "2022-01-23 05:26:51.534314\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:54.060095\n",
      "validation Loss: 0.0474 Acc: 0.9883\n",
      "2022-01-23 05:26:54.424545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:26:56.956831\n",
      "validation Loss: 0.0506 Acc: 0.9883\n",
      "2022-01-23 05:26:57.467735\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:26:59.892472\n",
      "validation Loss: 0.0496 Acc: 0.9883\n",
      "2022-01-23 05:27:00.308694\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:02.775946\n",
      "validation Loss: 0.0551 Acc: 0.9860\n",
      "2022-01-23 05:27:03.156086\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:05.604489\n",
      "validation Loss: 0.0501 Acc: 0.9883\n",
      "2022-01-23 05:27:05.966544\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:08.382027\n",
      "validation Loss: 0.0513 Acc: 0.9883\n",
      "2022-01-23 05:27:08.754363\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:11.324793\n",
      "validation Loss: 0.0490 Acc: 0.9883\n",
      "2022-01-23 05:27:11.864454\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:14.417915\n",
      "validation Loss: 0.0532 Acc: 0.9883\n",
      "2022-01-23 05:27:14.817502\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:17.277464\n",
      "validation Loss: 0.0483 Acc: 0.9883\n",
      "2022-01-23 05:27:17.626994\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:20.152554\n",
      "validation Loss: 0.0510 Acc: 0.9883\n",
      "2022-01-23 05:27:20.495553\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:23.071484\n",
      "validation Loss: 0.0560 Acc: 0.9860\n",
      "2022-01-23 05:27:23.553799\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:26.287190\n",
      "validation Loss: 0.0510 Acc: 0.9883\n",
      "2022-01-23 05:27:26.637837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:29.172918\n",
      "validation Loss: 0.0515 Acc: 0.9883\n",
      "2022-01-23 05:27:29.527836\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:32.118186\n",
      "validation Loss: 0.0497 Acc: 0.9883\n",
      "2022-01-23 05:27:32.492237\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:35.092732\n",
      "validation Loss: 0.0503 Acc: 0.9883\n",
      "2022-01-23 05:27:35.573268\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:38.162068\n",
      "validation Loss: 0.0528 Acc: 0.9883\n",
      "2022-01-23 05:27:38.526593\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:27:41.088510\n",
      "validation Loss: 0.0499 Acc: 0.9883\n",
      "2022-01-23 05:27:41.454020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:43.978698\n",
      "validation Loss: 0.0562 Acc: 0.9860\n",
      "2022-01-23 05:27:44.399316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:47.019482\n",
      "validation Loss: 0.0526 Acc: 0.9883\n",
      "2022-01-23 05:27:47.433757\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:50.008536\n",
      "validation Loss: 0.0501 Acc: 0.9883\n",
      "2022-01-23 05:27:50.338189\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:52.787938\n",
      "validation Loss: 0.0509 Acc: 0.9883\n",
      "2022-01-23 05:27:53.149159\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:55.103663\n",
      "validation Loss: 0.0500 Acc: 0.9883\n",
      "2022-01-23 05:27:55.436855\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:27:58.075226\n",
      "validation Loss: 0.0529 Acc: 0.9883\n",
      "2022-01-23 05:27:58.659485\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:01.307734\n",
      "validation Loss: 0.0511 Acc: 0.9883\n",
      "2022-01-23 05:28:01.670950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:04.156311\n",
      "validation Loss: 0.0497 Acc: 0.9883\n",
      "2022-01-23 05:28:04.509368\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:07.027616\n",
      "validation Loss: 0.0516 Acc: 0.9883\n",
      "2022-01-23 05:28:07.432324\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:09.968478\n",
      "validation Loss: 0.0542 Acc: 0.9860\n",
      "2022-01-23 05:28:10.495378\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:13.112733\n",
      "validation Loss: 0.0512 Acc: 0.9883\n",
      "2022-01-23 05:28:13.470088\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:16.015643\n",
      "validation Loss: 0.0517 Acc: 0.9860\n",
      "2022-01-23 05:28:16.377053\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:18.856908\n",
      "validation Loss: 0.0512 Acc: 0.9883\n",
      "2022-01-23 05:28:19.220030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:21.797511\n",
      "validation Loss: 0.0514 Acc: 0.9883\n",
      "2022-01-23 05:28:22.271998\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:24.841717\n",
      "validation Loss: 0.0557 Acc: 0.9883\n",
      "2022-01-23 05:28:25.259306\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:27.811075\n",
      "validation Loss: 0.0543 Acc: 0.9883\n",
      "2022-01-23 05:28:28.193830\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:30.720475\n",
      "validation Loss: 0.0519 Acc: 0.9860\n",
      "2022-01-23 05:28:31.173917\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:33.839857\n",
      "validation Loss: 0.0564 Acc: 0.9883\n",
      "2022-01-23 05:28:34.210157\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:36.684358\n",
      "validation Loss: 0.0497 Acc: 0.9883\n",
      "2022-01-23 05:28:37.073903\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:39.566856\n",
      "validation Loss: 0.0510 Acc: 0.9883\n",
      "2022-01-23 05:28:39.942335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:42.520103\n",
      "validation Loss: 0.0550 Acc: 0.9883\n",
      "2022-01-23 05:28:42.914748\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:45.445981\n",
      "validation Loss: 0.0546 Acc: 0.9883\n",
      "2022-01-23 05:28:45.795515\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:48.321830\n",
      "validation Loss: 0.0509 Acc: 0.9883\n",
      "2022-01-23 05:28:48.675167\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:51.181178\n",
      "validation Loss: 0.0496 Acc: 0.9860\n",
      "2022-01-23 05:28:51.539519\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:54.001230\n",
      "validation Loss: 0.0536 Acc: 0.9883\n",
      "2022-01-23 05:28:54.473588\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:56.903399\n",
      "validation Loss: 0.0495 Acc: 0.9883\n",
      "2022-01-23 05:28:57.253865\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:28:59.757273\n",
      "validation Loss: 0.0510 Acc: 0.9860\n",
      "2022-01-23 05:29:00.128545\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:02.568583\n",
      "validation Loss: 0.0526 Acc: 0.9883\n",
      "2022-01-23 05:29:02.997935\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:05.395101\n",
      "validation Loss: 0.0528 Acc: 0.9883\n",
      "2022-01-23 05:29:05.904400\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:08.364141\n",
      "validation Loss: 0.0522 Acc: 0.9883\n",
      "2022-01-23 05:29:08.707504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:11.136278\n",
      "validation Loss: 0.0527 Acc: 0.9860\n",
      "2022-01-23 05:29:11.493327\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:13.913939\n",
      "validation Loss: 0.0524 Acc: 0.9860\n",
      "2022-01-23 05:29:14.263339\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:16.742255\n",
      "validation Loss: 0.0591 Acc: 0.9860\n",
      "2022-01-23 05:29:17.240835\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:29:19.859813\n",
      "validation Loss: 0.0559 Acc: 0.9883\n",
      "2022-01-23 05:29:20.218595\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:29:22.717279\n",
      "validation Loss: 0.0514 Acc: 0.9860\n",
      "2022-01-23 05:29:23.103712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:29:25.664398\n",
      "validation Loss: 0.0525 Acc: 0.9883\n",
      "2022-01-23 05:29:26.120717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:29:28.519025\n",
      "validation Loss: 0.0544 Acc: 0.9883\n",
      "2022-01-23 05:29:28.928909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9883\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2mu1ncn7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27245... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▅▇▆▇▇▇▇█▇██</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▄▆▇▇▇▇▆▆▆▆████████████████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.98834</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.98834</td></tr><tr><td>best_val_loss</td><td>0.04417</td></tr><tr><td>loss_train</td><td>5e-05</td></tr><tr><td>loss_validation</td><td>0.05441</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2mu1ncn7\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2mu1ncn7</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_052419-2mu1ncn7/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2mu1ncn7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2l8lhbfe\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.005_comment_None.pt'}\n",
      "2022-01-23 05:29:38.693474\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 1.4742 Acc: 0.6905\n",
      "2022-01-23 05:29:41.281668\n",
      "validation Loss: 0.5174 Acc: 0.9417\n",
      "2022-01-23 05:29:41.743309\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.3280 Acc: 0.9465\n",
      "2022-01-23 05:29:44.647821\n",
      "validation Loss: 0.2203 Acc: 0.9534\n",
      "2022-01-23 05:29:44.989800\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1611 Acc: 0.9700\n",
      "2022-01-23 05:29:47.881379\n",
      "validation Loss: 0.1523 Acc: 0.9627\n",
      "2022-01-23 05:29:48.355789\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.1050 Acc: 0.9810\n",
      "2022-01-23 05:29:51.340159\n",
      "validation Loss: 0.1280 Acc: 0.9580\n",
      "2022-01-23 05:29:51.703524\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0759 Acc: 0.9870\n",
      "2022-01-23 05:29:54.321940\n",
      "validation Loss: 0.1120 Acc: 0.9604\n",
      "2022-01-23 05:29:54.676311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0691 Acc: 0.9830\n",
      "2022-01-23 05:29:57.282611\n",
      "validation Loss: 0.1287 Acc: 0.9627\n",
      "2022-01-23 05:29:57.652699\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0504 Acc: 0.9895\n",
      "2022-01-23 05:30:00.819719\n",
      "validation Loss: 0.1075 Acc: 0.9627\n",
      "2022-01-23 05:30:01.149389\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0381 Acc: 0.9920\n",
      "2022-01-23 05:30:04.083997\n",
      "validation Loss: 0.0632 Acc: 0.9767\n",
      "2022-01-23 05:30:04.598959\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0360 Acc: 0.9925\n",
      "2022-01-23 05:30:07.745389\n",
      "validation Loss: 0.0736 Acc: 0.9697\n",
      "2022-01-23 05:30:08.127002\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0322 Acc: 0.9935\n",
      "2022-01-23 05:30:10.585153\n",
      "validation Loss: 0.1052 Acc: 0.9604\n",
      "2022-01-23 05:30:10.975187\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0434 Acc: 0.9890\n",
      "2022-01-23 05:30:13.598594\n",
      "validation Loss: 0.0710 Acc: 0.9720\n",
      "2022-01-23 05:30:13.978664\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0460 Acc: 0.9855\n",
      "2022-01-23 05:30:16.546111\n",
      "validation Loss: 0.0708 Acc: 0.9697\n",
      "2022-01-23 05:30:16.883745\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0276 Acc: 0.9930\n",
      "2022-01-23 05:30:19.378853\n",
      "validation Loss: 0.0595 Acc: 0.9814\n",
      "2022-01-23 05:30:19.751364\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0255 Acc: 0.9940\n",
      "2022-01-23 05:30:22.701386\n",
      "validation Loss: 0.0684 Acc: 0.9767\n",
      "2022-01-23 05:30:23.258810\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0144 Acc: 0.9980\n",
      "2022-01-23 05:30:25.901203\n",
      "validation Loss: 0.0575 Acc: 0.9837\n",
      "2022-01-23 05:30:26.269677\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 0.9995\n",
      "2022-01-23 05:30:29.249298\n",
      "validation Loss: 0.0482 Acc: 0.9860\n",
      "2022-01-23 05:30:29.635491\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0152 Acc: 0.9965\n",
      "2022-01-23 05:30:32.727082\n",
      "validation Loss: 0.0559 Acc: 0.9883\n",
      "2022-01-23 05:30:33.113081\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 0.9975\n",
      "2022-01-23 05:30:36.258843\n",
      "validation Loss: 0.0987 Acc: 0.9720\n",
      "2022-01-23 05:30:36.654004\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0198 Acc: 0.9955\n",
      "2022-01-23 05:30:39.372799\n",
      "validation Loss: 0.0470 Acc: 0.9883\n",
      "2022-01-23 05:30:39.848977\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9995\n",
      "2022-01-23 05:30:42.900469\n",
      "validation Loss: 0.0377 Acc: 0.9860\n",
      "2022-01-23 05:30:43.271291\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0146 Acc: 0.9960\n",
      "2022-01-23 05:30:45.897372\n",
      "validation Loss: 0.0968 Acc: 0.9790\n",
      "2022-01-23 05:30:46.280412\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0213 Acc: 0.9930\n",
      "2022-01-23 05:30:48.861575\n",
      "validation Loss: 0.0530 Acc: 0.9837\n",
      "2022-01-23 05:30:49.223192\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0146 Acc: 0.9970\n",
      "2022-01-23 05:30:51.830927\n",
      "validation Loss: 0.0560 Acc: 0.9790\n",
      "2022-01-23 05:30:52.232299\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 0.9995\n",
      "2022-01-23 05:30:54.806236\n",
      "validation Loss: 0.0289 Acc: 0.9953\n",
      "2022-01-23 05:30:55.154171\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0047 Acc: 0.9995\n",
      "2022-01-23 05:30:58.258134\n",
      "validation Loss: 0.0286 Acc: 0.9883\n",
      "2022-01-23 05:30:58.643800\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 0.9995\n",
      "2022-01-23 05:31:01.560636\n",
      "validation Loss: 0.0337 Acc: 0.9883\n",
      "2022-01-23 05:31:01.919902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0027 Acc: 1.0000\n",
      "2022-01-23 05:31:04.623629\n",
      "validation Loss: 0.0260 Acc: 0.9930\n",
      "2022-01-23 05:31:04.994390\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 05:31:07.741925\n",
      "validation Loss: 0.0274 Acc: 0.9930\n",
      "2022-01-23 05:31:08.121520\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 1.0000\n",
      "2022-01-23 05:31:10.617261\n",
      "validation Loss: 0.0295 Acc: 0.9953\n",
      "2022-01-23 05:31:11.022753\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 05:31:13.704749\n",
      "validation Loss: 0.0280 Acc: 0.9953\n",
      "2022-01-23 05:31:14.055269\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 05:31:16.987593\n",
      "validation Loss: 0.0258 Acc: 0.9953\n",
      "2022-01-23 05:31:17.576194\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 05:31:20.382678\n",
      "validation Loss: 0.0268 Acc: 0.9953\n",
      "2022-01-23 05:31:20.741277\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "2022-01-23 05:31:23.204821\n",
      "validation Loss: 0.0270 Acc: 0.9930\n",
      "2022-01-23 05:31:23.543518\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0016 Acc: 1.0000\n",
      "2022-01-23 05:31:25.983901\n",
      "validation Loss: 0.0278 Acc: 0.9930\n",
      "2022-01-23 05:31:26.536526\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 05:31:29.144721\n",
      "validation Loss: 0.0247 Acc: 0.9930\n",
      "2022-01-23 05:31:29.482494\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 05:31:32.174619\n",
      "validation Loss: 0.0228 Acc: 0.9953\n",
      "2022-01-23 05:31:32.513659\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 05:31:35.533221\n",
      "validation Loss: 0.0203 Acc: 0.9953\n",
      "2022-01-23 05:31:36.029971\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 05:31:38.833254\n",
      "validation Loss: 0.0280 Acc: 0.9953\n",
      "2022-01-23 05:31:39.265649\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 05:31:41.682567\n",
      "validation Loss: 0.0218 Acc: 0.9953\n",
      "2022-01-23 05:31:42.037232\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 05:31:44.541528\n",
      "validation Loss: 0.0286 Acc: 0.9953\n",
      "2022-01-23 05:31:44.944915\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 05:31:47.555119\n",
      "validation Loss: 0.0246 Acc: 0.9930\n",
      "2022-01-23 05:31:47.956353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "2022-01-23 05:31:50.635949\n",
      "validation Loss: 0.0239 Acc: 0.9953\n",
      "2022-01-23 05:31:51.031656\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:31:53.588400\n",
      "validation Loss: 0.0209 Acc: 0.9953\n",
      "2022-01-23 05:31:53.943228\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:31:56.480646\n",
      "validation Loss: 0.0182 Acc: 0.9953\n",
      "2022-01-23 05:31:56.883311\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:31:59.813388\n",
      "validation Loss: 0.0195 Acc: 0.9953\n",
      "2022-01-23 05:32:00.164026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:32:02.762213\n",
      "validation Loss: 0.0249 Acc: 0.9930\n",
      "2022-01-23 05:32:03.109949\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:32:05.667382\n",
      "validation Loss: 0.0196 Acc: 0.9953\n",
      "2022-01-23 05:32:06.315194\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:32:09.028537\n",
      "validation Loss: 0.0232 Acc: 0.9953\n",
      "2022-01-23 05:32:09.405629\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:32:12.191319\n",
      "validation Loss: 0.0213 Acc: 0.9953\n",
      "2022-01-23 05:32:12.585010\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:32:15.096983\n",
      "validation Loss: 0.0237 Acc: 0.9953\n",
      "2022-01-23 05:32:15.606415\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:32:18.192834\n",
      "validation Loss: 0.0234 Acc: 0.9953\n",
      "2022-01-23 05:32:18.539004\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:32:21.076901\n",
      "validation Loss: 0.0196 Acc: 0.9953\n",
      "2022-01-23 05:32:21.478780\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "2022-01-23 05:32:24.184555\n",
      "validation Loss: 0.0277 Acc: 0.9953\n",
      "2022-01-23 05:32:24.786703\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0480 Acc: 0.9835\n",
      "2022-01-23 05:32:27.311648\n",
      "validation Loss: 0.1071 Acc: 0.9744\n",
      "2022-01-23 05:32:27.701250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0502 Acc: 0.9845\n",
      "2022-01-23 05:32:29.939964\n",
      "validation Loss: 0.0790 Acc: 0.9837\n",
      "2022-01-23 05:32:30.292809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0328 Acc: 0.9910\n",
      "2022-01-23 05:32:32.549043\n",
      "validation Loss: 0.0726 Acc: 0.9744\n",
      "2022-01-23 05:32:32.980254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0086 Acc: 0.9970\n",
      "2022-01-23 05:32:35.632311\n",
      "validation Loss: 0.0341 Acc: 0.9860\n",
      "2022-01-23 05:32:36.199123\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 1.0000\n",
      "2022-01-23 05:32:38.661777\n",
      "validation Loss: 0.0378 Acc: 0.9883\n",
      "2022-01-23 05:32:39.042209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 05:32:41.525957\n",
      "validation Loss: 0.0449 Acc: 0.9883\n",
      "2022-01-23 05:32:41.888707\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "2022-01-23 05:32:44.382920\n",
      "validation Loss: 0.0364 Acc: 0.9953\n",
      "2022-01-23 05:32:44.884797\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:32:47.433312\n",
      "validation Loss: 0.0380 Acc: 0.9930\n",
      "2022-01-23 05:32:47.860566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:32:50.471382\n",
      "validation Loss: 0.0375 Acc: 0.9953\n",
      "2022-01-23 05:32:50.869246\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:32:53.358932\n",
      "validation Loss: 0.0310 Acc: 0.9953\n",
      "2022-01-23 05:32:53.896422\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:32:56.636589\n",
      "validation Loss: 0.0376 Acc: 0.9953\n",
      "2022-01-23 05:32:57.097886\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:32:59.740844\n",
      "validation Loss: 0.0331 Acc: 0.9953\n",
      "2022-01-23 05:33:00.193262\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:33:02.868803\n",
      "validation Loss: 0.0351 Acc: 0.9953\n",
      "2022-01-23 05:33:03.344504\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:33:06.026261\n",
      "validation Loss: 0.0341 Acc: 0.9953\n",
      "2022-01-23 05:33:06.491870\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:33:09.162131\n",
      "validation Loss: 0.0321 Acc: 0.9953\n",
      "2022-01-23 05:33:09.535368\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:12.057592\n",
      "validation Loss: 0.0364 Acc: 0.9953\n",
      "2022-01-23 05:33:12.427982\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:15.003727\n",
      "validation Loss: 0.0337 Acc: 0.9953\n",
      "2022-01-23 05:33:15.346930\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:17.883706\n",
      "validation Loss: 0.0304 Acc: 0.9953\n",
      "2022-01-23 05:33:18.260177\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:20.828510\n",
      "validation Loss: 0.0322 Acc: 0.9953\n",
      "2022-01-23 05:33:21.250043\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:23.742975\n",
      "validation Loss: 0.0334 Acc: 0.9953\n",
      "2022-01-23 05:33:24.087584\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:26.498880\n",
      "validation Loss: 0.0306 Acc: 0.9953\n",
      "2022-01-23 05:33:26.860602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "2022-01-23 05:33:29.317288\n",
      "validation Loss: 0.0298 Acc: 0.9953\n",
      "2022-01-23 05:33:29.761767\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:32.207054\n",
      "validation Loss: 0.0304 Acc: 0.9953\n",
      "2022-01-23 05:33:32.599711\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:35.083226\n",
      "validation Loss: 0.0289 Acc: 0.9953\n",
      "2022-01-23 05:33:35.441421\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:37.888000\n",
      "validation Loss: 0.0280 Acc: 0.9953\n",
      "2022-01-23 05:33:38.246340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:40.701851\n",
      "validation Loss: 0.0292 Acc: 0.9953\n",
      "2022-01-23 05:33:41.203195\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:43.919029\n",
      "validation Loss: 0.0299 Acc: 0.9953\n",
      "2022-01-23 05:33:44.264765\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:46.726991\n",
      "validation Loss: 0.0316 Acc: 0.9953\n",
      "2022-01-23 05:33:47.183495\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:49.780541\n",
      "validation Loss: 0.0291 Acc: 0.9953\n",
      "2022-01-23 05:33:50.171586\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:52.585788\n",
      "validation Loss: 0.0310 Acc: 0.9953\n",
      "2022-01-23 05:33:53.002041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:55.410770\n",
      "validation Loss: 0.0276 Acc: 0.9953\n",
      "2022-01-23 05:33:55.913115\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:33:58.537155\n",
      "validation Loss: 0.0300 Acc: 0.9953\n",
      "2022-01-23 05:33:59.028852\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:34:01.656018\n",
      "validation Loss: 0.0296 Acc: 0.9953\n",
      "2022-01-23 05:34:02.047799\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:34:04.573465\n",
      "validation Loss: 0.0274 Acc: 0.9953\n",
      "2022-01-23 05:34:04.986692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:34:06.576618\n",
      "validation Loss: 0.0272 Acc: 0.9953\n",
      "2022-01-23 05:34:06.939005\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:34:09.455097\n",
      "validation Loss: 0.0324 Acc: 0.9953\n",
      "2022-01-23 05:34:09.795108\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:34:12.378374\n",
      "validation Loss: 0.0318 Acc: 0.9953\n",
      "2022-01-23 05:34:12.723089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:15.261789\n",
      "validation Loss: 0.0292 Acc: 0.9953\n",
      "2022-01-23 05:34:15.906103\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:18.576582\n",
      "validation Loss: 0.0309 Acc: 0.9953\n",
      "2022-01-23 05:34:18.969258\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:21.571999\n",
      "validation Loss: 0.0248 Acc: 0.9953\n",
      "2022-01-23 05:34:21.975914\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:24.522719\n",
      "validation Loss: 0.0250 Acc: 0.9953\n",
      "2022-01-23 05:34:24.871995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:27.469864\n",
      "validation Loss: 0.0285 Acc: 0.9953\n",
      "2022-01-23 05:34:27.817109\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:30.338654\n",
      "validation Loss: 0.0297 Acc: 0.9953\n",
      "2022-01-23 05:34:30.706318\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:33.195009\n",
      "validation Loss: 0.0268 Acc: 0.9953\n",
      "2022-01-23 05:34:33.624134\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:35.109932\n",
      "validation Loss: 0.0248 Acc: 0.9953\n",
      "2022-01-23 05:34:35.477155\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:38.067912\n",
      "validation Loss: 0.0265 Acc: 0.9953\n",
      "2022-01-23 05:34:38.434608\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.005\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:34:41.002552\n",
      "validation Loss: 0.0281 Acc: 0.9953\n",
      "2022-01-23 05:34:41.347624\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9953\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2l8lhbfe) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19264... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▄▆▇▇▇▇█▆▇██████</td></tr><tr><td>accuracy_train</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▄▄▆▅▆▇▅▆▆▇██████████▅▅▇████████████████</td></tr><tr><td>loss_train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▃▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99534</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.99534</td></tr><tr><td>best_val_loss</td><td>0.01819</td></tr><tr><td>loss_train</td><td>0.00011</td></tr><tr><td>loss_validation</td><td>0.02814</td></tr><tr><td>lr</td><td>0.005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2l8lhbfe\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/2l8lhbfe</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_052929-2l8lhbfe/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2l8lhbfe). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1mqlxz5j\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.001_comment_None.pt'}\n",
      "2022-01-23 05:34:51.400554\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 2.5778 Acc: 0.3940\n",
      "2022-01-23 05:34:53.968058\n",
      "validation Loss: 2.0511 Acc: 0.7622\n",
      "2022-01-23 05:34:54.314592\n",
      "Accuracy of the network on the 429 test samples: 77.62237762237763\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.6351 Acc: 0.8075\n",
      "2022-01-23 05:34:57.447375\n",
      "validation Loss: 1.2464 Acc: 0.8625\n",
      "2022-01-23 05:34:57.794267\n",
      "Accuracy of the network on the 429 test samples: 88.81118881118881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 1.0203 Acc: 0.9020\n",
      "2022-01-23 05:35:00.720240\n",
      "validation Loss: 0.8007 Acc: 0.9207\n",
      "2022-01-23 05:35:01.059848\n",
      "Accuracy of the network on the 429 test samples: 91.37529137529138\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.6790 Acc: 0.9255\n",
      "2022-01-23 05:35:03.898980\n",
      "validation Loss: 0.5567 Acc: 0.9441\n",
      "2022-01-23 05:35:04.248145\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.4870 Acc: 0.9390\n",
      "2022-01-23 05:35:07.233136\n",
      "validation Loss: 0.4136 Acc: 0.9534\n",
      "2022-01-23 05:35:07.605555\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.3705 Acc: 0.9500\n",
      "2022-01-23 05:35:10.626831\n",
      "validation Loss: 0.3284 Acc: 0.9604\n",
      "2022-01-23 05:35:10.988648\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2967 Acc: 0.9640\n",
      "2022-01-23 05:35:14.140384\n",
      "validation Loss: 0.2641 Acc: 0.9650\n",
      "2022-01-23 05:35:14.475038\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2402 Acc: 0.9665\n",
      "2022-01-23 05:35:17.366017\n",
      "validation Loss: 0.2259 Acc: 0.9627\n",
      "2022-01-23 05:35:17.830342\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.2036 Acc: 0.9710\n",
      "2022-01-23 05:35:20.453348\n",
      "validation Loss: 0.1909 Acc: 0.9674\n",
      "2022-01-23 05:35:20.815724\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1748 Acc: 0.9780\n",
      "2022-01-23 05:35:23.753349\n",
      "validation Loss: 0.1717 Acc: 0.9674\n",
      "2022-01-23 05:35:24.153917\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1510 Acc: 0.9795\n",
      "2022-01-23 05:35:27.212989\n",
      "validation Loss: 0.1467 Acc: 0.9744\n",
      "2022-01-23 05:35:27.590774\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1337 Acc: 0.9830\n",
      "2022-01-23 05:35:30.658077\n",
      "validation Loss: 0.1317 Acc: 0.9790\n",
      "2022-01-23 05:35:31.043391\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1169 Acc: 0.9865\n",
      "2022-01-23 05:35:33.967137\n",
      "validation Loss: 0.1255 Acc: 0.9837\n",
      "2022-01-23 05:35:34.392176\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.1070 Acc: 0.9870\n",
      "2022-01-23 05:35:37.160299\n",
      "validation Loss: 0.1113 Acc: 0.9790\n",
      "2022-01-23 05:35:37.516552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0943 Acc: 0.9865\n",
      "2022-01-23 05:35:40.012625\n",
      "validation Loss: 0.0986 Acc: 0.9837\n",
      "2022-01-23 05:35:40.429145\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0847 Acc: 0.9890\n",
      "2022-01-23 05:35:43.278100\n",
      "validation Loss: 0.0929 Acc: 0.9837\n",
      "2022-01-23 05:35:43.713502\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0766 Acc: 0.9905\n",
      "2022-01-23 05:35:46.561754\n",
      "validation Loss: 0.0852 Acc: 0.9883\n",
      "2022-01-23 05:35:46.911742\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0731 Acc: 0.9915\n",
      "2022-01-23 05:35:49.719232\n",
      "validation Loss: 0.0819 Acc: 0.9837\n",
      "2022-01-23 05:35:50.196649\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0665 Acc: 0.9905\n",
      "2022-01-23 05:35:52.808920\n",
      "validation Loss: 0.0786 Acc: 0.9814\n",
      "2022-01-23 05:35:53.192733\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0608 Acc: 0.9910\n",
      "2022-01-23 05:35:55.730828\n",
      "validation Loss: 0.0703 Acc: 0.9907\n",
      "2022-01-23 05:35:56.197865\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0563 Acc: 0.9920\n",
      "2022-01-23 05:35:59.339465\n",
      "validation Loss: 0.0674 Acc: 0.9860\n",
      "2022-01-23 05:35:59.874162\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0515 Acc: 0.9935\n",
      "2022-01-23 05:36:02.367468\n",
      "validation Loss: 0.0631 Acc: 0.9860\n",
      "2022-01-23 05:36:02.743925\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0499 Acc: 0.9935\n",
      "2022-01-23 05:36:05.137034\n",
      "validation Loss: 0.0591 Acc: 0.9883\n",
      "2022-01-23 05:36:05.562370\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0457 Acc: 0.9940\n",
      "2022-01-23 05:36:08.066325\n",
      "validation Loss: 0.0579 Acc: 0.9907\n",
      "2022-01-23 05:36:08.460011\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0403 Acc: 0.9960\n",
      "2022-01-23 05:36:11.502873\n",
      "validation Loss: 0.0553 Acc: 0.9883\n",
      "2022-01-23 05:36:11.857146\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0378 Acc: 0.9950\n",
      "2022-01-23 05:36:14.285754\n",
      "validation Loss: 0.0530 Acc: 0.9883\n",
      "2022-01-23 05:36:14.620209\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0383 Acc: 0.9940\n",
      "2022-01-23 05:36:17.130140\n",
      "validation Loss: 0.0814 Acc: 0.9720\n",
      "2022-01-23 05:36:17.488781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0338 Acc: 0.9955\n",
      "2022-01-23 05:36:19.982839\n",
      "validation Loss: 0.0492 Acc: 0.9883\n",
      "2022-01-23 05:36:20.521179\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0312 Acc: 0.9970\n",
      "2022-01-23 05:36:23.056348\n",
      "validation Loss: 0.0448 Acc: 0.9907\n",
      "2022-01-23 05:36:23.416009\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0301 Acc: 0.9960\n",
      "2022-01-23 05:36:26.399313\n",
      "validation Loss: 0.0479 Acc: 0.9860\n",
      "2022-01-23 05:36:26.756800\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0304 Acc: 0.9955\n",
      "2022-01-23 05:36:29.428628\n",
      "validation Loss: 0.0557 Acc: 0.9837\n",
      "2022-01-23 05:36:30.039674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0275 Acc: 0.9975\n",
      "2022-01-23 05:36:32.645649\n",
      "validation Loss: 0.0428 Acc: 0.9907\n",
      "2022-01-23 05:36:32.997515\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0245 Acc: 0.9965\n",
      "2022-01-23 05:36:35.890034\n",
      "validation Loss: 0.0382 Acc: 0.9930\n",
      "2022-01-23 05:36:36.280023\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0226 Acc: 0.9985\n",
      "2022-01-23 05:36:39.359166\n",
      "validation Loss: 0.0370 Acc: 0.9930\n",
      "2022-01-23 05:36:39.697413\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0221 Acc: 0.9985\n",
      "2022-01-23 05:36:42.633932\n",
      "validation Loss: 0.0405 Acc: 0.9930\n",
      "2022-01-23 05:36:43.036772\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0212 Acc: 0.9985\n",
      "2022-01-23 05:36:45.586434\n",
      "validation Loss: 0.0337 Acc: 0.9930\n",
      "2022-01-23 05:36:46.011798\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0185 Acc: 0.9980\n",
      "2022-01-23 05:36:48.881965\n",
      "validation Loss: 0.0365 Acc: 0.9930\n",
      "2022-01-23 05:36:49.256353\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0197 Acc: 0.9985\n",
      "2022-01-23 05:36:51.842474\n",
      "validation Loss: 0.0397 Acc: 0.9930\n",
      "2022-01-23 05:36:52.206771\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0180 Acc: 0.9995\n",
      "2022-01-23 05:36:54.937673\n",
      "validation Loss: 0.0360 Acc: 0.9953\n",
      "2022-01-23 05:36:55.311230\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0163 Acc: 0.9985\n",
      "2022-01-23 05:36:58.202593\n",
      "validation Loss: 0.0327 Acc: 0.9977\n",
      "2022-01-23 05:36:58.534684\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0162 Acc: 0.9995\n",
      "2022-01-23 05:37:01.477624\n",
      "validation Loss: 0.0296 Acc: 0.9930\n",
      "2022-01-23 05:37:01.916787\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0134 Acc: 0.9995\n",
      "2022-01-23 05:37:04.392573\n",
      "validation Loss: 0.0343 Acc: 0.9907\n",
      "2022-01-23 05:37:04.745657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0142 Acc: 1.0000\n",
      "2022-01-23 05:37:07.294094\n",
      "validation Loss: 0.0321 Acc: 0.9930\n",
      "2022-01-23 05:37:07.637292\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0130 Acc: 0.9990\n",
      "2022-01-23 05:37:10.138103\n",
      "validation Loss: 0.0261 Acc: 0.9953\n",
      "2022-01-23 05:37:10.509309\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0128 Acc: 0.9995\n",
      "2022-01-23 05:37:13.146658\n",
      "validation Loss: 0.0274 Acc: 0.9953\n",
      "2022-01-23 05:37:13.504103\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0133 Acc: 0.9995\n",
      "2022-01-23 05:37:16.020854\n",
      "validation Loss: 0.0311 Acc: 0.9930\n",
      "2022-01-23 05:37:16.369787\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0119 Acc: 0.9995\n",
      "2022-01-23 05:37:18.825744\n",
      "validation Loss: 0.0277 Acc: 0.9930\n",
      "2022-01-23 05:37:19.175697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0130 Acc: 0.9980\n",
      "2022-01-23 05:37:21.642750\n",
      "validation Loss: 0.0293 Acc: 0.9953\n",
      "2022-01-23 05:37:21.977952\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0108 Acc: 0.9985\n",
      "2022-01-23 05:37:24.516111\n",
      "validation Loss: 0.0295 Acc: 0.9930\n",
      "2022-01-23 05:37:24.873601\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0116 Acc: 0.9990\n",
      "2022-01-23 05:37:27.392166\n",
      "validation Loss: 0.0295 Acc: 0.9930\n",
      "2022-01-23 05:37:27.768712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 0.9995\n",
      "2022-01-23 05:37:29.257696\n",
      "validation Loss: 0.0212 Acc: 0.9977\n",
      "2022-01-23 05:37:29.630106\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0131 Acc: 0.9985\n",
      "2022-01-23 05:37:32.475858\n",
      "validation Loss: 0.0240 Acc: 0.9953\n",
      "2022-01-23 05:37:32.884700\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 1.0000\n",
      "2022-01-23 05:37:35.477373\n",
      "validation Loss: 0.0246 Acc: 0.9953\n",
      "2022-01-23 05:37:36.048479\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 1.0000\n",
      "2022-01-23 05:37:38.710599\n",
      "validation Loss: 0.0283 Acc: 0.9953\n",
      "2022-01-23 05:37:39.062959\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 1.0000\n",
      "2022-01-23 05:37:41.710026\n",
      "validation Loss: 0.0213 Acc: 0.9977\n",
      "2022-01-23 05:37:42.067411\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0072 Acc: 1.0000\n",
      "2022-01-23 05:37:44.524364\n",
      "validation Loss: 0.0269 Acc: 0.9930\n",
      "2022-01-23 05:37:44.908764\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0074 Acc: 0.9995\n",
      "2022-01-23 05:37:47.402442\n",
      "validation Loss: 0.0218 Acc: 0.9977\n",
      "2022-01-23 05:37:47.786925\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0071 Acc: 0.9995\n",
      "2022-01-23 05:37:50.642554\n",
      "validation Loss: 0.0364 Acc: 0.9883\n",
      "2022-01-23 05:37:51.032859\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0062 Acc: 1.0000\n",
      "2022-01-23 05:37:53.738093\n",
      "validation Loss: 0.0367 Acc: 0.9860\n",
      "2022-01-23 05:37:54.205567\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 0.9990\n",
      "2022-01-23 05:37:56.907898\n",
      "validation Loss: 0.0180 Acc: 0.9977\n",
      "2022-01-23 05:37:57.278626\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0106 Acc: 0.9970\n",
      "2022-01-23 05:38:00.052689\n",
      "validation Loss: 0.0216 Acc: 0.9953\n",
      "2022-01-23 05:38:00.406098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0069 Acc: 0.9995\n",
      "2022-01-23 05:38:02.920700\n",
      "validation Loss: 0.0171 Acc: 0.9977\n",
      "2022-01-23 05:38:03.297385\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 1.0000\n",
      "2022-01-23 05:38:06.177990\n",
      "validation Loss: 0.0267 Acc: 0.9953\n",
      "2022-01-23 05:38:06.532566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 1.0000\n",
      "2022-01-23 05:38:09.123584\n",
      "validation Loss: 0.0192 Acc: 0.9953\n",
      "2022-01-23 05:38:09.521014\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 1.0000\n",
      "2022-01-23 05:38:12.121658\n",
      "validation Loss: 0.0165 Acc: 0.9977\n",
      "2022-01-23 05:38:12.483218\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 1.0000\n",
      "2022-01-23 05:38:15.458915\n",
      "validation Loss: 0.0200 Acc: 0.9953\n",
      "2022-01-23 05:38:15.860661\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0043 Acc: 1.0000\n",
      "2022-01-23 05:38:18.356025\n",
      "validation Loss: 0.0360 Acc: 0.9907\n",
      "2022-01-23 05:38:18.745809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 0.9995\n",
      "2022-01-23 05:38:21.197904\n",
      "validation Loss: 0.0165 Acc: 0.9977\n",
      "2022-01-23 05:38:21.619281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "2022-01-23 05:38:24.064734\n",
      "validation Loss: 0.0181 Acc: 0.9953\n",
      "2022-01-23 05:38:24.417818\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0039 Acc: 1.0000\n",
      "2022-01-23 05:38:26.867286\n",
      "validation Loss: 0.0182 Acc: 0.9977\n",
      "2022-01-23 05:38:27.213068\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0099 Acc: 0.9985\n",
      "2022-01-23 05:38:29.674084\n",
      "validation Loss: 0.0264 Acc: 0.9953\n",
      "2022-01-23 05:38:30.020833\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 0.9990\n",
      "2022-01-23 05:38:32.484325\n",
      "validation Loss: 0.0322 Acc: 0.9930\n",
      "2022-01-23 05:38:33.030898\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0038 Acc: 1.0000\n",
      "2022-01-23 05:38:35.629560\n",
      "validation Loss: 0.0184 Acc: 0.9977\n",
      "2022-01-23 05:38:36.005707\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0034 Acc: 1.0000\n",
      "2022-01-23 05:38:38.554179\n",
      "validation Loss: 0.0195 Acc: 0.9953\n",
      "2022-01-23 05:38:38.927515\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0031 Acc: 1.0000\n",
      "2022-01-23 05:38:41.382656\n",
      "validation Loss: 0.0181 Acc: 0.9977\n",
      "2022-01-23 05:38:41.720894\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0029 Acc: 1.0000\n",
      "2022-01-23 05:38:44.280366\n",
      "validation Loss: 0.0229 Acc: 0.9953\n",
      "2022-01-23 05:38:44.722420\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0028 Acc: 1.0000\n",
      "2022-01-23 05:38:47.198916\n",
      "validation Loss: 0.0188 Acc: 0.9953\n",
      "2022-01-23 05:38:47.556710\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0029 Acc: 1.0000\n",
      "2022-01-23 05:38:50.153629\n",
      "validation Loss: 0.0136 Acc: 0.9977\n",
      "2022-01-23 05:38:50.488445\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0026 Acc: 1.0000\n",
      "2022-01-23 05:38:53.408577\n",
      "validation Loss: 0.0146 Acc: 0.9977\n",
      "2022-01-23 05:38:53.941124\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 05:38:56.550345\n",
      "validation Loss: 0.0175 Acc: 0.9953\n",
      "2022-01-23 05:38:56.918995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0025 Acc: 1.0000\n",
      "2022-01-23 05:38:59.424349\n",
      "validation Loss: 0.0196 Acc: 0.9953\n",
      "2022-01-23 05:38:59.785564\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "2022-01-23 05:39:02.300298\n",
      "validation Loss: 0.0165 Acc: 0.9977\n",
      "2022-01-23 05:39:02.670651\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 05:39:05.221921\n",
      "validation Loss: 0.0220 Acc: 0.9953\n",
      "2022-01-23 05:39:05.668422\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 1.0000\n",
      "2022-01-23 05:39:08.386004\n",
      "validation Loss: 0.0153 Acc: 0.9977\n",
      "2022-01-23 05:39:08.774402\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 05:39:11.284256\n",
      "validation Loss: 0.0211 Acc: 0.9953\n",
      "2022-01-23 05:39:11.709463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0020 Acc: 1.0000\n",
      "2022-01-23 05:39:14.301566\n",
      "validation Loss: 0.0169 Acc: 0.9953\n",
      "2022-01-23 05:39:14.852458\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "2022-01-23 05:39:17.361720\n",
      "validation Loss: 0.0157 Acc: 0.9977\n",
      "2022-01-23 05:39:17.719152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 0.9995\n",
      "2022-01-23 05:39:20.230973\n",
      "validation Loss: 0.0283 Acc: 0.9907\n",
      "2022-01-23 05:39:20.578712\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0028 Acc: 1.0000\n",
      "2022-01-23 05:39:23.129793\n",
      "validation Loss: 0.0148 Acc: 0.9953\n",
      "2022-01-23 05:39:23.529132\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0194 Acc: 0.9935\n",
      "2022-01-23 05:39:26.119407\n",
      "validation Loss: 0.0618 Acc: 0.9790\n",
      "2022-01-23 05:39:26.588199\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9955\n",
      "2022-01-23 05:39:29.140871\n",
      "validation Loss: 0.0236 Acc: 0.9930\n",
      "2022-01-23 05:39:29.500190\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "2022-01-23 05:39:31.955574\n",
      "validation Loss: 0.0156 Acc: 0.9977\n",
      "2022-01-23 05:39:32.311944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0021 Acc: 1.0000\n",
      "2022-01-23 05:39:34.827153\n",
      "validation Loss: 0.0156 Acc: 0.9977\n",
      "2022-01-23 05:39:35.188726\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0017 Acc: 1.0000\n",
      "2022-01-23 05:39:37.705458\n",
      "validation Loss: 0.0166 Acc: 0.9977\n",
      "2022-01-23 05:39:38.251021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "2022-01-23 05:39:40.778728\n",
      "validation Loss: 0.0179 Acc: 0.9953\n",
      "2022-01-23 05:39:41.138588\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "2022-01-23 05:39:43.640639\n",
      "validation Loss: 0.0165 Acc: 0.9977\n",
      "2022-01-23 05:39:43.994152\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 05:39:46.509426\n",
      "validation Loss: 0.0158 Acc: 0.9977\n",
      "2022-01-23 05:39:46.880315\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "2022-01-23 05:39:49.645203\n",
      "validation Loss: 0.0167 Acc: 0.9977\n",
      "2022-01-23 05:39:50.071781\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "2022-01-23 05:39:52.515179\n",
      "validation Loss: 0.0160 Acc: 0.9977\n",
      "2022-01-23 05:39:52.865416\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.001\n",
      "------------------------------\n",
      "train Loss: 0.0011 Acc: 1.0000\n",
      "2022-01-23 05:39:55.296725\n",
      "validation Loss: 0.0149 Acc: 0.9977\n",
      "2022-01-23 05:39:55.657995\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9977\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1mqlxz5j) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12020... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▅▆▆▇▇▇█▇█▇█████████████████</td></tr><tr><td>accuracy_train</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99767</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99767</td></tr><tr><td>best_val_loss</td><td>0.01357</td></tr><tr><td>loss_train</td><td>0.00114</td></tr><tr><td>loss_validation</td><td>0.01487</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1mqlxz5j\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1mqlxz5j</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_053441-1mqlxz5j/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1mqlxz5j). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1sn11tr9\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0005, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0005_comment_None.pt'}\n",
      "2022-01-23 05:40:05.053919\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.7527 Acc: 0.3150\n",
      "2022-01-23 05:40:07.673626\n",
      "validation Loss: 2.4927 Acc: 0.5711\n",
      "2022-01-23 05:40:08.051391\n",
      "Accuracy of the network on the 429 test samples: 56.87645687645687\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 2.2360 Acc: 0.6585\n",
      "2022-01-23 05:40:10.872298\n",
      "validation Loss: 1.9788 Acc: 0.7529\n",
      "2022-01-23 05:40:11.259346\n",
      "Accuracy of the network on the 429 test samples: 76.92307692307693\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.7520 Acc: 0.8190\n",
      "2022-01-23 05:40:14.242100\n",
      "validation Loss: 1.5272 Acc: 0.8555\n",
      "2022-01-23 05:40:14.696565\n",
      "Accuracy of the network on the 429 test samples: 87.41258741258741\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.3512 Acc: 0.8830\n",
      "2022-01-23 05:40:17.538370\n",
      "validation Loss: 1.1729 Acc: 0.8928\n",
      "2022-01-23 05:40:17.892877\n",
      "Accuracy of the network on the 429 test samples: 90.67599067599068\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 1.0452 Acc: 0.9155\n",
      "2022-01-23 05:40:20.765502\n",
      "validation Loss: 0.9094 Acc: 0.9207\n",
      "2022-01-23 05:40:21.250438\n",
      "Accuracy of the network on the 429 test samples: 93.24009324009323\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.8174 Acc: 0.9405\n",
      "2022-01-23 05:40:24.113934\n",
      "validation Loss: 0.7148 Acc: 0.9441\n",
      "2022-01-23 05:40:24.483749\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.6508 Acc: 0.9500\n",
      "2022-01-23 05:40:27.323841\n",
      "validation Loss: 0.5754 Acc: 0.9510\n",
      "2022-01-23 05:40:27.669236\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.5291 Acc: 0.9575\n",
      "2022-01-23 05:40:29.618319\n",
      "validation Loss: 0.4756 Acc: 0.9557\n",
      "2022-01-23 05:40:29.956611\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.4387 Acc: 0.9655\n",
      "2022-01-23 05:40:33.200166\n",
      "validation Loss: 0.3954 Acc: 0.9674\n",
      "2022-01-23 05:40:33.567928\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3698 Acc: 0.9670\n",
      "2022-01-23 05:40:36.375265\n",
      "validation Loss: 0.3381 Acc: 0.9674\n",
      "2022-01-23 05:40:36.712022\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.3159 Acc: 0.9740\n",
      "2022-01-23 05:40:39.593120\n",
      "validation Loss: 0.2887 Acc: 0.9744\n",
      "2022-01-23 05:40:39.950225\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2728 Acc: 0.9780\n",
      "2022-01-23 05:40:42.916566\n",
      "validation Loss: 0.2561 Acc: 0.9744\n",
      "2022-01-23 05:40:43.265961\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2390 Acc: 0.9785\n",
      "2022-01-23 05:40:46.104437\n",
      "validation Loss: 0.2297 Acc: 0.9767\n",
      "2022-01-23 05:40:46.458534\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.2132 Acc: 0.9800\n",
      "2022-01-23 05:40:48.491360\n",
      "validation Loss: 0.2040 Acc: 0.9790\n",
      "2022-01-23 05:40:48.865032\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1898 Acc: 0.9810\n",
      "2022-01-23 05:40:51.966983\n",
      "validation Loss: 0.1840 Acc: 0.9790\n",
      "2022-01-23 05:40:52.409411\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1702 Acc: 0.9830\n",
      "2022-01-23 05:40:55.389456\n",
      "validation Loss: 0.1688 Acc: 0.9790\n",
      "2022-01-23 05:40:55.805390\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1547 Acc: 0.9840\n",
      "2022-01-23 05:40:58.704601\n",
      "validation Loss: 0.1529 Acc: 0.9814\n",
      "2022-01-23 05:40:59.072820\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1426 Acc: 0.9845\n",
      "2022-01-23 05:41:02.081248\n",
      "validation Loss: 0.1446 Acc: 0.9790\n",
      "2022-01-23 05:41:02.437463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1302 Acc: 0.9855\n",
      "2022-01-23 05:41:04.986692\n",
      "validation Loss: 0.1339 Acc: 0.9814\n",
      "2022-01-23 05:41:05.326241\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1199 Acc: 0.9870\n",
      "2022-01-23 05:41:08.314652\n",
      "validation Loss: 0.1235 Acc: 0.9860\n",
      "2022-01-23 05:41:08.821017\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1124 Acc: 0.9865\n",
      "2022-01-23 05:41:12.003987\n",
      "validation Loss: 0.1173 Acc: 0.9790\n",
      "2022-01-23 05:41:12.377550\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.1049 Acc: 0.9875\n",
      "2022-01-23 05:41:14.916350\n",
      "validation Loss: 0.1143 Acc: 0.9814\n",
      "2022-01-23 05:41:15.294813\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0973 Acc: 0.9875\n",
      "2022-01-23 05:41:17.784470\n",
      "validation Loss: 0.1050 Acc: 0.9837\n",
      "2022-01-23 05:41:18.135717\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0906 Acc: 0.9890\n",
      "2022-01-23 05:41:20.659639\n",
      "validation Loss: 0.1018 Acc: 0.9814\n",
      "2022-01-23 05:41:21.220571\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0858 Acc: 0.9885\n",
      "2022-01-23 05:41:23.785053\n",
      "validation Loss: 0.0940 Acc: 0.9837\n",
      "2022-01-23 05:41:24.164915\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0806 Acc: 0.9885\n",
      "2022-01-23 05:41:26.728595\n",
      "validation Loss: 0.0904 Acc: 0.9883\n",
      "2022-01-23 05:41:27.095352\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0764 Acc: 0.9885\n",
      "2022-01-23 05:41:29.022923\n",
      "validation Loss: 0.0843 Acc: 0.9883\n",
      "2022-01-23 05:41:29.369471\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0715 Acc: 0.9900\n",
      "2022-01-23 05:41:32.322636\n",
      "validation Loss: 0.0806 Acc: 0.9883\n",
      "2022-01-23 05:41:32.733652\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0673 Acc: 0.9895\n",
      "2022-01-23 05:41:36.019101\n",
      "validation Loss: 0.0810 Acc: 0.9883\n",
      "2022-01-23 05:41:36.382645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0636 Acc: 0.9925\n",
      "2022-01-23 05:41:38.915591\n",
      "validation Loss: 0.0746 Acc: 0.9883\n",
      "2022-01-23 05:41:39.267282\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0598 Acc: 0.9920\n",
      "2022-01-23 05:41:42.473627\n",
      "validation Loss: 0.0733 Acc: 0.9860\n",
      "2022-01-23 05:41:42.840345\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0580 Acc: 0.9905\n",
      "2022-01-23 05:41:45.719612\n",
      "validation Loss: 0.0713 Acc: 0.9883\n",
      "2022-01-23 05:41:46.067711\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0542 Acc: 0.9920\n",
      "2022-01-23 05:41:49.125523\n",
      "validation Loss: 0.0686 Acc: 0.9907\n",
      "2022-01-23 05:41:49.524716\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0524 Acc: 0.9910\n",
      "2022-01-23 05:41:52.725230\n",
      "validation Loss: 0.0689 Acc: 0.9883\n",
      "2022-01-23 05:41:53.077080\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0510 Acc: 0.9930\n",
      "2022-01-23 05:41:55.557339\n",
      "validation Loss: 0.0648 Acc: 0.9883\n",
      "2022-01-23 05:41:55.934191\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0471 Acc: 0.9935\n",
      "2022-01-23 05:41:58.478366\n",
      "validation Loss: 0.0669 Acc: 0.9860\n",
      "2022-01-23 05:41:58.842868\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0450 Acc: 0.9935\n",
      "2022-01-23 05:42:01.349473\n",
      "validation Loss: 0.0579 Acc: 0.9883\n",
      "2022-01-23 05:42:01.918565\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0433 Acc: 0.9935\n",
      "2022-01-23 05:42:04.419387\n",
      "validation Loss: 0.0574 Acc: 0.9883\n",
      "2022-01-23 05:42:04.781327\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0405 Acc: 0.9950\n",
      "2022-01-23 05:42:07.411919\n",
      "validation Loss: 0.0569 Acc: 0.9953\n",
      "2022-01-23 05:42:07.772099\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0389 Acc: 0.9945\n",
      "2022-01-23 05:42:10.771732\n",
      "validation Loss: 0.0568 Acc: 0.9883\n",
      "2022-01-23 05:42:11.293957\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0384 Acc: 0.9960\n",
      "2022-01-23 05:42:13.925021\n",
      "validation Loss: 0.0523 Acc: 0.9953\n",
      "2022-01-23 05:42:14.284000\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0356 Acc: 0.9980\n",
      "2022-01-23 05:42:17.311338\n",
      "validation Loss: 0.0508 Acc: 0.9907\n",
      "2022-01-23 05:42:17.674288\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0337 Acc: 0.9960\n",
      "2022-01-23 05:42:20.127312\n",
      "validation Loss: 0.0510 Acc: 0.9907\n",
      "2022-01-23 05:42:20.508533\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0315 Acc: 0.9960\n",
      "2022-01-23 05:42:23.262485\n",
      "validation Loss: 0.0519 Acc: 0.9930\n",
      "2022-01-23 05:42:23.699372\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0325 Acc: 0.9960\n",
      "2022-01-23 05:42:26.219619\n",
      "validation Loss: 0.0477 Acc: 0.9953\n",
      "2022-01-23 05:42:26.624695\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0303 Acc: 0.9960\n",
      "2022-01-23 05:42:29.470296\n",
      "validation Loss: 0.0480 Acc: 0.9930\n",
      "2022-01-23 05:42:29.837782\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0281 Acc: 0.9970\n",
      "2022-01-23 05:42:32.273122\n",
      "validation Loss: 0.0440 Acc: 0.9953\n",
      "2022-01-23 05:42:32.627184\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0280 Acc: 0.9975\n",
      "2022-01-23 05:42:35.619070\n",
      "validation Loss: 0.0427 Acc: 0.9953\n",
      "2022-01-23 05:42:36.024999\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0259 Acc: 0.9965\n",
      "2022-01-23 05:42:39.025643\n",
      "validation Loss: 0.0530 Acc: 0.9907\n",
      "2022-01-23 05:42:39.380229\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0252 Acc: 0.9985\n",
      "2022-01-23 05:42:41.913433\n",
      "validation Loss: 0.0425 Acc: 0.9953\n",
      "2022-01-23 05:42:42.245024\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0243 Acc: 0.9970\n",
      "2022-01-23 05:42:45.187184\n",
      "validation Loss: 0.0439 Acc: 0.9953\n",
      "2022-01-23 05:42:45.526268\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0244 Acc: 0.9970\n",
      "2022-01-23 05:42:47.955803\n",
      "validation Loss: 0.0387 Acc: 0.9930\n",
      "2022-01-23 05:42:48.326442\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0227 Acc: 0.9985\n",
      "2022-01-23 05:42:50.987611\n",
      "validation Loss: 0.0395 Acc: 0.9953\n",
      "2022-01-23 05:42:51.372724\n",
      "Accuracy of the network on the 429 test samples: 98.83449883449883\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0220 Acc: 0.9970\n",
      "2022-01-23 05:42:54.265290\n",
      "validation Loss: 0.0492 Acc: 0.9907\n",
      "2022-01-23 05:42:54.674536\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0203 Acc: 0.9990\n",
      "2022-01-23 05:42:57.369076\n",
      "validation Loss: 0.0401 Acc: 0.9953\n",
      "2022-01-23 05:42:57.710680\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0219 Acc: 0.9985\n",
      "2022-01-23 05:43:00.154976\n",
      "validation Loss: 0.0378 Acc: 0.9930\n",
      "2022-01-23 05:43:00.520902\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0192 Acc: 0.9985\n",
      "2022-01-23 05:43:03.051738\n",
      "validation Loss: 0.0362 Acc: 0.9930\n",
      "2022-01-23 05:43:03.402311\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0180 Acc: 0.9985\n",
      "2022-01-23 05:43:05.961281\n",
      "validation Loss: 0.0353 Acc: 0.9930\n",
      "2022-01-23 05:43:06.302508\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0189 Acc: 0.9985\n",
      "2022-01-23 05:43:08.898398\n",
      "validation Loss: 0.0406 Acc: 0.9930\n",
      "2022-01-23 05:43:09.290468\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0175 Acc: 0.9990\n",
      "2022-01-23 05:43:10.665222\n",
      "validation Loss: 0.0414 Acc: 0.9953\n",
      "2022-01-23 05:43:11.020548\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0165 Acc: 0.9990\n",
      "2022-01-23 05:43:13.523286\n",
      "validation Loss: 0.0336 Acc: 0.9953\n",
      "2022-01-23 05:43:13.974831\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0157 Acc: 0.9980\n",
      "2022-01-23 05:43:16.954887\n",
      "validation Loss: 0.0366 Acc: 0.9953\n",
      "2022-01-23 05:43:17.358041\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0148 Acc: 0.9990\n",
      "2022-01-23 05:43:19.690843\n",
      "validation Loss: 0.0405 Acc: 0.9930\n",
      "2022-01-23 05:43:20.028406\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0153 Acc: 0.9990\n",
      "2022-01-23 05:43:22.504433\n",
      "validation Loss: 0.0446 Acc: 0.9907\n",
      "2022-01-23 05:43:22.867721\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0151 Acc: 0.9985\n",
      "2022-01-23 05:43:25.640081\n",
      "validation Loss: 0.0344 Acc: 0.9953\n",
      "2022-01-23 05:43:25.995025\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0139 Acc: 0.9995\n",
      "2022-01-23 05:43:28.527417\n",
      "validation Loss: 0.0421 Acc: 0.9907\n",
      "2022-01-23 05:43:28.905652\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0154 Acc: 0.9985\n",
      "2022-01-23 05:43:30.447365\n",
      "validation Loss: 0.0348 Acc: 0.9953\n",
      "2022-01-23 05:43:30.800302\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0130 Acc: 0.9990\n",
      "2022-01-23 05:43:33.597413\n",
      "validation Loss: 0.0369 Acc: 0.9953\n",
      "2022-01-23 05:43:33.941629\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0116 Acc: 0.9995\n",
      "2022-01-23 05:43:35.485479\n",
      "validation Loss: 0.0305 Acc: 0.9953\n",
      "2022-01-23 05:43:35.877632\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0121 Acc: 0.9990\n",
      "2022-01-23 05:43:38.753031\n",
      "validation Loss: 0.0304 Acc: 0.9953\n",
      "2022-01-23 05:43:39.095930\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0123 Acc: 1.0000\n",
      "2022-01-23 05:43:41.993989\n",
      "validation Loss: 0.0293 Acc: 0.9953\n",
      "2022-01-23 05:43:42.614991\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0125 Acc: 0.9980\n",
      "2022-01-23 05:43:45.511354\n",
      "validation Loss: 0.0325 Acc: 0.9930\n",
      "2022-01-23 05:43:45.889685\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0101 Acc: 0.9995\n",
      "2022-01-23 05:43:48.560794\n",
      "validation Loss: 0.0406 Acc: 0.9930\n",
      "2022-01-23 05:43:48.975486\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0114 Acc: 0.9985\n",
      "2022-01-23 05:43:51.556606\n",
      "validation Loss: 0.0300 Acc: 0.9953\n",
      "2022-01-23 05:43:52.097038\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0095 Acc: 1.0000\n",
      "2022-01-23 05:43:54.624317\n",
      "validation Loss: 0.0410 Acc: 0.9930\n",
      "2022-01-23 05:43:54.960821\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0102 Acc: 1.0000\n",
      "2022-01-23 05:43:57.570091\n",
      "validation Loss: 0.0265 Acc: 0.9953\n",
      "2022-01-23 05:43:57.903073\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0117 Acc: 0.9985\n",
      "2022-01-23 05:44:00.816236\n",
      "validation Loss: 0.0290 Acc: 0.9953\n",
      "2022-01-23 05:44:01.281374\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0092 Acc: 0.9995\n",
      "2022-01-23 05:44:03.361262\n",
      "validation Loss: 0.0336 Acc: 0.9953\n",
      "2022-01-23 05:44:03.920180\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0094 Acc: 0.9995\n",
      "2022-01-23 05:44:06.428463\n",
      "validation Loss: 0.0294 Acc: 0.9930\n",
      "2022-01-23 05:44:06.780246\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0081 Acc: 1.0000\n",
      "2022-01-23 05:44:09.582760\n",
      "validation Loss: 0.0341 Acc: 0.9953\n",
      "2022-01-23 05:44:09.955448\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 1.0000\n",
      "2022-01-23 05:44:12.453765\n",
      "validation Loss: 0.0288 Acc: 0.9930\n",
      "2022-01-23 05:44:12.837619\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0078 Acc: 1.0000\n",
      "2022-01-23 05:44:15.415691\n",
      "validation Loss: 0.0315 Acc: 0.9953\n",
      "2022-01-23 05:44:16.075286\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0083 Acc: 1.0000\n",
      "2022-01-23 05:44:18.733740\n",
      "validation Loss: 0.0263 Acc: 0.9930\n",
      "2022-01-23 05:44:19.193777\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0080 Acc: 0.9995\n",
      "2022-01-23 05:44:21.830311\n",
      "validation Loss: 0.0264 Acc: 0.9953\n",
      "2022-01-23 05:44:22.182992\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 1.0000\n",
      "2022-01-23 05:44:25.145962\n",
      "validation Loss: 0.0271 Acc: 0.9953\n",
      "2022-01-23 05:44:25.618071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0076 Acc: 0.9995\n",
      "2022-01-23 05:44:28.164342\n",
      "validation Loss: 0.0348 Acc: 0.9930\n",
      "2022-01-23 05:44:28.494697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0068 Acc: 1.0000\n",
      "2022-01-23 05:44:31.015846\n",
      "validation Loss: 0.0266 Acc: 0.9930\n",
      "2022-01-23 05:44:31.386589\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0060 Acc: 1.0000\n",
      "2022-01-23 05:44:33.908211\n",
      "validation Loss: 0.0343 Acc: 0.9953\n",
      "2022-01-23 05:44:34.275426\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0070 Acc: 1.0000\n",
      "2022-01-23 05:44:36.977716\n",
      "validation Loss: 0.0402 Acc: 0.9930\n",
      "2022-01-23 05:44:37.414684\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0065 Acc: 0.9995\n",
      "2022-01-23 05:44:39.982056\n",
      "validation Loss: 0.0325 Acc: 0.9930\n",
      "2022-01-23 05:44:40.328795\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0073 Acc: 0.9990\n",
      "2022-01-23 05:44:42.903559\n",
      "validation Loss: 0.0367 Acc: 0.9907\n",
      "2022-01-23 05:44:43.276130\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0072 Acc: 0.9995\n",
      "2022-01-23 05:44:45.949797\n",
      "validation Loss: 0.0328 Acc: 0.9930\n",
      "2022-01-23 05:44:46.372663\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0055 Acc: 1.0000\n",
      "2022-01-23 05:44:48.822680\n",
      "validation Loss: 0.0258 Acc: 0.9930\n",
      "2022-01-23 05:44:49.183467\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0048 Acc: 1.0000\n",
      "2022-01-23 05:44:51.620296\n",
      "validation Loss: 0.0295 Acc: 0.9930\n",
      "2022-01-23 05:44:52.089674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 05:44:54.566053\n",
      "validation Loss: 0.0265 Acc: 0.9953\n",
      "2022-01-23 05:44:54.920186\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0049 Acc: 1.0000\n",
      "2022-01-23 05:44:57.379724\n",
      "validation Loss: 0.0255 Acc: 0.9953\n",
      "2022-01-23 05:44:57.830668\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0051 Acc: 1.0000\n",
      "2022-01-23 05:45:00.655323\n",
      "validation Loss: 0.0268 Acc: 0.9930\n",
      "2022-01-23 05:45:01.017634\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0057 Acc: 0.9990\n",
      "2022-01-23 05:45:03.698054\n",
      "validation Loss: 0.0270 Acc: 0.9953\n",
      "2022-01-23 05:45:04.084030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0042 Acc: 1.0000\n",
      "2022-01-23 05:45:05.415907\n",
      "validation Loss: 0.0220 Acc: 0.9953\n",
      "2022-01-23 05:45:05.787337\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0005\n",
      "------------------------------\n",
      "train Loss: 0.0040 Acc: 1.0000\n",
      "2022-01-23 05:45:08.731376\n",
      "validation Loss: 0.0208 Acc: 0.9977\n",
      "2022-01-23 05:45:09.084643\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9977\n",
      "Accuracy of the network on the 429 test samples: 99.06759906759906\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1sn11tr9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9155... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▄▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>loss_train</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99068</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.99767</td></tr><tr><td>best_test_accuracy</td><td>0.99068</td></tr><tr><td>best_val_accuracy</td><td>0.99767</td></tr><tr><td>best_val_loss</td><td>0.02083</td></tr><tr><td>loss_train</td><td>0.00399</td></tr><tr><td>loss_validation</td><td>0.02083</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/1sn11tr9\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/1sn11tr9</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_053956-1sn11tr9/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1sn11tr9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3v27bph8\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.0001, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'orthogonal', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_orthogonal_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.0001_comment_None.pt'}\n",
      "2022-01-23 05:45:19.747966\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): orthogonal()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.9632 Acc: 0.0805\n",
      "2022-01-23 05:45:22.185561\n",
      "validation Loss: 2.9272 Acc: 0.1235\n",
      "2022-01-23 05:45:22.533852\n",
      "Accuracy of the network on the 429 test samples: 13.51981351981352\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.8863 Acc: 0.1615\n",
      "2022-01-23 05:45:25.374648\n",
      "validation Loss: 2.8455 Acc: 0.2005\n",
      "2022-01-23 05:45:25.780233\n",
      "Accuracy of the network on the 429 test samples: 20.51282051282051\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.7954 Acc: 0.2920\n",
      "2022-01-23 05:45:28.777388\n",
      "validation Loss: 2.7469 Acc: 0.3730\n",
      "2022-01-23 05:45:29.139853\n",
      "Accuracy of the network on the 429 test samples: 37.995337995338\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.6889 Acc: 0.4340\n",
      "2022-01-23 05:45:32.232955\n",
      "validation Loss: 2.6335 Acc: 0.4872\n",
      "2022-01-23 05:45:32.597942\n",
      "Accuracy of the network on the 429 test samples: 47.31934731934732\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.5705 Acc: 0.5240\n",
      "2022-01-23 05:45:35.761717\n",
      "validation Loss: 2.5102 Acc: 0.5594\n",
      "2022-01-23 05:45:36.098404\n",
      "Accuracy of the network on the 429 test samples: 56.41025641025641\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.4450 Acc: 0.5810\n",
      "2022-01-23 05:45:38.995418\n",
      "validation Loss: 2.3820 Acc: 0.6224\n",
      "2022-01-23 05:45:39.405563\n",
      "Accuracy of the network on the 429 test samples: 62.7039627039627\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.3181 Acc: 0.6560\n",
      "2022-01-23 05:45:42.340145\n",
      "validation Loss: 2.2545 Acc: 0.6923\n",
      "2022-01-23 05:45:42.720460\n",
      "Accuracy of the network on the 429 test samples: 68.53146853146853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.1930 Acc: 0.7295\n",
      "2022-01-23 05:45:45.320593\n",
      "validation Loss: 2.1304 Acc: 0.7506\n",
      "2022-01-23 05:45:45.674198\n",
      "Accuracy of the network on the 429 test samples: 74.35897435897436\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 2.0726 Acc: 0.7850\n",
      "2022-01-23 05:45:48.603446\n",
      "validation Loss: 2.0115 Acc: 0.7949\n",
      "2022-01-23 05:45:48.995661\n",
      "Accuracy of the network on the 429 test samples: 80.65268065268066\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.9579 Acc: 0.8245\n",
      "2022-01-23 05:45:52.054951\n",
      "validation Loss: 1.8992 Acc: 0.8228\n",
      "2022-01-23 05:45:52.398178\n",
      "Accuracy of the network on the 429 test samples: 84.61538461538461\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.8496 Acc: 0.8505\n",
      "2022-01-23 05:45:55.209644\n",
      "validation Loss: 1.7937 Acc: 0.8485\n",
      "2022-01-23 05:45:55.549174\n",
      "Accuracy of the network on the 429 test samples: 86.7132867132867\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.7478 Acc: 0.8690\n",
      "2022-01-23 05:45:58.487925\n",
      "validation Loss: 1.6935 Acc: 0.8648\n",
      "2022-01-23 05:45:58.862008\n",
      "Accuracy of the network on the 429 test samples: 88.11188811188812\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.6518 Acc: 0.8825\n",
      "2022-01-23 05:46:01.782784\n",
      "validation Loss: 1.5992 Acc: 0.8834\n",
      "2022-01-23 05:46:02.152629\n",
      "Accuracy of the network on the 429 test samples: 89.04428904428904\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.5615 Acc: 0.8890\n",
      "2022-01-23 05:46:05.115884\n",
      "validation Loss: 1.5119 Acc: 0.8881\n",
      "2022-01-23 05:46:05.461561\n",
      "Accuracy of the network on the 429 test samples: 89.5104895104895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.4771 Acc: 0.9010\n",
      "2022-01-23 05:46:08.579961\n",
      "validation Loss: 1.4292 Acc: 0.8974\n",
      "2022-01-23 05:46:08.949746\n",
      "Accuracy of the network on the 429 test samples: 89.5104895104895\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3981 Acc: 0.9055\n",
      "2022-01-23 05:46:11.920400\n",
      "validation Loss: 1.3510 Acc: 0.9021\n",
      "2022-01-23 05:46:12.321667\n",
      "Accuracy of the network on the 429 test samples: 90.20979020979021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.3234 Acc: 0.9125\n",
      "2022-01-23 05:46:15.476557\n",
      "validation Loss: 1.2796 Acc: 0.9091\n",
      "2022-01-23 05:46:15.822007\n",
      "Accuracy of the network on the 429 test samples: 90.9090909090909\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.2538 Acc: 0.9160\n",
      "2022-01-23 05:46:18.703870\n",
      "validation Loss: 1.2099 Acc: 0.9207\n",
      "2022-01-23 05:46:19.073963\n",
      "Accuracy of the network on the 429 test samples: 91.6083916083916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1882 Acc: 0.9190\n",
      "2022-01-23 05:46:22.044195\n",
      "validation Loss: 1.1464 Acc: 0.9301\n",
      "2022-01-23 05:46:22.641382\n",
      "Accuracy of the network on the 429 test samples: 91.6083916083916\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.1267 Acc: 0.9245\n",
      "2022-01-23 05:46:25.512012\n",
      "validation Loss: 1.0860 Acc: 0.9371\n",
      "2022-01-23 05:46:25.877808\n",
      "Accuracy of the network on the 429 test samples: 92.54079254079254\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0689 Acc: 0.9265\n",
      "2022-01-23 05:46:28.723642\n",
      "validation Loss: 1.0293 Acc: 0.9371\n",
      "2022-01-23 05:46:29.370678\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 1.0149 Acc: 0.9325\n",
      "2022-01-23 05:46:32.513915\n",
      "validation Loss: 0.9769 Acc: 0.9394\n",
      "2022-01-23 05:46:32.857475\n",
      "Accuracy of the network on the 429 test samples: 93.7062937062937\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9641 Acc: 0.9330\n",
      "2022-01-23 05:46:34.762712\n",
      "validation Loss: 0.9273 Acc: 0.9417\n",
      "2022-01-23 05:46:35.125818\n",
      "Accuracy of the network on the 429 test samples: 93.93939393939394\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.9163 Acc: 0.9350\n",
      "2022-01-23 05:46:38.184042\n",
      "validation Loss: 0.8820 Acc: 0.9394\n",
      "2022-01-23 05:46:38.586905\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8718 Acc: 0.9385\n",
      "2022-01-23 05:46:41.035782\n",
      "validation Loss: 0.8383 Acc: 0.9417\n",
      "2022-01-23 05:46:41.386009\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.8299 Acc: 0.9395\n",
      "2022-01-23 05:46:44.216620\n",
      "validation Loss: 0.7971 Acc: 0.9441\n",
      "2022-01-23 05:46:44.580809\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7905 Acc: 0.9415\n",
      "2022-01-23 05:46:47.530934\n",
      "validation Loss: 0.7585 Acc: 0.9510\n",
      "2022-01-23 05:46:47.921001\n",
      "Accuracy of the network on the 429 test samples: 94.4055944055944\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7535 Acc: 0.9420\n",
      "2022-01-23 05:46:51.020171\n",
      "validation Loss: 0.7232 Acc: 0.9510\n",
      "2022-01-23 05:46:51.382999\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.7188 Acc: 0.9425\n",
      "2022-01-23 05:46:54.299407\n",
      "validation Loss: 0.6907 Acc: 0.9487\n",
      "2022-01-23 05:46:54.688022\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6859 Acc: 0.9440\n",
      "2022-01-23 05:46:57.214424\n",
      "validation Loss: 0.6577 Acc: 0.9557\n",
      "2022-01-23 05:46:57.559612\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6558 Acc: 0.9455\n",
      "2022-01-23 05:47:00.401889\n",
      "validation Loss: 0.6288 Acc: 0.9510\n",
      "2022-01-23 05:47:00.819911\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6269 Acc: 0.9480\n",
      "2022-01-23 05:47:03.309358\n",
      "validation Loss: 0.6018 Acc: 0.9580\n",
      "2022-01-23 05:47:03.809989\n",
      "Accuracy of the network on the 429 test samples: 95.33799533799534\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.6001 Acc: 0.9510\n",
      "2022-01-23 05:47:06.639630\n",
      "validation Loss: 0.5753 Acc: 0.9580\n",
      "2022-01-23 05:47:07.009582\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5748 Acc: 0.9515\n",
      "2022-01-23 05:47:09.945227\n",
      "validation Loss: 0.5513 Acc: 0.9604\n",
      "2022-01-23 05:47:10.343622\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5504 Acc: 0.9530\n",
      "2022-01-23 05:47:13.568903\n",
      "validation Loss: 0.5284 Acc: 0.9627\n",
      "2022-01-23 05:47:13.961067\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5283 Acc: 0.9550\n",
      "2022-01-23 05:47:16.877113\n",
      "validation Loss: 0.5070 Acc: 0.9604\n",
      "2022-01-23 05:47:17.225039\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.5070 Acc: 0.9565\n",
      "2022-01-23 05:47:19.843448\n",
      "validation Loss: 0.4868 Acc: 0.9604\n",
      "2022-01-23 05:47:20.226447\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4871 Acc: 0.9570\n",
      "2022-01-23 05:47:22.632624\n",
      "validation Loss: 0.4673 Acc: 0.9604\n",
      "2022-01-23 05:47:22.986809\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4680 Acc: 0.9565\n",
      "2022-01-23 05:47:25.353724\n",
      "validation Loss: 0.4498 Acc: 0.9604\n",
      "2022-01-23 05:47:25.709497\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4503 Acc: 0.9590\n",
      "2022-01-23 05:47:28.162283\n",
      "validation Loss: 0.4334 Acc: 0.9627\n",
      "2022-01-23 05:47:28.527834\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4333 Acc: 0.9610\n",
      "2022-01-23 05:47:31.774590\n",
      "validation Loss: 0.4168 Acc: 0.9627\n",
      "2022-01-23 05:47:32.155712\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4172 Acc: 0.9610\n",
      "2022-01-23 05:47:34.896845\n",
      "validation Loss: 0.4021 Acc: 0.9627\n",
      "2022-01-23 05:47:35.235785\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.4025 Acc: 0.9605\n",
      "2022-01-23 05:47:38.020903\n",
      "validation Loss: 0.3878 Acc: 0.9627\n",
      "2022-01-23 05:47:38.491167\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3880 Acc: 0.9650\n",
      "2022-01-23 05:47:41.372118\n",
      "validation Loss: 0.3742 Acc: 0.9627\n",
      "2022-01-23 05:47:41.734951\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3743 Acc: 0.9645\n",
      "2022-01-23 05:47:44.607105\n",
      "validation Loss: 0.3614 Acc: 0.9627\n",
      "2022-01-23 05:47:44.939834\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3614 Acc: 0.9640\n",
      "2022-01-23 05:47:48.073548\n",
      "validation Loss: 0.3496 Acc: 0.9627\n",
      "2022-01-23 05:47:48.529927\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3491 Acc: 0.9655\n",
      "2022-01-23 05:47:51.483385\n",
      "validation Loss: 0.3382 Acc: 0.9650\n",
      "2022-01-23 05:47:51.838385\n",
      "Accuracy of the network on the 429 test samples: 96.27039627039628\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3375 Acc: 0.9670\n",
      "2022-01-23 05:47:54.940438\n",
      "validation Loss: 0.3273 Acc: 0.9627\n",
      "2022-01-23 05:47:55.315692\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3265 Acc: 0.9680\n",
      "2022-01-23 05:47:57.814202\n",
      "validation Loss: 0.3170 Acc: 0.9627\n",
      "2022-01-23 05:47:58.176762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3158 Acc: 0.9675\n",
      "2022-01-23 05:48:00.712984\n",
      "validation Loss: 0.3078 Acc: 0.9650\n",
      "2022-01-23 05:48:01.070746\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.3057 Acc: 0.9685\n",
      "2022-01-23 05:48:04.240635\n",
      "validation Loss: 0.2975 Acc: 0.9650\n",
      "2022-01-23 05:48:04.662935\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2963 Acc: 0.9685\n",
      "2022-01-23 05:48:07.577439\n",
      "validation Loss: 0.2888 Acc: 0.9650\n",
      "2022-01-23 05:48:07.952665\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2874 Acc: 0.9685\n",
      "2022-01-23 05:48:10.864047\n",
      "validation Loss: 0.2809 Acc: 0.9650\n",
      "2022-01-23 05:48:11.211765\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2786 Acc: 0.9710\n",
      "2022-01-23 05:48:14.421034\n",
      "validation Loss: 0.2729 Acc: 0.9650\n",
      "2022-01-23 05:48:14.763253\n",
      "Accuracy of the network on the 429 test samples: 96.5034965034965\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2704 Acc: 0.9710\n",
      "2022-01-23 05:48:17.727954\n",
      "validation Loss: 0.2650 Acc: 0.9650\n",
      "2022-01-23 05:48:18.102837\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2622 Acc: 0.9705\n",
      "2022-01-23 05:48:21.092919\n",
      "validation Loss: 0.2580 Acc: 0.9650\n",
      "2022-01-23 05:48:21.436165\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2545 Acc: 0.9725\n",
      "2022-01-23 05:48:24.315519\n",
      "validation Loss: 0.2509 Acc: 0.9650\n",
      "2022-01-23 05:48:24.692966\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2471 Acc: 0.9740\n",
      "2022-01-23 05:48:27.685036\n",
      "validation Loss: 0.2446 Acc: 0.9674\n",
      "2022-01-23 05:48:28.048509\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2404 Acc: 0.9725\n",
      "2022-01-23 05:48:30.973550\n",
      "validation Loss: 0.2390 Acc: 0.9697\n",
      "2022-01-23 05:48:31.396974\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2339 Acc: 0.9750\n",
      "2022-01-23 05:48:34.389597\n",
      "validation Loss: 0.2319 Acc: 0.9674\n",
      "2022-01-23 05:48:34.780390\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2271 Acc: 0.9750\n",
      "2022-01-23 05:48:37.306921\n",
      "validation Loss: 0.2258 Acc: 0.9674\n",
      "2022-01-23 05:48:37.659602\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2208 Acc: 0.9750\n",
      "2022-01-23 05:48:40.281003\n",
      "validation Loss: 0.2207 Acc: 0.9697\n",
      "2022-01-23 05:48:40.662899\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2150 Acc: 0.9750\n",
      "2022-01-23 05:48:43.542622\n",
      "validation Loss: 0.2149 Acc: 0.9697\n",
      "2022-01-23 05:48:44.044416\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2095 Acc: 0.9750\n",
      "2022-01-23 05:48:46.929245\n",
      "validation Loss: 0.2098 Acc: 0.9697\n",
      "2022-01-23 05:48:47.293842\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.2040 Acc: 0.9775\n",
      "2022-01-23 05:48:50.193584\n",
      "validation Loss: 0.2056 Acc: 0.9697\n",
      "2022-01-23 05:48:50.557928\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1987 Acc: 0.9760\n",
      "2022-01-23 05:48:53.620453\n",
      "validation Loss: 0.2003 Acc: 0.9697\n",
      "2022-01-23 05:48:53.989602\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1934 Acc: 0.9770\n",
      "2022-01-23 05:48:56.995347\n",
      "validation Loss: 0.1961 Acc: 0.9720\n",
      "2022-01-23 05:48:57.329840\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1887 Acc: 0.9790\n",
      "2022-01-23 05:49:00.355123\n",
      "validation Loss: 0.1919 Acc: 0.9697\n",
      "2022-01-23 05:49:00.734337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1841 Acc: 0.9785\n",
      "2022-01-23 05:49:02.103709\n",
      "validation Loss: 0.1879 Acc: 0.9697\n",
      "2022-01-23 05:49:02.660844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1793 Acc: 0.9780\n",
      "2022-01-23 05:49:05.149107\n",
      "validation Loss: 0.1830 Acc: 0.9720\n",
      "2022-01-23 05:49:05.585708\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1749 Acc: 0.9785\n",
      "2022-01-23 05:49:08.553658\n",
      "validation Loss: 0.1795 Acc: 0.9697\n",
      "2022-01-23 05:49:08.884025\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1708 Acc: 0.9795\n",
      "2022-01-23 05:49:11.345723\n",
      "validation Loss: 0.1754 Acc: 0.9720\n",
      "2022-01-23 05:49:11.692612\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1668 Acc: 0.9795\n",
      "2022-01-23 05:49:14.741023\n",
      "validation Loss: 0.1726 Acc: 0.9720\n",
      "2022-01-23 05:49:15.147216\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1629 Acc: 0.9810\n",
      "2022-01-23 05:49:18.189873\n",
      "validation Loss: 0.1686 Acc: 0.9720\n",
      "2022-01-23 05:49:18.542479\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1592 Acc: 0.9805\n",
      "2022-01-23 05:49:21.473929\n",
      "validation Loss: 0.1655 Acc: 0.9744\n",
      "2022-01-23 05:49:21.842057\n",
      "Accuracy of the network on the 429 test samples: 96.96969696969697\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1553 Acc: 0.9805\n",
      "2022-01-23 05:49:24.642509\n",
      "validation Loss: 0.1626 Acc: 0.9744\n",
      "2022-01-23 05:49:24.998891\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1518 Acc: 0.9805\n",
      "2022-01-23 05:49:28.082783\n",
      "validation Loss: 0.1589 Acc: 0.9767\n",
      "2022-01-23 05:49:28.512161\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1484 Acc: 0.9815\n",
      "2022-01-23 05:49:31.473034\n",
      "validation Loss: 0.1563 Acc: 0.9744\n",
      "2022-01-23 05:49:31.876222\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1450 Acc: 0.9815\n",
      "2022-01-23 05:49:34.321944\n",
      "validation Loss: 0.1524 Acc: 0.9744\n",
      "2022-01-23 05:49:34.685343\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1419 Acc: 0.9825\n",
      "2022-01-23 05:49:37.235304\n",
      "validation Loss: 0.1507 Acc: 0.9744\n",
      "2022-01-23 05:49:37.690698\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1388 Acc: 0.9820\n",
      "2022-01-23 05:49:40.177172\n",
      "validation Loss: 0.1476 Acc: 0.9767\n",
      "2022-01-23 05:49:40.579427\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1355 Acc: 0.9825\n",
      "2022-01-23 05:49:43.430761\n",
      "validation Loss: 0.1452 Acc: 0.9767\n",
      "2022-01-23 05:49:43.777634\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1328 Acc: 0.9830\n",
      "2022-01-23 05:49:46.820102\n",
      "validation Loss: 0.1421 Acc: 0.9767\n",
      "2022-01-23 05:49:47.182089\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1301 Acc: 0.9830\n",
      "2022-01-23 05:49:50.209335\n",
      "validation Loss: 0.1399 Acc: 0.9767\n",
      "2022-01-23 05:49:50.587502\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1272 Acc: 0.9840\n",
      "2022-01-23 05:49:53.518713\n",
      "validation Loss: 0.1386 Acc: 0.9744\n",
      "2022-01-23 05:49:54.019645\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1246 Acc: 0.9845\n",
      "2022-01-23 05:49:56.548529\n",
      "validation Loss: 0.1359 Acc: 0.9744\n",
      "2022-01-23 05:49:56.917888\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1221 Acc: 0.9830\n",
      "2022-01-23 05:49:59.471348\n",
      "validation Loss: 0.1335 Acc: 0.9767\n",
      "2022-01-23 05:49:59.820978\n",
      "Accuracy of the network on the 429 test samples: 97.43589743589743\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1198 Acc: 0.9840\n",
      "2022-01-23 05:50:02.709767\n",
      "validation Loss: 0.1308 Acc: 0.9767\n",
      "2022-01-23 05:50:03.263345\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1171 Acc: 0.9850\n",
      "2022-01-23 05:50:06.465560\n",
      "validation Loss: 0.1282 Acc: 0.9767\n",
      "2022-01-23 05:50:06.812672\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1151 Acc: 0.9845\n",
      "2022-01-23 05:50:09.734412\n",
      "validation Loss: 0.1276 Acc: 0.9720\n",
      "2022-01-23 05:50:10.327753\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1122 Acc: 0.9855\n",
      "2022-01-23 05:50:12.816422\n",
      "validation Loss: 0.1244 Acc: 0.9767\n",
      "2022-01-23 05:50:13.183454\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1103 Acc: 0.9850\n",
      "2022-01-23 05:50:16.007399\n",
      "validation Loss: 0.1225 Acc: 0.9767\n",
      "2022-01-23 05:50:16.352957\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1083 Acc: 0.9845\n",
      "2022-01-23 05:50:19.349003\n",
      "validation Loss: 0.1214 Acc: 0.9767\n",
      "2022-01-23 05:50:19.837575\n",
      "Accuracy of the network on the 429 test samples: 97.66899766899768\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1059 Acc: 0.9850\n",
      "2022-01-23 05:50:22.908292\n",
      "validation Loss: 0.1196 Acc: 0.9767\n",
      "2022-01-23 05:50:23.239831\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1039 Acc: 0.9850\n",
      "2022-01-23 05:50:26.166227\n",
      "validation Loss: 0.1182 Acc: 0.9767\n",
      "2022-01-23 05:50:26.683136\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.1018 Acc: 0.9865\n",
      "2022-01-23 05:50:29.576580\n",
      "validation Loss: 0.1155 Acc: 0.9790\n",
      "2022-01-23 05:50:29.974012\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0999 Acc: 0.9865\n",
      "2022-01-23 05:50:32.902296\n",
      "validation Loss: 0.1142 Acc: 0.9790\n",
      "2022-01-23 05:50:33.528936\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0981 Acc: 0.9865\n",
      "2022-01-23 05:50:36.604749\n",
      "validation Loss: 0.1119 Acc: 0.9790\n",
      "2022-01-23 05:50:37.007871\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0960 Acc: 0.9870\n",
      "2022-01-23 05:50:40.069722\n",
      "validation Loss: 0.1111 Acc: 0.9790\n",
      "2022-01-23 05:50:40.544630\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.0001\n",
      "------------------------------\n",
      "train Loss: 0.0942 Acc: 0.9870\n",
      "2022-01-23 05:50:43.467916\n",
      "validation Loss: 0.1098 Acc: 0.9790\n",
      "2022-01-23 05:50:43.868802\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9790\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3v27bph8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11421... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▃▅▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>accuracy_train</td><td>▁▃▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▃▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>loss_train</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.97902</td></tr><tr><td>accuracy_train</td><td>0.987</td></tr><tr><td>accuracy_validation</td><td>0.97902</td></tr><tr><td>best_test_accuracy</td><td>0.97902</td></tr><tr><td>best_val_accuracy</td><td>0.97902</td></tr><tr><td>best_val_loss</td><td>0.10983</td></tr><tr><td>loss_train</td><td>0.09419</td></tr><tr><td>loss_validation</td><td>0.10983</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/3v27bph8\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/3v27bph8</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_054509-3v27bph8/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3v27bph8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/b6npx7v0\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.02, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.02_comment_None.pt'}\n",
      "2022-01-23 05:50:53.517011\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 1.3506 Acc: 0.5925\n",
      "2022-01-23 05:50:56.125348\n",
      "validation Loss: 0.5013 Acc: 0.8485\n",
      "2022-01-23 05:50:56.496778\n",
      "Accuracy of the network on the 429 test samples: 81.58508158508158\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.4537 Acc: 0.8550\n",
      "2022-01-23 05:50:59.438096\n",
      "validation Loss: 0.2657 Acc: 0.9184\n",
      "2022-01-23 05:50:59.789675\n",
      "Accuracy of the network on the 429 test samples: 91.84149184149184\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.3333 Acc: 0.8970\n",
      "2022-01-23 05:51:02.764286\n",
      "validation Loss: 0.2458 Acc: 0.9301\n",
      "2022-01-23 05:51:03.340860\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1985 Acc: 0.9370\n",
      "2022-01-23 05:51:06.327668\n",
      "validation Loss: 0.1378 Acc: 0.9580\n",
      "2022-01-23 05:51:06.686687\n",
      "Accuracy of the network on the 429 test samples: 95.57109557109557\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1459 Acc: 0.9500\n",
      "2022-01-23 05:51:09.885329\n",
      "validation Loss: 0.2367 Acc: 0.9371\n",
      "2022-01-23 05:51:10.434259\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1337 Acc: 0.9570\n",
      "2022-01-23 05:51:13.128482\n",
      "validation Loss: 0.1702 Acc: 0.9510\n",
      "2022-01-23 05:51:13.515173\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1767 Acc: 0.9500\n",
      "2022-01-23 05:51:16.108791\n",
      "validation Loss: 0.2011 Acc: 0.9417\n",
      "2022-01-23 05:51:16.538098\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1659 Acc: 0.9490\n",
      "2022-01-23 05:51:19.004605\n",
      "validation Loss: 0.1356 Acc: 0.9580\n",
      "2022-01-23 05:51:19.361649\n",
      "Accuracy of the network on the 429 test samples: 95.8041958041958\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0656 Acc: 0.9790\n",
      "2022-01-23 05:51:22.599158\n",
      "validation Loss: 0.0650 Acc: 0.9697\n",
      "2022-01-23 05:51:22.962945\n",
      "Accuracy of the network on the 429 test samples: 96.03729603729604\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0419 Acc: 0.9850\n",
      "2022-01-23 05:51:25.991317\n",
      "validation Loss: 0.0619 Acc: 0.9837\n",
      "2022-01-23 05:51:26.427933\n",
      "Accuracy of the network on the 429 test samples: 98.13519813519814\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0711 Acc: 0.9805\n",
      "2022-01-23 05:51:29.616460\n",
      "validation Loss: 0.2614 Acc: 0.9207\n",
      "2022-01-23 05:51:29.975642\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0970 Acc: 0.9650\n",
      "2022-01-23 05:51:32.439840\n",
      "validation Loss: 0.1341 Acc: 0.9557\n",
      "2022-01-23 05:51:32.846459\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0601 Acc: 0.9790\n",
      "2022-01-23 05:51:35.439144\n",
      "validation Loss: 0.1123 Acc: 0.9580\n",
      "2022-01-23 05:51:35.803312\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0530 Acc: 0.9845\n",
      "2022-01-23 05:51:38.241533\n",
      "validation Loss: 0.1121 Acc: 0.9720\n",
      "2022-01-23 05:51:38.580020\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1051 Acc: 0.9740\n",
      "2022-01-23 05:51:40.944257\n",
      "validation Loss: 0.1506 Acc: 0.9674\n",
      "2022-01-23 05:51:41.271563\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1549 Acc: 0.9470\n",
      "2022-01-23 05:51:43.747579\n",
      "validation Loss: 0.2127 Acc: 0.9510\n",
      "2022-01-23 05:51:44.127381\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1000 Acc: 0.9700\n",
      "2022-01-23 05:51:46.643273\n",
      "validation Loss: 0.1445 Acc: 0.9604\n",
      "2022-01-23 05:51:47.077981\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0555 Acc: 0.9835\n",
      "2022-01-23 05:51:49.492765\n",
      "validation Loss: 0.0943 Acc: 0.9744\n",
      "2022-01-23 05:51:49.884463\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0411 Acc: 0.9870\n",
      "2022-01-23 05:51:52.244191\n",
      "validation Loss: 0.0619 Acc: 0.9767\n",
      "2022-01-23 05:51:52.635165\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0374 Acc: 0.9860\n",
      "2022-01-23 05:51:55.089547\n",
      "validation Loss: 0.0973 Acc: 0.9744\n",
      "2022-01-23 05:51:55.512755\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0596 Acc: 0.9800\n",
      "2022-01-23 05:51:58.001201\n",
      "validation Loss: 0.0900 Acc: 0.9627\n",
      "2022-01-23 05:51:58.382776\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0898 Acc: 0.9715\n",
      "2022-01-23 05:52:00.820161\n",
      "validation Loss: 0.1015 Acc: 0.9674\n",
      "2022-01-23 05:52:01.193631\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0878 Acc: 0.9710\n",
      "2022-01-23 05:52:03.721187\n",
      "validation Loss: 0.1339 Acc: 0.9650\n",
      "2022-01-23 05:52:04.098841\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0741 Acc: 0.9775\n",
      "2022-01-23 05:52:06.569973\n",
      "validation Loss: 0.0597 Acc: 0.9860\n",
      "2022-01-23 05:52:06.973213\n",
      "Accuracy of the network on the 429 test samples: 98.6013986013986\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0376 Acc: 0.9890\n",
      "2022-01-23 05:52:09.975838\n",
      "validation Loss: 0.0592 Acc: 0.9790\n",
      "2022-01-23 05:52:10.343316\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0194 Acc: 0.9930\n",
      "2022-01-23 05:52:12.878896\n",
      "validation Loss: 0.0703 Acc: 0.9790\n",
      "2022-01-23 05:52:13.264267\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0248 Acc: 0.9925\n",
      "2022-01-23 05:52:16.202231\n",
      "validation Loss: 0.0891 Acc: 0.9720\n",
      "2022-01-23 05:52:16.594677\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0279 Acc: 0.9890\n",
      "2022-01-23 05:52:19.111074\n",
      "validation Loss: 0.0442 Acc: 0.9790\n",
      "2022-01-23 05:52:19.502396\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0626 Acc: 0.9865\n",
      "2022-01-23 05:52:22.014957\n",
      "validation Loss: 0.9621 Acc: 0.8625\n",
      "2022-01-23 05:52:22.408950\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.2915 Acc: 0.9240\n",
      "2022-01-23 05:52:25.365257\n",
      "validation Loss: 0.1497 Acc: 0.9604\n",
      "2022-01-23 05:52:25.746572\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.1286 Acc: 0.9580\n",
      "2022-01-23 05:52:28.281671\n",
      "validation Loss: 0.1264 Acc: 0.9674\n",
      "2022-01-23 05:52:28.645100\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0719 Acc: 0.9780\n",
      "2022-01-23 05:52:31.624692\n",
      "validation Loss: 0.1157 Acc: 0.9697\n",
      "2022-01-23 05:52:32.053876\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0397 Acc: 0.9880\n",
      "2022-01-23 05:52:34.784874\n",
      "validation Loss: 0.0458 Acc: 0.9837\n",
      "2022-01-23 05:52:35.148325\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0511 Acc: 0.9860\n",
      "2022-01-23 05:52:37.698043\n",
      "validation Loss: 0.2505 Acc: 0.9394\n",
      "2022-01-23 05:52:38.147335\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0958 Acc: 0.9660\n",
      "2022-01-23 05:52:40.809977\n",
      "validation Loss: 0.0798 Acc: 0.9720\n",
      "2022-01-23 05:52:41.174560\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0225 Acc: 0.9940\n",
      "2022-01-23 05:52:42.562287\n",
      "validation Loss: 0.0527 Acc: 0.9814\n",
      "2022-01-23 05:52:43.137471\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0679 Acc: 0.9810\n",
      "2022-01-23 05:52:45.604007\n",
      "validation Loss: 0.1186 Acc: 0.9674\n",
      "2022-01-23 05:52:46.021849\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0754 Acc: 0.9780\n",
      "2022-01-23 05:52:48.507610\n",
      "validation Loss: 0.1573 Acc: 0.9627\n",
      "2022-01-23 05:52:49.001821\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0259 Acc: 0.9910\n",
      "2022-01-23 05:52:51.688557\n",
      "validation Loss: 0.0850 Acc: 0.9767\n",
      "2022-01-23 05:52:52.154770\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0246 Acc: 0.9940\n",
      "2022-01-23 05:52:54.705095\n",
      "validation Loss: 0.0696 Acc: 0.9860\n",
      "2022-01-23 05:52:55.069881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0045 Acc: 0.9985\n",
      "2022-01-23 05:52:57.561423\n",
      "validation Loss: 0.0666 Acc: 0.9814\n",
      "2022-01-23 05:52:58.040537\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0009 Acc: 1.0000\n",
      "2022-01-23 05:53:00.537552\n",
      "validation Loss: 0.0665 Acc: 0.9860\n",
      "2022-01-23 05:53:01.018881\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "2022-01-23 05:53:03.636803\n",
      "validation Loss: 0.0639 Acc: 0.9814\n",
      "2022-01-23 05:53:03.980012\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "2022-01-23 05:53:06.466784\n",
      "validation Loss: 0.0626 Acc: 0.9790\n",
      "2022-01-23 05:53:06.889023\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "2022-01-23 05:53:09.516137\n",
      "validation Loss: 0.0610 Acc: 0.9837\n",
      "2022-01-23 05:53:10.054766\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:53:12.740255\n",
      "validation Loss: 0.0597 Acc: 0.9860\n",
      "2022-01-23 05:53:13.142170\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:53:15.984041\n",
      "validation Loss: 0.0719 Acc: 0.9837\n",
      "2022-01-23 05:53:16.342722\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:53:19.181594\n",
      "validation Loss: 0.0542 Acc: 0.9860\n",
      "2022-01-23 05:53:19.587741\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "2022-01-23 05:53:22.743515\n",
      "validation Loss: 0.0596 Acc: 0.9814\n",
      "2022-01-23 05:53:23.208974\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:25.899666\n",
      "validation Loss: 0.0653 Acc: 0.9814\n",
      "2022-01-23 05:53:26.279220\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:28.794512\n",
      "validation Loss: 0.0747 Acc: 0.9814\n",
      "2022-01-23 05:53:29.289552\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:32.025357\n",
      "validation Loss: 0.0725 Acc: 0.9837\n",
      "2022-01-23 05:53:32.524540\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:35.056265\n",
      "validation Loss: 0.0800 Acc: 0.9837\n",
      "2022-01-23 05:53:35.414026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:38.102998\n",
      "validation Loss: 0.0847 Acc: 0.9837\n",
      "2022-01-23 05:53:38.450943\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:41.132159\n",
      "validation Loss: 0.0892 Acc: 0.9837\n",
      "2022-01-23 05:53:41.649191\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:44.198139\n",
      "validation Loss: 0.0923 Acc: 0.9837\n",
      "2022-01-23 05:53:44.556948\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:47.033608\n",
      "validation Loss: 0.0979 Acc: 0.9837\n",
      "2022-01-23 05:53:47.409032\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "2022-01-23 05:53:49.867711\n",
      "validation Loss: 0.1038 Acc: 0.9814\n",
      "2022-01-23 05:53:50.233384\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:53:52.778937\n",
      "validation Loss: 0.1070 Acc: 0.9814\n",
      "2022-01-23 05:53:53.133935\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:53:55.682114\n",
      "validation Loss: 0.1109 Acc: 0.9814\n",
      "2022-01-23 05:53:56.085840\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:53:58.558495\n",
      "validation Loss: 0.1147 Acc: 0.9814\n",
      "2022-01-23 05:53:58.948030\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:01.580329\n",
      "validation Loss: 0.1182 Acc: 0.9814\n",
      "2022-01-23 05:54:01.922346\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:04.325682\n",
      "validation Loss: 0.1233 Acc: 0.9814\n",
      "2022-01-23 05:54:04.763851\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:07.170420\n",
      "validation Loss: 0.1282 Acc: 0.9814\n",
      "2022-01-23 05:54:07.521870\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:09.936963\n",
      "validation Loss: 0.1311 Acc: 0.9814\n",
      "2022-01-23 05:54:10.298502\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:12.866954\n",
      "validation Loss: 0.1359 Acc: 0.9814\n",
      "2022-01-23 05:54:13.275026\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:15.748004\n",
      "validation Loss: 0.1401 Acc: 0.9814\n",
      "2022-01-23 05:54:16.087524\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:18.550536\n",
      "validation Loss: 0.1438 Acc: 0.9814\n",
      "2022-01-23 05:54:18.878071\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:20.534169\n",
      "validation Loss: 0.1463 Acc: 0.9790\n",
      "2022-01-23 05:54:20.887183\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:23.341771\n",
      "validation Loss: 0.1522 Acc: 0.9767\n",
      "2022-01-23 05:54:23.720657\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:26.429466\n",
      "validation Loss: 0.1554 Acc: 0.9767\n",
      "2022-01-23 05:54:26.872871\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:29.644130\n",
      "validation Loss: 0.1603 Acc: 0.9767\n",
      "2022-01-23 05:54:30.080774\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:32.831758\n",
      "validation Loss: 0.1630 Acc: 0.9767\n",
      "2022-01-23 05:54:33.200644\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:35.840505\n",
      "validation Loss: 0.1675 Acc: 0.9767\n",
      "2022-01-23 05:54:36.235425\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:38.726654\n",
      "validation Loss: 0.1710 Acc: 0.9767\n",
      "2022-01-23 05:54:39.070756\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:41.717870\n",
      "validation Loss: 0.1766 Acc: 0.9767\n",
      "2022-01-23 05:54:42.071035\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:44.672538\n",
      "validation Loss: 0.1800 Acc: 0.9767\n",
      "2022-01-23 05:54:45.028735\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:47.542835\n",
      "validation Loss: 0.1820 Acc: 0.9767\n",
      "2022-01-23 05:54:47.897361\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:49.455376\n",
      "validation Loss: 0.1869 Acc: 0.9767\n",
      "2022-01-23 05:54:49.842693\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:52.310185\n",
      "validation Loss: 0.1892 Acc: 0.9767\n",
      "2022-01-23 05:54:52.723376\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:55.388493\n",
      "validation Loss: 0.1934 Acc: 0.9767\n",
      "2022-01-23 05:54:55.760137\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:54:58.221761\n",
      "validation Loss: 0.1975 Acc: 0.9767\n",
      "2022-01-23 05:54:58.582281\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:01.111349\n",
      "validation Loss: 0.2014 Acc: 0.9767\n",
      "2022-01-23 05:55:01.448079\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:04.034726\n",
      "validation Loss: 0.2039 Acc: 0.9767\n",
      "2022-01-23 05:55:04.554923\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:07.128590\n",
      "validation Loss: 0.2086 Acc: 0.9767\n",
      "2022-01-23 05:55:07.491970\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:09.972527\n",
      "validation Loss: 0.2113 Acc: 0.9744\n",
      "2022-01-23 05:55:10.360915\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:13.102121\n",
      "validation Loss: 0.2148 Acc: 0.9744\n",
      "2022-01-23 05:55:13.625962\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:16.119476\n",
      "validation Loss: 0.2181 Acc: 0.9744\n",
      "2022-01-23 05:55:16.472133\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:19.040590\n",
      "validation Loss: 0.2212 Acc: 0.9744\n",
      "2022-01-23 05:55:19.389052\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:21.951230\n",
      "validation Loss: 0.2251 Acc: 0.9744\n",
      "2022-01-23 05:55:22.293649\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:24.896146\n",
      "validation Loss: 0.2283 Acc: 0.9744\n",
      "2022-01-23 05:55:25.434089\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:28.005412\n",
      "validation Loss: 0.2320 Acc: 0.9744\n",
      "2022-01-23 05:55:28.471337\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:30.022954\n",
      "validation Loss: 0.2352 Acc: 0.9744\n",
      "2022-01-23 05:55:30.421452\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:33.080405\n",
      "validation Loss: 0.2393 Acc: 0.9744\n",
      "2022-01-23 05:55:33.566312\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:36.300306\n",
      "validation Loss: 0.2416 Acc: 0.9744\n",
      "2022-01-23 05:55:36.849772\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:39.337180\n",
      "validation Loss: 0.2445 Acc: 0.9744\n",
      "2022-01-23 05:55:39.670417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:42.165572\n",
      "validation Loss: 0.2471 Acc: 0.9744\n",
      "2022-01-23 05:55:42.544197\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:44.097229\n",
      "validation Loss: 0.2506 Acc: 0.9744\n",
      "2022-01-23 05:55:44.445711\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:46.987452\n",
      "validation Loss: 0.2544 Acc: 0.9744\n",
      "2022-01-23 05:55:47.329289\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "Learning Rate: 0.02\n",
      "------------------------------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "2022-01-23 05:55:49.821362\n",
      "validation Loss: 0.2579 Acc: 0.9744\n",
      "2022-01-23 05:55:50.168844\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Best Val Acc: 0.9860\n",
      "Accuracy of the network on the 429 test samples: 99.3006993006993\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:b6npx7v0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27559... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>▁▅▆▇▇▇███</td></tr><tr><td>accuracy_train</td><td>▁▆▇▇██▇█████▇███████████████████████████</td></tr><tr><td>accuracy_validation</td><td>▁▅▆▇▅▇▆▇▇▇██▇▆████████████████████▇▇▇▇▇▇</td></tr><tr><td>loss_train</td><td>█▃▂▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_validation</td><td>█▄▃▂▄▂▄▂▂▂▁▁▂▄▁▂▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_para</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_test</td><td>0.99301</td></tr><tr><td>accuracy_train</td><td>1.0</td></tr><tr><td>accuracy_validation</td><td>0.97436</td></tr><tr><td>best_test_accuracy</td><td>0.99301</td></tr><tr><td>best_val_accuracy</td><td>0.98601</td></tr><tr><td>best_val_loss</td><td>0.05417</td></tr><tr><td>loss_train</td><td>0.0</td></tr><tr><td>loss_validation</td><td>0.25795</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>num_para</td><td>7804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">LSTM_development</strong>: <a href=\"https://wandb.ai/hangl/CharTrajectories/runs/b6npx7v0\" target=\"_blank\">https://wandb.ai/hangl/CharTrajectories/runs/b6npx7v0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220123_055044-b6npx7v0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:b6npx7v0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hangl/CharTrajectories/runs/2yoai2f1\" target=\"_blank\">LSTM_development</a></strong> to <a href=\"https://wandb.ai/hangl/CharTrajectories\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0}\n",
      "Number of parameters: 7804\n",
      "GPU's available: 1\n",
      "WARNING! The model exists in directory and will be overwritten\n",
      "{'batch_size': 32, 'comment': None, 'dataset': 'CharTrajectories', 'device': 'cuda:0', 'drop_rate': 0.3, 'epochs': 100, 'gamma': 1, 'gpu_id': '3', 'lr': 0.01, 'model': 'LSTM_development', 'n_hidden1': 14, 'n_hidden2': 14, 'optimizer': 'Adam', 'param': 'real_symp', 'patience': 50, 'pretrained': False, 'scheduler': 'exponential', 'seed': 0, 'train': True, 'weight_decay': 0.0, 'path': 'CharTrajectories/models/CharTrajectories_model_LSTM_development_param_real_symp_nhid1_14_nhid2_14_droprate_0.3_gamma_1_lr_0.01_comment_None.pt'}\n",
      "2022-01-23 05:56:00.201788\n",
      "LSTM_development(\n",
      "  (rnn): LSTM(4, 14, batch_first=True)\n",
      "  (development): development_layer(\n",
      "    (projection): projection(\n",
      "      (param_map): real_symp()\n",
      "    )\n",
      "  )\n",
      "  (fc2_2): Linear(in_features=196, out_features=20, bias=True)\n",
      ")\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 1.2292 Acc: 0.6205\n",
      "2022-01-23 05:56:02.605574\n",
      "validation Loss: 0.4167 Acc: 0.8671\n",
      "2022-01-23 05:56:02.953839\n",
      "Accuracy of the network on the 429 test samples: 87.41258741258741\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.4284 Acc: 0.8750\n",
      "2022-01-23 05:56:05.714256\n",
      "validation Loss: 0.3144 Acc: 0.9068\n",
      "2022-01-23 05:56:06.196053\n",
      "Accuracy of the network on the 429 test samples: 93.00699300699301\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1855 Acc: 0.9405\n",
      "2022-01-23 05:56:09.031589\n",
      "validation Loss: 0.2072 Acc: 0.9207\n",
      "2022-01-23 05:56:09.476604\n",
      "Accuracy of the network on the 429 test samples: 94.17249417249417\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1783 Acc: 0.9405\n",
      "2022-01-23 05:56:12.399568\n",
      "validation Loss: 0.1707 Acc: 0.9417\n",
      "2022-01-23 05:56:12.737400\n",
      "Accuracy of the network on the 429 test samples: 94.63869463869464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1420 Acc: 0.9545\n",
      "2022-01-23 05:56:15.745315\n",
      "validation Loss: 0.2745 Acc: 0.9417\n",
      "2022-01-23 05:56:16.182905\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1343 Acc: 0.9560\n",
      "2022-01-23 05:56:18.757307\n",
      "validation Loss: 0.1161 Acc: 0.9650\n",
      "2022-01-23 05:56:19.106491\n",
      "Accuracy of the network on the 429 test samples: 96.73659673659674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1129 Acc: 0.9625\n",
      "2022-01-23 05:56:21.943497\n",
      "validation Loss: 0.1803 Acc: 0.9301\n",
      "2022-01-23 05:56:22.285582\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0941 Acc: 0.9700\n",
      "2022-01-23 05:56:24.800633\n",
      "validation Loss: 0.1162 Acc: 0.9604\n",
      "2022-01-23 05:56:25.156051\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0804 Acc: 0.9735\n",
      "2022-01-23 05:56:27.655719\n",
      "validation Loss: 0.0842 Acc: 0.9720\n",
      "2022-01-23 05:56:28.014677\n",
      "Accuracy of the network on the 429 test samples: 97.2027972027972\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0554 Acc: 0.9810\n",
      "2022-01-23 05:56:30.999142\n",
      "validation Loss: 0.1171 Acc: 0.9487\n",
      "2022-01-23 05:56:31.380926\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0737 Acc: 0.9755\n",
      "2022-01-23 05:56:33.857109\n",
      "validation Loss: 0.0681 Acc: 0.9744\n",
      "2022-01-23 05:56:34.239609\n",
      "Accuracy of the network on the 429 test samples: 98.36829836829837\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0782 Acc: 0.9775\n",
      "2022-01-23 05:56:37.087668\n",
      "validation Loss: 0.1945 Acc: 0.9417\n",
      "2022-01-23 05:56:37.429553\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0707 Acc: 0.9755\n",
      "2022-01-23 05:56:39.892723\n",
      "validation Loss: 0.1120 Acc: 0.9627\n",
      "2022-01-23 05:56:40.290566\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0509 Acc: 0.9825\n",
      "2022-01-23 05:56:43.124872\n",
      "validation Loss: 0.0729 Acc: 0.9697\n",
      "2022-01-23 05:56:43.483860\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0794 Acc: 0.9740\n",
      "2022-01-23 05:56:46.007201\n",
      "validation Loss: 0.1430 Acc: 0.9604\n",
      "2022-01-23 05:56:46.509462\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0798 Acc: 0.9760\n",
      "2022-01-23 05:56:49.065955\n",
      "validation Loss: 0.1261 Acc: 0.9627\n",
      "2022-01-23 05:56:49.426266\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0660 Acc: 0.9800\n",
      "2022-01-23 05:56:51.915776\n",
      "validation Loss: 0.0919 Acc: 0.9674\n",
      "2022-01-23 05:56:52.298419\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0742 Acc: 0.9750\n",
      "2022-01-23 05:56:54.823295\n",
      "validation Loss: 0.1405 Acc: 0.9627\n",
      "2022-01-23 05:56:55.267496\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0728 Acc: 0.9780\n",
      "2022-01-23 05:56:57.921874\n",
      "validation Loss: 0.1281 Acc: 0.9580\n",
      "2022-01-23 05:56:58.331206\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0455 Acc: 0.9825\n",
      "2022-01-23 05:57:01.056747\n",
      "validation Loss: 0.0689 Acc: 0.9767\n",
      "2022-01-23 05:57:01.471098\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0222 Acc: 0.9930\n",
      "2022-01-23 05:57:04.485734\n",
      "validation Loss: 0.0570 Acc: 0.9837\n",
      "2022-01-23 05:57:04.829349\n",
      "Accuracy of the network on the 429 test samples: 97.9020979020979\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0213 Acc: 0.9940\n",
      "2022-01-23 05:57:07.822179\n",
      "validation Loss: 0.0698 Acc: 0.9744\n",
      "2022-01-23 05:57:08.179464\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0439 Acc: 0.9880\n",
      "2022-01-23 05:57:10.753939\n",
      "validation Loss: 0.1312 Acc: 0.9604\n",
      "2022-01-23 05:57:11.102310\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0619 Acc: 0.9845\n",
      "2022-01-23 05:57:13.629512\n",
      "validation Loss: 0.1120 Acc: 0.9580\n",
      "2022-01-23 05:57:13.973639\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1409 Acc: 0.9605\n",
      "2022-01-23 05:57:16.599331\n",
      "validation Loss: 0.1420 Acc: 0.9580\n",
      "2022-01-23 05:57:16.953340\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0503 Acc: 0.9800\n",
      "2022-01-23 05:57:18.429899\n",
      "validation Loss: 0.1335 Acc: 0.9674\n",
      "2022-01-23 05:57:18.965219\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0211 Acc: 0.9915\n",
      "2022-01-23 05:57:21.553069\n",
      "validation Loss: 0.1094 Acc: 0.9720\n",
      "2022-01-23 05:57:21.995151\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0514 Acc: 0.9845\n",
      "2022-01-23 05:57:24.537184\n",
      "validation Loss: 0.1802 Acc: 0.9417\n",
      "2022-01-23 05:57:24.896015\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0421 Acc: 0.9865\n",
      "2022-01-23 05:57:27.378458\n",
      "validation Loss: 0.1597 Acc: 0.9534\n",
      "2022-01-23 05:57:27.862853\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0249 Acc: 0.9910\n",
      "2022-01-23 05:57:30.326588\n",
      "validation Loss: 0.0910 Acc: 0.9720\n",
      "2022-01-23 05:57:30.906148\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0434 Acc: 0.9875\n",
      "2022-01-23 05:57:33.412224\n",
      "validation Loss: 0.2370 Acc: 0.9371\n",
      "2022-01-23 05:57:33.756773\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0564 Acc: 0.9785\n",
      "2022-01-23 05:57:36.319010\n",
      "validation Loss: 0.1635 Acc: 0.9371\n",
      "2022-01-23 05:57:36.668966\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0742 Acc: 0.9770\n",
      "2022-01-23 05:57:39.209677\n",
      "validation Loss: 0.0980 Acc: 0.9744\n",
      "2022-01-23 05:57:39.650715\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0328 Acc: 0.9890\n",
      "2022-01-23 05:57:42.116754\n",
      "validation Loss: 0.1472 Acc: 0.9464\n",
      "2022-01-23 05:57:42.458125\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0582 Acc: 0.9825\n",
      "2022-01-23 05:57:44.948049\n",
      "validation Loss: 0.0992 Acc: 0.9674\n",
      "2022-01-23 05:57:45.356226\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0243 Acc: 0.9915\n",
      "2022-01-23 05:57:47.878333\n",
      "validation Loss: 0.1328 Acc: 0.9674\n",
      "2022-01-23 05:57:48.274081\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0382 Acc: 0.9880\n",
      "2022-01-23 05:57:50.775943\n",
      "validation Loss: 0.0625 Acc: 0.9767\n",
      "2022-01-23 05:57:51.131674\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0173 Acc: 0.9955\n",
      "2022-01-23 05:57:53.587300\n",
      "validation Loss: 0.1402 Acc: 0.9744\n",
      "2022-01-23 05:57:53.955141\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0111 Acc: 0.9965\n",
      "2022-01-23 05:57:56.436417\n",
      "validation Loss: 0.1103 Acc: 0.9744\n",
      "2022-01-23 05:57:56.857482\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0231 Acc: 0.9910\n",
      "2022-01-23 05:57:59.477123\n",
      "validation Loss: 0.0997 Acc: 0.9744\n",
      "2022-01-23 05:57:59.909762\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0172 Acc: 0.9950\n",
      "2022-01-23 05:58:02.582165\n",
      "validation Loss: 0.1223 Acc: 0.9767\n",
      "2022-01-23 05:58:02.967322\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0688 Acc: 0.9790\n",
      "2022-01-23 05:58:05.582390\n",
      "validation Loss: 0.0950 Acc: 0.9674\n",
      "2022-01-23 05:58:06.121393\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.1691 Acc: 0.9560\n",
      "2022-01-23 05:58:08.777904\n",
      "validation Loss: 0.1801 Acc: 0.9510\n",
      "2022-01-23 05:58:09.133543\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0574 Acc: 0.9790\n",
      "2022-01-23 05:58:11.641942\n",
      "validation Loss: 0.1170 Acc: 0.9674\n",
      "2022-01-23 05:58:11.983543\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0574 Acc: 0.9795\n",
      "2022-01-23 05:58:14.493388\n",
      "validation Loss: 0.0582 Acc: 0.9767\n",
      "2022-01-23 05:58:14.846250\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0441 Acc: 0.9850\n",
      "2022-01-23 05:58:17.451309\n",
      "validation Loss: 0.0840 Acc: 0.9697\n",
      "2022-01-23 05:58:17.806021\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0334 Acc: 0.9910\n",
      "2022-01-23 05:58:20.258987\n",
      "validation Loss: 0.0631 Acc: 0.9814\n",
      "2022-01-23 05:58:20.615925\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0211 Acc: 0.9940\n",
      "2022-01-23 05:58:23.095428\n",
      "validation Loss: 0.0598 Acc: 0.9790\n",
      "2022-01-23 05:58:23.458382\n",
      "validation and schedulaer\n",
      "\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "Learning Rate: 0.01\n",
      "------------------------------\n",
      "train Loss: 0.0097 Acc: 0.9975\n",
      "2022-01-23 05:58:26.005341\n"
     ]
    }
   ],
   "source": [
    "lr_list = [2e-2,1e-2,5e-3,1e-3,5e-4,1e-4]\n",
    "df_lstm_dev = get_lr_acc(lr_list=lr_list,models=['lstm_dev'],params = ['SO','Sp'],runs = 5)\n",
    "df_lstm = get_lr_acc(lr_list=lr_list,models=['lstm'],params = ['s'],runs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2 = pd.concat([df_lstm_dev,df_lstm])\n",
    "# rename model name in df\n",
    "dfs2.loc[(dfs1.model == 'lstm_dev_SO'),'model']='LSTM+DEV(SO)'\n",
    "dfs2.loc[(dfs1.model == 'lstm_dev_Sp'),'model']='LSTM+DEV(Sp)'\n",
    "dfs2.loc[(dfs1.model == 'lstm_s'),'model']='LSTM'\n",
    "dfs2.to_csv('CharTrajectories/notebooks/acc_vs_lr.csv')#save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = pd.read_csv('CharTrajectories/notebooks/training_process.csv')\n",
    "dfs2 = pd.read_csv('CharTrajectories/notebooks/acc_vs_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(11,6)})\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "df_plot = dfs1.loc[(dfs1['training time / seconds'] <= 500)]\n",
    "#plt.figure()\n",
    "sns.lineplot(data=df_plot, x=\"training time / seconds\", y=\"validation loss\",hue='model',ax = axes[0])\n",
    "sns.boxplot(ax = axes[1],data=dfs2, x=\"learning rate\", y=\"test accuracy\",hue='model',linewidth=0.5,saturation=0.6)\n",
    "plt.tight_layout()\n",
    "fig.savefig('CharTrajectories/notebooks/CT_analysis.png',dpi=350)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = dfs1.loc[(dfs1['training time / seconds'] <= 500)]\n",
    "plt.figure()\n",
    "sns.lineplot(data=df_plot, x=\"training time / seconds\", y=\"validation accuracy\",hue='model')\n",
    "plt.tight_layout()\n",
    "plt.plot()\n",
    "plt.savefig('CharTrajectories/notebooks/CT_val_acc.png',dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "development"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
